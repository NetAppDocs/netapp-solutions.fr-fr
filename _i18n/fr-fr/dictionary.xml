<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">Ce cas d'utilisation est basé sur un client réseau de télévision. Le client souhaitait migrer les fichiers de sauvegarde RMAN (Oracle Recovery Manager) vers le cloud et exécuter l'application Oracle E-Business Suite (EBS) à l'aide du logiciel Azure NetApp Files with Pacemaker. Il souhaitait également migrer ses fichiers de sauvegarde de base de données vers un stockage cloud à la demande et transférer des fichiers volumineux (de 25 à 50 Go chacun) vers Azure.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">Utilisation du Data Mover XCP pour migrer des fichiers volumineux</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">Précédent : utilisation de XCP Data Mover pour migrer des millions de petits fichiers vers un système de stockage flexible.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">La figure suivante illustre la migration des données entre une infrastructure sur site et un système Azure NetApp Files pour des fichiers volumineux.</block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">Solution NetApp XCP Data Mover : du site au cloud</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">Pour plus d'informations, reportez-vous à la section<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> blog.</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">Suivant : fichiers en double.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">La migration a des phases différentes à suivre pour une meilleure planification et une meilleure finalisation de la migration. Pour migrer des données d'un stockage NAS tiers ou d'un stockage NAS directement attaché à l'aide de NetApp XCP, suivez les instructions de migration fournies dans cette section.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">Flux de travail de la migration</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">Précédent : NetApp XCP.</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">La figure suivante illustre le workflow de migration d'un NAS vers un NAS NetApp.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Erreur : image graphique manquante</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">Sur site</block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">Le workflow de migration d'un NAS vers un système NetApp NAS comprend les étapes suivantes :</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">Découvrez les partages et les données NAS.</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">Scannez les données et produisez un rapport pour trouver la disposition des données.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">Créez une référence en exécutant la commande XCP Copy. Pour des migrations plus rapides, sélectionnez plus d'instances XCP et divisez la charge de travail au niveau du sous-dossier pour lancer des tâches de migration parallèle.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">Pour les mises à jour incrémentielles, utilisez XCP sync jusqu'à ce que le taux de modification soit faible pour la fenêtre de mise en service.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">Marquer la source en lecture seule pour effectuer une synchronisation finale en exécutant la commande XCP sync pour terminer la migration.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">Pour vérifier que les données transférées sont correctes, comparez la source et la destination en exécutant le<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> commande.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="section-title">Le cloud</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">Pour le cloud, vous pouvez suivre un workflow de migration sur site similaire si la connectivité entre le site et le cloud est une connexion directe (AWS), ExpressRoute (Azure) ou une interconnexion cloud (GCP).</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">La figure suivante illustre le workflow de migration des systèmes sur site vers le cloud.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">En l'absence de connexion Internet directe entre le site et le cloud, vous devez transférer les données de sur site vers le cloud via une méthode de transport des données hors ligne telle que le camion. Chaque fournisseur de services clouds dispose d'une méthode différente et d'une terminologie propre pour déplacer des données vers son data Center.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">La figure suivante décrit la solution de déplacement des données pour les environnements sur site vers Azure sans ExpressRoute.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">Vous pouvez ainsi utiliser une architecture similaire avec les composants respectifs des différents fournisseurs de services cloud.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">Next : analytique des fichiers.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">L'interface graphique d'analytique des fichiers XCP de NetApp permet d'exécuter des analyses du système de fichiers en utilisant XCP au niveau du back-end et de visualiser des statistiques, telles que des graphiques et des vues, pour tout système de fichiers NAS (NFS, SMB).</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">Analytique des fichiers</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">Précédent : flux de travail de migration.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">L'interface graphique d'analytique des fichiers XCP de NetApp permet d'exécuter des analyses du système de fichiers en utilisant XCP au niveau du back-end et de visualiser des statistiques, telles que des graphiques et des vues, pour tout système de fichiers NAS (NFS, SMB). À partir de 1.6, XCP peut être exécuté en tant que service à l'aide d'étapes de déploiement simples en utilisant les options Configure et systemctl. L'option XCP Configure vous guide pour installer et configurer Postgres et un serveur Web ainsi que pour collecter des informations d'identification. L'option systemctl exécute XCP en tant que service pour les communications API REST à partir de l'interface utilisateur graphique.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">La figure suivante illustre le flux d'analytique du fichier XCP.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6 offre des fonctionnalités d'analytique des fichiers ouverts et d'amélioration de l'infrastructure</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">Pour plus d'informations sur l'architecture de haut niveau de l'analytique des fichiers XCP, des vues de tableau de bord basées sur l'interface graphique, telles que les statistiques et les détails de la vue de distribution de fichiers, consultez le bulletin de blog<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">Il existe une interface graphique limitée dans XCP 1.6 pour les graphiques personnalisés. Pour créer les graphiques requis, vous pouvez utiliser l'interface de ligne de commandes pour exécuter le<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> commande de numérisation avec filtres correspondants. Voir les exemples suivants.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">Générez une liste de fichiers modifiés au-delà d'un an en utilisant<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block> et le<block ref="af7e4e4bdf56fd6022afd2b0cf443794" prefix=" " category="inline-code"></block> filtrer avec l'espace utilisé.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">Trouvez l'espace utilisé par les fichiers qui ont plus d'un an.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">Trouvez la taille totale et la vue graphique des données modifiées il y a plus d'un an.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">Le rapport suivant est un exemple personnalisé d'analyse des fichiers qui ont été modifiés il y a plus d'un an.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">Ensuite, étapes du déploiement.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">Cette section fournit certains des paramètres de réglage qui aident à améliorer la performance des opérations XCP.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">Réglage des performances</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">Précédent : instructions de dimensionnement.</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">Cette section fournit certains paramètres d'ajustement qui aident à améliorer la performance des opérations XCP :</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">Pour une meilleure évolutivité et une meilleure distribution de la charge de travail sur plusieurs instances XCP, divisez les sous-dossiers de chaque instance XCP pour la migration et le transfert de données.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">XCP peut utiliser des ressources CPU maximales, plus il y a de cœurs de processeur, plus les performances sont élevées. Par conséquent, vous devriez avoir plus de processeurs dans le serveur XCP. Nous avons testé 128 Go de RAM et 48x de processeurs cœurs, ce qui nous a permis de bénéficier de performances supérieures à 8 fois CPU et de 8 Go de RAM.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">Copie XCP avec<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> L'option est basée sur le nombre de CPU. Le nombre par défaut de threads parallèles (sept) est parfois suffisant pour la plupart des opérations de transfert et de migration de données XCP. Pour XCP Windows par défaut, le nombre de processus parallèles est égal au nombre de CPU. Le nombre maximum de<block ref="7c497b25395c5c56889e20e941e5e84d" prefix=" " category="inline-code"></block> l'option doit être inférieure ou égale au nombre de cœurs.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">Le 10GbE est un bon début pour le transfert de données. Nos tests ont été réalisés avec 25 GbE et 100 GbE, qui constituent un meilleur transfert de données et sont recommandés pour le transfert de données de grande taille.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Pour Azure NetApp Files, les performances varient selon le niveau de service. Pour plus d'informations, consultez le tableau suivant présentant les niveaux de service et les performances des disques Azure NetApp Files.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">Niveau de service</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">Premium</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">Ultra</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">Débit</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16 Mbit/s/téraoctet (To)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64 Mbit/s/To</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128 Mo/To</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">Types de workloads</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">Partages de fichiers à usage général, messagerie électronique et web</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">Gestion des bâtiments, bases de données et applications</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">Applications sensibles à la latence</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">Performances expliquées</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">Performances standard : 4 1,000 IOPS par To (16 000 E/S) et 16 Mbit/s/To</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">Performances Premium : 4 4,000 IOPS par To (16 000 E/S) et 64 Mbit/s/To</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">Performances extrêmes : 8,000 000 IOPS par To (16 000 E/S) et 128 Mo/To</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">Vous devez choisir le niveau de service qui convient en fonction du débit et des types de workloads. La plupart des clients commencent par le niveau Premium et modifient le niveau de service en fonction du workload.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">Suivant : scénarios client.</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">Ce cas d'utilisation est basé sur le plus grand client du secteur touristique NetApp dans le domaine de la migration de millions de fichiers sur site vers le cloud.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">Utilisation de XCP Data Mover pour migrer des millions de petits fichiers vers un système de stockage flexible</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">Précédent : l'informatique hautes performances jusqu'à ONTAP NFS.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">Ce cas d'utilisation repose sur le plus grand client du secteur touristique de NetApp pour la migration de données d'un site vers le cloud. Les entreprises de COVID-19 ont réduit la demande dans le secteur des voyages, ce qui leur permet de réduire leurs dépenses d'investissement dans un stockage haut de gamme pour l'application de tarification à la demande. Avec un SLA très serré, il est possible de migrer des millions de petits fichiers vers le cloud.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">La figure suivante décrit la migration des données entre des environnements sur site et Azure NetApp Files pour les fichiers de petite taille.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">Suivant : utilisation du Data Mover XCP pour migrer des fichiers volumineux.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">Ce cas d'utilisation repose sur la démonstration de faisabilité financière la plus importante que nous ayons effectuée auprès de nos clients. À l'origine, nous avons utilisé le module d'analytique sur place NetApp (NIPAM) pour transférer les données d'analytique vers NetApp ONTAP ai. Toutefois, en raison des améliorations récentes et des performances améliorées de NetApp XCP et de l'approche unique de la solution de transfert de données NetApp, nous relons la migration de données à l'aide de NetApp XCP.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">Data Lake à ONTAP NFS</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">Précédent : scénarios client.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">Défis et besoins des clients</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">Voici les défis et les exigences des clients à prendre en compte :</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">Les clients disposent de différents types de données, qu'il s'agisse de données structurées, non structurées ou semi-structurées, de journaux et des données machine à machine dans des data lakes. Les systèmes d'IA nécessitent tous ces types de données pour les opérations de prédiction. Le traitement des données est complexe lorsque les données se trouvent dans un système de fichiers natif du data Lake.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">L'architecture d'IA du client n'accède pas aux données des systèmes HDFS (Hadoop Distributed File System) et HCFS (Hadoop Distributed File System). Les données ne sont donc pas disponibles pour les opérations d'IA. L'IA requiert des données dans un format de système de fichiers compréhensible, tel que NFS.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">Des processus spéciaux sont nécessaires pour déplacer les données du data Lake en raison de la grande quantité de données et du débit élevé. De plus, il faut une méthode économique pour les déplacer vers le système d'IA.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Solution de transfert de données</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">Dans cette solution, le système de fichiers MapR (MapR-FS) est créé à partir de disques locaux du cluster MapR. La passerelle NFS de MapR est configurée sur chaque nœud de données avec des adresses IP virtuelles. Le service de serveur de fichiers stocke et gère les données de MapR-FS. NFS Gateway rend les données Map-FS accessibles depuis le client NFS via l'adresse IP virtuelle. Une instance XCP s'exécute sur chaque nœud de données de MapR pour transférer les données du Map NFS Gateway vers NetApp ONTAP NFS NFS. Chaque instance XCP transfère un ensemble spécifique de dossiers source à l'emplacement de destination.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">La figure suivante illustre la solution NetApp de transfert de données pour un cluster de MapR utilisant XCP.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">Utilisation de XCP pour transférer des données d'un Data Lake et de calcul haute performance vers NFS ONTAP</block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">Pour en savoir plus sur les utilisations client, les démonstrations enregistrées et les résultats des tests, consultez le<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">Tr-4732 : analytique Big Data dans l'intelligence artificielle</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">Pour des étapes détaillées sur le transfert des données de MapR-FS vers ONTAP NFS à l'aide de NetApp XCP, voir l'Annexe B de<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">Next : l'informatique hautes performances pour ONTAP NFS.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">Ce document fournit des instructions sur les bonnes pratiques de NetApp XCP et une solution de test basée sur un scénario. Ces bonnes pratiques couvrent le workflow de migration pour les environnements sur site et cloud, l'analytique du système de fichiers, le dépannage et l'ajustement de la performance du XCP.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">Tr-4863 : instructions sur les meilleures pratiques pour NetApp XCP - Data Mover, migration de fichiers et analytique</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">Ce document fournit des instructions sur les bonnes pratiques de NetApp XCP et une solution de test basée sur un scénario. Ces bonnes pratiques couvrent le workflow de migration pour les environnements sur site et cloud, l'analytique du système de fichiers, le dépannage et l'ajustement de la performance de XCP. La section de test-scénario couvre les cas d'utilisation et leurs exigences, la solution NetApp qui utilise XCP et les avantages pour le client.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">Suivant: NetApp XCP.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="doc">Historique des versions</block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Précédent : où trouver des informations supplémentaires.</block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">Version</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">Date</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">Historique des versions du document</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">Version 1.0</block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">Octobre 2020</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">Version initiale.</block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">Cette solution est basée sur un client qui doit copier les données en fonction d'une date précise.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">Analyse et copie de données spécifiques à la date</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">Précédent : fichiers en double.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">Cette solution est basée sur un client qui doit copier les données en fonction d'une date précise. Vérifiez les informations suivantes :</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">Suivant : création d'un fichier CSV à partir d'un partage SMB/CIFS.</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">Cette section fournit des conseils de dépannage pour la migration des données à l'aide de NetApp XCP.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Dépannage</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">Précédent : recommandations et directives sur les meilleures pratiques.</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">Erreur 1 : XCP a échoué avec nfs3 erreur 70 : erreur de descripteur de fichier obsolète dans le xcp.log</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">*Raison et orientation.*</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">Montez le dossier source et vérifiez qu'il existe. S'il n'existe pas ou s'il a été supprimé, vous recevrez un<block ref="00b68e4b07be7b89e91e391a70e312d1" prefix=" " category="inline-code"></block> erreur, dans ce cas, vous pouvez ignorer l'erreur.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">Erreur 2 : le volume de destination NFS de NetApp a de l'espace, mais XCP a échoué avec l'erreur nfs3 28 : aucun espace n'est restant sur le périphérique</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">Vérifiez l'espace du volume de destination NFS en exécutant le<block ref="eff7d5dba32b4da32d9a67a519434d3f" prefix=" " category="inline-code"></block> commander ou vérifier le stockage.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">Vérifier les inodes du contrôleur de stockage.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">Si inode est utilisé, augmentez le nombre d'inodes en exécutant la commande suivante :</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">Suivant : où trouver des informations supplémentaires ?</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP transfère des données à l'aide de multithreads et de fonctionnalités personnalisables. Conçu pour trois utilisations principales : déplacement ou migration des données, analytique du système de fichiers et suppression rapide des arborescences de répertoires.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="doc">NetApp XCP</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">Précédent : introduction.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP transfère des données à l'aide de multithreads et de fonctionnalités personnalisables. Conçu pour trois utilisations principales : déplacement ou migration des données, analytique du système de fichiers et suppression rapide des arborescences de répertoires.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">Déplacement ou migration des données</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP transfère les données de tout NAS vers NAS NetApp. Ce processus comprend quatre opérations principales : numérisation, copie, synchronisation et vérification. Certaines fonctions supplémentaires permettent de surveiller et de transférer les données :</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">*Scan.* fournit une disposition de haut niveau des données NAS et MAPR/HDFS.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">*Copier.* effectue un transfert de données de base.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">*Sync.* effectue le transfert de données incrémentiel.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">*Vérifier.* effectue une vérification approfondie de la cible.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">*Afficher (facultatif).* découvre les partages NAS.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">La figure suivante illustre les opérations de migration des données XCP et de réplication.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">Analytique du système de fichiers</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP vous permet d'identifier, de contrôler et d'analyser des données non structurées afin d'améliorer vos informations exploitables, ce qui constitue une exigence clé pour les clients d'entreprise qui souhaitent exploiter ces informations pour une meilleure planification, la mise en œuvre d'actifs numériques à forte valeur ajoutée et la gouvernance des données via la création de rapports et l'évaluation.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">Les clients qui traitent des données sensibles peuvent utiliser NetApp XCP pour répondre aux questions opérationnelles typiques, comme le suivant :</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">Où se trouvent mes données ?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">Quel volume de données et quels types de fichiers disposons-nous ?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">Quelles données sont utilisées activement et combien sont inactives ?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">La figure suivante illustre la communication d'analytique des fichiers NetApp XCP à partir de l'interface graphique.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">Supprimer</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">Il peut être très difficile pour les équipes chargées du stockage et les charges de travail EDA de nettoyer de grands répertoires, qu'il s'agisse de données obsolètes ou de données de test à nettoyer pour récupérer de l'espace de stockage. XCP fournit une fonctionnalité de suppression rapide qui peut supprimer une arborescence de répertoires complète. La fonction de suppression de NetApp XCP supprime des fichiers et des dossiers d'un chemin NAS donné. Vous pouvez utiliser les filtres de correspondance pour supprimer un ensemble spécifique de fichiers et de dossiers. Pour un grand nombre de fichiers et de dossiers, vous pouvez utiliser l'option forcer, qui ne nécessite pas de confirmation à supprimer.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">Prise en charge de la migration Live Source</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">La prise en charge de la migration Live Source incluse dans XCP 1.7 permet la migration à partir d'une source de données en cours d'utilisation (activité de lecture et d'écriture). XCP quitte les fichiers qui sont utilisés pendant la migration, comme la copie et la synchronisation, et les informations sur les fichiers ignorés sont capturées dans le journal XCP.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">Cette fonctionnalité prend en charge les modifications sur la source, mais ne prend pas en charge les modifications sur la destination. Pendant la migration, la destination ne doit pas être active. La prise en charge de la migration en direct source est uniquement disponible pour les migrations NFS.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">Aucun paramètre spécial n'est requis pour les migrations Live Source.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">Conditions préalables pour XCP</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">Avant de déployer NetApp XCP, les prérequis suivants doivent être respectés :</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">Vérifiez les ports NFS utilisés par le serveur NFS en exécutant la commande suivante :</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">Pour accéder à l'emplacement de l'emplacement où vous exécutez les opérations XCP, comme les instances sur site ou cloud (par exemple, Azure, AWS ou les instances de machine virtuelle Google), ouvrez les ports pare-feu des ports NFS.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">Vérifiez que le port NFS est accessible depuis le serveur XCP en utilisant la commande telnet<block ref="450e3ef5096f09acecd7b33e07b6e190" prefix=" " category="inline-code"></block>. Le port par défaut est 2049. Si votre environnement possède un autre port, utilisez cette adresse IP.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">Pour NFS, vérifiez que les partages sont accessibles à partir du serveur XCP en utilisant le<block ref="3c4a3208b8bf46e9aa41c950ec1a73ba" prefix=" " category="inline-code"></block> commande.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">Augmentez le nombre d'inodes sur le volume de destination à un nombre supérieur au nombre de fichiers (nombre de fichiers) sur les fichiers source.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">Portail de licence XCP de NetApp</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">Téléchargez la licence XCP à partir du<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">Vous devez disposer d'un compte NetApp sur mysupport.netapp.com ou vous pouvez vous inscrire gratuitement.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">Téléchargez la licence et préparez-la.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">Créez un partage NFS sur site pour chaque volume Azure NetApp ou pour le service Cloud Volume Service (niveau de service Premium) dans le cloud pour le catalogue XCP.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">Créez un volume NAS et configurez le partage pour la destination des données.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">Pour plusieurs instances XCP, vous devez disposer d'un ou de plusieurs serveurs ou instances de cloud pour transférer les données de plusieurs dossiers ou fichiers source vers la destination.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">La taille maxdir (par défaut : 308Mo) définit le nombre maximal de fichiers (environ un million) dans un seul dossier. Augmentez la valeur de la taille maxdir pour augmenter le nombre de fichiers. L'augmentation de la valeur a un effet sur les cycles CPU supplémentaires.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">Dans le cloud, NetApp vous recommande de disposer d'ExpressRoute (Azure), de Direct Connect (AWS) ou d'une interconnexion cloud (GCP) entre votre site et le cloud.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">Suivant : workflow de migration.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp a reçu une demande de recherche de fichiers dupliqués à partir d'un seul volume ou de plusieurs volumes. NetApp a fourni la solution suivante.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">Fichiers en double</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">Précédent : utilisation du Data Mover XCP pour migrer des fichiers volumineux.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">Pour un seul volume, lancer les commandes suivantes :</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">Pour plusieurs volumes lancer les commandes suivantes :</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">Suivant : analyse et copie de données spécifiques à la date.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">Cette section fournit le temps approximatif d'exécution des opérations de copie XCP et de synchronisation XCP avec une taille de fichier différente d'un million de fichiers pour NFS.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">Instructions de dimensionnement</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">Précédent : étapes de déploiement.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">Estimation du temps basée sur les tests</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">Les tests des opérations de copie XCP et de synchronisation ont utilisé le même lit de test que celui utilisé pour le déploiement. Un million de fichiers de trois ensembles de 8 Ko, 16 Ko et 1 Mo ont été créés et les modifications ont été effectuées en temps réel. La fonction de synchronisation XCP a effectué les mises à jour incrémentielles différentielles de la source vers la cible au niveau du fichier. L'opération de mise à jour incrémentielle est une ou plusieurs de ces quatre opérations : renommer les fichiers et dossiers existants, ajouter des données aux fichiers existants, supprimer des fichiers et des dossiers et inclure des liens matériels, logiciels et multiliens supplémentaires. À des fins de test, nous avons mis l'accent sur les opérations de renommage, d'ajout, de suppression et de liens. En d'autres termes, les opérations de modification telles que renommer, ajouter et supprimer ont été effectuées à un taux de modification de 10 à 90 % sur un million de fichiers.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">La figure suivante montre les résultats de l'opération de copie XCP.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">La figure suivante montre les résultats des opérations de renommage et de liaison XCP Sync.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">La taille du fichier n'est pas propositionnelle à l'<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> temps de fin pour le transfert des fichiers source renommés ; les graphiques sont linéaires.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">Les types de lien sont des liens souples, des liens rigides et des liens multiples. Les liens logiciels sont considérés comme des fichiers normaux. La taille des fichiers n'est pas pertinente pour le temps de terminer l'opération de synchronisation XCP.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">Les figures suivantes montrent les résultats des opérations d'ajout et de suppression de XCP sync.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">Pour les opérations d'ajout et de suppression, les fichiers volumineux sont plus rapides que les fichiers de petite taille. Le temps nécessaire pour terminer l'opération est linéaire selon le pourcentage d'ajout et de suppression des modifications.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">Comparaison de XCP 1.6.1 à XCP 1.5</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">Par rapport aux versions précédentes, XCP 1.6.3 et 1.7 offre des performances améliorées. La section suivante présente une comparaison des performances de synchronisation entre XCP 1.6.3 et 1.7 pour des tailles de 8 Ko, 16 Ko et 1 Mo de 1 million de fichiers.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">Les figures suivantes montrent les résultats de la performance de synchronisation XCP pour XCP 1.6.3 par rapport à 1.7 (avec une taille de 8 Ko d'un million de fichiers).</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">La figure suivante montre les résultats de la performance de synchronisation XCP pour XCP 1.6.1 par rapport à 1.5 (avec une taille de 16K d'un million de fichiers).</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">La figure suivante montre les résultats de la performance de synchronisation XCP pour XCP 1.6.1 par rapport à 1.5 avec une taille de 1 Mo d'un million de fichiers.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">En moyenne, la performance de XCP 1.7 s'est améliorée sur ou était similaire à XCP 1.6.3 pour le<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> Mise à jour incrémentielle différentielle : opérations de renommage, d'ajout, de liaison et de suppression avec une taille de 1 Mo d'un million de fichiers.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">En fonction de cette validation des performances, NetApp recommande l'utilisation de XCP 1.7 pour la migration de vos données sur site et dans le cloud.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">Suivant : réglage des performances.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">La commande dans cette section « vide » les données au format CSV. Vous pouvez additionner la colonne size pour obtenir la taille totale des données.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">Création d'un fichier CSV à partir d'un partage SMB/CIFS</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">Précédent : analyse par date et copie des données spécifiques.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">La commande suivante « vide » les données au format CSV. Vous pouvez additionner la colonne size pour obtenir la taille totale des données.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">Le résultat doit ressembler à l'exemple suivant :</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">Pour numériser jusqu'à la profondeur de trois sous-répertoires et fournir le résultat dans l'ordre de tri, exécutez le<block ref="cadccce7ea0e7fd5923a57bff135b0f1" prefix=" " category="inline-code"></block> commande et dump la taille à chaque niveau de répertoire jusqu'à la profondeur de trois sous-répertoires.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">Pour trier les informations, videz-les dans un fichier CSV et triez-les.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">Il s'agit d'un rapport personnalisé qui utilise le<block ref="3c8468c40f21d7ea04242771207b5d3e" prefix=" " category="inline-code"></block> commande. Il analyse tous les répertoires et vide le nom du répertoire, le chemin et la taille du répertoire dans un fichier CSV. Vous pouvez trier la colonne taille à partir de la feuille de calcul.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">Suivant : migration des données de 7-mode vers ONTAP.</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Où trouver des informations complémentaires</block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">Précédent : dépannage.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">Pour en savoir plus sur les informations fournies dans ce document, consultez ces documents et/ou sites web :</block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">Blogs NetApp XCP<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">Guide de l'utilisateur NetApp XCP<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">Données d'analytique bigdata vers l'intelligence artificielle : solution de transfert de données pour l'IA<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">Suivant : historique des versions.</block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">Présentation</block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">Précédent : réglage des performances.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">Cette section décrit les scénarios client et leurs architectures.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">Next : du data Lake au protocole ONTAP NFS.</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">Cette section décrit les étapes détaillées de la migration des données de NetApp Data ONTAP sous 7-mode vers ONTAP.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">Migration des données de 7-mode vers ONTAP</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">Précédent : création d'un fichier CSV à partir d'un partage SMB/CIFS.</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">La transition du stockage 7-mode NFSv3 vers ONTAP pour les données NFS</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">Cette section présente la procédure détaillée dans le tableau suivant pour la transition d'une exportation 7-mode NFSv3 source vers un système ONTAP.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp suppose que le volume NFSv3 7-mode source est exporté et monté sur le système client et que XCP est déjà installé sur un système Linux.</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">Vérifier que le système ONTAP cible fonctionne correctement.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">Vérifier qu'au moins un agrégat non racine existe sur le système cible. L'agrégat est normal.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">Si il n'y a pas d'agrégat de données, créez-en un nouveau à l'aide de<block ref="b83f9c30c432b834d5aa4c7b46881164" prefix=" " category="inline-code"></block> commande.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">Créer un SVM (Storage Virtual machine) sur le système cluster cible.</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">Retirer les protocoles FCP, iSCSI, NDMP et CIDS du SVM cible.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">Vérifier que NFS est le protocole autorisé pour ce SVM.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">Créer un nouveau volume de données en lecture-écriture sur le SVM de destination Vérifiez que le style de sécurité, les paramètres de langue et les besoins en capacité correspondent au volume source.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">Créez une LIF de données pour traiter les requêtes des clients NFS.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">Vérifier que le LIF a été créé avec succès.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">Créer une route statique avec le SVM, si nécessaire.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">Vérifiez que la route a été créée avec succès.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">Monter le volume de données NFS cible dans le namespace du SVM.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">Vérifiez que le volume est monté correctement.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">Vous pouvez également spécifier les options de montage du volume (Junction path) avec le<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> commande.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">Démarrer le service NFS sur le SVM cible.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">Vérifiez que le service est démarré et en cours d'exécution.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">Vérifier que l'export policy NFS par défaut a été appliquée au SVM cible.</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">Si besoin est, créer une nouvelle export policy personnalisée pour le SVM cible.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">Vérifiez que la nouvelle export-policy personnalisée a été créée avec succès.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">Modifiez les règles export policy pour autoriser l'accès aux clients NFS.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">Vérifiez que le client est autorisé à accéder au volume.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Connectez-vous au serveur Linux NFS. Créer un point de montage pour le volume exporté NFS.</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">Montez le volume exporté NFSv3 cible à ce point de montage.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">Les volumes NFSv3 doivent être exportés, mais pas nécessairement montés par le serveur NFS. S'ils peuvent être montés, le client hôte XCP Linux monte ces volumes.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">Vérifiez que le point de montage a bien été créé.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">Créez un fichier de test sur le point de montage exporté NFS pour activer l'accès en lecture/écriture.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">Une fois le test de lecture/écriture terminé, supprimez le fichier du point de montage NFS cible.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">Connectez-vous au système client Linux dans lequel XCP est installé. Accédez au chemin d'installation XCP.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">Interrogez les exportations 7-mode NFSv3 source en exécutant le<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Commande sur le système hôte client XCP Linux.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">Scannez les chemins exportés par NFSv3 source et imprimez les statistiques de leur structure de fichiers.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">NetApp recommande de mettre les exportations NFSv3 source en mode lecture seule au cours de xcp<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, et<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> exploitation.</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">Copiez les exports 7-mode NFSv3 source dans les exports NFSv3 sur le système ONTAP cible.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">Une fois la copie terminée, vérifiez que les exportations NFSv3 source et destination ont des données identiques. Exécutez le<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> commande.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">Si<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> recherche les différences entre les données source et de destination, puis l'erreur<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> est signalé dans le résumé. Pour résoudre ce problème, exécutez le<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> commande permettant de copier les modifications de la source vers la destination.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">Avant et pendant la mise en service, exécutez<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> encore. Si la source contient des données nouvelles ou mises à jour, effectuez des mises à jour incrémentielles. Exécutez le<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> commande.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">Pour reprendre une opération de copie interrompue précédemment, exécutez le<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> commande.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">Après<block ref="69f2afc2390cec954f7c208b07212d39" prefix=" " category="inline-code"></block> termine la copie des fichiers, exécution<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> là encore, le stockage source et cible a les mêmes données.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">L'hôte client NFSv3 doit démonter les exportations NFSv3 source provisionnées depuis le stockage 7-mode et monter les exportations NFSv3 cibles depuis ONTAP. La mise en service doit être en panne.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">Transition des copies Snapshot de volume 7-mode vers ONTAP</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">Cette section explique comment migrer une copie NetApp Snapshot NetApp d'un volume 7-mode source vers ONTAP.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp suppose que le volume 7-mode source est exporté et monté sur le système client et que XCP est déjà installé sur un système Linux. Une copie Snapshot est une image instantanée d'un volume qui enregistre les modifications incrémentielles depuis la dernière copie Snapshot. Utilisez le<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> Option avec un système 7-mode comme source.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">*Avertissement :* conserver la copie Snapshot de base. Ne supprimez pas la copie Snapshot de base une fois la copie de base terminée. La copie Snapshot de base est requise pour les opérations de synchronisation ultérieures.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">Création d'un SVM sur le système cluster cible.</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">Supprimer les protocoles FCP, iSCSI, NDMP et CIFS du SVM cible.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">Si nécessaire, créer une route statique avec la SVM.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">Vérifiez que le volume a été monté correctement.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">Vous pouvez également spécifier les options de montage du volume (Junction path) avec le<block ref="4784dd0ffa42c3d1b43b0afd079dfc17" prefix=" " category="inline-code"></block> commande.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">Vérifier que l'export policy NFS par défaut est appliquée au SVM cible.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">Modifiez les règles d'export policy pour autoriser l'accès aux clients NFS sur le système cible.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">Vérifiez que le client a accès au volume cible.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">NetApp recommande de placer les exports source NFSv3 en mode lecture seule pendant<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, et<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> exploitation. Dans<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> opération, vous devez passer<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> avec une valeur correspondante.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">Copiez le snapshot NFSv3 7-mode source (base) vers les exports NFSv3 sur le système ONTAP cible.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">Conservez cette copie Snapshot de base pour des opérations de synchronisation ultérieures.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">Une fois la copie terminée, vérifiez que les exportations NFSv3 source et de destination ont des données identiques. Exécutez le<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> commande.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">Si<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> recherche les différences entre les données source et de destination, puis l'erreur<block ref="dc84cf44b83b105281c2d7846f1ed44f" prefix=" " category="inline-code"></block> commande permettant de copier les modifications de la source vers la destination.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">Avant et pendant la mise en service, exécutez<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> encore. Si la source contient des données nouvelles ou mises à jour, effectuez des mises à jour incrémentielles. En cas de modifications incrémentielles, créez une nouvelle copie Snapshot pour ces modifications et transmettez ce chemin de snapshot à la<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> option pour les opérations de synchronisation.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">Exécutez le<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> commande avec<block ref="3e126213c93cfd745d918a1d244a79cf" prefix=" " category="inline-code"></block> option et chemin du snapshot.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">Pour cette opération, l'instantané de base est requis.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">L'hôte client NFSv3 doit démonter les exportations NFSv3 source provisionnées depuis le stockage 7-mode et monter les exportations NFSv3 cibles depuis ONTAP. Cette mise en service nécessite une interruption.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">Migration d'ACLv4 de NetApp 7-mode vers un système de stockage NetApp</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">Cette section aborde étape par étape la transition de l'exportation NFSv4 source vers un système ONTAP.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp suppose que le volume NFSv4 source est exporté et monté sur le système client et que XCP est déjà installé sur un système Linux. La source doit être un système NetApp 7-mode qui prend en charge les ACL. La migration ACL est prise en charge uniquement de NetApp à NetApp. Pour copier des fichiers avec un caractère spécial dans le nom, assurez-vous que la source et la destination prennent en charge le langage codé UTF-8.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">Conditions préalables à la migration d'une exportation NFSv4 source vers ONTAP</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">Avant de migrer une exportation NFSv4 source vers ONTAP, les conditions préalables suivantes doivent être remplies :</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">NFSv4 doit avoir configuré le système de destination.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">La source et la cible NFSv4 doivent être montées sur l'hôte XCP. Sélectionnez NFS 4.0 pour correspondre au stockage source et cible, et vérifiez que les listes de contrôle d'accès sont activées sur le système source et cible.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">XCP exige que le chemin source/cible soit monté sur l'hôte XCP pour le traitement ACL.dans l'exemple suivant,<block ref="d07c77c05891b869ab2111118b006bed" prefix=" " category="inline-code"></block> est monté sur le<block ref="dfecb62ab540058a212419f33235e6da" prefix=" " category="inline-code"></block> chemin :</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">Options des sous-répertoires</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">Les deux options pour travailler avec les sous-répertoires sont les suivantes :</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">Pour que XCP fonctionne sur un sous-répertoire<block ref="9ce87e1289284ccca8cf788db9dd7804" prefix=" " category="inline-code"></block>), montez le chemin complet <block ref="58753164ce38e8977360bb376dda6e76" prefix="(" category="inline-code"></block>) Sur l'hôte XCP.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">Si le chemin complet n'est pas monté, XCP signale l'erreur suivante :</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">Utilisez la syntaxe du sous-répertoire <block ref="ca6c8952cf206b58c7fc63aa1552d665" prefix="(" category="inline-code"></block>), comme indiqué dans l'exemple ci-dessous :</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">Suivez les étapes suivantes pour migrer les fichiers ACLv4 de NetApp 7-mode vers un système de stockage NetApp.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">Vérifier que le SVM a été créé avec succès</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">Vérifier que l'export policy NFS par défaut est appliquée au SVM cible.</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">Vérifiez que les règles de stratégie ont été modifiées.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">Montez le volume cible NFSv4 exporté à ce point de montage.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">Les volumes NFSv4 doivent être exportés mais pas nécessairement montés par le serveur NFS. S'ils peuvent être montés, le client hôte XCP Linux monte ces volumes.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">Vérifiez que le fichier est créé.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">Interrogez les exportations NFSv4 source en exécutant la<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Commande sur le système hôte client XCP Linux.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">Scannez les chemins exportés de NFSv4 source et imprimez les statistiques de leur structure de fichiers.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">NetApp recommande de placer les exportations NFSv4 source en mode lecture seule pendant<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>, et<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block> exploitation.</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">Copiez les exportations NFSv4 source vers les exports NFSv4 sur le système ONTAP cible.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">Après<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> Est terminée, vérifiez que les exportations NFSv4 source et destination ont des données identiques. Exécutez le<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block> commande.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">Si<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> recherche les différences entre les données source et de destination, puis l'erreur<block ref="54779b0a97a87c0c6df786545eae5f68" prefix=" " category="inline-code"></block> est signalé dans le résumé. Pour résoudre ce problème, exécutez le<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block> commande permettant de copier les modifications de la source vers la destination.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">Pour cette opération, le nom ou le numéro d'index de copie précédent est requis.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">Pour reprendre une interruption précédemment<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> exécutez le<block ref="d932e9ef0438ae21326fc9becf98ace1" prefix=" " category="inline-code"></block> commande.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">La transition du stockage SMB 7-mode vers ONTAP pour les données CIFS</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">Cette section décrit la procédure détaillée de transition d'un partage SMB 7-mode source vers un système ONTAP.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp suppose une licence SMB pour les systèmes 7-mode et ONTAP. Le SVM de destination est créé, les partages SMB source et de destination sont exportés, et XCP est installé et sous licence.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">Analysez les partages SMB pour les fichiers et les répertoires.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">Copiez les fichiers (avec ou sans ACL) de la source vers le partage SMB de destination. L'exemple suivant montre une copie avec ACL.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">Si il n'y a pas d'agrégat de données, créez-en un nouveau en utilisant le stockage<block ref="a3c52ca282dcb77dd824f54a7b270068" prefix=" " category="inline-code"></block> commande.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">Synchronisez les fichiers de la source et de la destination.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">Vérifiez que les fichiers ont été copiés correctement.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">Ensuite : migration des données CIFS avec listes de contrôle d'accès d'une boîte de stockage source vers ONTAP.</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">Cette section décrit la procédure détaillée de migration des données CIFS avec des informations de sécurité d'une source vers un système ONTAP cible.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">Migration des données CIFS avec listes de contrôle d'accès depuis le boîtier de stockage source vers ONTAP</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">Précédent : migration des données de 7-mode vers ONTAP.</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">Créez une LIF de données pour répondre aux demandes des clients SMB.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">Monter le volume de données cible dans le namespace du SVM</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">Démarrer le service CIFS sur le SVM cible</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">Vérifier que l'export policy par défaut est appliquée au SVM cible.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">Modifiez les règles des export-policy pour autoriser l'accès aux clients CIFS.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">Vérifiez que les règles de stratégie sont modifiées.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">Connectez-vous au système client Windows sur lequel XCP est installé. Accédez au chemin d'installation XCP.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">Interrogez les exportations SMB du nœud source en exécutant le<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block> Commande sur le système hôte client XCP Windows.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">Exécutez le<block ref="657f8b8da628ef83cf69101b6817150a" prefix=" " category="inline-code"></block> commande de copie.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">Sur le système ONTAP cible, obtenez la liste des noms d'utilisateur et de groupe local que vous devez fournir comme valeurs pour le<block ref="7a80adbcbc4a0b2e96e8eb2710f30c85" prefix=" " category="inline-code"></block> et<block ref="8d03d04d9c44ec2988a893826753f985" prefix=" " category="inline-code"></block> chemin des arguments.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">Pour migrer les données CIFS avec des listes de contrôle d'accès de la source vers la cible, exécutez la<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> commande avec<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> et<block ref="a72a6079b50973fd59860e6635a4ea62" prefix=" " category="inline-code"></block> options.</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">Pour le<block ref="a3fe89370a4bb214c60bfe40074b2c43" prefix=" " category="inline-code"></block> Options, spécifiez tout utilisateur ou groupe qui peut être trouvé dans Active Directory ou utilisateur/groupe local vers le système cible.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">Si<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> entraîne le message d'erreur<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block>, ajoutez la zone de destination dans le fichier hosts <block ref="803976de87f6862821bd3c4d94e0ff2b" prefix="(" category="inline-code"></block>).</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">Utilisez le format suivant pour l'entrée de boîte de destination du stockage NetApp.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">Si vous recevez toujours le message d'erreur<block ref="2400b6710d9959881ab1c252d8b07325" prefix=" " category="inline-code"></block> après avoir ajouté l'entrée de boîte de destination dans les fichiers hôtes, l'utilisateur/le groupe n'existe pas dans le système cible.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">Utiliser<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> Pour migrer des données CIFS avec des listes de contrôle d'accès (avec ou sans le dossier racine).</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">Sans le dossier racine, exécutez les commandes suivantes :</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">Avec le dossier racine, exécutez les commandes suivantes :</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">Ensuite, des recommandations et des bonnes pratiques.</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">Cette section contient les meilleures pratiques, des instructions et des recommandations pour la migration de données à l'aide de NetApp XCP.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">Recommandations et recommandations sur les bonnes pratiques</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">Précédente : migration des données CIFS avec listes de contrôle d'accès depuis une boîte de stockage source vers ONTAP.</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">Utilisez le système d'exploitation client XCP, qui est pris en charge par IMT. Le client pris en charge par IMT est qualifié par NetApp.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Exécutez XCP en tant qu'utilisateur root dans le système d'exploitation Linux pour effectuer la migration. Vous pouvez exécuter la commande xcp en tant qu'utilisateur sudo, mais elle n'est pas prise en charge par XCP.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">Exécutez une seule instance de XCP par client. Techniquement, vous pouvez exécuter plusieurs instabilités de XCP sur le même hôte à partir d'un emplacement différent, mais cette pratique n'est pas prise en charge. En effet, l'exécution de nombreuses instances peut entraîner une défaillance.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">Dans la version XCP actuelle, Live Source n'est pas pris en charge. Si le volume NetApp source est actif et modifié en permanence par les applications et les utilisateurs, vous devez prendre un snapshot du volume source pour effectuer une migration.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">Il est recommandé de créer un nouveau snapshot avec un nom différent pour chaque synchronisation incrémentielle afin de créer facilement un chemin de migration incrémentielle basé sur le nom du snapshot en cas de défaillance.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">Si vous effectuez une migration basée sur des snapshots, il est conseillé de continuer la migration basée sur des snapshots jusqu'à la mise en service.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">Si vous avez plus de 10 millions de fichiers et que vous avez une modification incrémentielle des données de plus de 50 %, il est recommandé d'utiliser un nombre de cœurs supérieur et plus de mémoire que le minimum recommandé dans le guide d'installation et d'administration.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">Suivant : dépannage.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">Nous avons utilisé NetApp XCP pour migrer les données de GPFS vers NFS, de sorte que les GPU puissent traiter les données. L'IA traite généralement les données d'un système de fichiers en réseau.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">L'informatique haute performance pour ONTAP NFS</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">Précédent : Data Lake à ONTAP NFS.</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">Ce cas d'utilisation est basé sur les demandes des organisations de terrain. Certains clients de NetApp disposent de leurs données dans un environnement informatique hautes performances, qui assure l'analytique des modèles d'entraînement et permet aux organismes de recherche de mieux comprendre un grand nombre de données numériques. Les ingénieurs de terrain NetApp ont besoin d'une procédure détaillée pour extraire les données de GPFS d'IBM vers NFS. Nous avons utilisé NetApp XCP pour migrer les données de GPFS vers NFS, de sorte que les GPU puissent traiter les données. L'IA traite généralement les données d'un système de fichiers en réseau.</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">Pour plus d'informations sur le calcul haute performance du cas d'utilisation de ONTAP NFS, une démonstration enregistrée et les résultats des tests, consultez le<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> blog.</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">Pour des étapes détaillées sur le transfert des données de MapR-FS vers ONTAP NFS à l'aide de NetApp XCP, voir l'annexe A : GPFS vers NFS―étapes détaillées<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">Suivant : utilisation de XCP Data Mover pour migrer des millions de petits fichiers vers un système de stockage flexible.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">Cette section décrit les étapes de déploiement de NetApp XCP pour le transfert de données.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">Étapes de déploiement</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">Précédent : analytique des fichiers.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">Détails du banc d'essai</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">Le tableau suivant fournit les détails du banc d'essai utilisé pour ce déploiement et la validation des performances.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">Composants de la solution</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">Détails</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">XCP version 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Un serveur Linux - Linux (RHEL 7.9 ou RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Un serveur Windows – norme Windows Server 2019</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">Paire haute disponibilité de baies de stockage NetApp AFF pour le volume source</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF 8080</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="list-text">NetApp ONTAP 9</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">Protocole NFS</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">Paire haute disponibilité de baies de stockage NetApp AFF pour volume de destination</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="list-text">AFF A800</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Serveur Fujitsu PRIMERGY RX2540</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">Chacun équipé de : * 48 processeurs * mémoire physique Intel Xeon * 256 Go * double port 10GbE</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">Mise en réseau</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">Étapes de déploiement - NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">Guide de l'utilisateur de NetApp XCP</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">Pour déployer NetApp XCP pour le transfert de données, installez d'abord et activez le logiciel XCP sur l'emplacement de destination. Vous pouvez consulter les détails dans le<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. Pour ce faire, procédez comme suit :</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">« Conditions préalables pour XCP ».</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">Respectez les conditions préalables décrites dans la section <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">Page NetApp XCP (téléchargements)</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">Téléchargez le logiciel XCP à partir du<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">Copiez les fichiers tar XCP téléchargés sur le serveur XCP.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">Décompressez le fichier tartre.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">Téléchargez la licence sur<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> Et copiez vers le serveur XCP.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">Activez la licence.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">Recherchez le port NFS source et le serveur NFS de destination. Le port par défaut est 2049.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">Vérifiez la connexion NFS. Vérifiez le serveur NFS (pour la source et la destination) en utilisant telnet sur le port du serveur NFS.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">Configurer le catalogue.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">Créer un volume NFS et exporter un NFS pour le catalogue XCP. Vous pouvez également exploiter l'exportation NFS du système d'exploitation pour le catalogue XCP.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">Vérifier l'exportation NFS.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">Mise à jour<block ref="d509f49d5d9a07934f91eefcf45a7334" prefix=" " category="inline-code"></block>.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">Recherchez les exportations NAS sources à l'aide de<block ref="b28233b6c0fdcbe5d1e403bc2be8f960" prefix=" " category="inline-code"></block>. Ciblez :</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(Facultatif) analyser les données NAS source.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">L'analyse des données NAS source vous aide à comprendre la disposition des données et à identifier les problèmes potentiels de migration. Le temps d'opération d'acquisition XCP est proportionnel au nombre de fichiers et à la profondeur du répertoire. Vous pouvez ignorer cette étape si vous connaissez bien vos données NAS.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">Vérifiez le rapport créé par<block ref="79b37c0e9765296c2ba8efc16a70d15f" prefix=" " category="inline-code"></block>. Recherchez principalement des dossiers illisibles et des fichiers illisibles.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(Facultatif) modifiez l'inode. Afficher le nombre d'inodes et modifier le nombre en fonction du nombre de fichiers à migrer ou à copier pour les volumes catalogue et de destination (si nécessaire).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">Scannez le volume de destination.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">Vérifiez l'espace du volume source et de destination.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">Copiez les données de la source vers la destination à l'aide de<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> et vérifier le récapitulatif.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">Par défaut, XCP crée sept processus parallèles pour copier les données. Il est possible de l'ajuster.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">NetApp recommande que le volume source soit en lecture seule. En temps réel, le volume source est un système de fichiers actif et actif. Le<block ref="e64df9c2f5a72d0adb1dbea21a609c16" prefix=" " category="inline-code"></block> L'opération peut échouer, car NetApp XCP ne prend pas en charge une source en direct qui est modifiée en continu par une application.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Pour Linux, XCP nécessite un identifiant d'index car XCP Linux effectue le catalogage.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(Facultatif) Vérifiez les inodes sur le volume NetApp de destination.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">Effectuez la mise à jour incrémentielle à l'aide de<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">Pour ce document, afin de simuler en temps réel, le million de fichiers des données sources ont été renommés, puis les fichiers mis à jour ont été copiés vers la destination à l'aide de<block ref="d7c230358c5f1f129db01db058343ec4" prefix=" " category="inline-code"></block>. Pour Windows, XCP a besoin à la fois des chemins source et de destination.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">Validation du transfert de données Vous pouvez vérifier que la source et la destination ont les mêmes données à l'aide de<block ref="7cee3f697022ca3eab4ad2341c03bc2b" prefix=" " category="inline-code"></block>.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">La documentation XCP fournit plusieurs options (avec des exemples) pour le<block ref="53aefec08170b2ebed981a0a86d0dbe0" prefix=" " category="inline-code"></block>,<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block>,<block ref="63ad9d34f3503826e5f649ae6b7ac92c" prefix=" " category="inline-code"></block>, et<block ref="e8418d1d706cd73548f9f16f1d55ad6e" prefix=" " category="inline-code"></block> exploitation. Pour plus d'informations, reportez-vous à la section<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Les clients Windows doivent copier les données à l'aide des listes de contrôle d'accès (ACL). NetApp recommande d'utiliser la commande<block ref="1b5d03dc1e4b5c3623897fd210394888" prefix=" " category="inline-code"></block>. Pour des performances maximales, en tenant compte du volume source contenant des données SMB avec une liste de contrôle d'accès et des données accessibles aussi bien par NFS que SMB, la cible doit être un volume NTFS. À l'aide de XCP (version NFS), copiez les données du serveur Linux et exécutez la synchronisation XCP (version SMB) avec le<block ref="4332bdcfbd72db6a4dae51bd101af3d6" prefix=" " category="inline-code"></block> et<block ref="0e638f18c7569b1e062f20f430b0a5fc" prefix=" " category="inline-code"></block> Options du serveur Windows pour copier les ACL des données source vers les données SMB cibles.</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">Configuration de la stratégie de gestion des journaux d'audit et de sécurité</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">Pour obtenir des instructions détaillées, reportez-vous à la section<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">Étapes de déploiement - migration des données HDFS/MapRFS</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">Dans cette section, nous abordons la nouvelle fonctionnalité XCP appelée transfert de données de système de fichiers Hadoop vers NAS, qui migre les données de HDFS/MapRFS vers NFS et vice versa.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Prérequis</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">Pour la fonction MapRFS/HDFS, vous devez effectuer la procédure suivante dans un environnement utilisateur non racine. Normalement, l'utilisateur non-root est hdfs, mapr ou un utilisateur autorisé à effectuer des modifications dans le système de fichiers HDFS et MapRFS.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">Définissez les variables CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH et NHDFS_LIBHDFS_PATH dans l'interface de ligne de commande ou le fichier .bashrc de l'utilisateur avec l'<block ref="430e727eb7fa4c8fdeb29b396f232465" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_PATH pointe vers le fichier libhdfs.so. Ce fichier fournit des API HDFS pour interagir et manipuler les fichiers et le système de fichiers HDFS/MapRFS dans le cadre de la distribution Hadoop.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH pointe vers le fichier libjvm.so. Il s'agit d'une bibliothèque de machine virtuelle JAVA partagée dans l'emplacement jre.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH pointe vers tous les fichiers JAR à l'aide des valeurs (Hadoop classpath –glob).</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">LD_LIBRARY_PATH pointe vers l'emplacement du dossier de bibliothèque natif Hadoop.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Consultez l'exemple suivant sur la base d'un cluster Cloudera.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">Dans cette version, nous prenons en charge le scan XCP, la copie et la vérification des opérations et de la migration des données de HDFS vers NFS. Vous pouvez transférer des données d'un cluster de data Lake à un seul nœud de travail et à plusieurs nœuds workers. Dans la version 1.8, les utilisateurs root et non-root peuvent effectuer une migration des données.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">Étapes de déploiement : l'utilisateur non root migre les données HDFS/MaprFS vers NetApp NFS</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">Suivez les mêmes étapes que la section déploiement en 1-9 étapes.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">Dans l'exemple suivant, l'utilisateur migre les données de HDFS vers NFS.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">Créez un dossier et des fichiers (à l'aide de<block ref="f45bd8fcd9fdd879ec3b59c5cb0cf396" prefix=" " category="inline-code"></block>) Dans HDFS.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">Vérifiez les autorisations dans le dossier HDFS.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">Créez un dossier dans NFS et vérifiez les autorisations.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">Copiez les fichiers de HDFS vers NFS à l'aide de XCP et vérifiez les autorisations.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">Suivant : instructions de dimensionnement.</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">Les solutions NetApp sont un ensemble de fonctionnalités stratégiques et technologiques qui mettent l'accent sur la gamme de produits et de services NetApp afin de répondre aux besoins métier les plus stratégiques de nos clients.</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">Les solutions NetApp</block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">Le kit NetApp DataOps pour Kubernetes extrait les ressources de stockage et les workloads Kubernetes jusqu'à l'espace de travail data-science. Ces fonctionnalités sont packagées dans une interface simple et conviviale conçue pour les data Scientists et les ingénieurs de données.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">Gestion des versions de datasets et de modèles avec le kit NetApp DataOps</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">Précédent : surveillez DAsk et RAPIDS avec Prometheus et Grafana.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">Le kit NetApp DataOps pour Kubernetes extrait les ressources de stockage et les workloads Kubernetes jusqu'à l'espace de travail data-science. Ces fonctionnalités sont packagées dans une interface simple et conviviale conçue pour les data Scientists et les ingénieurs de données. Ce kit, qui se présente sous la forme familière d'un programme Python, permet aux scientifiques et aux ingénieurs des données de provisionner et de déployer des espaces de travail JupyterLab en quelques secondes. Ces espaces de travail peuvent contenir des téraoctets, voire des pétaoctets, de capacité de stockage, ce qui permet aux data Scientists de stocker tous leurs datasets d'entraînement directement dans leur espace de travail de projet. Il ne fait plus que gérer séparément les espaces de travail et les volumes de données.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">Référentiel GitHub</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">Pour en savoir plus, visitez la boîte à outils<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">Suivant: Conclusion.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="doc">Installation de Trident</block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">Précédent : Peer AKS VNet et Azure NetApp Files vnet.</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Pour installer Trident à l'aide de Helm, effectuez les opérations suivantes :</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">source</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Installez Helm (pour obtenir des instructions d'installation, consultez le<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>).</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Téléchargez et extrayez le programme d'installation de Trident 20.01.1.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">Définissez le répertoire sur<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block>.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">Copier<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> dans un répertoire de votre système<block ref="b6aef5812b57b2270b8146870910b1d3" prefix=" " category="inline-code"></block>.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Installez Trident sur le cluster Kubernetes (K8s) avec Helm (<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>) :</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">Changez le répertoire en<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Installation de Trident.</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Vérifier l'état des pods Trident.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">Si tous les modules sont opérationnels, Trident est installé et vous pouvez passer à l'étape supérieure.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">Configurer le système Azure NetApp Files backend et la classe de stockage pour AKS.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Créer un principe de service Azure</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">Le principal service est de la façon dont Trident communique avec Azure pour manipuler vos ressources Azure NetApp Files.</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">Le résultat de la commande doit ressembler à l'exemple suivant :</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Créez un fichier json backend Trident, par exemple un nom<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block>.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">À l'aide de votre éditeur de texte préféré, renseignez les champs suivants à l'intérieur du<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> fichier :</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">Remplacez les champs suivants :</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text"><block ref="8c443e170595ba0feac007ffb92cb49a" prefix="" category="inline-code"></block>. Votre ID d'abonnement Azure.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text"><block ref="bc54592d6183695b841c6d1880ec0bf8" prefix="" category="inline-code"></block>. Votre ID de locataire Azure à partir des résultats de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> à l'étape précédente.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text"><block ref="93c5bebdea9c94a0740fe6fd9bb250f0" prefix="" category="inline-code"></block>. Votre AppID à partir de la sortie de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> à l'étape précédente.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text"><block ref="2b53761249254ce6b502f521e5cc0683" prefix="" category="inline-code"></block>. Votre mot de passe à partir de la sortie de<block ref="2cb022e0b25eceddfcd6a7ad728f7217" prefix=" " category="inline-code"></block> à l'étape précédente.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">Demandez à Trident de créer le back-end Azure NetApp Files dans le système<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> espace de noms avec<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> comme fichier de configuration :</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">Créer une classe de stockage. Les utilisateurs Kubernetes provisionnent les volumes à l'aide des demandes de volume qui spécifient une classe de stockage par nom. Demandez à K8s de créer une classe de stockage<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Qui fait référence au système back-end Trident créé dans l'étape précédente.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">Créez un YAML <block ref="330e60441e96769dd29fd0a282d4f84a" prefix="(" category="inline-code"></block>) fichier pour la classe de stockage et la copie.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">Vérifiez que la classe de stockage a été créée.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">Suivant : configurer le déploiement de DASK avec RAPIDS sur AKS à l'aide de Helm.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Pour exécuter un travail d'IA et DE ML à un seul nœud dans votre cluster Kubernetes, exécutez les tâches sur cette page à partir de l'hôte de démarrage du déploiement.</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">Exécutez un workload d'IA à un seul nœud</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Pour exécuter une tâche d'IA et DE ML à un seul nœud dans votre cluster Kubernetes, effectuez les tâches suivantes à partir de l'hôte de démarrage du déploiement. Trident vous permet de faire rapidement et facilement un volume de données, potentiellement contenant des pétaoctets de données, accessibles pour un workload Kubernetes. Pour rendre ce volume de données accessible depuis un pod Kubernetes, il vous suffit de spécifier une demande de volume persistant dans la définition du pod. Cette étape est une opération Kubernetes native ; aucune expertise de NetApp n'est requise.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">Dans cette section, vous devez déjà avoir conteneurisé (au format du conteneur Docker) le workload d'IA et DE ML spécifique que vous essayez d'exécuter dans votre cluster Kubernetes.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">Site Web ImageNET</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">L'exemple de commandes suivant montre la création d'un travail Kubernetes pour un workload de banc d'essai TensorFlow qui utilise le dataset ImageNet. Pour plus d'informations sur le dataset ImageNet, reportez-vous à la<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">Cet exemple de tâche nécessite huit GPU, soit un nœud worker doté d'au moins huit GPU. Cet exemple de tâche peut être envoyée dans un cluster pour lequel un nœud worker doté d'au moins huit GPU n'est pas présent ou est actuellement occupé par une autre charge de travail. Si c'est le cas, le travail reste à l'état en attente jusqu'à ce qu'un nœud de travail soit disponible.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Documentation officielle Kubernetes</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">En outre, pour optimiser la bande passante de stockage, le volume contenant les données d'entraînement requises est monté deux fois dans le pod que cette tâche crée. Un autre volume est également monté dans le pod. Ce deuxième volume sera utilisé pour stocker les résultats et les mesures. Ces volumes sont référencés dans la définition de travail en utilisant les noms des ESV. Pour plus d'informations sur les tâches Kubernetes, consultez le<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">An<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> volume avec un<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> valeur de<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> est monté sur<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> dans le pod créé par cet exemple de travail. La taille par défaut du<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Le volume virtuel créé automatiquement par le runtime des conteneurs Docker peut parfois manquer pour TensorFlow. Montage d'un<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> comme dans l'exemple suivant, le volume est suffisamment grand<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> volume virtuel. Pour plus d'informations sur<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> les volumes, voir<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">Le conteneur unique spécifié dans cet exemple de définition de travail est donné un<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Cette valeur signifie que le conteneur dispose d'un accès racine sur l'hôte. Cette annotation est utilisée dans ce cas, car la charge de travail spécifique exécutée nécessite un accès racine. Plus précisément, une opération de mise en cache claire exécutée par la charge de travail nécessite un accès racine. Si cela est ou non<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> l'annotation est nécessaire dépend des exigences de la charge de travail spécifique que vous exécutez.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">Vérifiez que le travail que vous avez créé à l'étape 1 fonctionne correctement. L'exemple de commande suivant confirme qu'un seul pod a été créé pour le travail, comme spécifié dans la définition du travail, et que ce pod s'exécute actuellement sur l'un des nœuds workers GPU.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">Vérifiez que le travail que vous avez créé à l'étape 1 s'est terminé avec succès. L'exemple de commandes suivant confirme que le travail a été terminé avec succès.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*Facultatif:* nettoyer les artefacts de travail. Les exemples de commandes suivants montrent la suppression de l'objet de travail créé à l'étape 1.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">Lorsque vous supprimez l'objet travail, Kubernetes supprime automatiquement les pods associés.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">Ensuite : exécuter un workload d'IA distribué synchrone.</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">Allocation fractionnelle de GPU pour des charges de travail moins exigeantes ou interactives</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">Lorsque les chercheurs et développeurs travaillent sur leurs modèles, que ce soit au stade de développement, de réglage des hyperparamètres ou de débogage, ces charges de travail nécessitent généralement moins de ressources de calcul. Il est donc plus efficace de provisionner des GPU et de la mémoire fractionnaires afin que les mêmes GPU puissent être alloués simultanément à d'autres charges de travail. La solution d'orchestration Run:ai propose un système de partage GPU fractionnaire pour les workloads conteneurisés sur Kubernetes. Le système prend en charge les charges de travail exécutant des programmes CUDA et est particulièrement adapté aux tâches d'IA légères telles que l'inférence et la création de modèles. Le système GPU fractionnel permet aux équipes d'ingénierie d'IA et de data science d'exécuter plusieurs charges de travail simultanément sur un seul GPU. Les entreprises peuvent ainsi exécuter davantage de charges de travail, comme la vision informatique, la reconnaissance vocale et le traitement du langage naturel sur le même matériel, ce qui réduit les coûts.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">Run :le système GPU fractionnel de l'IA crée efficacement des GPU logiques virtualisés avec leur propre mémoire et espace de calcul que les conteneurs peuvent utiliser et accéder comme s'il s'agissait de processeurs autonomes. Ce qui permet d'exécuter plusieurs charges de travail côte à côte dans des conteneurs sur le même GPU sans interférer entre les deux. La solution est transparente, simple et portable. Elle ne nécessite aucune modification des conteneurs eux-mêmes.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">Une upecase type peut voir deux à huit tâches s'exécutant sur le même GPU, ce qui signifie que vous pouvez faire huit fois le travail avec le même matériel.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">Pour le travail<block ref="9ee74d566135099889c5305d14349d44" prefix=" " category="inline-code"></block> appartenant au projet<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> La figure suivante montre que le nombre de GPU alloués était de 0.50. Ceci est vérifié par le<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> La commande, qui montre que la mémoire GPU disponible pour le conteneur était de 16 255 Mo : la moitié de 32 Go par GPU V100 dans le nœud DGX-1.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">Suivant : une utilisation élevée des clusters avec une allocation GPU sur-quota</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">Cette section décrit l'environnement de validation de la conception de la solution.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">Configuration du test</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">Précédent : plan de test et de validation.</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">Le tableau suivant présente l'environnement de validation de la conception de la solution.</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">Composant</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">Pilote NetApp Astra Trident CSI</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kit NetApp DataOps pour Kubernetes</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="cell">Serveur d'inférence NVIDIA Triton</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">Suivant : procédure de test.</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">Résumé</block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">Dans ce rapport technique, vous nombreuses pistes pour optimiser l'utilisation du cluster Kubernetes et des processeurs graphiques avec l'interface de ligne de commande Run:ai et le tableau de bord système de NetApp ONTAP ai. Elle inclut également des informations sur l'installation de la plateforme Run:ai, des scénarios de test et des commandes détaillées pour des cas de test validés. La solution Run:ai d'orchestration combinée à NetApp ai Control plane accélère l'innovation en améliorant la productivité des développeurs grâce à une utilisation optimale des ressources.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">Suivant : synthèse</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis déploiement</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis accès précoce</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">Vous pouvez vous inscrire à<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> Pour accéder aux conteneurs Jarvis sur NVIDIA GPU Cloud (NGC). Après avoir reçu les informations d'identification de NVIDIA, vous pouvez déployer Jarvis en procédant comme suit :</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">Connexion au contrôleur NGC.</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">Définissez votre organisation sur NGC :<block ref="7aa2b5d0d3058d0080d19281dc9d071c" prefix=" " category="inline-code"></block>.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Localiser Jarvis EA v0.2 biens: Les conteneurs Jarvis sont dans<block ref="57383b3fa3bf1fe40b83355ea69945df" prefix=" " category="inline-code"></block> &gt;<block ref="15ce31151446746acfe9a6cb94ac5cbe" prefix=" " category="inline-code"></block>.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">Sélectionnez Jarvis : accédez à<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> et cliquez sur<block ref="29a846043a00b3f8b78a15edcb8ac726" prefix=" " category="inline-code"></block></block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">Vérifiez que toutes les ressources fonctionnent correctement.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">Trouvez la documentation pour créer vos propres applications : les PDF se trouvent dans<block ref="eb6a57c968a3671eebe48d3c0a1d6a9a" prefix=" " category="inline-code"></block> &gt;<block ref="4ce995c78680dc78d6a0745744c2811b" prefix=" " category="inline-code"></block> &gt;<block ref="b8c128190e09e6c57a1df2180e8c73fb" prefix=" " category="inline-code"></block>.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">Suivant : personnalisez les États et les flux pour le cas d'utilisation de la vente au détail</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">Vous pouvez ajuster la configuration utilisée pour la validation afin qu'elle s'adapte à d'autres cas d'utilisation.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">Options de dimensionnement de l'architecture</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">Précédent : résultats du test.</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">Serveur de calcul</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">Nous avons utilisé un processeur Intel Xeon D-2123IT, qui est le niveau de CPU le plus bas pris en charge dans SE350, avec quatre cœurs physiques et 60 W TDP. Bien que le serveur ne prend pas en charge le remplacement des processeurs, il peut être commandé avec un processeur plus puissant. Le processeur le plus pris en charge est le processeur Intel Xeon D-2183IT avec 16 cœurs, 100 W fonctionnant à 2,20 GHz. Cela augmente considérablement la capacité de calcul du processeur. Bien que le processeur ne constitue pas un goulot d'étranglement pour l'exécution des workloads d'inférence eux-mêmes, il facilite le traitement des données et d'autres tâches liées à l'inférence. Actuellement, NVIDIA T4 est le seul GPU disponible pour les cas d'utilisation en périphérie. Il n'est donc pas possible de mettre à niveau ou de rétrograder le GPU.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">Stockage partagé</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">À des fins de test et de validation, le système NetApp AFF C190, qui possède une capacité de stockage maximale de 50,5 To, un débit de 4,4 Gbit/s pour les lectures séquentielles et 230 000 IOPS pour les lectures aléatoires de petite taille, a été utilisé pour ce document. Il est prouvé qu'il est parfaitement adapté aux workloads d'inférence à la périphérie.</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="inline-link">NetApp AFF A250</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">Toutefois, si vous avez besoin de plus de capacité de stockage ou de vitesses réseau plus rapides, vous devriez utiliser NetApp AFF A220 ou bien<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> systèmes de stockage netapp fas. Elle a également permis d'utiliser le système NetApp EF280, dont la capacité maximale est de 1,5 po et 10 Gbit/s de bande passante, pour cette validation. Si vous préférez augmenter votre capacité de stockage avec une bande passante plus élevée,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> peut être utilisé.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">Sources d'informations complémentaires</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">Pour en savoir plus sur les informations données dans ce document, consultez les ressources suivantes :</block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, V100 GPU, cloud GPU</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">Station NVIDIA DGX<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="inline-link"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">GPU NVIDIA V100 à cœurs Tensor<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="inline-link"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NVIDIA NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="list-text">Structure multimodale NVIDIA Jarvis</block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis accès précoce<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="list-text">NVIDIA Nemo</block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA Nemo<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">Guide du développeur<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="list-text">Systèmes NetApp AFF</block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">Fiche technique NetApp AFF A-Series<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">Avantages du Flash NetApp pour les systèmes FAS 100 % Flash<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">Bibliothèque d'informations ONTAP 9<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="inline-link"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">Rapport technique sur NetApp ONTAP FlexGroup volumes<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="list-text">NetApp ONTAP ai</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et connectivité réseau Cisco<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">Guide de déploiement d'ONTAP ai avec DGX-1 et réseau Cisco<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et réseau Mellanox<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">Guide de conception de ONTAP ai avec DGX-2<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA ai Enterprise with NetApp and VMware - Présentation technologique</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">Présentation de la technologie</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA ai Enterprise</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA ai Enterprise est une suite logicielle cloud complète d'IA et d'analytique de données optimisée, certifiée et prise en charge par NVIDIA pour s'exécuter sur VMware vSphere avec les systèmes NVIDIA certifiés. Ce logiciel facilite le déploiement, la gestion et l'évolutivité simples et rapides des workloads d'IA dans un environnement de cloud hybride moderne.</block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU CLOUD (NGC)</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC héberge un catalogue de logiciels optimisés pour les GPU destinés aux professionnels de l'IA afin qu'ils développent leurs solutions d'IA. Elle permet également d'accéder à plusieurs services d'IA, notamment NVIDIA base Command pour l'entraînement des modèles, NVIDIA Fleet Command pour déployer et surveiller les modèles, et NGC Private Registry pour accéder et gérer en toute sécurité des logiciels d'IA propriétaires. En outre, les clients NVIDIA ai Enterprise peuvent demander une assistance via le portail NGC.</block>
  <block id="8887a9a417a1629326acdb917d224337" category="section-title">VMware vSphere</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere est la plateforme de virtualisation de VMware, qui transforme les data centers en infrastructures informatiques agrégées, incluant les ressources de CPU, de stockage et de réseau. VSphere gère ces infrastructures en tant qu'environnement d'exploitation unifié et fournit aux administrateurs les outils nécessaires pour gérer les data centers participant à cet environnement.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">Les deux principaux composants de vSphere sont ESXi et vCenter Server. ESXi est la plateforme de virtualisation sur laquelle les administrateurs créent et exécutent des machines virtuelles et des appliances virtuelles. VCenter Server est le service par l'intermédiaire duquel les administrateurs gèrent plusieurs hôtes connectés dans un réseau et regroupent des ressources hôtes.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP permet de gérer et de protéger les données avec un seul ensemble d'outils, quel que soit leur emplacement. Vous pouvez aussi déplacer vos données librement partout où elles sont nécessaires : la périphérie, le cœur ou le cloud. ONTAP 9 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques, et permettent d'utiliser des fonctionnalités d'infrastructure nouvelle génération dans toutes les architectures de cloud hybride.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">Gestion simplifiée</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">La gestion des données est cruciale pour les opérations IT et les data Scientists, de sorte que les ressources appropriées sont utilisées pour les applications d'IA et pour l'entraînement des datasets d'IA/DE ML. Les informations supplémentaires suivantes sur les technologies NetApp ne sont pas incluses dans cette validation, mais elles peuvent être pertinentes en fonction de votre déploiement.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">Le logiciel de gestion des données ONTAP comprend les fonctionnalités suivantes pour rationaliser et simplifier les opérations et réduire le coût total d'exploitation :</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">Compaction des données à la volée et déduplication étendue La compaction des données réduit le gaspillage d'espace à l'intérieur des blocs de stockage, et la déduplication augmente considérablement la capacité effective. Cela s'applique aux données stockées localement et à leur placement dans le cloud.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">Qualité de service (AQoS) minimale, maximale et adaptative. Les contrôles granulaires de la qualité de service (QoS) permettent de maintenir les niveaux de performance des applications stratégiques dans des environnements hautement partagés.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">Tr-4598 : meilleures pratiques de FabricPool</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool Tiering automatique des données inactives vers des options de stockage de cloud public et privé, notamment Amazon Web Services (AWS), Azure et la solution de stockage NetApp StorageGRID. Pour plus d'informations sur FabricPool, voir<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">Accélération et protection des données</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP offre des niveaux supérieurs de performances et de protection des données et étend ces fonctionnalités aux méthodes suivantes :</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">Des performances élevées et une faible latence. ONTAP offre le débit le plus élevé possible à la latence la plus faible possible.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">Protection des données. ONTAP fournit des fonctionnalités de protection des données intégrées avec une gestion commune sur toutes les plateformes.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp Volume Encryption (NVE). ONTAP offre un chiffrement natif au niveau du volume avec un support de gestion des clés interne et externe.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">Colocation et authentification multifacteur. ONTAP permet le partage des ressources d'infrastructure avec les plus hauts niveaux de sécurité.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">Une infrastructure pérenne</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP permet de répondre aux besoins métier en constante évolution grâce aux fonctionnalités suivantes :</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">Évolutivité transparente et opérations non disruptives. ONTAP prend en charge l'ajout non disruptif de capacité aux contrôleurs et l'évolution scale-out des clusters. Les clients peuvent effectuer la mise à niveau vers les technologies les plus récentes, telles que NVMe et FC 32 Gb, sans migration des données ni panne coûteuse.</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">Connexion cloud. ONTAP est le logiciel de gestion de stockage le plus connecté au cloud, avec des options de stockage SDS (ONTAP Select) et des instances natives de cloud (NetApp Cloud Volumes Service) dans tous les clouds publics.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">Intégration avec les applications émergentes ONTAP propose des services de données d'entreprise pour les plateformes et applications nouvelle génération, telles que les véhicules autonomes, les Smart cities et Industry 4.0, en utilisant la même infrastructure prenant en charge les applications d'entreprise existantes.</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="section-title">Kit NetApp DataOps</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">Le kit NetApp DataOps est un outil Python qui simplifie la gestion des espaces de travail de développement/formation et des serveurs d'inférence, lesquels sont basés sur un stockage NetApp haute performance et scale-out. Les fonctionnalités principales comprennent :</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">Provisionnez rapidement de nouveaux espaces de travail JupyterLab haute capacité, soutenus par un stockage NetApp haute performance et scale-out.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">Provisionnez rapidement les nouvelles instances NVIDIA Triton Inférence Server, qui sont sauvegardées par un système de stockage NetApp de grande qualité.</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">Cloner simultanément des espaces de travail JupyterLab haute capacité afin de permettre des expériences ou une itération rapide.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">Vous pouvez sauvegarder simultanément des snapshots des espaces de travail JupyterLab haute capacité pour la sauvegarde et/ou la traçabilité/l'établissement de base.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">Provisionnement, clonage et snapshot quasi instantanés des volumes de données haute capacité haute performance.</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">Ensuite : l'architecture.</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">Ce document présente une solution de conception validée dans trois scénarios différents, avec et sans confusion d'images concernant le maintien de la confidentialité et le déploiement d'une solution d'IA responsable.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">Tr-4928 : IA responsable et inférence confidentielle : NetApp ai avec Protopia image et la transformation des données</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp Byung Hoon Ahn, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">Les interprétations visuelles font désormais partie intégrante de la communication avec l'émergence de la capture d'images et du traitement d'images. L'intelligence artificielle (IA) dans le traitement d'images numériques offre de nouvelles opportunités commerciales, notamment dans le domaine médical du cancer et de l'identification de maladies, dans l'analyse visuelle géospatiale pour l'étude des risques environnementaux, la reconnaissance de modèles, dans le traitement vidéo pour la lutte contre le crime, etc. Toutefois, cette opportunité est également liée à des responsabilités extraordinaires.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">Plus les entreprises sont aux prises avec l'IA, plus elles acceptent de risques liés à la confidentialité et à la sécurité des données, ainsi qu'aux questions juridiques, éthiques et réglementaires. Une approche IA responsable permet aux entreprises et aux administrations de gagner la confiance et de la gouvernance nécessaires à l'IA à grande échelle. Ce document décrit une solution d'inférence d'IA validée par NetApp dans trois scénarios différents en utilisant les technologies de gestion de données NetApp avec le logiciel Protopia Data obfuscation pour privatiser les données sensibles et réduire les risques et les préoccupations d'ordre éthique.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">Des millions d'images sont générées chaque jour avec différents appareils numériques, aussi bien par des particuliers que des entités commerciales. Avec l'explosion massive des données et des charges de travail de calcul qui en résulte, les entreprises se tournent vers les plateformes de cloud computing pour améliorer leur évolutivité et leur efficacité. Dans le même temps, la confidentialité des données sensibles contenues dans les données d'images est sujet à la transmission vers un cloud public. Le manque d'assurances de sécurité et de protection de la vie privée devient le principal obstacle au déploiement de systèmes d'IA de traitement des images.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">droit d'effacement</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">Protection de la vie privée</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">De plus, il y a le<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> Par le RGPD, le droit d'une personne de demander à une entreprise d'effacer toutes ses données personnelles. Il y a également le<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>, qui établit un code de pratiques équitables en matière d'information. Les images numériques telles que les photographies peuvent constituer des données personnelles selon le RGPD, qui régit la collecte, le traitement et l'effacement des données. Le non-respect de cette règle est un non-respect du RGPD, qui peut entraîner de lourdes sanctions pour non-respect des conformités qui peuvent être sérieusement préjudiciables à des entreprises. Les principes de confidentialité constituent l'une des piliers de l'implémentation d'une IA responsable qui garantit l'équité dans les prévisions des modèles de machine learning (ML) et de deep learning (DL) et réduit les risques associés à la violation de la confidentialité ou à la conformité réglementaire.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">Ce document présente une solution de conception validée dans trois scénarios différents, avec et sans confusion d'images concernant la préservation de la confidentialité et le déploiement d'une solution d'IA responsable :</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*Scénario 1.* inférence à la demande dans le bloc-notes Jupyter.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*Scénario 2.* inférence par lot sur Kubernetes.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*Scénario 3.* serveur d'inférence NVIDIA Triton.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">Pour cette solution, nous utilisons le jeu de données de détection de visage et le banc d'essai (FDDB), un jeu de zones de face conçues pour étudier le problème de la détection de visage sans contrainte, combiné au cadre d'apprentissage machine PyTorch pour la mise en œuvre de FaceBoxes. Ce jeu de données contient les annotations pour 5171 faces dans un ensemble de 2845 images de différentes résolutions. Ce rapport technique présente également certains domaines de solutions et plusieurs utilisations pertinentes, recueillies par les clients et par les ingénieurs de terrain de NetApp, dans les situations où la solution est applicable.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">Public visé</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">Ce rapport technique est destiné aux publics suivants :</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">Des dirigeants d'entreprise et des architectes d'entreprise qui souhaitent concevoir et déployer une IA responsable et résoudre des problèmes de protection des données et de confidentialité concernant le traitement d'images faciales dans les espaces publics.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">Les data Scientists, les ingénieurs en données, les chercheurs d'IA et de machine learning (ML), et les développeurs de systèmes d'IA/ML qui cherchent à protéger et à préserver la confidentialité.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">Les architectes d'entreprise qui conçoivent des solutions de fusion des données pour des modèles et des applications d'IA/DE ML conformes aux normes réglementaires telles que le RGPD, la loi CCPA ou la loi sur la confidentialité des données du ministère de la Défense (DoD) et des administrations.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">Les data Scientists et les ingénieurs d'IA recherchent des méthodes efficaces pour déployer le deep learning (DL) et les modèles d'inférence d'IA/AM/AP qui protègent les informations sensibles.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">Des gestionnaires de terminaux et des administrateurs de serveurs en périphérie sont chargés du déploiement et de la gestion des modèles d'inférence à la périphérie.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">Architecture de la solution</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">Cette solution est conçue pour traiter des workloads d'IA d'inférence en temps réel et par lots sur des datasets volumineux, grâce à la puissance de traitement des GPU avec des processeurs classiques. Cette validation démontre l'inférence à la confidentialité pour L'AM et une gestion optimale des données requises pour les entreprises qui souhaitent déployer des déploiements d'IA responsables. Cette solution fournit une architecture adaptée à une plateforme Kubernetes à un ou plusieurs nœuds pour la périphérie et le cloud computing interconnectée avec NetApp ONTAP ai dans le cœur, le kit NetApp DataOps Toolkit et le logiciel Protopia obfuscation via des interfaces Jupyter Lab et CLI. La figure suivante présente l'architecture logique de Data Fabric optimisée par NetApp avec DataOps Toolkit et Protopia.</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Le logiciel d'obfuscation Protopia s'exécute en toute transparence au-dessus du kit d'outils NetApp DataOps et transforme les données avant de quitter le serveur de stockage.</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">Ensuite, catégories de solutions.</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">Définition de la demande de volume persistant</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">Enregistrez le YAML suivant dans un fichier pour créer un PVC de type Basic.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Appliquez le fichier YAML sur votre cluster Kubernetes Iguazio.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Relier un volume NetApp au bloc-notes Jupyter</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio Présentation des services et outils d'application</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio propose plusieurs services gérés afin de fournir aux data Scientists une pile complète pour le développement et le déploiement d'applications d'IA/ML. Pour en savoir plus sur ces composants, consultez le<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">Jupyter Notebook est l'un des services gérés. Chaque développeur a son propre déploiement d'un conteneur d'ordinateur portable avec les ressources dont il a besoin pour le développement. Pour leur donner accès à NetApp Cloud Volume, vous pouvez attribuer le volume à leur container et à leur allocation des ressources, exécuter les paramètres des utilisateurs et des variables d'environnement pour les demandes de volume persistant. Cette image présente.</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">Pour une configuration sur site, vous pouvez vous reporter à<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> Vous configurez Trident pour activer les fonctionnalités de gestion des données de NetApp ONTAP, comme l'exécution de copies Snapshot de vos données ou un modèle pour le contrôle des versions. Ajoutez la ligne suivante dans votre fichier de configuration back-end Trident pour rendre les répertoires Snapshot visibles :</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Commande Trident</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">Vous devez créer un fichier de configuration back-end Trident au format JSON, puis exécuter la commande suivante<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> pour la référencer :</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">Suivant : déploiement de l'application</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">Cette section décrit la base technologique de cette solution d'IA.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">Présentation de la technologie</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">Les systèmes de stockage NetApp AFF de pointe permettent les déploiements d'inférence d'IA à la périphérie de répondre aux besoins de stockage des entreprises avec les meilleures performances du secteur, la flexibilité supérieure, l'intégration au cloud et une gestion de données optimale. Conçues spécifiquement pour les systèmes Flash, les AFF NetApp contribuent à accélérer, gérer et protéger les données stratégiques.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">Les systèmes de stockage NetApp AFF d'entrée de gamme sont basés sur du matériel FAS2750 et sur les disques SSD Flash</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">Deux contrôleurs en configuration haute disponibilité</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">Les fonctionnalités des systèmes de stockage AFF C190 d'entrée de gamme de NetApp sont les suivantes :</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">Le nombre maximal de disques SSD 24 x 960 Go</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">Deux configurations possibles :</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">Ethernet (10GbE) : 4 ports 10GBASE-T (RJ-45)</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">Unifié (FC 16 Gb ou 10 GbE) : 4 ports UTA2 (adaptateur « Unified Target » 2)</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">Un maximum de 50,5 To de capacité effective</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">Pour les workloads NAS, un seul système AFF C190 d'entrée de gamme prend en charge un débit de 4,4 Gbit/s pour les lectures séquentielles, et 230 000 IOPS pour les lectures aléatoires de petite taille à des latences inférieures ou inférieures à 1 ms.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">Avec AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp propose également d'autres systèmes de stockage d'entrée de gamme qui offrent des performances et une évolutivité supérieures pour les déploiements à plus grande échelle. Pour les charges de travail NAS, un système AFF A220 unique d'entrée de gamme prend en charge :</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">Débit de 6,2 Gbit/s pour les lectures séquentielles</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375 000 IOPS pour les lectures aléatoires de petite taille à des latences inférieures ou inférieures à 1 ms.</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">Le nombre maximum de disques de 144 SSD de 960 Go, de 3,8 To ou 7,6 To</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 évolue jusqu'à plus de 1 po de capacité effective</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">La capacité effective maximale est de 35 po avec une évolutivité scale-out maximale de 2-24 nœuds (12 paires HA)</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">Offre une augmentation ≥ 45 % des performances par rapport à AFF A220</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440 000 IOPS en lectures aléatoires à 1 ms.</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">Basé sur la dernière version de NetApp ONTAP : ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">Exploite deux Ethernet 25 Gb pour la haute disponibilité et l'interconnexion de clusters</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">Baies NetApp E-Series EF</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">La gamme EF-Series est une gamme de baies de stockage SAN d'entrée de gamme et de milieu de gamme. Elles accélèrent l'accès à vos données et vous permettent de les valoriser plus rapidement grâce au logiciel NetApp SANtricity. Proposant un stockage Flash NVMe et SAS, ces systèmes incluent des IOPS exceptionnelles, des temps de réponse inférieurs à 100 microsecondes et 44 Gbit/s de bande passante. Ils sont ainsi parfaitement adaptés aux workloads mixtes et aux applications exigeantes telles que l'inférence d'IA et le calcul haute performance (HPC).</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">La figure suivante montre la baie de stockage NetApp EF280.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">Prise en charge des protocoles FC 32 Gb/16 Gb, iSCSI 25 Gb/10 Gb et SAS 12 Gb</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">La capacité effective maximale est de 96 disques totalisant 1,5 po</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">Débit de 10 Gbit/s (lectures séquentielles)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300 000 IOPS (lectures aléatoires)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">La baie NetApp EF280 est la baie 100 % Flash la moins chère du portefeuille NetApp</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 disques SSD NVMe pour une capacité totale de 367 To</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">Vous pouvez étendre des options d'extension au total 240 disques durs NL-SAS, 96 disques SSD SAS, ou une combinaison</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">NVMe/IB 100 Gb, NVMe/RoCE, iser/IB et SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">NVME/FC 32 GB, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">ISCSI 25 Gb</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20 Gbit/s (lectures séquentielles)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670 000 IOPS (lectures aléatoires)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">Fiche technique des baies 100 % Flash NetApp EF-Series EF600, F300, EF570 et EF280</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">Pour plus d'informations, reportez-vous à la section<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP permet de gérer et de protéger les données avec un seul ensemble d'outils, quel que soit leur emplacement. Vous pouvez aussi déplacer vos données librement partout où elles sont nécessaires : la périphérie, le cœur ou le cloud. ONTAP 9.8.1 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques, et permettent d'utiliser des fonctionnalités d'infrastructure nouvelle génération dans toutes les architectures de cloud hybride.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">La gestion des données est essentielle pour les opérations IT, car elle permet d'utiliser les ressources appropriées pour les applications et les jeux de données. ONTAP inclut les fonctionnalités suivantes pour rationaliser et simplifier les opérations et réduire le coût total d'exploitation :</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*La compaction des données à la volée et la déduplication étendue* la compaction des données réduit le gaspillage d'espace dans les blocs de stockage, et la déduplication augmente considérablement la capacité effective. Cela s'applique aux données stockées localement et à leur placement dans le cloud.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*Les contrôles de qualité de service (AQoS) granulaires (minimum, maximum et adaptative).* les contrôles de qualité de service (QoS) aident à maintenir les niveaux de performance des applications critiques dans des environnements hautement partagés.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">*NetApp FabricPool* cette fonctionnalité permet une hiérarchisation automatique des données inactives vers des options de stockage en cloud public et privé, notamment Amazon Web Services (AWS), Azure et NetApp StorageGRID. Pour plus d'informations sur FabricPool, voir <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 offre des niveaux supérieurs de performances et de protection des données et étend ces fonctionnalités aux méthodes suivantes :</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* Performances et latence plus faible.* ONTAP offre le débit le plus élevé possible à la latence la plus faible possible.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*Protection des données.* ONTAP fournit des fonctionnalités de protection des données intégrées avec une gestion commune sur toutes les plates-formes.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">*NetApp Volume Encryption (NVE).* ONTAP offre le chiffrement natif au niveau du volume, avec prise en charge de la gestion des clés à la fois intégrée et externe.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*Colocation et authentification multifactorielle.* ONTAP permet de partager les ressources de l'infrastructure avec les niveaux de sécurité les plus élevés.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 propose les fonctionnalités suivantes pour répondre aux besoins métier en constante évolution :</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*Évolutivité transparente et continuité de l'activité.* ONTAP prend en charge l'ajout non disruptif de capacité aux contrôleurs et l'évolution scale-out des clusters. Les clients peuvent effectuer la mise à niveau vers les technologies les plus récentes, telles que NVMe et FC 32 Gb, sans migration des données ni panne coûteuse.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">*Connexion au cloud.* ONTAP est le logiciel de gestion de stockage le plus connecté au cloud, avec des options de stockage SDS (ONTAP Select) et des instances natives du cloud (NetApp Cloud Volumes Service) dans tous les clouds publics.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*Intégration avec les applications émergentes* ONTAP offre des services de données d'entreprise pour les plates-formes et applications de nouvelle génération, telles que les véhicules autonomes, les villes intelligentes et l'industrie 4.0, en utilisant la même infrastructure qui prend en charge les applications d'entreprise existantes.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">Logiciel SANtricity NetApp E-Series : Fiche technique</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">Les systèmes SANtricity de NetApp offrent les meilleures performances, la fiabilité et la simplicité des baies 100 % Flash hybrides E-Series et EF-Series. Optimisez les performances et l'utilisation de vos baies 100 % Flash hybrides E-Series et EF-Series pour les applications nécessitant des charges de travail importantes, notamment l'analytique des données, la vidéosurveillance, et la sauvegarde et la restauration. Avec SANtricity, les tâches de configuration, de maintenance et d'extension de la capacité peuvent être effectuées en garantissant la disponibilité du système de stockage. SANtricity offre d'excellentes fonctionnalités de protection des données et de surveillance proactive, ainsi qu'une sécurité certifiée. System Manager, son interface intégrée, est facile d'emploi. Pour en savoir plus, consultez le<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">Optimisation des performances</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">Le logiciel SANtricity combine d'excellentes performances, des IOPS élevées, un haut débit et une faible latence, pour l'analytique, la vidéosurveillance et les applications de sauvegarde. Accélérez les performances des applications à débit d'IOPS élevé et à faible latence, et celles des applications à large bande passante et à haut débit.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">Disponibilité optimisée</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">Réalisez toutes vos tâches de gestion pendant que le stockage reste en ligne. Modifiez la configuration, effectuez la maintenance ou étendez la capacité de stockage sans interrompre les E/S. Bénéficiez d'une fiabilité exceptionnelle avec les fonctionnalités automatisées, la configuration en ligne, la technologie DPP (Dynamic Disk pools), et bien plus encore.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">Travaillez en toute sérénité</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">Le logiciel SANtricity, qui respecte les normes de sécurité les plus strictes, offre d'excellentes fonctionnalités de protection des données et assure une surveillance proactive. System Manager, son interface intégrée, est facile d'emploi. Simplifiez les tâches courantes de gestion du stockage. Obtenez la flexibilité dont vous avez besoin pour un réglage ultra-précis de tous les systèmes de stockage E-Series. Gérez votre système NetApp E-Series grâce à Une interface web intégrée conçue pour simplifier vos workflows de gestion.</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="section-title">NetApp Trident</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> À partir de NetApp, est un orchestrateur de stockage dynamique open source pour Docker et Kubernetes qui simplifie la création, la gestion et la consommation du stockage persistant. Trident, une application Kubernetes native, s'exécute directement dans un cluster Kubernetes. Trident permet de déployer de manière transparente des images de conteneur d'apprentissage profond sur un système de stockage NetApp et offre une expérience haute performance pour les déploiements de conteneurs d'IA. Les utilisateurs de Kubernetes (développeurs DE ML et data Scientists, par exemple) peuvent créer, gérer et automatiser l'orchestration et le clonage pour exploiter les fonctionnalités avancées de gestion de données de NetApp optimisées par la technologie NetApp.</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Est un service NetApp qui permet une synchronisation sûre et rapide des données. Qu'il s'agisse de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage, Ou IBM Cloud Object Storage, Cloud Sync déplace les fichiers là où vous en avez besoin, rapidement et de manière sécurisée. Une fois vos données transférées, elles peuvent être utilisées à la source et à la cible. Cloud Sync synchronise en continu les données en fonction de votre planification prédéfinie et ne déplace que les données modifiées. Le temps et les coûts liés à la réplication des données sont ainsi réduits. Cloud Sync est un outil SaaS extrêmement simple à configurer et à utiliser. Les transferts de données déclenchés par Cloud Sync sont effectués par des courtiers de données. Vous pouvez déployer des courtiers de données Cloud Sync sur AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Serveurs Lenovo ThinkSystem</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Les serveurs Lenovo ThinkSystem sont dotés de matériel, de logiciels et de services innovants qui répondent aux défis actuels des clients et offrent une approche évolutive, adaptée et modulaire pour répondre aux défis de demain. Ces serveurs exploitent les meilleures technologies standard du secteur, associées à des innovations Lenovo différenciées, pour offrir la plus grande flexibilité possible aux serveurs x86.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Les principaux avantages du déploiement des serveurs Lenovo ThinkSystem sont les suivants :</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">Des conceptions modulaires extrêmement évolutives qui s'étendent à votre business</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">La résilience optimale du secteur pour économiser des heures de temps d'arrêt imprévus coûteux</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">Des technologies Flash rapides pour des latences plus faibles, des temps de réponse plus rapides et une gestion intelligente des données en temps réel</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">Dans le domaine de l'IA, Lenovo propose une approche pratique pour aider les entreprises à comprendre et à exploiter les avantages DU ML et de l'IA pour leurs workloads. Les clients Lenovo peuvent explorer et évaluer les offres d'IA de Lenovo dans les centres d'innovation d'IA de Lenovo afin de connaître pleinement la valeur de leur utilisation. Pour améliorer le retour sur investissement, cette approche axée sur le client permet aux clients de réaliser des démonstrations de faisabilité pour les plateformes de développement de solutions prêtes à l'emploi et optimisées pour l'IA.</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Serveur Lenovo ThinkSystem SE350 Edge</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">Le Edge Computing permet aux données des terminaux IoT d'être analysées à la périphérie du réseau avant d'être envoyées vers le data Center ou le cloud. Le Lenovo ThinkSystem SE350, tel qu'illustré dans la figure ci-dessous, est conçu pour répondre aux exigences uniques de déploiement en périphérie, avec un accent sur la flexibilité, la connectivité, la sécurité et la téléadministration dans un format compact renforcé et résistant à l'environnement.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">Doté d'un processeur Intel Xeon D avec la flexibilité nécessaire pour prendre en charge l'accélération des charges de travail Edge ai, le SE350 est conçu pour relever les défis de déploiement de serveurs dans divers environnements en dehors du centre de données.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">Diminution des</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">Inférence MLPerf v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf est une suite de banc d'essai leader du secteur pour évaluer les performances de l'IA. Il couvre de nombreux domaines de l'IA appliquée, notamment le classement des images, la détection des objets, l'imagerie médicale et le traitement du langage naturel (NLP). Dans cette validation, nous avons utilisé des charges de travail Inférence v0.7, qui est la dernière itération de l'Inférence MLPerf à la fin de cette validation. Le<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> la suite comprend quatre nouveaux bancs d'essai pour les systèmes de data center et de périphérie :</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*BERT.* Encoder bidirectionnel représentation des transformateurs (BERT) affinée pour répondre aux questions en utilisant le jeu de données de l'équipe.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.* le modèle de recommandation en apprentissage profond (DLRM) est un modèle de personnalisation et de recommandation qui est formé pour optimiser les taux de clics (CTR).</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-Net.* l'architecture 3D U-Net est formée sur le dataset de segmentation de la tumeur cérébrale (brats).</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* transducteur de réseau neuronal récurrent (RNN-T) est un modèle de reconnaissance vocale automatique (ASR) qui est entraîné sur un sous-ensemble de LibriSpeech. Les résultats et le code MLPerf Inférence sont accessibles au public et publiés sous licence Apache. MLPerf Inférence possède une division Edge qui prend en charge les scénarios suivants :</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*Single stream.* ce scénario imite les systèmes où la réactivité est un facteur critique, comme les requêtes ai hors ligne effectuées sur les smartphones. Les requêtes individuelles sont envoyées au système et les temps de réponse sont enregistrés. le résultat est une latence du 90e centile de toutes les réponses.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*Multistream.* ce banc d'essai est destiné aux systèmes qui traitent l'entrée à partir de plusieurs capteurs. Pendant le test, les requêtes sont envoyées à un intervalle de temps fixe. Une contrainte de QoS (latence maximale autorisée) est imposée. Le test indique le nombre de flux que le système peut traiter tout en respectant la contrainte QoS.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*Hors ligne.* c'est le scénario le plus simple pour les applications de traitement par lots et la mesure est le débit en échantillons par seconde. Toutes les données sont disponibles pour le système et le banc d'essai mesure le temps nécessaire pour traiter tous les échantillons.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo a publié les scores d'inférence MLPerf pour SE350 avec T4, le serveur utilisé dans ce document. Voir les résultats à<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> Dans la section "Edge, Closed Division" de l'entrée 0.7-145.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">Suivant : plan de test.</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Avant de pouvoir utiliser Trident pour provisionner dynamiquement les ressources de stockage dans votre cluster Kubernetes, vous devez créer un ou plusieurs systèmes back-end Trident. Les exemples présentés sur cette page représentent les différents types de systèmes back-end que vous pouvez créer si vous déployez la solution NetApp ai Control plane sur un pod ONTAP ai.</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="doc">Exemple de systèmes back-end Trident pour les déploiements d'IA de ONTAP</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Documentation Trident</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Avant de pouvoir utiliser Trident pour provisionner dynamiquement les ressources de stockage dans votre cluster Kubernetes, vous devez créer un ou plusieurs systèmes back-end Trident. Les exemples suivants représentent différents types de systèmes back-end que vous pouvez créer si vous déployez la solution NetApp ai Control plane sur un pod ONTAP ai. Pour plus d'informations sur les systèmes back-end, reportez-vous au<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp recommande de créer un système back-end Trident compatible avec FlexGroup pour chaque LIF de données (interface réseau logique offrant un accès aux données) que vous souhaitez utiliser sur votre système NetApp AFF. Vous pourrez ainsi équilibrer les montages de volumes entre les LIF</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">Les exemples de commandes ci-dessous montrent la création de deux backends Trident compatibles avec FlexGroup pour deux LIF de données différentes associées à un même SVM (Storage Virtual machine) ONTAP. Ces extrémités arrière utilisent le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> pilote de stockage ONTAP prend en charge deux principaux types de volumes de données : FlexVol et FlexGroup. La taille des volumes FlexVol est limitée (à compter de cette écriture, la taille maximale dépend du déploiement spécifique). Au contraire, les volumes FlexGroup peuvent évoluer de manière linéaire jusqu'à 20 po et 400 milliards de fichiers, fournissant un espace de nom unique qui simplifie considérablement la gestion des données. Par conséquent, les volumes FlexGroup sont optimaux pour les workloads d'IA et DE ML qui s'appuient sur des quantités importantes de données.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">Si vous travaillez avec un volume de données réduit et que vous souhaitez utiliser des volumes FlexVol plutôt que des volumes FlexGroup, vous pouvez créer des systèmes back-end Trident qui utilisent le<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> pilote de stockage au lieu du<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> pilote de stockage</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">NetApp recommande également de créer un ou plusieurs systèmes back-end Trident compatibles avec FlexVol. Si vous utilisez les volumes FlexGroup pour le stockage des jeux de données d'entraînement, vous pouvez utiliser les volumes FlexVol pour stocker les résultats, les résultats, les informations de débogage, etc. Si vous souhaitez utiliser des volumes FlexVol, vous devez créer un ou plusieurs systèmes back-end Trident compatibles avec FlexVol. Les exemples de commandes ci-dessous montrent la création d'un système back-end Trident compatible avec FlexVol utilisant un seul LIF de données.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">Ensuite, exemple de stockage Kubernetes Storageclasses pour les déploiements d'IA ONTAP.</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">Conclusion</block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp et cnvrg.io se sont associés pour offrir aux clients une solution complète de gestion des données pour le développement de logiciels DE ML et de DL. ONTAP ai fournit des ressources de calcul et de stockage haute performance à n'importe quelle échelle d'opérations. Le logiciel nvrg.io rationalise les workflows en data science et améliore l'utilisation des ressources.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">Suivant : Remerciements</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">Présentation du cas d'utilisation et déclaration du problème</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">Les datasets et les versions des datasets se trouvent généralement dans un data Lake, tel que le stockage objet StorageGRID de NetApp, ce qui permet de réduire les coûts et d'autres avantages opérationnels. Les data Scientists extraient ces datasets et les préparent en plusieurs étapes pour l'entraînement d'un modèle spécifique, créant souvent plusieurs versions tout au long du processus. À l'étape suivante, le data Scientist doit sélectionner des ressources de calcul optimisées (GPU, instances de processeurs haut de gamme, cluster sur site, etc.) pour exécuter le modèle. La figure suivante illustre l'absence de proximité du dataset dans un environnement de calcul DE ML.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">Toutefois, plusieurs expériences d'entraînement doivent être menées en parallèle dans différents environnements de calcul. Chacune d'entre elles nécessite le téléchargement du dataset depuis le data Lake, ce qui est un processus coûteux et chronophage. La proximité du dataset avec l'environnement de calcul (notamment dans le cloud hybride) n'est pas garantie. De plus, les autres membres de l'équipe qui exécutent leurs propres expériences avec le même dataset doivent suivre le même processus fastidieux. Au-delà de la lenteur évidente de l'accès aux données, le suivi des versions de dataset, le partage de dataset, la collaboration et la reproductibilité sont des difficultés autres.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">Besoins des clients</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">Les exigences des clients peuvent varier afin d'atteindre les performances d'EXÉCUTION D'APPRENTISSAGE MACHINE tout en utilisant efficacement les ressources. Par exemple, les clients peuvent exiger les éléments suivants :</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">L'accès rapide aux datasets à partir de chaque instance de calcul exécutant le modèle d'entraînement, sans complexité coûteuse liée à l'accès aux données ni à des téléchargements</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">L'utilisation d'une instance de calcul (GPU ou processeur) dans le cloud ou sur site sans craindre l'emplacement des datasets</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">Efficacité et productivité accrues grâce aux tests d'entraînement exécutés en parallèle avec les différentes ressources de calcul sur le même dataset, sans délais supplémentaires et sans latence des données</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">Réduction des coûts des instances de calcul</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">Meilleure reproductibilité grâce à des outils permettant de conserver les enregistrements des ensembles de données, leur traçabilité, leurs versions et d'autres détails de métadonnées</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">Partage et collaboration améliorés pour que les membres de l'équipe autorisés puissent accéder aux données et réaliser des expériences</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">Pour implémenter la mise en cache du dataset avec le logiciel de gestion des données NetApp ONTAP, les clients doivent effectuer les tâches suivantes :</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">Configurez et définissez le stockage NFS le plus proche des ressources de calcul.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">Détermination du jeu de données et de la version à mettre en cache</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">Contrôlez la mémoire totale allouée aux datasets en cache et la quantité de stockage NFS disponible pour les validations de cache supplémentaires (par exemple, la gestion du cache).</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">L'âge des datasets dans le cache s'ils n'ont pas été utilisés pendant un certain temps. La valeur par défaut est un jour ; d'autres options de configuration sont disponibles.</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">Ensuite : présentation de la solution</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">Optimisation de l'utilisation des clusters et des GPU avec Run:ai</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">Présentation de la solution</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">Cette section examine un pipeline conventionnel de data science et ses inconvénients. Il présente également l'architecture de la solution de mise en cache de jeux de données proposée.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">Pipeline de traitement de données conventionnel et inconvénients</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">Une séquence standard de développement et de déploiement de modèles DE ML implique des étapes itératives qui incluent :</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">Ingestion des données</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">Prétraitement des données (création de plusieurs versions des datasets)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">Exécution de plusieurs expériences impliquant l'optimisation des hyperparamètres, différents modèles, etc</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="list-text">Déploiement</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io a développé une plateforme complète pour automatiser toutes les tâches, de la recherche au déploiement. Un petit exemple de captures d'écran du tableau de bord concernant le pipeline est présenté dans la figure suivante.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">Il est très courant d'avoir plusieurs jeux de données dans les référentiels publics et les données privées. En outre, plusieurs versions sont possibles pour chaque jeu de données suite à un nettoyage de jeux de données ou à l'ingénierie des fonctionnalités. Un tableau de bord fournissant un hub de jeux de données et une version Hub est nécessaire pour garantir la disponibilité des outils de collaboration et de cohérence à l'équipe, comme l'illustre la figure suivante.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">L'étape suivante du pipeline est l'entraînement, qui nécessite plusieurs instances parallèles de modèles d'entraînement, chacun associé à un dataset et à une instance de calcul spécifique. La liaison d'un dataset à une certaine instance de calcul est un défi, car il est possible que certaines expériences soient réalisées par des instances GPU d'Amazon Web Services (AWS), tandis que d'autres expériences sont réalisées par des instances DGX-1 ou DGX-2 sur site. D'autres expériences peuvent être exécutées sur des serveurs CPU dans GCP, tandis que l'emplacement du dataset n'est pas à proximité des ressources de calcul lors de l'entraînement. Une proximité raisonnable aurait une connectivité complète 10 GbE ou plus faible latence entre le stockage du dataset et l'instance de calcul.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">Les data Scientists doivent en effet télécharger le dataset sur l'instance de calcul pour effectuer l'entraînement et l'expérience. Toutefois, cette approche peut rencontrer plusieurs problèmes :</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">Lorsque l'analyste de données télécharge le dataset sur une instance de calcul, aucune garantie ne garantit que le stockage de calcul intégré est performant (un exemple de système haute performance serait la solution NVMe de ONTAP AFF A800).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">Lorsque le dataset téléchargé réside dans un nœud de calcul, le stockage peut former un goulot d'étranglement lorsque les modèles distribués sont exécutés sur plusieurs nœuds (contrairement au stockage distribué haute performance NetApp ONTAP).</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">La prochaine itération de l'expérience d'entraînement peut être réalisée dans une autre instance de calcul en raison de conflits ou de priorités de file d'attente, créant ainsi une distance réseau considérable entre le dataset et l'emplacement de calcul.</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">Les autres membres de l'équipe effectuant des expériences de formation sur le même cluster de calcul ne peuvent pas partager ce dataset ; chacun effectue le téléchargement (coûteux) du dataset à partir d'un emplacement arbitraire.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">Si d'autres datasets ou versions du même dataset sont nécessaires pour les tâches d'entraînement ultérieures, les data Scientists doivent de nouveau effectuer le téléchargement (coûteux) du dataset sur l'instance de calcul exécutant les fichiers training.NetApp et cnvrg.io ont créé une nouvelle solution de mise en cache des datasets qui élimine ces obstacles. La solution accélère l'exécution du pipeline DE ML en mettant en cache les datasets fortement sollicités sur le système de stockage hautes performances ONTAP. Avec ONTAP NFS, les datasets sont mis en cache une seule fois dans une structure de données optimisée par NetApp (comme AFF A800), qui est située dans un environnement de calcul. Le stockage ultra-rapide NetApp ONTAP NFS peut servir plusieurs nœuds de calcul DE ML. Résultat : les performances des modèles de formation sont optimisées, ce qui permet à l'entreprise de réaliser des économies, d'améliorer la productivité et d'optimiser l'efficacité opérationnelle.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">Architecture de la solution</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">Cette solution de NetApp et cnvrg.io fournit une mise en cache des datasets, comme l'illustre la figure suivante. La mise en cache des datasets permet aux data Scientists de choisir la version souhaitée du jeu de données ou du dataset et de la déplacer vers le cache NFS ONTAP, qui se trouve à proximité du cluster de calcul DU ML. Le data Scientist peut désormais réaliser plusieurs expériences sans devoir engendrer de retards ou de téléchargements supplémentaires. En outre, tous les ingénieurs collaborant peuvent utiliser le même dataset avec le cluster de calcul associé (avec la liberté de choisir un nœud) sans téléchargements supplémentaires depuis le data Lake. Ils ont également accès à un tableau de bord qui assure le suivi et le contrôle de tous les datasets et versions, et offre une vue des datasets mis en cache.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">La plateforme cnvrg.io détecte automatiquement les datasets obsolètes qui n'ont pas été utilisés depuis un certain temps et les supprime du cache, ce qui conserve l'espace de cache NFS libre pour les datasets plus fréquemment utilisés. Il est important de noter que la mise en cache du dataset avec ONTAP fonctionne dans le cloud et sur site, pour une flexibilité maximale.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">Suivant : concepts et composants</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">Cette section comprend des exemples de tâches haute performance pouvant être exécutées lorsque Kubernetes est déployé sur un pod ONTAP ai.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">Exemple d'tâches hautes performances pour les déploiements d'IA ONTAP</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">Next : exécutez un workload d'IA à un seul nœud.</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">Les solutions NetApp d'intelligence artificielle sont un ensemble de solutions stratégiques et techniques qui démontrent les fonctionnalités du stockage NetApp dans l'ensemble de l'espace d'IA ET DE ML.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">Solutions d'intelligence artificielle NetApp</block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">Cette page décrit les étapes de création d'un sous-réseau délégué pour Azure NetApp Files.</block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="doc">Créez un sous-réseau délégué pour Azure NetApp Files</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">Précédent : installez et configurez le cluster AKS.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Pour créer un sous-réseau délégué pour Azure NetApp Files, effectuez les opérations suivantes :</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Accédez aux réseaux virtuels depuis le portail Azure. Trouvez votre nouveau réseau virtuel. Il doit avoir un préfixe tel que<block ref="a3f69ea034ab8b71fed9b8fc221db9b4" prefix=" " category="inline-code"></block>.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">Cliquez sur le nom du vNet.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">Cliquez sur sous-réseaux et sur +sous-réseau dans la barre d'outils supérieure.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">Indiquez au sous-réseau un nom tel que<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Et, sous l'en-tête délégation de sous-réseau, sélectionnez<block ref="0c20a1ae75c1cc4efae31193e0d47718" prefix=" " category="inline-code"></block>. Ne rien changer. Cliquez sur OK.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Les volumes Azure NetApp Files sont alloués au cluster d'applications et utilisés en tant que demandes de volume persistant dans Kubernetes. Par conséquent, ce processus vous offre la possibilité de les associer à différents services, tels que les ordinateurs portables Jupyter, les fonctions sans serveur, etc.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">Les utilisateurs des services peuvent consommer le stockage depuis la plateforme de différentes manières. Dans ce rapport technique, NFSS, les principaux avantages de Azure NetApp Files sont les suivants :</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">Possibilité d'utiliser des copies Snapshot pour les utilisateurs.</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">Possibilité pour les utilisateurs de stocker d'importants volumes de données sur des volumes Azure NetApp Files.</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">Avantages des performances des volumes Azure NetApp Files lors de l'exécution de modèles sur de vastes ensembles de fichiers.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">Suivant : Peer AKS vnet et Azure NetApp Files vnet.</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="doc">Développez les modèles d'intention à l'aide de la formation Nemo</block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo est un kit conçu par NVIDIA pour créer des applications d'IA conversationnelles. Ce kit comprend des ensembles de modules pré-entraînés pour ASR, NLP et TTS, ce qui permet aux chercheurs et aux scientifiques des données de composer facilement des architectures de réseaux neuronaux complexes et de se concentrer davantage sur la conception de leurs propres applications.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">Comme le montre l'exemple précédent, NARA ne peut traiter qu'un type limité de question. En effet, le modèle NLP pré-formé ne s'entraîne que sur ces types de questions. Si nous voulons permettre À NARA de gérer un plus large éventail de questions, nous devons le réentraîner avec nos propres jeux de données. Ainsi, ici, nous démontrons comment nous pouvons utiliser Nemo pour étendre le modèle NLP pour satisfaire les exigences. Nous commençons par convertir le journal collecté à partir DE NARA dans le format pour Nemo, puis nous entraînons avec le dataset pour améliorer le modèle NLP.</block>
  <block id="a559b87068921eec05086ce5485e9784" category="section-title">Modèle</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">Notre objectif est de permettre À NARA de trier les éléments en fonction des préférences de l'utilisateur. Par exemple, nous pourrions demander À NARA de proposer le restaurant de sushis le mieux noté ou pourrait vouloir NARA chercher les jeans avec le prix le plus bas. À cette fin, nous utilisons le modèle de détection d'intention et de remplissage de fente fourni dans Nemo comme modèle d'entraînement. Ce modèle permet À NARA de comprendre l'intention de la préférence de recherche.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">Préparation des données</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">Pour entraîner le modèle, nous collectons l'ensemble de données pour ce type de question et le convertissons au format Nemo. Ici, nous avons répertorié les fichiers que nous utilisons pour entraîner le modèle.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">Ce fichier liste tous les éléments que nous voulons que le Nemo comprenne. Ici, nous avons deux intentions principales et une intention seulement utilisée pour classer les questions qui ne correspondent à aucune des intentions principales.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">Ce fichier répertorie tous les emplacements que nous pouvons étiqueter sur nos questions de formation.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">train.tsv</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">Il s'agit du dataset d'entraînement principal. Chaque ligne commence par la question qui suit la liste des catégories d'intention dans le fichier dict.intent.csv. L'étiquette est énumérée à partir de zéro.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">train_slots.tsv</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">Entraîner le modèle</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">Nous utilisons ensuite la commande suivante pour lancer le conteneur. Dans cette commande, nous limitons le conteneur à utiliser un seul GPU (ID de processeur graphique = 1), car il s'agit d'un exercice d'entraînement léger. Nous mappons également notre espace de travail local /Workspace/nemo/ vers le dossier à l'intérieur du conteneur /nemo.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">Dans le conteneur, si nous voulons commencer par le modèle original de BERT pré-formé, nous pouvons utiliser la commande suivante pour démarrer la procédure de formation. data_dir est l'argument pour définir le chemin des données d'entraînement. work_dir vous permet de configurer l'emplacement où vous souhaitez stocker les fichiers de point de contrôle.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">Si nous avons de nouveaux datasets d'entraînement et que nous souhaitons améliorer le modèle précédent, nous pouvons utiliser la commande suivante pour continuer à partir du point que nous avons arrêté. checkpoint_dir indique le chemin d'accès au dossier points de contrôle précédent.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">Inférence du modèle</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">Nous devons valider la performance du modèle entraîné après un certain nombre de tests. La commande suivante nous permet de tester la requête un par un. Par exemple, dans cette commande, nous voulons vérifier si notre modèle peut correctement identifier l'intention de la requête<block ref="fe494faf7f8c52514a674b8162027072" prefix=" " category="inline-code"></block>.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">Ensuite, le résultat suivant est le résultat de l'inférence. Dans ce résultat, nous pouvons constater que notre modèle entraîné peut prévoir correctement l'intention Find_the_store et renvoyer les mots-clés qui nous intéressent. Avec ces mots-clés, nous permettons à NARA de rechercher ce que les utilisateurs veulent et de faire une recherche plus précise.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">Suivant: Conclusion</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Exemple d'opérations Trident</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">Cette section comprend des exemples d'opérations que vous pouvez effectuer avec Trident.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">Importer un volume existant</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Si votre système/plateforme de stockage NetApp contient des volumes que vous souhaitez monter sur des conteneurs au sein de votre cluster Kubernetes, mais qui ne sont pas liés aux demandes de volume persistant dans le cluster, vous devez importer ces volumes. Vous pouvez utiliser la fonctionnalité d'importation de volumes Trident pour importer ces volumes.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">Les exemples de commandes ci-dessous montrent l'importation du même volume, nommé<block ref="716577bd9ec46fd219326b2aa7404103" prefix=" " category="inline-code"></block> Deux fois, une fois pour chaque système back-end Trident créé dans l'exemple de la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 1. Si vous importez le même volume deux fois de cette manière, vous pouvez monter le volume (un volume FlexGroup existant) plusieurs fois sur plusieurs LIF, comme décrit dans la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 1. Pour plus d'informations sur les ESV, consultez le<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. Pour plus d'informations sur la fonctionnalité d'importation de volume, reportez-vous à la section<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valeur de<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> Est spécifié dans les fichiers de spécifications PVC d'exemple. Pour plus d'informations sur le<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> voir<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">Exemple de classes de stockage Kubernetes pour les déploiements d'IA ONTAP</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">Les noms de back-end spécifiés dans l'exemple de commandes d'importation suivant correspondent aux Backend créés dans l'exemple de la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 1. Les noms de classes de stockage spécifiés dans les exemples de fichiers de définition de PVC suivants correspondent aux classes de stockage créées dans l'exemple de la section <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, étape 1.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">Provisionner un nouveau volume</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Vous pouvez utiliser Trident pour provisionner un nouveau volume sur votre système ou plateforme de stockage NetApp. L'exemple suivant montre le provisionnement d'un nouveau volume FlexVol. Dans cet exemple, le volume est provisionné à l'aide de la classe de stockage créée dans l'exemple de la section <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, étape 2.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">An<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> valeur de<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> Est spécifié dans l'exemple de fichier de définition de PVC suivant. Pour plus d'informations sur le<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> voir<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">Next : exemple - Présentation des tâches hautes performances pour les déploiements d'IA ONTAP.</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">Un véritable système d'IA et d'échange s'engage dans un dialogue similaire à celui de l'homme, comprend le contexte et propose des réponses intelligentes. Ces modèles d'IA sont souvent énormes et extrêmement complexes. Avec les processeurs graphiques NVIDIA et le stockage NetApp, des modèles linguistiques de pointe peuvent être entraînés et optimisés pour exécuter rapidement l'inférence. C'est une tendance majeure vers la fin du compromis entre un modèle d'IA qui est rapide contre un modèle important et complexe. Les modèles de compréhension du langage optimisés par les GPU peuvent être intégrés aux applications d'IA dans des secteurs tels que la santé, le commerce de détail et les services financiers, permettant ainsi aux assistants numériques avancés dans les enceintes intelligentes et les lignes de services client. Ces systèmes d'IA conversationnels de haute qualité permettent aux entreprises de tous les marchés verticaux de fournir des services personnalisés jusqu'alors inaccessibles lors de l'entretien avec les clients.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis permet le déploiement de cas d'utilisation tels que des assistants virtuels, des avatars numériques, des Fusion de capteur multimodal (CV fusionné avec ASR/NLP/TTS), ou tout cas d'utilisation autonome ASR/NLP/TTS/CV, comme la transcription. Nous avons créé un assistant de vente au détail virtuel qui répond à vos questions concernant la météo, les points d'intérêt et les prix des stocks. Nous avons également démontré comment améliorer la compréhension du langage naturel du système d'IA conversationnel en archivant l'historique des conversations à l'aide de Cloud Sync et en formant les modèles Nemo sur de nouvelles données.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">Technologie de la solution</block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">Configuration matérielle et logicielle requise</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">Cette section présente les exigences technologiques de la solution ONTAP d'IA.</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">Configuration matérielle requise</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">Site Web ONTAP ai</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">Bien que les exigences matérielles dépendent de workloads spécifiques, ONTAP ai peut être déployé à n'importe quelle échelle pour l'ingénierie des données, l'entraînement des modèles et l'inférence de production à partir d'un seul GPU jusqu'à des configurations en rack pour les opérations D'AM/AP à grande échelle. Pour en savoir plus sur ONTAP ai, rendez-vous sur le<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">Cette solution a été validée à l'aide d'un système DGX-1 pour les ressources de calcul, d'un système de stockage NetApp AFF A800 et de Cisco Nexus 3232C pour la connectivité réseau. L'outil AFF A800 utilisé dans cette validation peut prendre en charge jusqu'à 10 systèmes DGX-1 pour la plupart des workloads D'APPRENTISSAGE PROFOND/D'APPRENTISSAGE PROFOND. La figure suivante présente la topologie ONTAP ai utilisée pour l'entraînement des modèles dans cette validation.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">Pour étendre cette solution à un cloud public, Cloud Volumes ONTAP peut être déployé avec des ressources de calcul GPU cloud et intégré dans un environnement Data Fabric de cloud hybride qui permet aux clients d'utiliser les ressources appropriées pour chaque charge de travail.</block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="section-title">Configuration logicielle requise</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">Le tableau suivant indique les versions spécifiques utilisées pour la validation de cette solution.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">SYSTÈME D'EXPLOITATION NVIDIA DGX</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="142f782bb2b326679982208fe40cec31" category="cell">NVIDIA DeepOps</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">Gouvernail</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="cell">cnvrg.io</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">Pour la validation de cette solution, Kubernetes a été déployé en tant que cluster à un seul nœud sur le système DGX-1. Pour les déploiements à grande échelle, des nœuds maîtres Kubernetes indépendants doivent être déployés pour assurer la haute disponibilité des services de gestion et réserver des ressources DGX précieuses pour les workloads DE ML et de DL.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">Ensuite : détails du déploiement et de la validation de la solution</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">Cette solution a été implémentée avec un système NetApp AFF A800, deux serveurs DGX-1 et deux switchs Cisco Nexus 3232C de 100 GbE. Chaque serveur DGX-1 est relié aux switchs Nexus par des liaisons de 100 GbE utilisées pour les communications entre les GPU via le protocole RoCE (RDMA over Converged Ethernet). Les communications IP classiques pour l'accès au stockage NFS s'effectuent également sur ces liaisons. Chaque contrôleur de stockage est relié aux switchs réseau par quatre liaisons de 100 GbE. La figure suivante montre l'architecture de la solution ONTAP ai utilisée dans ce rapport technique pour tous les scénarios de test.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="section-title">Matériel utilisé dans cette solution</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">Cette solution a été validée à l'aide de l'architecture de référence ONTAP ai, deux nœuds DGX-1 et un système de stockage AFF A800. Voir<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> pour plus de détails sur l'infrastructure utilisée dans cette validation.</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">Le tableau suivant répertorie les composants matériels requis pour implémenter la solution testée.</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">Sous-jacent</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">Quantité</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">Systèmes DGX-1</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Switchs Nexus 3232C</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">Cette solution a été validée à l'aide d'un déploiement Kubernetes de base avec l'opérateur Run:ai installé. Kubernetes a été déployé à l'aide du<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> le moteur de déploiement déploie tous les composants nécessaires pour un environnement prêt à la production. Déploiement automatique de DeepOps<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> Pour l'intégration du stockage persistant avec l'environnement k8s et des classes de stockage par défaut ont été créées afin que les conteneurs exploitent le stockage du système de stockage AFF A800. Pour en savoir plus sur Trident avec Kubernetes sur ONTAP ai, rendez-vous sur<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">Le tableau suivant répertorie les composants logiciels requis pour implémenter la solution testée.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">Logiciel</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">Version ou autres informations</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">Le logiciel de gestion des données NetApp ONTAP</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Firmware du switch Cisco NX-OS</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3)I6(1)</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Version Kubernetes</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Version Trident</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">Exécutez :CLI ai</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">Exécution : version de l'opérateur Kubernetes d'orchestration d'IA</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Plateforme de conteneurisation Docker</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1 ce [e68fc7a]</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">Pré-requis pour le cluster de GPU Run:ai</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">D'autres exigences logicielles supplémentaires pour Run:ai sont disponibles à l'adresse<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">Next : une utilisation optimale des clusters et des GPU avec l'exécution d'IA</block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick et David Arnette, NetApp</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">Ce document présente une architecture vérifiée NetApp pour les workloads de machine learning (ML) et d'intelligence artificielle (IA) avec les systèmes de stockage NVMe NetApp EF600, le système de fichiers parallèle ThinkParQ BeeGFS, les systèmes NVIDIA DGX A100 et les switchs NVIDIA Mellanox QM8700 200 Gbit/s InfiniBand (IB). Ce document contient également des instructions pour l'exécution des tests de validation une fois le déploiement terminé.</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">La figure suivante illustre l'architecture du système d'IA proposé. Vous pouvez interagir avec le système avec le signal vocal ou la saisie de texte. Si l'entrée vocale est détectée, Jarvis ai-as-service (AIaaS) exécute ASR pour produire du texte pour Dialog Manager. Dialogue Manager mémorise les États de conversation, achemine le texte vers les services correspondants et transmet les commandes au moteur de traitement. Jarvis NLP Service prend du texte, reconnaît les intentions et les entités, et renvoie ces intentions et slots d'entité au Dialog Manager, qui envoie ensuite action au moteur de traitement. Le moteur d'exécution se compose d'API tierces ou de bases de données SQL qui répondent aux requêtes des utilisateurs. Après réception du résultat du moteur de traitement, le Gestionnaire de dialogue achemine le texte vers Jarvis TTS AIaaS afin de générer une réponse audio pour l'utilisateur final. Nous pouvons archiver l'historique des conversations, annoter des phrases avec des intentions et des slots pour la formation de Nemo, de sorte que le service NLP s'améliore à mesure que davantage d'utilisateurs interagissent avec le système.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">Cette solution a été validée à l'aide d'une station DGX et d'un système de stockage AFF A220. Jarvis requiert un processeur graphique T4 ou V100 pour effectuer des calculs profonds des réseaux neuronaux.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">GPU T4 OU V100</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">Station NVIDIA DGX</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">Structure de NVIDIA Jarvis</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo:v0.10</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">Suivant: Construire un assistant virtuel en utilisant Jarvis, Cloud Sync, et Nemo Aperçu</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">Cette page répertorie les bibliothèques et les structures utilisées pour créer cette tâche. Tous ces composants ont été entièrement intégrés aux contrôles d'accès et de sécurité basés sur les rôles d'Azure.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">Bibliothèques de traitement de données et d'entraînement des modèles</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">Précédent : niveaux de performance de Azure NetApp Files.</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">Le tableau suivant répertorie les bibliothèques et les structures utilisées pour créer cette tâche. Tous ces composants ont été entièrement intégrés aux contrôles d'accès et de sécurité basés sur les rôles d'Azure.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">Bibliothèques/structures</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">Description</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">DMASK cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">Bibliothèque cuML</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">Pour QUE LE ML fonctionne sur le GPU, le<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Donne accès au forfait RAPIDS cuML avec Dask. RAPIDS cuML implémente des algorithmes DE ML courants, notamment la mise en cluster, la réduction de la dimensionnalité et les approches de régression, avec des implémentations basées sur GPU haute performance, offrant des vitesses jusqu'à 100 fois supérieures aux approches basées sur les processeurs.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">DASK cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">bibliothèque dask-cudf</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF inclut diverses autres fonctions prenant en charge l'extraction accélérée par GPU, la transformation, la charge (ETL), telles que la sous-définition de données, les transformations, l'encodage à chaud unique, etc. L'équipe DE RAPIDS a<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> Cela inclut des méthodes d'aide pour utiliser DASK et cuDF.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Apprendre Scikit</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">estimateur</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">ajustement</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn fournit des dizaines d'algorithmes et de modèles d'apprentissage machine intégrés, appelés estimateurs. Chacun<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> peut être installé sur certaines données à l'aide de son<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> méthode.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">Nous avons utilisé deux ordinateurs portables pour construire les pipelines DE ML à des fins de comparaison. L'une est l'approche classique Pandas scikit d'apprentissage et l'autre, une formation distribuée à RAPIDS et DASK. Chaque ordinateur portable peut être testé individuellement pour connaître les performances en termes de temps et d'échelle. Nous recouvrons chaque ordinateur portable individuellement pour démontrer les avantages de la formation distribuée à L'aide DE RAPIDS et DASK.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">Suivant: Charger Criteo cliquez sur Logs Day 15 dans Pandas et former un modèle de forêt aléatoire de scikit.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">Cette page décrit les tâches que vous devez effectuer pour installer et configurer NetApp Trident dans votre cluster Kubernetes.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">Déploiement et configuration de NetApp Trident</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">Cette section décrit les tâches que vous devez effectuer pour installer et configurer NetApp Trident dans votre cluster Kubernetes.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">Avant d'effectuer l'exercice de déploiement décrit dans cette section, nous supposons que vous avez déjà effectué les tâches suivantes :</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Vous disposez déjà d'un cluster Kubernetes opérationnel, et vous exécutez une version de Kubernetes prise en charge par Trident. Pour obtenir la liste des versions prises en charge, reportez-vous à la section<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>.</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Vous disposez déjà d'un dispositif de stockage NetApp, d'une instance Software-defined ou d'un service de stockage cloud, pris en charge par Trident.</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Pour installer et configurer NetApp Trident dans votre cluster Kubernetes, effectuez les tâches suivantes à partir de l'hôte de démarrage du déploiement :</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">Déployez Trident selon l'une des méthodes suivantes :</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Instructions de déploiement de Trident</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">Si vous avez utilisé NVIDIA DeepOps pour déployer votre cluster Kubernetes, vous pouvez également utiliser NVIDIA DeepOps pour déployer Trident dans votre cluster Kubernetes. Pour déployer Trident avec DeepOps, suivez le<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">instructions de déploiement</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">Systèmes back-end</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">Les classes de stockage</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">Si vous n'avez pas utilisé NVIDIA DeepOps pour déployer votre cluster Kubernetes ou si vous préférez simplement déployer Trident manuellement, vous pouvez déployer Trident en suivant les instructions du<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> Dans la documentation Trident. Veillez à créer au moins un système back-end Trident et au moins une classe de stockage Kubernetes pour plus d'informations sur la configuration<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> et<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> Consultez les sous-sections liées dans NetApp Docs.</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">Exemple de Kubernetes Storageclasse pour les déploiements d'IA ONTAP</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">Si vous déployez la solution NetApp ai Control plane sur un pod ONTAP ai, consultez la <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> Pour certains exemples de systèmes back-end Trident, vous pouvez créer et <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> Vous voudrez peut-être créer des exemples de classes de stockage Kubernetes différentes.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">Ensuite, par exemple, Trident systèmes back-end pour les déploiements d'IA de ONTAP.</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Avant de pouvoir utiliser Trident pour provisionner les ressources de stockage de façon dynamique dans votre cluster Kubernetes, vous devez créer une ou plusieurs classes de stockage Kubernetes. Les exemples présentés sur cette page représentent les différents types de classes de stockage que vous pourriez souhaiter créer si vous déployez la solution NetApp ai Control plane sur un pod ONTAP ai.</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Avant de pouvoir utiliser Trident pour provisionner les ressources de stockage de façon dynamique dans votre cluster Kubernetes, vous devez créer une ou plusieurs classes de stockage Kubernetes. Les exemples ci-dessous représentent les différents types de classes de stockage que vous pourriez souhaiter créer si vous déployez la solution NetApp ai Control plane sur un pod ONTAP ai. Pour plus d'informations sur les classes de stockage, consultez le<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp recommande de créer une classe de stockage distincte pour chaque système back-end Trident compatible avec FlexGroup que vous avez créé dans la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 1. Ces classes de stockage granulaire vous permettent d'ajouter des montages NFS qui correspondent à des LIF spécifiques (les LIF que vous avez spécifiées lors de la création des backends Trident) en tant que système back-end spécifique spécifié dans le fichier des spécifications de classe de stockage. Les exemples de commandes qui suivent montrent la création de deux classes de stockage qui correspondent aux deux exemples de backends créés dans la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 1. Pour plus d'informations sur les classes de stockage, consultez le<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Documentation Kubernetes</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">Pour qu'un volume persistant ne soit pas supprimé lorsque la demande de volume persistant correspondante est supprimée, l'exemple suivant utilise une<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> valeur de<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>. Pour plus d'informations sur le<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> consultez le champ officiel<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">NetApp recommande également de créer une classe de stockage correspondant au système back-end Trident activé pour FlexVol que vous avez créé dans la section <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, étape 2. Les exemples de commandes ci-dessous montrent la création d'une classe de stockage unique pour les volumes FlexVol.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">Dans l'exemple suivant, un système back-end particulier n'est pas spécifié dans le fichier de définition StorageClass car un seul système back-end Trident activé pour FlexVol a été créé. Lorsque vous utilisez Kubernetes pour administrer des volumes qui utilisent cette classe de stockage, Trident tente d'utiliser tout back-end disponible qui utilise le<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> conducteur.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">NetApp recommande également de créer une classe de stockage générique pour les volumes FlexGroup. Les exemples de commandes suivants montrent la création d'une classe de stockage générique pour les volumes FlexGroup.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">Notez qu'un back-end particulier n'est pas spécifié dans le fichier de définition de classe de stockage. Par conséquent, lorsque vous utilisez Kubernetes pour gérer des volumes qui utilisent cette classe de stockage, Trident tente d'utiliser tout back-end disponible qui utilise le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> conducteur.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">Next : présentation du déploiement Kubeflow.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">David Arnette et Sung-Han Lin, NetApp</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">La conception NVA-1153 décrit une architecture vérifiée NetApp pour les workloads de machine learning (ML) et d'intelligence artificielle (IA) utilisant les systèmes de stockage NetApp AFF A800, les systèmes NVIDIA DGX A100 et les switchs Ethernet de 200 Go NVIDIA Mellanox Spectrum SN3700V. Cette conception comprend le protocole RDMA over Converged Ethernet (RoCE) pour la structure d'interconnexion des clusters de calcul. Elle offre aux clients une architecture entièrement basée sur ethernet pour les charges de travail haute performance. Ce document inclut également les résultats des tests de performance pour l'architecture mise en œuvre.</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang, Sung-Han Lin, Satish Thyagarajan, NetApp Jacci Cencii, NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">Cette architecture de référence apporte des lignes directrices aux clients du secteur de la santé qui créent des infrastructures d'intelligence artificielle (IA) reposant sur des systèmes NVIDIA DGX-2 et de stockage NetApp AFF. Vous y trouverez des informations sur les workflows généraux utilisés dans le développement de modèles de deep learning (DL) pour l'imagerie diagnostique médicale, des scénarios et des résultats de tests de validation Il inclut également des recommandations de dimensionnement pour les déploiements client.</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link-macro"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">Les sections suivantes décrivent l'installation de Run:ai, les scénarios de test et les résultats obtenus lors de cette validation.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">Le fonctionnement et les performances de ce système ont été validées à l'aide d'outils de test standard du secteur, dont des bancs d'essai TensorFlow. Le dataset ImageNet a été utilisé pour entraîner le modèle ResNet-50, qui est un modèle d'apprentissage profond connu des réseaux neuronaux convolutifs (CNN) pour la classification d'images. RESNET-50 offre des résultats d'entraînement précis avec un temps de traitement plus rapide, ce qui nous a permis d'obtenir une demande suffisante en matière de stockage.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">Ensuite : exécutez l'installation d'IA</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="doc">Détails des tests pour la section 4.9</block>
  <block id="c83553858a60514501e9751c0747dea0" category="inline-link-macro">Équité de l'allocation des ressources de base</block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">Cette section contient des détails sur les tests pour la section <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">Soumettre les travaux dans l'ordre suivant :</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">Projet</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">NB de GPU</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">Total</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">Commentaire</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">équipe-d</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">La charge de travail TEAM-b/c s'interrompt et passe à<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8/8</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">Les autres charges de travail d'équipe (b/c) sont suspendues et transférées vers<block ref="7c6c2e5d48ab37a007cbf70d3ea25fa4" prefix=" " category="inline-code"></block>.</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">Voir la séquence de commande exécutée suivante :</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">À ce stade, vous devez avoir les États suivants :</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU alloués</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">Charges de travail en file d'attente</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">équipe a</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4/4</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">Aucune</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">équipe-b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2/2</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">equipe-c</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">Voir la section <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> pour une discussion sur le scénario de test en cours.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">Suivant : détails des tests pour la section 4.10</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">Optimiser l'utilisation des clusters</block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="inline-link-macro">RESNET-50 avec résumé du banc d'essai ImageNet sur le dataset</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">Dans cette section, nous émulons un scénario réaliste dans lequel quatre équipes de data science soumettent leurs propres charges de travail pour présenter la solution d'orchestration Run:ai qui optimise l'utilisation des clusters, tout en maintenant les niveaux de priorité et l'équilibrage des ressources GPU. Nous commençons par le banc d'essai ResNet-50 décrit dans la section <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">Nous avons exécuté le même banc d'essai ResNet-50 que dans<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. Nous avons utilisé le drapeau<block ref="f4fdcbb99cb8e39e4706115c80cb3968" prefix=" " category="inline-code"></block> pour les conteneurs qui ne résident pas dans le référentiel docker public. Nous avons monté les répertoires<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> et<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> Sur le nœud hôte DGX-1 vers<block ref="39de0dbcfb68c8735bd088c62fa061a4" prefix=" " category="inline-code"></block> et<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> vers le conteneur, respectivement. Le dataset est disponible dans le système NetApp AFFA800 avec le<block ref="a64503025c7495ecf42633d117f8b536" prefix=" " category="inline-code"></block> argument pointant vers le répertoire. Les deux<block ref="96dbae4bbcb6841c17bc66f858d93982" prefix=" " category="inline-code"></block> et<block ref="a78db0f035a543e24e7b038d359b5e74" prefix=" " category="inline-code"></block> Cela signifie que nous allouez un GPU pour ce travail. Le premier est un argument pour le<block ref="6e38f16215ae91c11fc5c54b74c66d54" prefix=" " category="inline-code"></block> script, tandis que ce dernier est un indicateur pour le<block ref="7897d57a96444dff260ef2bf8a0589b1" prefix=" " category="inline-code"></block> commande.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">La figure ci-dessous montre un tableau de bord de présentation du système avec un taux d'utilisation des GPU de 97 % et les seize GPU disponibles alloués. Vous pouvez consulter le nombre de GPU alloués à chaque équipe dans le graphique à barres projet/GPU. Le volet travaux en cours affiche les noms des travaux en cours d'exécution, le projet, l'utilisateur, le type, le nœud, GPU utilisés, temps d'exécution, progression et informations d'utilisation. Une liste des charges de travail en file d'attente avec leur temps d'attente est affichée dans tâches en attente. Enfin, la zone nœuds fournit les nombres de GPU et l'utilisation de nœuds DGX-1 individuels dans le cluster.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">Ensuite : allocation fractionnelle des GPU pour des charges de travail moins exigeantes ou interactives</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">Cette section décrit les procédures de test utilisées pour valider cette solution.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">Procédure de test</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">Précédent : test de la configuration.</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">Nous avons utilisé la procédure de test suivante pour cette validation.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">Installation du système d'exploitation et de l'inférence d'IA</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">code</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">Pour la baie AFF C190, nous avons utilisé Ubuntu 18.04 avec les pilotes NVIDIA et docker avec la prise en charge des GPU NVIDIA et MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Disponible dans le cadre de la soumission Lenovo à MLPerf Inférence v0.7.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">Pour l'EF280, nous avons utilisé Ubuntu 20.04 avec les pilotes NVIDIA et docker avec prise en charge des GPU NVIDIA et MLPerf<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Disponible dans le cadre de la soumission Lenovo à MLPerf Inférence v1.1.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">Pour configurer l'inférence d'IA, procédez comme suit :</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">Téléchargez les datasets qui nécessitent un enregistrement, le jeu de validation ImageNet 2012, le jeu de données Criteo Terabyte et brats 2019 Training Set, puis décompressez les fichiers.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">Créez un répertoire de travail d'au moins 1 To et définissez une variable d'environnement<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> se référant au répertoire.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">Vous devez partager ce répertoire sur le stockage partagé pour le cas d'utilisation du stockage réseau ou sur le disque local lors des tests avec des données locales.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">Exécuter la marque<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> commande, qui crée et lance le conteneur docker pour les tâches d'inférence requises.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">Les commandes suivantes sont toutes exécutées depuis le conteneur Docker en cours d'exécution :</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">Télécharger les modèles d'IA pré-entraînés pour les tâches d'inférence MLPerf :<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">Téléchargez des datasets supplémentaires qui peuvent être téléchargés librement :<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">Prétraiter les données : marque<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">Exécuter :<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block>.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">Création de moteurs d'inférence optimisés pour les GPU dans les serveurs de calcul :<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">Pour exécuter des workloads Inférence, exécutez les éléments suivants (une commande) :</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">L'inférence d'IA s'exécute</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">Trois types de passages ont été exécutés :</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">Inférence d'IA à un seul serveur avec le stockage local</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">Inférence d'IA à un serveur unique avec le stockage réseau</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">Inférence d'IA à plusieurs serveurs à l'aide d'un stockage réseau</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">Suivant : résultats du test.</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Créez un assistant virtuel en utilisant Jarvis, Cloud Sync et Nemo</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">Suivant: Construire un assistant virtuel en utilisant Jarvis, Cloud Sync, et Nemo Aperçu</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">Dans cette section, quand nous le montrons<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block> Lorsque plusieurs GPU sont en attente (ils sont sous leur quota), le système interrompt les charges de travail de<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> et les déplace dans un état en attente de façon équitable.</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">Pour plus de détails, y compris les soumissions de travaux, les images de conteneur utilisées et les séquences de commandes exécutées, reportez-vous à la section <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">La figure suivante montre l'utilisation du cluster résultant, les GPU alloués par équipe et les tâches en attente dus à l'équilibrage de la charge automatique et à la planification préventive. Nous pouvons observer que lorsque le nombre total de GPU requis par toutes les charges de travail d'équipe dépasse le nombre total de GPU disponibles dans le cluster, l'algorithme d'équité interne de Run:ai interrompt chaque tâche pour<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> parce qu'ils ont atteint leur quota de projet. Cela assure, de manière générale, l'utilisation élevée des clusters et les équipes de data Scientists restent contraintes pour les ressources définies par un administrateur.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">Les résultats de ce scénario de test démontrent ce qui suit :</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">*Équilibrage automatique de la charge.* le système équilibre automatiquement le quota des GPU, de sorte que chaque équipe utilise maintenant son quota. Les charges de travail suspendues appartiennent à des équipes qui ont terminé leur quota.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">*Pause de partage équitable.* le système choisit d'arrêter la charge de travail d'une équipe qui a surpassé leur quota et de mettre fin à la charge de travail de l'autre équipe. Exécutez :l'IA dispose d'algorithmes d'équité internes.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">Suivant : équité excessive</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">Cette section offre un aperçu des trois scénarios validés dans cette solution.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">Plan de test et de validation</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">Précédent : présentation de la technologie.</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">Pour cette conception de la solution, les trois scénarios suivants ont été validés :</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Une tâche d'inférence, avec et sans projet d'obfuscation Protopia, dans un espace de travail JupyterLab orchestré à l'aide du kit d'outils NetApp DataOps pour Kubernetes.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Une tâche d'inférence par lot, avec et sans objetProtopia obfuscation, sur Kubernetes avec un volume de données orchestré à l'aide du kit d'outils NetApp DataOps pour Kubernetes.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Une tâche d'inférence avec une instance de serveur NVIDIA Triton Inférence orchestrée avec le kit d'outils NetApp DataOps pour Kubernetes. Nous avons appliqué l'obfuscation Protopia à l'image avant d'appeler l'API d'inférence Triton pour simuler l'exigence commune selon laquelle les données transmises sur le réseau doivent être brouillées. Ce workflow s'applique aux cas où les données sont collectées dans une zone de confiance mais doivent être transférées en dehors de cette zone de confiance pour l'inférence. Sans l'obfuscation Protopia, il n'est pas possible d'implémenter ce type de flux de travail sans données sensibles quittant la zone de confiance.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">Suivant : test de la configuration.</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">Récapitulatif</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">Plusieurs scénarios d'applications émergents, tels que les systèmes d'assistance à la conduite automobile (ADAS), le concept d'industrie 4.0, les Smart cities et l'Internet des objets (IoT), requièrent le traitement des flux de données en continu avec une latence quasi nulle. Ce document présente une architecture de calcul et de stockage permettant de déployer l'inférence d'intelligence artificielle (IA) basée sur les processeurs graphiques sur des contrôleurs de stockage NetApp et des serveurs Lenovo ThinkSystem dans un environnement en périphérie qui répond à ces exigences. Ce document fournit également des données de performance pour le banc d'essai MLPerf Inférence standard, en évaluant diverses tâches d'inférence sur des serveurs de périphérie équipés de processeurs graphiques NVIDIA T4. Nous examinons les performances des scénarios d'inférence hors ligne, à flux unique et à flux multiples. Nous montrons également que l'architecture associée à un système de stockage en réseau partagé économique est hautement performante et qu'elle constitue un point central pour la gestion des données et des modèles pour les serveurs de périphérie multiples.</block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">Comme mentionné dans la section précédente, les erreurs sont propagées dans l'ensemble du pipeline chaque fois qu'au moins deux modèles d'apprentissage machine sont exécutés dans l'ordre. Pour cette solution, le sentiment de la phrase est le facteur le plus important dans la mesure du niveau de risque stock de l’entreprise. Le modèle de parole à texte, bien qu'essentiel au pipeline, sert d'unité de prétraitement avant que les sentiments ne puissent être prédits.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">Résultats de la validation</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">Précédent : déploiement de l'analyse des sentiments du centre de support.</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">Comme mentionné dans la section précédente, les erreurs sont propagées dans l'ensemble du pipeline chaque fois qu'au moins deux modèles d'apprentissage machine sont exécutés dans l'ordre. Pour cette solution, le sentiment de la phrase est le facteur le plus important dans la mesure du niveau de risque stock de l’entreprise. Le modèle de parole à texte, bien qu'essentiel au pipeline, sert d'unité de prétraitement avant que les sentiments ne puissent être prédits. Ce qui compte vraiment, c'est la différence de sentiment entre les phrases de vérité au sol et les phrases prévues. Cela sert de proxy pour le taux d'erreur de mot (WER). La précision de la parole au texte est importante, mais le WER n'est pas directement utilisé dans la mesure finale du pipeline.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">Ces mesures de sentiment peuvent être calculées pour le score F1, le rappel et la précision de chaque phrase. Les résultats peuvent ensuite être agrégés et affichés dans une matrice de confusion, ainsi que les intervalles de confiance pour chaque mesure.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">L'apprentissage par transfert améliore les performances des modèles pour une fraction des besoins de données, des délais d'entraînement et des coûts. Les modèles optimisés doivent également être comparés à leurs versions de base afin de garantir que l'apprentissage par transfert améliore les performances au lieu de l'associer. En d'autres termes, le modèle affinée doit optimiser les performances des données de centre de support par rapport au modèle pré-entraînés.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">Évaluation du pipeline</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">Cas de test</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">Numéro de test</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">Mesure du sentiment du pipeline</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">Conditions préalables au test</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">Modèles optimisés pour les modèles d'analyse de la voix au texte et des sentiments</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">Résultat attendu</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">La mesure de sentiment du modèle affinée est plus performante que le modèle pré-pré-pré-entraînés d'origine.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">Calculez la mesure du sentiment pour le modèle de référence.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">Calculez la mesure du sentiment pour le modèle affinée.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">Calculez la différence entre ces mesures.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">Faire la moyenne des différences entre toutes les phrases.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">Suivant : vidéos et démonstrations.</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">Plan de contrôle pour l'IA de NetApp :</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">Rapport technique sur le plan de contrôle d'IA de NetApp</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">Le stockage persistant NetApp pour les conteneurs :</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">Structure ET outils ML :</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow : un framework d'apprentissage machine open source pour tous<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="list-text">Docker</block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="list-text">Kubeflow</block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="inline-link"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter Notebook Server</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="inline-link"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Plateforme Iguazio pour la science des données</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Documentation de la plateforme Iguazio pour la science des données</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Fonction sans serveur Nucio</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun : framework d'orchestration du pipeline open source</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">Systèmes NVIDIA DGX-1</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="inline-link"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">GPU NVIDIA Tesla V100 à cœurs Tensor</block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU Cloud</block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">Fiche technique AFF</block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">Avantages Flash de NetApp pour AFF</block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">Documentation ONTAP 9.x.</block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">Rapport technique NetApp FlexGroup</block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et connectivité réseau Cisco</block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">Guide de déploiement d'ONTAP ai avec DGX-1 et réseau Cisco</block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et réseau Mellanox</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">La connectivité réseau d'ONTAP ai</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Switchs de la gamme Cisco Nexus 3232C</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="inline-link"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Gamme de commutateurs Ethernet SN2000 à évolutivité horizontale Mellanox</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">Cette section décrit les tâches à effectuer pour déployer l'air dans votre cluster Kubernetes.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Déploiement du flux d'air Apache</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">NetApp recommande d'exécuter le flux d'air Apache sur Kubernetes. Cette section décrit les tâches à effectuer pour déployer l'air dans votre cluster Kubernetes.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Il est possible de déployer du flux d'air sur d'autres plateformes que Kubernetes. Le déploiement de flux d'air sur des plateformes autres que Kubernetes ne fait pas partie du cadre de cette solution.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Vous disposez déjà d'un cluster Kubernetes fonctionnel.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">Vous avez déjà installé et configuré NetApp Trident dans votre cluster Kubernetes comme décrit dans la section « déploiement et configuration de NetApp Trident ».</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Installer Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">instructions d'installation</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Le flux d'air est déployé à l'aide de Helm, un gestionnaire de packages populaire pour Kubernetes. Avant de déployer le flux d'air, vous devez installer Helm sur l'hôte de démarrage à déploiement rapide. Pour installer Helm sur l'hôte de saut de déploiement, suivez le<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> Dans la documentation officielle Helm.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">Définissez la classe de stockage Kubernetes par défaut</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Déploiement Kubeflow</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">Avant de déployer le flux d'air, vous devez désigner une classe de stockage par défaut dans votre cluster Kubernetes. Le processus de déploiement du flux d'air tente de provisionner de nouveaux volumes persistants à l'aide de la classe de stockage par défaut. Si aucune classe de stockage n'est désignée comme classe de stockage par défaut, le déploiement échoue. Pour désigner une classe de stockage par défaut au sein de votre cluster, suivez les instructions de la section <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. Si vous avez déjà désigné une classe de stockage par défaut dans votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Utilisez Helm pour déployer le flux d'air</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Pour déployer le flux d'air dans votre cluster Kubernetes à l'aide de Helm, effectuez les tâches suivantes à partir de l'hôte saut de déploiement :</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Déployer le flux d'air à l'aide de Helm en suivant le<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Pour le tableau de débit d'air officiel sur le concentrateur d'artefacts. Les exemples de commandes qui suivent montrent le déploiement du flux d'air à l'aide de Helm. Modifiez, ajoutez et/ou supprimez des valeurs dans<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> fichier selon votre environnement et la configuration de votre choix.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">Assurez-vous que tous les modules de ventilation sont opérationnels. Le démarrage des modules peut prendre quelques minutes.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">Pour obtenir l'URL du service Web de flux d'air, suivez les instructions qui ont été imprimées sur la console lorsque vous avez déployé du flux d'air à l'aide de Helm à l'étape 1.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Confirmez que vous pouvez accéder au service Web de débit d'air.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">Suivant : exemple de flux de production du flux d'air Apache.</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">Présentation de NetApp</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp est la référence en matière de gestion des données dans le cloud hybride NetApp propose une gamme complète de services qui simplifient la gestion des applications et des données dans les environnements cloud et sur site afin d'accélérer la transformation digitale. Avec ses partenaires, NetApp permet aux entreprises d'envergure mondiale d'exploiter tout le potentiel de leurs données afin de multiplier les points de contact avec les clients, de favoriser l'innovation et d'optimiser leurs opérations.</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NetApp ONTAP ai, optimisé par les systèmes NVIDIA DGX et le stockage 100 % Flash connecté au cloud NetApp, rationalise le flux des données en toute fiabilité et accélère l'analytique, l'entraînement et l'inférence avec votre Data Fabric qui s'étend de la périphérie, au cœur jusqu'au cloud. Et présente plusieurs avantages pour les services IT :</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">Simplifie la conception</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">Offre une évolutivité indépendante des ressources de calcul et de stockage</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">Possibilité de faire évoluer de manière fluide une infrastructure initiale de petite taille</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">NetApp ONTAP ai propose toute une gamme d'options de stockage pour répondre à différents besoins de performance et de costesNetApp ai propose des piles d'infrastructure convergée intégrant NVIDIA DGX-1, un système d'IA à l'échelle du pétaflop, et des switchs Ethernet haute performance NVIDIA Mellanox pour unifier les workloads d'IA, simplifier le déploiement et accélérer le retour sur investissement. Nous avons utilisé ONTAP ai avec un DGX-1 et un système de stockage NetApp AFF A800 pour obtenir ce rapport technique. L'image suivante montre la topologie de ONTAP ai avec le système DGX-1 utilisé dans cette validation.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">Plan de contrôle d'IA NetApp</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">NetApp ai Control plane vous permet de libérer le potentiel de l'IA et DE L'AM avec une solution qui offre une évolutivité extrême, des déploiements rationalisés et une disponibilité continue des données. La solution ai Control plane intègre Kubernetes et Kubeflow avec une Data Fabric NetApp. Kubernetes, la plateforme standard d'orchestration de conteneurs pour les déploiements cloud, assure l'évolutivité et la portabilité des workloads. Kubeflow est une plateforme de machine learning open-source qui simplifie la gestion et les déploiements, et permet aux développeurs d'optimiser leurs activités de data science. Une Data Fabric NetApp fournit une disponibilité et une portabilité optimales des données pour s'assurer que vos données sont accessibles dans l'ensemble du pipeline, de la périphérie au cœur et jusqu'au cloud. Ce rapport technique utilise le plan de contrôle NetApp ai dans un pipeline MLRun. L'image suivante présente la page de gestion de cluster Kubernetes dans laquelle vous pouvez avoir des terminaux différents pour chaque cluster. Nous avons connecté des volumes persistants NFS au cluster Kubernetes. Les images suivantes montrent un volume persistant connecté au cluster, où<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> offre une prise en charge du stockage persistant et des fonctionnalités de gestion des données.</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Vue d'ensemble d'Iguazio</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform est une plateforme de services en tant que service (PaaS) entièrement intégrée et sécurisée qui simplifie le développement, accélère les performances, facilite la collaboration et répond aux défis opérationnels. Cette plate-forme intègre les composants suivants, et la plate-forme Iguazio pour la science des données est présentée dans l'image suivante :</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Un atelier Data-science qui comprend des ordinateurs portables Jupyter, des moteurs d'analyse intégrés et des solutions Python</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">Gestion des modèles avec suivi des expériences et fonctionnalités de pipeline automatisées</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">Gérer des données et des services DE ML sur un cluster Kubernetes évolutif</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nucio, une structure de fonctions sans serveur en temps réel</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">Couche de données extrêmement rapide et sécurisée qui prend en charge SQL, NoSQL, les bases de données de séries chronologiques, les fichiers (objets simples) et la diffusion en continu</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">Intégration avec les bases de données tierces telles que NetApp, Amazon S3, HDFS, SQL et les protocoles de streaming ou de messagerie</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Tableaux de bord en temps réel basés sur Grafana</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">Ensuite : configuration logicielle et matérielle requise</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et sites web.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">Informations supplémentaires</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web :</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">Jeu de données : simple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">Architecture de réseau d'apprentissage profond : réseau neuronal spatial</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">Framework de formation d'apprentissage profond distribué : Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">EXÉCUTION : solution d'orchestration de conteneurs d'IA : EXÉCUTION : présentation d'un produit d'IA</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">EXÉCUTION : documentation d'installation d'IA</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">Soumission des tâches EN COURS D'EXÉCUTION : interface de ligne de commande d'IA</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Ressources cloud Azure : Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Service Azure Kubernetes</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Références de machines virtuelles Azure</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">Machine virtuelle Azure avec références de processeurs graphiques</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">Data Fabric optimisée par NetApp</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">Documentation produit NetApp</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">Exécutez :plateforme d'IA pour l'orchestration des workloads d'IA</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">Accélération du time-to-innovation. Par l'utilisationRun:IA : mise en pool de ressources, mise en file d'attente et mécanismes de priorisation associés au système de stockage NetApp, les chercheurs ne sont plus aux casse-tête de la gestion de l'infrastructure et peuvent se concentrer exclusivement sur la science des données. Exécution :les clients qui possèdent des solutions d'IA et NetApp augmentent la productivité en exécutant autant de workloads que nécessaire, sans goulot d'étranglement au niveau du calcul ou du pipeline de données.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">Une productivité accrue de l'équipe. Exécution :les algorithmes d'équité d'IA garantissent que tous les utilisateurs et toutes les équipes bénéficient du partage plus équitable des ressources. Les stratégies relatives aux projets prioritaires peuvent être prédéfinies et la plateforme permet d'allouer des ressources de manière dynamique d'une équipe utilisateur à l'autre, ce qui aide les utilisateurs à accéder rapidement aux ressources GPU convoitées.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">Amélioration du taux d'utilisation des GPU. Le planificateur Run:ai permet aux utilisateurs d'utiliser facilement des GPU fractionnaires, des GPU entiers et plusieurs nœuds de GPU pour l'entraînement distribué sur Kubernetes. De cette façon, les workloads d'IA s'exécutent en fonction des besoins, et non pas de la capacité. Les équipes de data Scientists sont en mesure d'exécuter davantage d'expériences d'IA sur la même infrastructure.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">Suivant : technologie de la solution</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">Le traitement numérique de l'image présente de nombreux avantages, permettant ainsi à de nombreuses entreprises d'exploiter au mieux les données associées aux représentations visuelles. Cette solution NetApp et Protopia propose une conception unique d'inférence d'IA pour protéger et privatiser les données d'IA/ML tout au long du cycle de vie DU ML/DL. Il permet aux clients de conserver la propriété des données sensibles, d'utiliser des modèles de déploiement de cloud public ou hybride pour l'évolutivité et l'efficacité en allégeant les problèmes de confidentialité et en déployant l'inférence d'IA à la périphérie.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="doc">Domaines de solutions</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">Précédent : présentation.</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">Intelligence environnementale</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">Il existe de nombreuses façons dont les industries peuvent tirer parti de l'analyse géospatiale dans les domaines des dangers environnementaux. Les gouvernements et le ministère des travaux publics peuvent obtenir des renseignements exploitables sur la santé publique et les conditions météorologiques afin de mieux conseiller le public lors d'une pandémie ou d'une catastrophe naturelle comme les incendies de forêt. Par exemple, vous pouvez identifier un patient COVID-positif dans les espaces publics, tels que les aéroports ou les hôpitaux, sans compromettre la confidentialité de la personne concernée et avertir les autorités respectives et le public à proximité de ces mesures de sécurité.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">Les dispositifs de bord sont wearables</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">Dans l'armée et sur les champs de bataille, vous pouvez utiliser l'inférence d'IA sur la périphérie comme dispositifs portables pour suivre la santé des soldats, surveiller le comportement des conducteurs et alerter les autorités sur la sécurité et les risques associés à l'approche des véhicules militaires tout en préservant et en protégeant la vie privée des soldats. L'avenir de l'armée passe en haute technologie avec l'Internet des objets du champ de bataille (IoBT) et l'Internet des objets militaires (IoMT) pour des engins de combat portables qui aident les soldats à identifier leurs ennemis et à réaliser de meilleures performances dans les combats grâce à l'informatique de pointe rapide. La protection et la préservation des données visuelles collectées depuis des appareils en périphérie tels que les drones et les équipements portables sont essentielles pour que les pirates et l'ennemi soit à la hauteur.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">Opérations d'évacuation sans combattant</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">Les opérations d'évacuation des non-combattants (ONE) sont menées par le DoD pour aider à l'évacuation des citoyens et des ressortissants américains, du personnel civil DoD et des personnes désignées (pays hôte (HN) et des ressortissants de pays tiers (AMT) dont la vie est en danger pour un refuge sûr approprié. Les contrôles administratifs en place utilisent en grande partie les processus de dépistage manuel des évacuées. Cependant, l'exactitude, la sécurité et la rapidité de l'identification des données évacuées, du suivi des évacués et du filtrage des menaces peuvent être améliorées via des outils d'IA/DE ML hautement automatisés combinés aux technologies d'obfuscation vidéo d'IA et DE ML.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">Santé et recherche biomédicale</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">Le traitement des images est utilisé pour diagnostiquer des pathologies à des fins de planification chirurgicale à partir d'images 3D issues d'une tomographie informatisée (TI) ou d'une imagerie par résonance magnétique (IRM). Les règles de confidentialité HIPAA régissent la façon dont les données doivent être collectées, traitées et effacées par les entreprises pour toutes les données personnelles et images numériques, telles que les photographies. Pour que les données puissent être partagées conformément aux réglementations HIPAA Safe Harbor, les images photographiques en plein visage et les images comparables doivent être supprimées. Les techniques automatisées telles que la déidentification ou le décapage du crâne utilisées pour masquer les caractéristiques faciales d'un individu provenant d'images TDM/RM structurelles sont devenues un élément essentiel du processus de partage des données pour les établissements de recherche biomédicale.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">Migration vers le cloud de l'analytique d'IA/DE ML</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">protection des données</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">Les clients grands comptes ont traditionnellement entraîné et déployé des modèles d'IA/ML sur site. Pour des raisons d'évolutivité et d'efficacité, ces clients étendent leurs fonctions d'IA/ML aux déploiements dans un cloud public, hybride ou multicloud. Mais elles sont liées aux données qui peuvent être exposées à d'autres infrastructures. Les solutions NetApp répondent à l'ensemble des menaces de cybersécurité requises<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> Enfin, lorsqu'elle est associée à la transformation des données Protopia, l'évaluation de la sécurité a réduit les risques associés à la migration de workloads d'IA/DE ML d'images vers le cloud.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">Tr-4886 inférence d'IA à la périphérie</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">L'intelligence contre la confidentialité</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">Pour en savoir plus sur les champs d'application du calcul en périphérie et de l'inférence d'IA dans d'autres secteurs, consultez la page<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> Et le blog NetApp ai,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>.</block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">Suivant : présentation de la technologie.</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="doc">Détails des tests pour la section 4.8</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="inline-link-macro">Une utilisation élevée des clusters grâce à une allocation GPU sur-quota</block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">Cette section contient les détails des tests de la section <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">Image</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">NetApp</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2/4</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">Exécutez :ai</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">Utiliser tous leurs quotas</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">GPU fractionnaires</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4/2</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">Deux sur le quota</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">0.8/2</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3/2</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">Un au-delà des quotas</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">4/8</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">Utilisant la moitié de leur quota</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">Structure de commande :</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">Séquence de commande réelle utilisée lors du test :</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4 (quota mou/allocation réelle)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Optimiser l'utilisation des clusters grâce à l'allocation GPU sur-organismes</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">Voir la section <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> pour les discussions sur le scénario de test en cours.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">Suivant : détails des tests pour la section 4.9</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">Avec le déploiement d'ONTAP ai</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-DEPLOY : NetApp ONTAP ai, optimisé par NVIDIA</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">Le déploiement de ONTAP ai nécessite l'installation et la configuration du matériel de réseau, de calcul et de stockage. Ce rapport n'a pas pour objectif d'obtenir des instructions spécifiques pour le déploiement de l'infrastructure d'IA d'ONTAP, Pour des informations détaillées sur le déploiement, reportez-vous à la section<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">Pour la validation de cette solution, un volume unique a été créé et monté sur le système DGX-1. Ce point de montage a ensuite été monté sur les conteneurs pour faciliter l'accès aux données pour l'entraînement. Pour les déploiements à grande échelle, NetApp Trident automatise la création et le montage des volumes de manière à éliminer les surcharges administratives et à permettre la gestion des ressources des utilisateurs finaux.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">Suivant : déploiement Kubernetes</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">Cette page décrit les tâches à effectuer pour déployer Kubeflow dans votre cluster Kubernetes.</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">Cette section décrit les tâches à effectuer pour déployer Kubeflow dans votre cluster Kubernetes.</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Documentation officielle Kubeflow</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Vous disposez déjà d'un cluster Kubernetes opérationnel, et vous exécutez une version de Kubernetes prise en charge par Kubeflow. Pour obtenir la liste des versions prises en charge, reportez-vous à la section<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Déploiement et configuration de Trident</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">Vous avez déjà installé et configuré NetApp Trident dans votre cluster Kubernetes, comme indiqué dans la <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Avant de déployer Kubeflow, vous devez désigner une classe de stockage par défaut dans votre cluster Kubernetes. Le processus de déploiement Kubeflow tente de provisionner de nouveaux volumes persistants à l'aide de la classe de stockage par défaut. Si aucune classe de stockage n'est désignée comme classe de stockage par défaut, le déploiement échoue. Pour désigner une classe de stockage par défaut dans votre cluster, effectuez la tâche suivante à partir de l'hôte de démarrage du déploiement. Si vous avez déjà désigné une classe de stockage par défaut dans votre cluster, vous pouvez ignorer cette étape.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">Désignez une des classes de stockage existantes comme classe de stockage par défaut. Les exemples de commandes ci-dessous montrent la désignation d'une classe de stockage nommée<block ref="b3e01914c123afcd317121eb293386c4" prefix=" " category="inline-code"></block> Comme classe de stockage par défaut.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">Le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Le type de volume interne Trident a une taille de volume persistant minimale et est relativement élevée. Par défaut, Kubeflow tente de provisionner des demandes de volume qui n'ont que quelques Go. Par conséquent, vous ne devez pas désigner une classe de stockage utilisant le<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Taper back-end comme classe de stockage par défaut pour le déploiement Kubeflow.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">Utilisez NVIDIA DeepOps pour déployer Kubeflow</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NetApp recommande d'utiliser l'outil de déploiement Kubeflow qui est fourni par NVIDIA DeepOps. Pour déployer Kubeflow dans votre cluster Kubernetes à l'aide de l'outil de déploiement DeepOps, effectuez les tâches suivantes à partir de l'hôte de démarrage du déploiement.</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">Vous pouvez également déployer Kubeflow manuellement en suivant les options<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> Dans la documentation officielle Kubeflow</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Instructions de déploiement Kubeflow</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">Déployez Kubeflow dans votre cluster en suivant les options<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">Notez l'URL du tableau de bord Kubeflow que fournit l'outil de déploiement DeepOps Kubeflow.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Vérifier que tous les pods déployés dans l'espace de noms Kubeflow affichent un<block ref="5f241c8c8f985b3c51e05d39cf030f4c" prefix=" " category="inline-code"></block> de<block ref="5bda814c4aedb126839228f1a3d92f09" prefix=" " category="inline-code"></block> et assurez-vous qu'aucun composant déployé dans le namespace n'est à l'état d'erreur. Le démarrage des modules peut prendre plusieurs minutes.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">Dans votre navigateur web, accédez au tableau de bord central Kubeflow en accédant à l'URL que vous avez notée à l'étape 2.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">Le nom d'utilisateur par défaut est<block ref="e0fb0c8707d7da1341e171401e7c9e14" prefix=" " category="inline-code"></block>, et le mot de passe par défaut est<block ref="ed2b1f468c5f915f3f1cf75d7068baae" prefix=" " category="inline-code"></block>. Pour créer d'autres utilisateurs, suivez les instructions de la section<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">Ensuite, exemple Kubeflow Operations and Tasks.</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">Démonstration de NetApp Retail Assistant</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">ce lien</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">Nous avons enregistré une vidéo de démonstration de l'Assistant vente au détail NetApp (NARA). Cliquez sur<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> pour ouvrir la figure suivante et lire la démonstration vidéo.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">Ensuite, utilisez NetApp Cloud Sync pour archiver l'historique des conversations</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run ai s'est associé pour créer ce rapport technique afin de présenter les fonctionnalités uniques de Azure NetApp Files avec la plateforme D'IA EN COURS D'EXÉCUTION afin de simplifier l'orchestration des workloads d'IA.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp et EXÉCUTION : l'IA se sont associées à la création de ce rapport technique pour présenter les fonctionnalités uniques de Azure NetApp Files et DE L'EXÉCUTION : une plateforme d'IA qui simplifie l'orchestration des workloads d'IA. Ce rapport technique fournit une architecture de référence pour rationaliser le processus des pipelines de données et de l'orchestration de la charge de travail pour la formation sur la détection de voies distribuées.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">En conclusion, en ce qui concerne la formation distribuée à grande échelle (notamment dans un environnement de cloud public), le composant d'orchestration et de stockage des ressources est essentiel à la solution. S'assurer que la gestion des données n'entrave pas le traitement plusieurs GPU, ce qui optimise l'utilisation des cycles GPU. Ainsi, le système est aussi rentable que possible à des fins de formation distribuée à grande échelle.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">La Data Fabric fournie par NetApp relève le défi en permettant aux data Scientists et aux ingénieurs de données de se connecter sur site et dans le cloud à des données synchrones, sans aucune intervention manuelle. En d'autres termes, la Data Fabric opère en douceur pour gérer les workflows d'IA répartis sur plusieurs sites. Cette solution facilite également la disponibilité des données à la demande en rapprochant les données de calcul et en exécutant des opérations d'analyse, d'entraînement et de validation, quand et où vous en avez besoin. Cette fonctionnalité permet non seulement l'intégration des données, mais aussi la protection et la sécurité de l'ensemble du pipeline de données.</block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA ai Enterprise est une suite complète de logiciels d'IA et d'analytique cloud, optimisée pour que chaque entreprise puisse réussir avec l'IA.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA ai Enterprise avec NetApp et VMware</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">Pour les architectes ET les administrateurs IT, les outils d'IA peuvent être complexes et peu familiers. En outre, beaucoup de plateformes d'IA ne sont pas prêtes pour l'entreprise. La solution NVIDIA ai Enterprise, optimisée par NetApp et VMware, a été créée pour fournir une architecture d'IA rationalisée et haute performance.</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA ai Enterprise est une suite logicielle cloud complète d'IA et d'analytique de données optimisée, certifiée et prise en charge par NVIDIA pour s'exécuter sur VMware vSphere avec les systèmes NVIDIA certifiés. Ce logiciel facilite le déploiement, la gestion et l'évolutivité simples et rapides des workloads d'IA dans un environnement de cloud hybride moderne. La solution NVIDIA ai Enterprise, optimisée par NetApp et VMware, fournit un workload d'IA haute performance et une gestion des données dans un pack simplifié et familier.</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">Suivant : présentation de la technologie.</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">Configuration logicielle et matérielle requise</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">Configuration du réseau</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">Voici les exigences de configuration réseau pour la configuration dans le cloud :</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Le cluster Iguazio et NetApp Cloud volumes doivent se trouver dans le même cloud privé virtuel.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">Le responsable cloud doit avoir accès au port 6443 sur les nœuds applicatifs Iguazio.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">Nous avons utilisé Amazon Web Services dans ce rapport technique. Toutefois, les utilisateurs peuvent déployer la solution auprès de n'importe quel fournisseur cloud.pour les tests sur site de ONTAP ai avec NVIDIA DGX-1, nous avons utilisé le service DNS hébergé d'Iguazio pour des raisons de commodité.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">Les clients doivent pouvoir accéder aux domaines DNS créés de manière dynamique. Les clients peuvent utiliser leur propre DNS si nécessaire.</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">Vous pouvez installer Iguazio sur site dans votre propre cluster. Nous avons vérifié la solution dans NetApp ONTAP ai avec un système NVIDIA DGX-1. Le tableau suivant répertorie le matériel utilisé pour tester cette solution.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">Système NetApp AFF A800</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1 paire haute disponibilité (HA), comprend 2 contrôleurs et 48 SSD NVMe (3,8 To ou plus)</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Switchs réseau Cisco Nexus 3232C</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">Le tableau suivant répertorie les composants logiciels requis pour les tests sur site :</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4 - Ubuntu 18.04 LTS</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">Version du conteneur</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tf1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">Framework de machine learning</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">Iguazio</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">Version 2.8+</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">Serveur ESX</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">Cette solution a été entièrement testée avec Iguazio version 2.5 et NetApp Cloud Volumes ONTAP pour AWS. Le cluster Iguazio et le logiciel NetApp s'exécutent tous les deux sur AWS.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">Version ou type</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">Nœud d'application</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xlarge</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">Nœud de données</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3,4xlarge</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">Suivant : Résumé des cas d'utilisation de la prédiction d'échec du périphérique réseau</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">Depuis mai 2019, Microsoft propose un service de portail Azure propriétaire natif pour les services de fichiers NFS et SMB d'entreprise basés sur la technologie NetApp ONTAP.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">Tr-4896: Formation distribuée dans Azure: Détection de voie - conception de la solution</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad et Verron Martina, NetApp Ronen Dar, EXÉCUTEZ :ai</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">Depuis mai 2019, Microsoft propose un service de portail Azure propriétaire natif pour les services de fichiers NFS et SMB d'entreprise basés sur la technologie NetApp ONTAP. Ce développement est régi par un partenariat stratégique entre Microsoft et NetApp, et étend encore davantage la portée des services de données ONTAP à Azure.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">NetApp, l'un des principaux fournisseurs de services de données cloud, s'est associé À CETTE SOLUTION : l'IA, une entreprise qui virtualise l'infrastructure d'IA pour accélérer les tests d'IA en utilisant pleinement les GPU. Ce partenariat permet aux équipes d'accélérer l'IA en exécutant de nombreuses expériences en parallèle, avec un accès rapide aux données et en exploitant des ressources de calcul sans limites. EXÉCUTION : l'IA permet l'utilisation totale des GPU en automatisant l'allocation des ressources. L'architecture éprouvée du Azure NetApp Files permet également à tous les tests de s'exécuter à la vitesse maximale en éliminant les obstacles au pipeline de données.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp et LA GESTION : l'IA s'est associée afin de proposer aux clients une plateforme pérenne pour leur transition vers l'IA dans Azure. De l'analytique et du calcul haute performance aux décisions autonomes (où les clients peuvent optimiser leurs investissements IT en ne payant que ce dont ils ont besoin, quand ils en ont besoin), la alliance entre NetApp ET EXÉCUTION : l'IA offre une expérience unifiée dans le cloud Azure.</block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">Grâce à NetApp Cloud Sync, archivez l'historique des conversations</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">En dumping une fois par jour de l'historique des conversations dans un fichier CSV, nous pouvons ensuite utiliser Cloud Sync pour télécharger les fichiers journaux dans un système de stockage local. La figure suivante illustre l'architecture d'un déploiement sur site et dans des clouds publics par Jarvis, tout en utilisant Cloud Sync pour envoyer l'historique des conversations pour la formation de Nemo. Les détails de la formation de Nemo sont disponibles dans la section <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">Suivant : développez les modèles d'intention à l'aide de Nemo Training</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">L'automatisation basée sur l'IA et l'Edge Computing constituent une approche majeure pour aider les entreprises à réussir la transformation digitale et à optimiser l'efficacité opérationnelle et la sécurité. Avec l'Edge Computing, le traitement des données est beaucoup plus rapide car il n'est pas nécessaire de se rendre au data Center ni de les déplacer. C'est pourquoi les coûts associés à l'envoi de données vers des data centers ou le cloud sont réduits.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">Précédent : options de dimensionnement de l'architecture.</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">L'automatisation basée sur l'IA et l'Edge Computing constituent une approche majeure pour aider les entreprises à réussir la transformation digitale et à optimiser l'efficacité opérationnelle et la sécurité. Avec l'Edge Computing, le traitement des données est beaucoup plus rapide car il n'est pas nécessaire de se rendre au data Center ni de les déplacer. C'est pourquoi les coûts associés à l'envoi de données vers des data centers ou le cloud sont réduits. Une latence plus faible et une vitesse plus élevée peuvent être utiles pour les entreprises qui doivent prendre des décisions en temps quasi réel à l'aide de modèles d'inférence d'IA déployés à la périphérie.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">Les systèmes de stockage NetApp offrent les performances identiques ou supérieures au stockage SSD local et offrent les avantages suivants aux data Scientists, aux ingénieurs du data Center, aux développeurs d'IA/ML et aux décideurs IT ou business :</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">Partage sans effort des données entre des systèmes d'IA, l'analytique et d'autres systèmes métier stratégiques. Ce partage des données permet de réduire la surcharge de l'infrastructure, d'améliorer les performances et de rationaliser la gestion des données à l'échelle de l'entreprise.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">Faites évoluer indépendamment les ressources de calcul et de stockage pour réduire les coûts et améliorer l'utilisation des ressources.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">Rationalisation des workflows de développement et de déploiement à l'aide de copies et de clones Snapshot intégrés pour des espaces de travail utilisateur instantanés et compacts, un contrôle intégré des versions et un déploiement automatisé.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">Une protection des données d'entreprise pour la reprise après incident et la continuité de l'activité. La solution NetApp et Lenovo présentée dans ce document est une architecture scale-out flexible, idéale pour les déploiements d'inférence d'IA en périphérie.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">Remerciements</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger Directeur des solutions HPC et d'IA, Lenovo</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, Ingénieur marketing et technique, NetApp</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, Tech Lead E-Series ai Solutions, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, ingénieur QA, NetApp</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">Page produit sur les baies NetApp AFF A-Series</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">Le logiciel de gestion des données NetApp ONTAP – bibliothèque d'informations ONTAP 9</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">Tr-4727 : introduction à la gamme EF-Series de NetApp</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">Logiciel SANtricity NetApp E-Series : Fiche technique</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetApp Trident pour le stockage persistant pour les conteneurs</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">Banc d'essai TensorFlow</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Baie de stockage Flash unifiée Lenovo ThinkSystem DM5100F</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">Mars 2021</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">Version initiale</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">Version 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">Octobre 2021</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">Mise à jour avec EF et MLPerf Inférence v1.1</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">Ensuite : configuration logicielle requise</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">Équité excessive</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">Dans cette section et dans les sections <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, et <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, Nous avons conçu des scénarios de test avancés pour démontrer les capacités d'orchestration Run:ai pour une gestion de charges de travail complexe, une planification préventive automatique et un provisionnement GPU sur-quota. Nous avons ainsi pu atteindre une utilisation élevée des ressources en cluster et optimiser la productivité de nos équipes de data Scientists dans un environnement ONTAP d'IA.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">Pour ces trois sections, définissez les projets et quotas suivants :</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">Quota</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">En outre, nous utilisons les conteneurs suivants pour ces trois sections :</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Ordinateur portable Jupyter :<block ref="71f36d3504ef6b5a0ba9f34fe1143008" prefix=" " category="inline-code"></block></block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run:ai quickstart :<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block></block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">Nous avons défini les objectifs suivants dans ce scénario de test :</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">Présenter la simplicité du provisionnement des ressources et le mode d'abstraction des ressources des utilisateurs</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">Montrer comment les utilisateurs peuvent facilement provisionner des fractions d'un GPU et d'un nombre entier de GPU</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">Montrer comment le système élimine les goulots d'étranglement de calcul en permettant aux équipes ou aux utilisateurs de dépasser leur quota de ressources en cas de GPU gratuits dans le cluster</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">Montrez comment éliminer les goulots d'étranglement dans les pipelines de données avec la solution NetApp lors de l'exécution de tâches de calcul intensives, telles que le conteneur NetApp</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">Montre comment plusieurs types de conteneurs sont exécutés à l'aide du système</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Ordinateur portable Jupyter</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">Exécutez :conteneur d'IA</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">Affiche une utilisation élevée lorsque le cluster est plein</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">Pour plus de détails sur la séquence de commande réelle exécutée pendant le test, reportez-vous à la section <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">Une fois les 13 workloads envoyés, vous voyez la liste des noms de conteneurs et des GPU alloués, comme illustré ci-dessous. Nous avons sept formations et six tâches interactives qui simulent quatre équipes de data science, chacune ayant ses propres modèles en cours de développement ou en cours d'exécution. Pour les travaux interactifs, les développeurs individuels utilisent Jupyter Notebooks pour écrire ou déboguer leur code. Il convient donc de provisionner des fractions GPU sans utiliser trop de ressources du cluster.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">Les résultats de ce scénario de test montrent les éléments suivants :</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">Le cluster doit être complet : 16/16 GPU sont utilisés.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">Forte utilisation du cluster.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">Plus de tests que les GPU en raison de l'allocation fractionnaire.</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text"><block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix="" category="inline-code"></block> n'utilise pas tous leurs quotas ; par conséquent,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Peuvent exploiter des GPU supplémentaires pour leurs expérimentations, ce qui permet d'accélérer l'innovation.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">Suivant : équité de l'allocation des ressources de base</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">Tr-4834 : NetApp et Iguazio pour le pipeline MLRun</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">Ce document présente en détail le pipeline MLRun utilisant NetApp ONTAP ai, NetApp ai Control plane, le logiciel NetApp Cloud volumes et la plateforme data Science Iguazio. Nous utilisons la fonction sans serveur Nucio, Kubernetes persistent volumes, NetApp Cloud volumes, les copies NetApp Snapshot, le tableau de bord Grafana, Et d'autres services sur la plate-forme Iguazio pour créer un pipeline de données de bout en bout pour la simulation de la détection des défaillances réseau. Nous avons intégré les technologies Iguazio et NetApp afin de permettre un déploiement rapide des modèles, la réplication des données et la surveillance de la production, sur site comme dans le cloud.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">Le travail d'un data Scientist doit se concentrer sur l'entraînement et l'ajustement des modèles de machine learning (ML) et d'intelligence artificielle (IA). Toutefois, selon une étude Google, les data Scientists consacrent environ 80 % de leur temps à déterminer comment exploiter leurs modèles pour s'exécuter à grande échelle et dans des applications d'entreprise, comme l'illustre l'image suivante illustrant le développement de modèles dans le workflow d'IA/DE ML.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">Pour gérer des projets d'IA et DE ML de bout en bout, il faut avoir une vision plus large des composants de l'entreprise. Bien que le DevOps ait terminé la définition, l'intégration et le déploiement de ces types de composants, les opérations de machine learning ciblent un flux similaire qui inclut les projets d'IA/ML. Pour découvrir ce qu'un pipeline IA/ML de bout en bout touche dans l'entreprise, consultez la liste suivante de composants :</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="list-text">Stockage</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">Les bases de données</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">Systèmes de fichiers</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="list-text">Conteneurs</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">Intégration continue et pipeline de déploiement continu (ci/CD)</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">Environnement de développement intégré (IDE)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">Sécurité</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">Règles d'accès aux données</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="list-text">Virtualisation</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">Bibliothèques et jeux d'outils de science des données</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">Dans ce document, nous avons démontré que le partenariat entre NetApp et Iguazio simplifie considérablement le développement d'un pipeline IA/ML de bout en bout. Cette simplification accélère le time-to-market de toutes vos applications d'IA/ML.</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">Public visé</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">L'univers de la science des données touche de nombreuses disciplines en informatique et en affaires.</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">Les data Scientists doivent donc pouvoir utiliser leurs outils et leurs bibliothèques de choix.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">L'ingénieur doit savoir comment les données circulent et où elles résident.</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">Un ingénieur DevOps doit disposer des outils nécessaires pour intégrer les nouvelles applications d'IA et DE ML dans son pipeline ci/CD.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">Les utilisateurs professionnels veulent avoir accès aux applications d'IA et DE ML. Nous décrivons comment NetApp et Iguazio aident chacun de ces rôles à apporter de la valeur ajoutée à nos plateformes.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">Cette solution suit le cycle de vie d'une application d'IA/DE ML. Nous commençons par le travail des data Scientists pour définir les différentes étapes requises pour préparer les données, et entraîner et déployer les modèles. Nous travaillons avec les tâches nécessaires pour créer un pipeline complet, capable de suivre les artéfacts, de réaliser des tests et de déployer avec Kubeflow. Pour terminer le cycle complet, nous avons intégré le pipeline avec NetApp Cloud volumes pour faciliter le contrôle des versions des données, comme illustré dans l'image suivante.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">Suivant : présentation de la technologie</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">Exécution :tableaux de bord et vues d'IA</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Une fois l'installation de Run:ai sur votre cluster Kubernetes et la configuration correcte des conteneurs, vous voyez les tableaux de bord et les vues suivants sur<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> dans votre navigateur, comme illustré dans la figure suivante.</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">Le cluster fournit au total 16 GPU par deux nœuds DGX-1. Vous pouvez voir le nombre de nœuds, le nombre total de GPU disponibles, les GPU alloués avec des charges de travail, le nombre total de tâches en cours d'exécution, les tâches en attente et les GPU alloués inactifs. Sur le côté droit, le diagramme à barres affiche les GPU par projet, qui récapitule la manière dont les différentes équipes utilisent les ressources du cluster. Au milieu se trouve la liste des travaux en cours d'exécution avec des détails sur le travail, y compris le nom du travail, le projet, l'utilisateur, le type de travail, Le nœud sur lequel chaque travail est exécuté, le nombre de GPU alloués pour ce travail, la durée d'exécution actuelle du travail, la progression du travail en pourcentage et l'utilisation du GPU pour ce travail. Notez que le cluster est sous-utilisé (taux d'utilisation des GPU à 23 %) car seules trois tâches en cours d'exécution sont soumises par une seule équipe <block ref="9320270de4ff6824ae7a21f729fb7d44" prefix="(" category="inline-code"></block>).</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">Dans la section suivante, nous allons voir comment créer plusieurs équipes dans l'onglet projets et allouer des GPU à chaque équipe pour optimiser l'utilisation du cluster et gérer les ressources lorsqu'il y a de nombreux utilisateurs par cluster. Les scénarios de test reproduisent les environnements d'entreprise dans lesquels la mémoire et les ressources GPU sont partagées entre les charges de travail d'entraînement, d'inférence et interactives.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">Ensuite : création de projets pour les équipes de data science et allocation de GPU</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">Cette section fournit des informations détaillées sur la configuration de la plateforme pour exécuter l'entraînement à grande échelle avec détection de voie à l'aide de LA solution RUN ai orchestrator.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">Détection de voie – entraînement distribué avec RUN:ai</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">Cette section fournit des informations détaillées sur la configuration de la plateforme pour exécuter l'entraînement à grande échelle avec détection de voie, à l'aide de L'OUTIL RUN : ai orchestrator. Nous discutons de l'installation de tous les éléments de la solution et de l'exécution du travail de formation distribuée sur ladite plate-forme. La gestion des versions DE ML est réalisée à l'aide de NetApp SnapshotTM lié À L'EXÉCUTION : des expériences d'IA pour atteindre la reproductibilité des données et des modèles. La gestion des versions DE ML joue un rôle crucial dans le suivi des modèles, le partage du travail entre les membres de l'équipe, la reproductibilité des résultats, la rotation de nouvelles versions de modèles vers la production et la provenance des données. Le contrôle des versions DE NetApp ML (Snapshot) permet de capturer des versions instantanées des données, des modèles entraînés et des journaux associés à chaque expérience. Grâce à sa prise en charge avancée des API, il est facile à intégrer AVEC la plateforme D'IA POUR L'EXÉCUTION : il vous suffit de déclencher un événement basé sur l'état d'entraînement. Par ailleurs, il est nécessaire de capturer l'état de l'expérience dans son intégralité, sans modifier quoi que ce soit dans le code ou les conteneurs exécutés sur Kubernetes (K8s).</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">Enfin, ce rapport technique se conclut par une évaluation des performances sur plusieurs nœuds compatibles avec les processeurs graphiques dans AKS.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">Formation distribuée pour la détection de voie utilisation du boîtier à l'aide du jeu de données Tusimple</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">Dans le présent rapport technique, une formation distribuée est réalisée sur le jeu de données Tusimple pour la détection des voies. Horovod est utilisé dans le code d'entraînement pour l'entraînement distribué des données sur plusieurs nœuds GPU simultanément dans le cluster Kubernetes via AKS. Le code est emballé sous forme d'images conteneur pour le téléchargement et le traitement de données Tusimple. Les données traitées sont stockées sur des volumes persistants alloués par le plug-in NetApp Trident. Pour l'entraînement, une autre image de conteneur est créée, et elle utilise les données stockées sur les volumes persistants créés lors du téléchargement des données.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">Pour envoyer les données et la tâche d'entraînement, utilisez L'INTELLIGENCE artificielle pour orchestrer l'allocation et la gestion des ressources. EXÉCUTION : ai vous permet d'effectuer des opérations MPI (message Passing interface) nécessaires à Horovod. Cette disposition permet à plusieurs nœuds GPU de communiquer les uns avec les autres afin de mettre à jour le poids de l'entraînement après chaque mini-lot d'entraînement. Il permet également de surveiller la formation via l'interface et l'interface de ligne de commande, ce qui facilite le suivi de la progression des expériences.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot est intégré au code d'entraînement et capture l'état des données et le modèle d'entraînement pour chaque expérience. Cette fonctionnalité vous permet de suivre la version des données et du code utilisé, ainsi que le modèle entraîné associé généré.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">Installation et installation d'AKS</block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">Créer un cluster AKS</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">Pour la configuration et l'installation du cluster AKS, accédez à<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. Ensuite, suivez ces étapes :</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">Lors de la sélection du type de nœuds (qu'il s'agisse de nœuds système (CPU) ou de nœuds worker (GPU), sélectionnez les éléments suivants :</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">Ajouter le nœud système principal nommé<block ref="917718fb2e3dcf94043ea14d44580bc2" prefix=" " category="inline-code"></block> au<block ref="2ec023527b0bfb6c720d8dd19493ad0d" prefix=" " category="inline-code"></block> taille. Utilisez les trois nœuds par défaut.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Ajouter un nœud de travail<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block> avec<block ref="801b9db365bdc8cd72301ec3fd4ed2ff" prefix=" " category="inline-code"></block> de taille de pool. Utilisez trois nœuds au minimum pour les nœuds GPU.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">Le déploiement prend de 5 à 10 minutes.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">Installation des outils</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">Une fois le déploiement terminé, cliquez sur connexion au cluster. Pour vous connecter au cluster AKS récemment créé, installez l'outil de ligne de commandes Kubernetes à partir de votre environnement local (ordinateur portable/PC). Visitez<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> Pour l'installer conformément à votre système d'exploitation.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">Installez l'interface de ligne de commandes Azure dans votre environnement local</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">Pour accéder au cluster AKS à partir du terminal, entrez tout d'abord<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> et de saisir les informations d'identification.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">Exécutez les deux commandes suivantes :</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Entrez cette commande dans l'interface de ligne de commande Azure :</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">Si les six nœuds sont opérationnels comme indiqué ici, votre cluster AKS est prêt et connecté à votre environnement local.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Pour créer un sous-réseau délégué pour Azure NetApp Files, suivez cette série d'étapes :</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Accédez aux réseaux virtuels depuis le portail Azure. Trouvez votre nouveau réseau virtuel. Il devrait avoir un préfixe tel que aks-vnet, comme indiqué ici. Cliquez sur le nom du réseau virtuel.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">Cliquez sur sous-réseaux et sélectionnez +sous-réseau dans la barre d'outils supérieure.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">Indiquez au sous-réseau un nom tel que<block ref="d2acea3c674306459e768a41444551ba" prefix=" " category="inline-code"></block> Et sous l'en-tête délégation de sous-réseau, sélectionnez Microsoft.NetApp/volumes. Ne rien changer. Cliquez sur OK.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Les volumes Azure NetApp Files sont alloués au cluster d'applications et utilisés en tant que demandes de volume persistant dans Kubernetes. Par conséquent, cette allocation nous offre la flexibilité nécessaire pour mapper les volumes à différents services, qu'il s'agit d'ordinateurs portables Jupyter, de fonctions sans serveur, etc</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">Les utilisateurs des services peuvent consommer le stockage depuis la plateforme de différentes manières. Les principaux avantages de Azure NetApp Files sont les suivants :</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">Permet aux utilisateurs d'utiliser les snapshots.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">Permet aux utilisateurs de stocker de grandes quantités de données sur des volumes Azure NetApp Files.</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">Optimisez les performances des volumes Azure NetApp Files lorsque vous exécutez leurs modèles sur de vastes ensembles de fichiers.</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Définition Azure NetApp Files</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">Démarrage rapide : configurez Azure NetApp Files et créez un volume NFS</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Pour terminer la configuration de Azure NetApp Files, vous devez d'abord la configurer comme décrit à la section<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">Toutefois, vous pouvez ignorer les étapes de création d'un volume NFS pour Azure NetApp Files lorsque vous créez des volumes via Trident. Avant de continuer, assurez-vous d'avoir :</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Enregistré pour Azure NetApp Files et le fournisseur de ressources NetApp (via le shell cloud Azure)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Créé un compte dans Azure NetApp Files</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">Configurez un pool de capacité</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (Minimum 4 Tio Standard ou Premium selon vos besoins).</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">Peering de réseau virtuel AKS et de réseau virtuel Azure NetApp Files</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">Ensuite, Peer the AKS Virtual Network (vnet) with the Azure NetApp Files vNet en suivant les étapes suivantes :</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Dans la zone de recherche située en haut du portail Azure, saisissez les réseaux virtuels.</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">Cliquez sur VNet aks- vnet-name, puis entrez Peerings dans le champ de recherche.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">Cliquez sur +Add et entrez les informations fournies dans le tableau ci-dessous :</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">Champ</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">Valeur ou description</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">Nom de la liaison de peering</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">aks-vnet-name_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">ID d'abonnement</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">Abonnement au réseau VNet Azure NetApp Files auquel vous vous trouvez</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">Partenaire de peering vnet</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files vnet</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">Laissez toutes les sections non astérisque par défaut</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">Cliquez SUR AJOUTER ou sur OK pour ajouter le peering au réseau virtuel.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">Créez, modifiez ou supprimez un peering de réseau virtuel</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">Pour plus d'informations, rendez-vous sur<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident est un projet open source piloté par NetApp, conçu pour répondre aux demandes de stockage persistant des applications conteneurisées. Trident a été implémenté en tant que contrôleur de provisionnement externe. Fonctionnant comme un pod autonome, il contrôle les volumes et automatise entièrement le provisionnement.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident facilite l'intégration avec K8s en créant et en connectant des volumes persistants pour le stockage des datasets d'entraînement et des modèles entraînés. Grâce à cette fonctionnalité, les data Scientists et les ingénieurs de données peuvent utiliser K8s en toute simplicité, sans avoir à gérer et à stocker manuellement les datasets. Avec Trident, les data Scientists n'ont plus besoin d'apprendre à gérer de nouvelles plateformes de données, puisqu'il intègre les tâches liées à la gestion des données via l'intégration d'API logiques.</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Pour installer le logiciel Trident, procédez comme suit :</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">Installez tout d'abord le gouvernail</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Téléchargez et extrayez le programme d'installation de Trident 21.01.1.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">Copier<block ref="c67fd1b99934afa248dfeb285a9a4191" prefix=" " category="inline-code"></block> dans un répertoire de votre système<block ref="86657e3985b8aeae39f3d9136b5f3e58" prefix=" " category="inline-code"></block></block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Installation de Trident sur le cluster K8s avec Helm :</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">Changez le répertoire en répertoire Helm.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Vérifiez l'état des modules Trident de la façon habituelle de K8s :</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">Si tous les modules sont opérationnels, Trident est installé et vous pouvez passer à l'étape supérieure.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Configurer le back-end et la classe de stockage Azure NetApp Files</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Pour configurer la back-end et la classe de stockage Azure NetApp Files, procédez comme suit :</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">Revenir au répertoire de base.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">référentiel de projet</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">Cloner le<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block><block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">Accédez au<block ref="fb4dc0399a722eface234e077d9b496c" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Créez un principe de service Azure (le principe du service est celui de la façon dont Trident communique avec Azure pour accéder à vos ressources Azure NetApp Files).</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Création de Trident<block ref="27bac05160742a70c80c3e1db9b39988" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">À l'aide de votre éditeur de texte préféré, renseignez les champs suivants du tableau ci-dessous à l'intérieur du<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Valeur</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">ID d'abonnement</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Votre ID d'abonnement Azure</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">ID de tenantID</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Votre ID de locataire Azure (à partir de la sortie d'az ad sp à l'étape précédente)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">ID client</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">Votre AppID (à partir de la sortie d'az ad sp à l'étape précédente)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">ClientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">Votre mot de passe (à partir de la sortie d'az ad sp à l'étape précédente)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">Le fichier doit ressembler à l'exemple suivant :</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">Demandez à Trident de créer le back-end Azure NetApp Files dans le<block ref="47cb44be55a0dffa15dfc900a4c687be" prefix=" " category="inline-code"></block> espace de noms, utilisation<block ref="2f37b90d2adb135f3631c238ff072135" prefix=" " category="inline-code"></block> comme le fichier de configuration :</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">Créer la classe de stockage :</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">Les utilisateurs de K8 peuvent provisionner des volumes à l'aide des ESV qui spécifient une classe de stockage par nom. Demandez à K8s de créer une classe de stockage<block ref="9df91c80149f52e48e8f845cbad1b55c" prefix=" " category="inline-code"></block> Cela fera référence au back-end Azure NetApp Files créé à l'étape précédente en utilisant les éléments suivants :</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">Vérifiez que la classe de stockage est créée à l'aide de la commande suivante :</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">Déploiement et configuration des composants de snapshot de volume sur AKS</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">Si votre cluster n'est pas préinstallé avec les composants de snapshot de volume appropriés, vous pouvez installer ces composants manuellement en exécutant les étapes suivantes :</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14 n'a pas de contrôleur Snapshot préinstallé.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">Installez les CRD bêta de Snapshot à l'aide des commandes suivantes :</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">Installez le contrôleur Snapshot à l'aide des documents suivants de GitHub :</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">classe de snapshot de volume</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">Configuration de K8s<block ref="9431613e59ff5cc956e408e7f55906ef" prefix=" " category="inline-code"></block>: Avant de créer un snapshot de volume, a<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> doit être configuré. Créez une classe de snapshot de volumes pour Azure NetApp Files et utilisez-la pour gérer les versions DE MACHINE LEARNING avec la technologie NetApp Snapshot. Création<block ref="0c1b563c97a31c710fb1be0e355b42e2" prefix=" " category="inline-code"></block> et définissez-le sur `volumesnapshotclass `par défaut tels que :</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">Vérifier que la classe de copie Snapshot du volume a été créée à l'aide de la commande suivante :</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">EXÉCUTEZ :installation d'ai</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">Pour installer RUN:ai, procédez comme suit :</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">Installez le cluster RUN:ai sur AKS</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">Accédez à app.runai.ai, cliquez sur Créer un nouveau projet et nommez-le détection de voie. Un namespace est créé sur un cluster K8s à partir de<block ref="26ea39e1cbc12bc8c37993198043ec7c" prefix=" " category="inline-code"></block>- suivi du nom du projet. Dans ce cas, l'espace de noms créé serait runai-Lane-détection.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">INSTALLER RUN:AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">Sur votre terminal, définissez la détection de voie comme EXÉCUTION par défaut : projet ai à l'aide de la commande suivante :</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">Créer ClusterRole et ClusterRoleBinding pour l'espace de noms du projet (par exemple,<block ref="ff4072c643ff862f118d673b2655bd00" prefix=" " category="inline-code"></block> donc le compte de service par défaut appartenant à<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> l'espace de noms est autorisé à effectuer<block ref="2bbdf0e0d9e8bddf5f3f89a53a8e524f" prefix=" " category="inline-code"></block> opérations durant l'exécution du travail :</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">Indiquez les espaces de noms pour vérifier cela<block ref="13c89f25e4bc6da9c31044eb8fddf950" prefix=" " category="inline-code"></block> existe à l'aide de cette commande :</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">La sortie doit apparaître comme dans l'exemple suivant :</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">Créer ClusterRole<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> Et ClusterRoleBinding<block ref="1eddd02c8009227e14e36951541799be" prefix=" " category="inline-code"></block> à l'aide des commandes suivantes :</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">Téléchargez et traitez le jeu de données Tusimple AS RUN:ai</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">Le processus de téléchargement et de traitement de TuDataset simple en TANT QU'EXÉCUTION : travail ai est facultatif. Elle comprend les étapes suivantes :</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">Créez et poussez l'image docker ou omettez cette étape si vous souhaitez utiliser une image docker existante (par exemple,<block ref="c545ab6370eda2ad54aefbe9cf39084c" prefix=" " category="inline-code"></block></block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">Basculer vers le home Directory :</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">Accédez au répertoire des données du projet<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>:</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">Modifier<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> script shell et remplacez le référentiel docker par le vôtre. Par exemple, remplacer<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> avec le nom de votre référentiel docker. Vous pouvez également modifier le nom et LA BALISE de l'image docker (par exemple,<block ref="d9ff85f787933e1dd61935daa84a1bdf" prefix=" " category="inline-code"></block> et<block ref="e4c2e8edac362acab7123654b9e73432" prefix=" " category="inline-code"></block>) :</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">Exécutez le script pour créer l'image docker et l'envoyer dans le référentiel docker à l'aide des commandes suivantes :</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Soumettez la tâche RUN : ai pour télécharger, extraire, pré-traiter et stocker le jeu de données Tusimple Lane Detection dans un<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>, Qui est créé de manière dynamique par NetApp Trident :</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">Utiliser les commandes suivantes pour envoyer l'EXÉCUTION du travail ai :</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">Saisissez les informations du tableau ci-dessous pour soumettre le travail RUN:ai :</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-nom</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">Nom du travail</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-pvc</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">PVC du format [StorageClassName]:Size:ContainerMountPath dans la soumission de tâche ci-dessus, vous créez un PVC basé sur la demande à l'aide de Trident avec la classe de stockage azurenetappfiles. La capacité de volume persistant est ici de 100Gi et elle est montée sur le chemin /mnt.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">-image</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">Image Docker à utiliser lors de la création du conteneur pour cette tâche</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">Répertorier les travaux RUN:ai soumis.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">Vérifiez les journaux des travaux soumis.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">Énumérez le<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> créé. Utilisez-le<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> commande pour la formation à l'étape suivante.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">Vérifiez le travail EN COURS D'EXÉCUTION : ai UI (ou<block ref="a008ed925fe48e20407afaf702b23152" prefix=" " category="inline-code"></block>).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Effectuer une formation sur la détection de voie distribuée à l'aide de Horovod</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">La formation sur la détection de voie distribuée à l'aide de Horovod est un processus facultatif. Notez toutefois que voici les étapes impliquées :</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">Créez et poussez l'image docker ou ignorez cette étape pour utiliser l'image docker existante (par exemple,<block ref="ff48b891d5ff0bac7c6319fafb5cd296" prefix=" " category="inline-code"></block></block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">Basculez vers le répertoire de base.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">Accédez au répertoire du projet<block ref="3154c35109c9015233233f77dfc31bc7" prefix=" " category="inline-code"></block></block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">Modifiez le<block ref="40be60d1fc478ce6c2eeb49003834edf" prefix=" " category="inline-code"></block> script shell et remplacez le référentiel docker par le vôtre (par exemple, remplacez-le<block ref="c90c81f7ef628a8969142dee6550d8ef" prefix=" " category="inline-code"></block> avec le nom de votre référentiel docker). Vous pouvez également modifier le nom et LA BALISE de l'image docker <block ref="40797c3457645b9820c9a3f42dbea93b" prefix="(" category="inline-code"></block> et<block ref="dfddb1ffc29acf8914bca9a640b6362a" prefix=" " category="inline-code"></block>.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">Exécutez le script pour créer l'image docker et l'envoyer dans le référentiel docker.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">Soumettre le COURSE : travail d'IA pour la formation distribuée (MPI) :</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">Utilisation de l'option Submit of RUN : l'IA pour la création automatique de volume persistant à l'étape précédente (pour le téléchargement des données) vous permet uniquement d'avoir un accès RWO, qui permet non à plusieurs pods ou nœuds d'accéder au même volume persistant pour l'entraînement distribué. Mettez à jour le mode d'accès sur ReadWriteMany et utilisez le patch Kubernetes pour le faire.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">Commencez par obtenir le nom du volume de la demande de volume persistant en exécutant la commande suivante :</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">Corriger le volume et mettre à jour le mode d'accès à ReadWriteMany (remplacer le nom du volume par le vôtre dans la commande suivante) :</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">Soumettre le STAGE : ai MPI pour l'exécution du travail de formation répartie en utilisant les informations du tableau ci-dessous :</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">nom</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">Nom du travail de formation distribué</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">grand shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">Montage d'un périphérique grand /dev/shm il s'agit d'un système de fichiers partagé monté sur la RAM et fournit suffisamment de mémoire partagée pour que plusieurs collaborateurs du processeur puissent traiter et charger des lots dans la RAM du CPU.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">processus</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">Nombre de processus de formation distribués</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">gpu</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">Nombre de GPU/processus à allouer pour le travail, trois processus utilisateur sont nécessaires (--processus=3), chacun étant alloué avec un seul GPU (--gpu 1).</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">pvc</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">Utilisez le volume persistant existant (pvc-download-tusimple-data-0) créé par le travail précédent (download-tusimple-data) et monté sur le chemin /mnt</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">image</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">Définissez les variables d'environnement à définir dans le conteneur</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">EMPLOYÉS_UTILISÉS</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">Le fait de définir l'argument sur true active le chargement de données multi-processus</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">NOMBRE_D'EMPLOYÉS</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">Nombre de processus de travail du chargeur de données</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">TAILLE_LOT</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">Taille des lots d'entraînement</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">USE_VAL</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">Le fait de définir l'argument sur vrai permet la validation</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">VAL_BATCH_SIZE</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">Taille du lot de validation</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">ACTIVER_SNAPSHOT</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">La définition de l'argument sur true permet de prendre des données et des snapshots de modèles entraînés à des fins de gestion des versions DU ML</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">NOM_PVC</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">Nom de la demande de volume persistant pour créer un snapshot de. Dans la soumission des travaux ci-dessus, vous prenez un snapshot de pvc-download-tsimple-Data-0, composé d'un dataset et de modèles entraînés</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">Erreur : image graphique manquante</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">Répertorier le travail soumis.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">Journaux des travaux soumis :</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">Consulter la tâche d'entraînement EXÉCUTÉE : GUI d'IA (ou app.runai.ai): SESSIONS : tableau de bord d'IA, comme le montre les figures ci-dessous). La première figure présente trois processeurs graphiques alloués à la tâche d'entraînement distribuée sur trois nœuds sur AKS, puis la seconde SESSION :ai Jobs :</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">Une fois l'entraînement terminé, vérifiez la copie NetApp Snapshot créée et associée à L'EXÉCUTION du travail : IA.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">Restaurez les données à partir de la copie NetApp Snapshot</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">Pour restaurer les données à partir de la copie NetApp Snapshot, effectuez la procédure suivante :</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">Accédez au répertoire du projet<block ref="2277dab02c330ef055fe72a7776587ae" prefix=" " category="inline-code"></block>.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">Modifier<block ref="a5fe5fd907cdc55a6a74bfd705214476" prefix=" " category="inline-code"></block> et mettre à jour<block ref="d9d448f70687a1aa1f12b2f5ddaa4977" prefix=" " category="inline-code"></block><block ref="b068931cc450442b63f5b3d276ea4297" prefix=" " category="inline-code"></block> Champ de la copie Snapshot à partir duquel vous souhaitez restaurer les données. Vous pouvez également modifier le nom du volume persistant dans lequel les données seront restaurées, dans cet exemple son<block ref="1fcd0a4cb780ecfc14fadd89d5ad8fd2" prefix=" " category="inline-code"></block>.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">Créez un nouveau PVC à l'aide de<block ref="c6c5b510d872174c3b4e59ca4c66fd6e" prefix=" " category="inline-code"></block>.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">Si vous souhaitez utiliser les données restaurées pour l'entraînement, la candidature reste la même qu'auparavant. Remplacez uniquement la<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> avec le restauré<block ref="cdd7dd1603420ef6c3efe7b264205137" prefix=" " category="inline-code"></block> lors de la soumission du travail de formation, comme l'indique les commandes suivantes :</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">Évaluation des performances</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">Pour montrer l'évolutivité linéaire de la solution, des tests de performance ont été réalisés dans deux scénarios : un GPU et trois GPU. L'allocation du GPU, l'utilisation du GPU et de la mémoire, différents metrics à un ou trois nœuds ont été capturés lors de l'entraînement sur le dataset de détection Tulane simple. Les données sont multiplié par cinq dans le seul but d'analyser l'utilisation des ressources au cours des processus d'entraînement.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Niveaux de service Azure NetApp Files</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">La solution permet de commencer avec un petit dataset et quelques GPU. Lorsque le volume de données et la demande de GPU augmentent, les clients peuvent faire évoluer horizontalement dynamiquement les téraoctets dans le niveau standard et monter jusqu'au niveau Premium pour obtenir un débit par téraoctet sans déplacer de données. Ce processus est expliqué plus en détail dans la section, <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">Le temps de traitement d'un GPU était de 12 heures et 45 minutes. Le temps de traitement sur trois GPU sur trois nœuds était d'environ 4 heures et 30 minutes.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">Les chiffres présentés dans la suite de ce document illustrent des exemples de performances et d'évolutivité en fonction des besoins spécifiques de l'entreprise.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">La figure ci-dessous illustre l'allocation de 1 GPU et l'utilisation de la mémoire.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">La figure ci-dessous illustre l'utilisation des GPU d'un nœud.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">La figure ci-dessous illustre la taille de la mémoire d'un nœud unique (16 Go).</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">La figure ci-dessous illustre le nombre de GPU d'un nœud (1).</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">La figure ci-dessous illustre l'allocation de GPU d'un nœud (%).</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">La figure ci-dessous illustre trois GPU répartis sur trois nœuds : l'allocation des GPU et la mémoire.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">La figure ci-dessous illustre le taux d'utilisation de trois GPU sur trois nœuds (%).</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">La figure ci-dessous illustre l'utilisation de la mémoire de trois nœuds sur trois GPU (%).</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">niveau de service</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">Vous pouvez modifier le niveau de service d'un volume existant en déplaçant ce volume vers un autre pool de capacité qui utilise le<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> vous voulez le volume. Cette modification de niveau de service existante pour le volume n'exige pas la migration des données. Elle n'affecte pas non plus l'accès au volume.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">Modification dynamique du niveau de service d'un volume</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">Pour modifier le niveau de service d'un volume, procédez comme suit :</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">Sur la page volumes, cliquez avec le bouton droit de la souris sur le volume dont vous souhaitez modifier le niveau de service. Sélectionnez Modifier le pool.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">Dans la fenêtre change Pool, sélectionnez le pool de capacité vers lequel vous souhaitez déplacer le volume. Cliquez ensuite sur OK.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">Automatisez les changements de niveau de services</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">Le changement de niveau de service dynamique est actuellement dans l'aperçu public, mais il n'est pas activé par défaut. Pour activer cette fonction sur l'abonnement Azure, suivez les étapes indiquées dans le document «<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>. »</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">Volume az netappfiles : gestion des ressources de volume Azure NetApp Files (ANF)</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Vous pouvez également utiliser les commandes suivantes pour Azure : interface de ligne de commandes. Pour plus d'informations sur la modification de la taille du pool de Azure NetApp Files, rendez-vous sur<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Modification du pool d'un volume Azure NetApp Files</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">Le<block ref="2de1988ae552a465bf4f3a270c8403a4" prefix=" " category="inline-code"></block> Cmdlet affichée ici peut modifier le pool d’un volume Azure NetApp Files. Pour plus d'informations sur la modification de la taille du pool de volumes et d'Azure PowerShell, rendez-vous sur<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Exemple d'opérations et de tâches Kubeflow</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">Cette section fournit des exemples de diverses opérations et tâches que vous pouvez exécuter avec Kubeflow.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">Suivant : Provision a Jupyter Notebook Workspace for Data Scientist ou Developer Use.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">Une multitude de tests ont été effectués afin d'évaluer les performances de l'architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et flux multiples.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">Résultats du test</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">Précédent : procédure de test.</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">Résultats des tests pour AFF</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">Une multitude de tests ont été effectués afin d'évaluer les performances de l'architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et le traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et flux multiples.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">Le dernier scénario est implémenté uniquement pour la classification des images et la détection des objets.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">Ainsi, 15 charges de travail ont été testées sous trois configurations différentes :</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">Stockage local/serveur unique</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">Stockage à serveur unique/réseau</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">Stockage multiserveur/réseau</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">Les résultats sont décrits dans les sections suivantes.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">Inférence d'IA dans un scénario hors ligne pour AFF</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">Dans ce scénario, toutes les données étaient disponibles pour le serveur et le temps nécessaire pour traiter tous les échantillons a été mesuré. Nous avons signalé des largeurs de bande dans les échantillons par seconde comme résultats des tests. Lorsque plus d'un serveur de calcul était utilisé, nous faisons état de la bande passante totale additionnée sur tous les serveurs. Les résultats des trois cas d'utilisation sont présentés dans la figure ci-dessous. Pour le cas des deux serveurs, nous avons signalé la bande passante combinée des deux serveurs.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">Les résultats montrent que le stockage en réseau n'affecte pas les performances : le changement est minime et aucune n'a été trouvée pour certaines tâches. Lorsque vous ajoutez le second serveur, la bande passante totale double exactement ou, dans le pire des cas, cette modification est inférieure à 1 %.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">L'inférence d'IA dans un scénario de flux unique pour le AFF</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">Ce banc d'essai mesure la latence. Dans le cas d'un serveur de calcul multiple, nous faisons état de la latence moyenne. Les résultats de la suite de tâches sont indiqués dans la figure ci-dessous. Pour le cas des deux serveurs, nous avons signalé la latence moyenne des deux serveurs.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">Les résultats, encore une fois, montrent que le stockage réseau suffit à gérer les tâches. La différence entre le stockage local et le stockage réseau dans un même cas de serveur est minime, voire aucune. De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste inchangée ou les modifications par une très petite quantité.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">Inférence IA dans le scénario à flux multiples pour le AFF</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">Dans ce cas, le résultat est le nombre de flux que le système peut traiter tout en satisfaisant la contrainte QoS. Ainsi, le résultat est toujours un entier. Pour plus d'un serveur, nous faisons état du nombre total de flux sur tous les serveurs. Toutes les charges de travail ne prennent pas en charge ce scénario, mais nous en avons fait toutes. Les résultats de nos tests sont résumés dans la figure ci-dessous. Dans le cas des deux serveurs, nous faisons état du nombre combiné de flux provenant des deux serveurs.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">Les résultats montrent des performances parfaites de la configuration : le stockage local et réseau donne les mêmes résultats et l'ajout du second serveur double le nombre de flux que la configuration proposée peut gérer.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">Résultats des tests pour EF</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">Une multitude de tests ont été effectués afin d'évaluer les performances de l'architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et traitement du langage naturel [NLP]), qui ont été exécutés dans deux scénarios différents : hors ligne et flux unique. Les résultats sont décrits dans les sections suivantes.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">Inférence d'IA dans un scénario hors ligne pour la baie EF</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">Dans ce scénario, toutes les données étaient disponibles pour le serveur et le temps nécessaire pour traiter tous les échantillons a été mesuré. Nous avons signalé des largeurs de bande dans les échantillons par seconde comme résultats des tests. Pour les exécutions d'un nœud, nous faisons état d'une moyenne des deux serveurs, tandis que pour deux exécutions de serveur, nous avons signalé que la bande passante totale a été additionnée sur l'ensemble des serveurs. Les résultats pour des cas d'utilisation sont présentés dans la figure ci-dessous.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">Scénario d'inférence d'IA dans un flux unique pour la gamme EF</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">Ce banc d'essai mesure la latence. Dans tous les cas, nous faisons état d'une latence moyenne sur tous les serveurs en cours d'exécution. Les résultats de la suite de tâches sont donnés.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">Les résultats indiquent à nouveau que le stockage réseau suffit à gérer les tâches. La différence entre le stockage local et réseau dans un cas de serveur est minime ou aucun. De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste inchangée ou les modifications par une très petite quantité.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">Ensuite : options de dimensionnement de l'architecture.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">Les auteurs reconnaissent les contributions qui ont été faites à ce livre blanc par nos collègues estimés de NVIDIA : Davide Onofrio, Alex Qi, Sitong Ji, Marty Jain et Robert Sohigian. Les auteurs apprécient également les contributions des principaux membres de l'équipe NetApp : Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare, Erik Mulder et Mike McNamara.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">Nous tenons à remercier sincèrement tous ces contributeurs dont les connaissances et l'expertise ont étayé l'élaboration de ce document.</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">Suivante : où trouver des informations complémentaires</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">Cette section fournit des détails sur la mise en œuvre de l'assistant de vente au détail virtuel.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">Suivant: Jarvis déploiement</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">Cette solution suit le cycle de vie d'une application d'IA/DE ML. Nous commençons par le travail des data Scientists pour définir les différentes étapes requises pour préparer les données et entraîner les modèles. Grâce À RAPIDS on DASK, nous procédons à une formation distribuée dans le cluster Azure Kubernetes Service (AKS) afin de réduire considérablement le temps d'entraînement par rapport à l'approche conventionnelle Python scikit d'apprentissage. Pour terminer le cycle complet, nous intégrons le pipeline à Azure NetApp Files.</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">Tr-4904 : formation distribuée dans Azure - prévision de taux par clic</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">Le travail d'un data Scientist doit se concentrer sur l'entraînement et l'ajustement des modèles de machine learning (ML) et d'intelligence artificielle (IA). Toutefois, selon une étude menée par Google, les data Scientists consacrent environ 80 % de leur temps à comprendre comment exploiter leurs modèles pour les applications d'entreprise et leur fonctionnement à grande échelle.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">Pour gérer des projets d'IA et DE ML de bout en bout, il faut avoir une vision plus large des composants de l'entreprise. Bien que le DevOps ait pris en charge la définition, l'intégration et le déploiement, ces types de composants ciblent LES opérations DE ML un flux similaire qui inclut les projets d'IA/ML. Pour découvrir ce qu'un pipeline IA/ML de bout en bout touche dans l'entreprise, consultez la liste suivante de composants :</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">Environnement de développement intégré (IDE)</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">L'univers de la science des données touche plusieurs disciplines au NIVEAU DE L'INFORMATIQUE et des activités :</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">Les administrateurs et architectes du cloud doivent pouvoir configurer et gérer les ressources Azure.</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">Les utilisateurs professionnels veulent avoir accès aux applications d'IA et DE ML.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">Dans ce rapport technique, nous décrirons comment Azure NetApp Files, RAPIDS IA, DASK et Azure aident chacun de ces rôles à générer de la valeur pour le business.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="section-title">Présentation de la solution</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files offre plusieurs tiers de performance. Les clients peuvent commencer avec un niveau standard, puis évoluer horizontalement et verticalement jusqu'à un niveau hautes performances sans interruption, sans déplacer aucune donnée. Ainsi, les data Scientists peuvent entraîner des modèles à grande échelle sans problèmes de performances, en évitant les silos de données sur le cluster, comme l'illustre la figure ci-dessous.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp et Run:ai se sont associés dans ce rapport technique pour présenter les fonctionnalités uniques de la solution NetApp ONTAP ai avec la plateforme Run:ai pour simplifier l'orchestration des workloads d'IA. Les étapes précédentes procurent une architecture de référence afin de rationaliser le processus de pipelines de données et d'orchestration des workloads pour le deep learning. Les clients qui souhaitent implémenter ces solutions sont invités à contacter NetApp et Run:ai pour en savoir plus.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">Suivant : détails des tests pour la section 4.8</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">Cas d'utilisation</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">Bien que toutes les applications actuelles ne soient pas pilotées par l'IA, elles font évoluer des fonctionnalités qui leur permettent d'accéder aux avantages considérables de l'IA. Pour prendre en charge l'adoption de l'IA, les applications ont besoin d'une infrastructure qui leur fournit les ressources nécessaires pour fonctionner au mieux et soutenir leur évolution continue.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">Pour les applications d'IA, les emplacements de la périphérie font office de principale source de données. Les données disponibles peuvent être utilisées pour l'entraînement lorsqu'elles sont collectées depuis plusieurs sites en périphérie sur une période donnée pour former un dataset d'entraînement. Le modèle entraîné peut ensuite être déployé à nouveau vers la périphérie où les données ont été collectées. Ainsi, l'inférence est plus rapide sans avoir à transférer plusieurs fois les données de production vers une plateforme d'inférence dédiée.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">La solution d'inférence NetApp HCI ai, optimisée par les nœuds de calcul NetApp H615c avec les processeurs graphiques NVIDIA T4 et les systèmes de stockage NetApp connectés au cloud, a été développée et vérifiée par NetApp et NVIDIA. NetApp HCI simplifie le déploiement de solutions d'inférence d'IA dans les data centers en périphérie en éliminant les zones d'ambiguïté au niveau de la conception et en mettant fin aux approximations. Cette solution offre aux services INFORMATIQUES une architecture normative qui :</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">Permet l'inférence d'IA dans les data centers en périphérie</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">Optimisation de la consommation des ressources GPU</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">Offre une plateforme d'inférence basée sur Kubernetes pour plus de flexibilité et d'évolutivité</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">Les data centers de périphérie gèrent et traitent les données à des emplacements très proches du point de génération. Cette proximité augmente l'efficacité et réduit la latence impliquée dans le traitement des données. De nombreux marchés verticaux ont compris les avantages d'un data Center à la périphérie et adoptent massivement cette approche distribuée pour le traitement des données.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">Le tableau suivant répertorie les secteurs verticaux et les applications de périphérie.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">Verticale</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">En termes de latence</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">Médical</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">Les diagnostics assistés par ordinateur aident le personnel médical à détecter rapidement les maladies</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">Pétrole et gaz</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">Inspection autonome des installations de production distantes, de la vidéo et de l'analyse d'images</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">Aviation</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">Assistance au contrôle du trafic aérien et analyse des flux vidéo en temps réel</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">Les médias et le divertissement</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">Filtrage de contenu audio/vidéo pour offrir des contenus adaptés aux familles</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">Analyses commerciales</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">Reconnaissance de la marque pour analyser l'apparence de la marque lors d'événements télévisés en direct</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">E-commerce</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">Regroupement intelligent des offres de fournisseurs pour trouver des combinaisons de commerçants et d'entrepôts idéales</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">Commerce</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">Paiement automatisé pour reconnaître les articles placés dans le panier d'un client et faciliter le paiement numérique</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">Smart City</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">Améliorer la circulation routière, optimiser le stationnement et améliorer la sécurité des piétons et des cyclistes</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">Secteur industriel</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">Contrôle de la qualité, surveillance de la ligne de montage et identification des défauts</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">Service clientèle</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">Automatisation des services clients pour analyser et trier les demandes (téléphone, e-mails et réseaux sociaux)</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">Agriculture</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">Exploitation et planification intelligente des activités agricoles pour optimiser l'application d'engrais et d'herbicides</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">La solution cible plusieurs groupes d'utilisateurs :</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">Scientifiques des données</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">Les architectes IT</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">Consultants sur le terrain</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">Des services professionnels</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">Aux responsables INFORMATIQUES</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">Quiconque a besoin d'une infrastructure qui assure l'innovation IT et des services robustes de données et d'applications sur des sites en périphérie</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">Ensuite : l'architecture</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA ai Enterprise avec NetApp et VMware - Configuration initiale</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">Configuration initiale</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">Précédent : architecture.</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">Cette section décrit les tâches de configuration initiales à effectuer afin d'utiliser NVIDIA ai Enterprise avec NetApp et VMware.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">Matrice de support des produits NVIDIA ai Enterprise</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">Documentation des solutions NetApp et VMware</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">Avant d'exécuter les étapes décrites dans cette section, nous supposons que vous avez déjà déployé VMware vSphere et NetApp ONTAP. Reportez-vous à la <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> Pour plus d'informations sur les versions vSphere prises en charge. Reportez-vous à la <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> Pour des informations détaillées sur le déploiement de VMware vSphere avec NetApp ONTAP.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">Installez le logiciel hôte NVIDIA ai</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">Guide de démarrage rapide de la solution NVIDIA ai Enterprise</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">Pour installer le logiciel hôte NVIDIA ai Entrprise, suivez les instructions décrites dans les sections 1-4 du <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">Suivant : utilisez le logiciel NVIDIA NGC.</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette, NetApp Takashi Oishi, Fujitsu</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">Cette solution est axée sur une architecture scale-out pour déployer des systèmes d'intelligence artificielle avec des systèmes de stockage NetApp et des serveurs Fujitsu. La solution a été validée avec les bancs d'essai MLperf v0.6 d'entraînement des modèles utilisant des serveurs Fujitsu GX2570 et un système de stockage NetApp AFF A800.</block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">Cliquez par le biais du traitement des données de prédiction de taux et de l'entraînement des modèles</block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">Précédent: Conclusion.</block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">Démonstrations interactives en 3D</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">Entrez en contact directement avec un spécialiste de l'IA NetApp</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">Description de la solution NVDIA base Command Platform avec NetApp</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">Infographie NetApp pour l'IA 10 : bonnes raisons de choisir NetApp</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">L'IA dans le domaine de la santé : l'apprentissage profond pour identifier les lésions de la COVID-19 dans les analyses CT pulmonaires</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">L'IA dans le domaine de la santé : surveillance de l'utilisation du masque facial dans les établissements de santé. Livre blanc</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">Rapport technique sur l'IA dans le domaine de la santé : imagerie diagnostique</block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">L'IA pour le Retail : NetApp transversaux à l'IA avec NVIDIA RIVA</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">Description de la solution NetApp ONTAP ai</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">Description de la solution du kit DataOps NetApp</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">Description de la solution NetApp ai Control plane</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">Transformation du secteur grâce à l'eBook Data Drive IA</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">Description de la solution d'IA NetApp EF-Series</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">Description de la solution NetApp ai et Lenovo ThinkSystem for ai Inférence</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">Description des solutions NetApp pour l'IA et le ML Lenovo ThinkSystem pour les entreprises</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp et NVIDIA : redéfinir le contenu du possible avec la vidéo d'IA</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">Cette page compare le temps d'entraînement du modèle à l'aide de Pandas conventionnels par rapport à DASK. Pour Pandas, nous avons chargé une plus petite quantité de données en raison de la nature du temps de traitement plus lent pour éviter le débordement de mémoire. Par conséquent, nous avons interpolé les résultats pour offrir une comparaison équitable.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">Comparaison de la durée de formation</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">Précédent : surveillez le DASK à l'aide du tableau de bord natif des flux de tâches.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">Cette section compare le temps d'entraînement du modèle à l'aide de Pandas conventionnels par rapport à DASK. Pour Pandas, nous avons chargé une plus petite quantité de données en raison de la nature du temps de traitement plus lent pour éviter le débordement de mémoire. Par conséquent, nous avons interpolé les résultats pour offrir une comparaison équitable.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">Le tableau suivant montre la comparaison du temps d'entraînement brut lorsque le modèle Pandas utilise beaucoup moins de données pour sa forêt aléatoire (50 millions de lignes sur une base de 20 milliards par jour et 15 du dataset). Cet échantillon utilise uniquement moins de 0.25 % de toutes les données disponibles. Alors que pour DASK-cuML nous avons formé le modèle forestier aléatoire sur les 20 milliards de lignes disponibles. Les deux approches ont donné un temps de formation comparable.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">Approche</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">Temps de formation</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-Learn: L'utilisation de seulement 50M rangées en jour 15 comme données d'entraînement</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47 minutes et 21 secondes</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-DASK : utiliser les 20B rangées en jour 15 comme données d'entraînement</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1 heure, 12 minutes et 11 secondes</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">Si nous interpoler les résultats de temps d'entraînement de façon linéaire, comme le montre le tableau suivant, il y a un avantage significatif à utiliser la formation distribuée avec DASK. L'approche classique Pandas scikit-Learn prendra 13 jours pour traiter et entraîner 45 Go de données pour une seule journée de journaux, tandis QUE L'approche RAPIDS-DASK traite la même quantité de données 262.39 fois plus vite.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-Learn: Utiliser les données d'entraînement de toutes les lignes 20B en jour 15</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13 jours, 3 heures, 40 minutes et 11 secondes</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">Le tableau précédent montre que, GRÂCE À RAPIDS et DASK, le traitement des données et l'entraînement des modèles sur plusieurs instances GPU, la durée d'exécution est considérablement plus courte que le traitement classique Pandas DataFrame avec entraînement des modèles scikit. Cette structure permet une évolutivité verticale et horizontale dans le cloud et sur site au sein d'un cluster multinœud et multiprocesseur graphique.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">Suivant : surveillez DASK et RAPIDS avec Prometheus et Grafana.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP ai et la solution ai Control plane</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">L'architecture NetApp ONTAP ai, optimisée par les systèmes NVIDIA DGX et les systèmes de stockage NetApp connectés au cloud. Et présente plusieurs avantages pour les SERVICES IT :</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">Évolutivité indépendante des ressources de calcul et de stockage</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">NetApp ONTAP ai propose différentes options de stockage pour répondre à des besoins de performance et de cout. Il intègre étroitement les systèmes DGX et de stockage NetApp AFF A800 avec une connectivité réseau optimale. Les systèmes NetApp ONTAP ai et DGX simplifient les déploiements d'IA en éliminant la complexité et les approximations. Les clients peuvent commencer avec un déploiement de petite taille, puis évoluer sans interruption d'activité, tout en gérant intelligemment leurs données de la périphérie au cœur, et jusqu'au cloud, et inversement.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp ai Control plane est une solution complète d'IA, DE MACHINE LEARNING et de deep learning (DL) et de gestion des tests pour les data Scientists et les ingénieurs de données. Alors que les entreprises ont de plus en plus recours à l'IA, elles sont confrontées à de nombreux défis, notamment l'évolutivité des workloads et la disponibilité des données. NetApp ai Control plane répond à ces challenges grâce à des fonctionnalités telles que le clonage rapide d'un namespace de données comme vous le feriez avec un Git repo. Il définit et met en œuvre des workflows d'entraînement d'IA qui intègrent la création quasi instantanée de données et de références de modèles pour la traçabilité et la gestion des versions. NetApp ai Control plane vous permet de répliquer de manière transparente des données entre plusieurs sites et régions, et de provisionner rapidement des espaces de travail Jupyter Notebook avec un accès à des datasets volumineux.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">Exécutez la plateforme d'IA pour l'orchestration des workloads d'IA</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Exemple de flux de production de flux d'air Apache</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kit NetApp Data Science Toolkit pour Kubernetes</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">Le<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Peut être utilisé en conjonction avec le débit d'air. Grâce au kit NetApp Data Science Toolkit et à la circulation de l'air, vous pouvez incorporer les opérations de gestion des données NetApp dans des workflows automatisés orchestrés par le flux de production d'air.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">Exemples de débit d'air</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">Reportez-vous à la<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> Section du référentiel GitHub NetApp Data Science Toolkit pour plus d'informations sur l'utilisation du kit avec flux d'air.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">Ensuite, exemple d'opérations Trident.</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">Cette section propose des liens vers deux ordinateurs portables Jupyter pertinents à ce rapport technique.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Ordinateurs portables Jupyter à titre de référence</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">Précédent : gestion des versions de modèles et de jeux de données à l'aide du kit d'outils NetApp DataOps.</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">Deux ordinateurs portables Jupyter sont associés à ce rapport technique :</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">*CTR-PandasRF-Assemblé.ipynb.*</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> Cet ordinateur portable charge le jour 15 à partir du jeu de données de journaux Criteo Terabyte Click, traite et formate les données dans un Pandas DataFrame, forme un modèle de forêt aléatoire d'apprentissage Scikit, effectue des prédictions et calcule la précision.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">*criteo_dAsk_RF.ipynb.*</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> Cet ordinateur portable charge le jour 15 à partir du jeu de données de journal Criteo Terabun Click Logs, traite et formate les données dans un DAsk cuDF, forme un modèle forestier aléatoire DASk cuML, effectue des prévisions et calcule la précision. L'exploitation de plusieurs nœuds workers avec des processeurs graphiques permet de tirer parti de cette approche de traitement et d'entraînement des modèles distribués pour les données. Plus vous traitez de données, plus vous gagnez de temps par rapport à une approche ML classique. Vous pouvez déployer cet ordinateur portable dans le cloud, sur site ou dans un environnement hybride dans lequel le cluster Kubernetes contient des ressources de calcul et de stockage à différents emplacements, à condition que la configuration réseau permet la libre circulation des données et de la distribution des modèles.</block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">Déploiement cnvrg.io</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">Déploiement DU CŒUR cnvrg à l'aide de Helm</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm est le moyen le plus simple de déployer rapidement cnvrg dans n'importe quel cluster, sur site, Minikube ou dans n'importe quel cluster cloud (AKS, EKS et GKE, par exemple). Cette section décrit comment cnvrg a été installé sur une instance locale (DGX-1) avec Kubernetes installé.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">Avant de terminer l'installation, vous devez installer et préparer les dépendances suivantes sur votre ordinateur local :</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">Kubectl</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Cluster Kubernetes 1.15+</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">Déploiement à l'aide de Helm</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">Pour télécharger les graphiques cnvrg Helm les plus mis à jour, exécutez la commande suivante :</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">Avant de déployer cnvrg, vous devez disposer de l'adresse IP externe du cluster et du nom du nœud sur lequel vous allez déployer cnvrg. Pour déployer cnvrg sur un cluster Kubernetes sur site, exécutez la commande suivante :</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">Exécutez le<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> commande. L'ensemble des services et systèmes s'installent automatiquement sur le cluster. Ce processus peut prendre jusqu'à 15 minutes.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">Le<block ref="0562418e6d9a76d0dd22b2f186a2203d" prefix=" " category="inline-code"></block> la commande peut prendre jusqu'à 10 minutes. Une fois le déploiement terminé, accédez à l'URL de votre nouveau cluster cnvrg déployé ou ajoutez-le en tant que ressource au sein de votre organisation. Le<block ref="e7d07ed8aa8dd8cafce4a527a523d6c5" prefix=" " category="inline-code"></block> Commande vous informe de l'URL correcte.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">Lorsque l'état de tous les conteneurs est en cours d'exécution ou terminé, cnvrg a été déployé avec succès. Similaire à la sortie d'exemple suivante :</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">Computer Vision Model Training with ResNet50 and the thorax X-ray Dataset</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">Site de téléchargement NIH</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">Le système d'exploitation cesnvrg.io ai a été déployé sur une configuration Kubernetes sur une architecture NetApp ONTAP ai optimisée par le système NVIDIA DGX. Pour la validation, nous avons utilisé le jeu de données de radiographie du thorax NIH composé d'images déidentifiées des radiographies pulmonaires. Les images étaient au format PNG. Les données ont été fournies par le Centre clinique des NIH et sont disponibles par l'intermédiaire du<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. Nous avons utilisé un échantillon de 250 Go de données comportant 627, 615 images dans 15 classes.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">Le dataset a été téléchargé sur la plateforme cnvrg et a été mis en cache sur une exportation NFS depuis le système de stockage NetApp AFF A800.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">Configurez les ressources de calcul</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">L'architecture cnvrg et la fonctionnalité de méta-planification permettent aux ingénieurs et aux professionnels DE L'IT d'associer différentes ressources de calcul à une seule plateforme. Dans notre configuration, nous avons utilisé le même cluster cnvrg qui a été déployé pour exécuter les workloads d'apprentissage profond. Si vous devez ajouter des clusters, utilisez l'interface graphique, comme illustré ci-dessous.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">Charger les données</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">Pour charger des données sur la plateforme cnvrg, vous pouvez utiliser l'interface graphique ou l'interface de ligne de commande cnvrg. Pour les jeux de données volumineux, NetApp recommande l'utilisation de l'interface de ligne de commande, car il s'agit d'un outil robuste, évolutif et fiable capable de gérer un grand nombre de fichiers.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">Pour télécharger des données, procédez comme suit :</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">CLI cnvrg</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">Téléchargez le<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">accédez au répertoire des rayons x.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">Initialisez le dataset dans la plate-forme à l'aide du<block ref="93683f43f0985082ca58f41ff93ff85f" prefix=" " category="inline-code"></block> commande.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">Télécharger tout le contenu du répertoire vers le data Lake central avec le<block ref="3e18d74143663f7fae3446eb44229f0f" prefix=" " category="inline-code"></block> Commande.une fois les données chargées dans le magasin d'objets central (StorageGRID, S3 ou autres), vous pouvez naviguer à l'aide de l'interface graphique. La figure suivante montre un fichier PNG d'image de fibrose radiologique thoracique chargé. De plus, cnvrg version les données afin que tout modèle que vous construisez puisse être reproduit à la version des données.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Données de compte-tours</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">Pour accélérer l'entraînement et éviter de télécharger plus de 600 000 fichiers pour chaque essai et entraînement du modèle, nous avons utilisé la fonctionnalité de mise en cache des données après la première mise en ligne des données dans le magasin d'objets central du data Lake.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">Lorsque les utilisateurs cliquent sur cache, cnvrg télécharge les données de leur validation spécifique depuis le magasin d'objets distant et les met en cache sur le volume NFS ONTAP. Les données sont ensuite disponibles pour un entraînement instantané. De plus, si les données ne sont pas utilisées pendant quelques jours (pour l'entraînement ou l'exploration des modèles, par exemple), cnvrg efface automatiquement le cache.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">Créez un pipeline DE ML avec les données en cache</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">Les flux cnvrg vous permettent de construire facilement des pipelines DE ML de production. Les flux sont flexibles, peuvent fonctionner pour tous types d'utilisation DU ML et peuvent être créés via l'interface utilisateur graphique ou le code. Chaque composant d'un flux peut s'exécuter sur une ressource de calcul différente avec une image Docker différente, ce qui permet de créer un cloud hybride et des pipelines DE ML optimisés.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">Création du flux de rayons X thorax : réglage des données</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">Nous avons ajouté notre dataset à un nouveau flux créé. Lors de l'ajout du dataset, vous pouvez sélectionner la version spécifique (commit) et indiquer si vous voulez la version en cache. Dans cet exemple, nous avons sélectionné la validation en cache.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">Construction du flux de rayons X thorax : réglage du modèle d'entraînement : ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">Dans le pipeline, vous pouvez ajouter n'importe quel type de code personnalisé. Dans cnvrg, il y a aussi la bibliothèque ai, une collection de composants DE ML réutilisables. La bibliothèque d'IA comprend des algorithmes, des scripts, des sources de données et d'autres solutions qui peuvent être utilisés dans n'importe quel flux DE ML ou de deep learning. Dans cet exemple, nous avons sélectionné le module ResNet50 prédéfini. Nous avons utilisé des paramètres par défaut tels que batch_size:128, des séries de tests:10, etc. Ces paramètres peuvent être affichés dans la documentation de la bibliothèque d'IA. La capture d'écran suivante montre le nouveau flux avec le jeu de données de rayons X connecté à ResNet50.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">Définissez la ressource de calcul pour ResNet50</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">Chaque algorithme ou composant des flux cnvrg peut être exécuté sur une instance de calcul différente, avec une image Docker différente. Dans notre configuration, nous voulions exécuter l'algorithme d'entraînement sur les systèmes NVIDIA DGX avec l'architecture NetApp ONTAP ai. Dans la figure suivante, nous avons sélectionné<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block>, qui est un modèle de calcul et une spécification pour notre cluster sur site. Nous avons également créé une file d'attente de modèles et sélectionné plusieurs modèles. De cette façon, si le<block ref="26591d390a9f009f2af40ff68e37a26a" prefix=" " category="inline-code"></block> les ressources ne peuvent pas être allouées (si, par exemple, d'autres data scientists l'utilisent), vous pouvez activer la bursting en ajoutant un modèle de fournisseur de cloud. La capture d'écran suivante montre l'utilisation de gpu-Real comme nœud de calcul pour ResNet50.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">Suivi et surveillance des résultats</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">Après l'exécution d'un flux, cnvrg déclenche le moteur de suivi et de surveillance. Chaque cycle d'un flux est automatiquement documenté et mis à jour en temps réel. Hyperparamètres, mesures, utilisation des ressources (utilisation des GPU, etc.), version de code, artéfacts, journaux Et ainsi de suite sont automatiquement disponibles dans la section expériences, comme indiqué dans les deux captures d'écran suivantes.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">Dans cette architecture, l'accent est mis sur la partie la plus gourmande en capacité de calcul du processus d'IA ou de machine learning (ML) distribué de détection de voies.</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">Dans cette architecture, l'accent est mis sur la partie la plus gourmande en capacité de calcul du processus d'IA ou de machine learning (ML) distribué de détection de voies. La détection de voie est l'une des tâches les plus importantes en conduite autonome, ce qui aide à guider les véhicules en localisant les marquages de voie. Des composants statiques comme les marquages de voie guident le véhicule pour conduire sur la route de manière interactive et sûre.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">Les approches basées sur le réseau neuronal convolutif (CNN) ont poussé la compréhension et la segmentation des scènes à un nouveau niveau. Bien qu'il ne fonctionne pas bien pour les objets avec de longues structures et régions qui pourraient être obstruées (par exemple, poteaux, ombre sur la voie, etc.). Le réseau neuronal spatial convolutif (SCNN) généralise la CNN à un niveau spatial riche. Elle permet la propagation d'informations entre les neurones dans la même couche, ce qui le rend mieux adapté aux objets structurés tels que les voies, les pôles ou le chariot avec occlusions. Cette compatibilité est due au fait que les informations spatiales peuvent être renforcées et qu'elles préservent la fluidité et la continuité.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">Des milliers d'images de scène doivent être injectées dans le système pour permettre au modèle d'apprendre et de distinguer les différents composants du jeu de données. Ces images comprennent la météo, la journée ou la nuit, les routes à plusieurs voies et d'autres conditions de circulation.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">Pour la formation, il est nécessaire de disposer d'une bonne qualité et d'une bonne quantité de données. L'entraînement peut prendre plusieurs jours ou plusieurs semaines avec un seul GPU. L'entraînement distribué par les données peut accélérer le processus en utilisant plusieurs processeurs graphiques ou plusieurs nœuds. Horovod est un cadre de ce type qui permet des formations distribuées, mais la lecture des données dans l'ensemble des clusters des GPU peut jouer un rôle obstacle. Les systèmes Azure NetApp Files assurent des débits élevés et une faible latence continue pour fournir des fonctionnalités scale-up et scale-up que les GPU utilisent afin d'exploiter au mieux leur capacité de calcul. Nos expériences ont démontré que tous les GPU du cluster étaient utilisés à plus de 96 % en moyenne pour l'entraînement de la détection de voie à l'aide de SCNN.</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">La science des données inclut plusieurs disciplines INFORMATIQUES et commerciales. Par conséquent, plusieurs personnages font partie du public ciblé :</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">Les data Scientists doivent donc pouvoir utiliser les outils et les bibliothèques de leur choix.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">Les ingénieurs de données doivent savoir comment elles circulent et où elles résident.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">Des experts en matière de conduite autonome.</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">Administrateurs et architectes cloud pour configurer et gérer les ressources cloud (Azure).</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">Un ingénieur DevOps a besoin des outils pour intégrer les nouvelles applications d'IA et DE ML dans son pipeline d'intégration et de déploiement continus.</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">Dans ce document, nous vous présentons comment Azure NetApp Files, L'EXÉCUTION : l'IA et Microsoft Azure aident chacun de ces rôles à créer de la valeur commerciale.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">Technologie de la solution</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">Cette section traite des exigences technologiques pour la détection de voie en mettant en œuvre une solution de formation distribuée à grande échelle qui s'exécute entièrement dans le cloud Azure. La figure ci-dessous présente l'architecture de la solution.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">Les éléments utilisés dans cette solution sont les suivants :</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes Service (AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">Références de calcul Azure avec processeurs graphiques NVIDIA</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">EXÉCUTEZ : L'IA</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">Les liens vers tous les éléments mentionnés ici sont répertoriés dans le <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> section.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">Ressources et conditions des services clouds</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">Le tableau suivant répertorie les composants matériels requis pour implémenter la solution. Les composants cloud utilisés dans toute implémentation de cette solution peuvent varier en fonction des besoins du client.</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">Au moins trois nœuds système et trois nœuds workers GPU</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">Nœuds système SKU de machine virtuelle (VM)</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Trois Standard_DS2_v2</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">Nœuds worker GPU référence VM</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">Trois Standard_NC6s_v3</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">Niveau standard 4 To</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">Configuration logicielle requise</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">Le tableau suivant répertorie les composants logiciels requis pour implémenter la solution. Ils peuvent varier selon l'implémentation de la solution et les besoins du client.</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">Version ou autres informations</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - version Kubernetes</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">EXÉCUTEZ :CLI AI</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">EXÉCUTION : version de l'opérateur Kubernetes d'orchestration d'IA</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">Horovod</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">Résumé de cas d'utilisation de la prédiction de défaillance du périphérique réseau</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">Ce cas d'utilisation est basé sur un client d'Iguazio dans le secteur des télécommunications en Asie. Avec 100 000 clients grands comptes et 125 000 pannes réseau par an, il était essentiel de prévoir et d'agir de manière proactive pour éviter que les défaillances réseau n'affectent les clients. Cette solution a apporté à l'entreprise les avantages suivants :</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">Analyses prédictives pour les défaillances réseau</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">Intégration avec un système de gestion des tickets</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">En prenant des mesures proactives pour prévenir les défaillances réseau suite à cette mise en œuvre d'Iguazio, 60% des échecs ont été évités de manière proactive.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">Suivant : présentation de la configuration</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">Création de projets pour les équipes de data science et allocation de GPU</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">Les chercheurs peuvent envoyer des workloads via les processus Run:ai CLI, Kubeflow ou similaires. Afin de rationaliser l'allocation des ressources et de créer des priorités, Run:ai introduit le concept de projets. Les projets sont des entités de quotas qui associent un nom de projet à l'allocation et aux préférences GPU. Cette méthode simple et pratique vous permet de gérer plusieurs équipes de data science.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">Un chercheur soumettant une charge de travail doit associer un projet à une demande de charge de travail. Le planificateur Run:ai compare la demande aux allocations en cours et au projet et détermine si la charge de travail peut être allouée à des ressources ou si elle doit rester dans un état en attente.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">En tant qu'administrateur système, vous pouvez définir les paramètres suivants dans l'onglet exécution:projets ai :</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">*Modèles de projets.* définissez un projet par utilisateur, définissez un projet par équipe d'utilisateurs et définissez un projet par projet d'organisation réel.</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">*Quotas de projet.* chaque projet est associé à un quota de GPU qui peut être alloué pour ce projet en même temps. C'est un quota garanti. Les chercheurs qui utilisent ce projet sont garantis d'obtenir ce nombre de GPU, quel que soit l'état du cluster. En règle générale, la somme de l'allocation du projet doit être égale au nombre de GPU dans le cluster. Au-delà de cela, un utilisateur de ce projet peut recevoir un surquota. Tant que les GPU ne sont pas utilisés, un chercheur qui utilise ce projet peut obtenir davantage de processeurs graphiques. Nous démontrons des scénarios de test sur-quota et des considérations d'équité dans<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, et<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">Créez un nouveau projet, mettez à jour un projet existant et supprimez un projet existant.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">Exécuter:Documentation ai</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">*Limiter l'exécution des travaux sur des groupes de nœuds spécifiques*. Vous pouvez affecter des projets spécifiques à exécuter uniquement sur des nœuds spécifiques. Ceci est utile lorsque l'équipe de projet a besoin de matériel spécialisé, par exemple, avec suffisamment de mémoire. Une équipe de projet peut également être propriétaire de matériel spécifique acquis avec un budget spécialisé, ou lorsqu'il peut être nécessaire de concevoir directement des charges de travail interactives ou de travailler sur du matériel plus faible et d'entraîner plus longtemps ou des charges de travail non surveillées sur des nœuds plus rapides. Pour des commandes permettant de regrouper des nœuds et de définir l'affinité pour un projet spécifique, reportez-vous à la <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">*Limiter la durée des emplois interactifs*. Les chercheurs oublient souvent de fermer des emplois interactifs. Cela peut conduire à un gaspillage de ressources. Certaines organisations préfèrent limiter la durée des emplois interactifs et les fermer automatiquement.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">La figure suivante montre la vue projets avec quatre équipes créées. Un nombre différent de GPU est attribué à chaque équipe pour prendre en compte différentes charges de travail, avec un nombre total de GPU égal à celui du nombre total de GPU disponibles dans un cluster composé de deux DGX-1.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">Suivant : soumission des tâches dans l'interface de ligne de commande Exécuter l'IA</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA ai Enterprise avec NetApp et VMware : Architecture</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Architecture</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">Précédent : présentation de la technologie.</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">Cette solution s'appuie sur une architecture familière et familière avec des systèmes NetApp, VMware et NVIDIA-Certified. Voir le tableau suivant pour plus de détails.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">Logiciels d'IA et d'analytique</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">NVIDIA ai Enterprise pour VMware</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">Plateforme de virtualisation</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">Plateforme de calcul</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">Systèmes certifiés NVIDIA</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">Plateforme de gestion de données</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">Suivant : configuration initiale.</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">Obtenir le code à partir de GitHub</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">Maintenant que le volume NetApp Cloud Volume ou NetApp Trident est disponible pour le cluster Iguazio et l'environnement de développement, vous pouvez passer en revue l'application.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">Les utilisateurs ont leur propre espace de travail (répertoire). Sur chaque ordinateur portable, le chemin d'accès au répertoire de l'utilisateur est<block ref="60dfd72bb314eac7d0f73279723af059" prefix=" " category="inline-code"></block>. La plateforme Iguazio gère le répertoire. Si vous suivez les instructions ci-dessus, le volume NetApp Cloud est disponible dans le<block ref="61bc18ea7642b598a1fcfad2e953599b" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Obtenir le code à partir de GitHub à l'aide d'un terminal Jupyter.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">À l'invite du terminal Jupyter, clonez le projet.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">Vous devriez maintenant voir le<block ref="fbeae7c8d4df4765206d2abb38069752" prefix=" " category="inline-code"></block> Dans l'arborescence des fichiers de l'espace de travail Jupyter.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">Suivant : configurer l'environnement de travail</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA ai Enterprise avec NetApp et VMware - utilise le logiciel NVIDIA NGC - exemple d'utilisation - travail d'entraînement TensorFlow</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">Exemple d'utilisation - travail de formation TensorFlow</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">Précédent : Configuration.</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">Cette section décrit les tâches à effectuer pour exécuter un travail d'entraînement TensorFlow dans un environnement NVIDIA d'IA Enterprise.</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="inline-link-macro">Configuration</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">Avant d'effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà créé un modèle de machine virtuelle invité en suivant les instructions décrites dans le <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> page.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">Créer une VM invité à partir d'un modèle</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">Tout d'abord, vous devez créer une machine virtuelle invitée à partir du modèle que vous avez créé dans la section précédente. Pour créer une nouvelle machine virtuelle invitée à partir de votre modèle, connectez-vous à VMware vSphere, cliquez sur le nom du modèle, choisissez « New VM from this Template... », puis suivez l'assistant.</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">Créer et monter un volume de données</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">Vous devez ensuite créer un nouveau volume de données sur lequel stocker le dataset d'entraînement. Vous pouvez créer rapidement un nouveau volume de données à l'aide du kit NetApp DataOps. L'exemple de commande ci-dessous montre la création d'un volume nommé 'imagenet' d'une capacité de 2 To.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">Avant de pouvoir alimenter le volume de données avec des données, vous devez le monter sur la machine virtuelle invitée. Vous pouvez monter rapidement un volume de données à l'aide du kit NetApp DataOps. L'exemple de commande ci-dessous montre la commande de création du volume à l'étape précédente.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">Remplir le volume de données</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">Une fois le nouveau volume provisionné et monté, le dataset d'entraînement peut être récupéré à partir de l'emplacement source et placé sur le nouveau volume. Cela implique généralement de extraire les données d'un data Lake S3 ou Hadoop, et parfois d'obtenir de l'aide d'un ingénieur de données.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">Exécuter le travail de formation TensorFlow</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">Vous êtes maintenant prêt à exécuter votre travail de formation TensorFlow. Pour exécuter votre travail de formation TensorFlow, effectuez les tâches suivantes.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">Tirez l'image du conteneur NVIDIA NGC Enterprise TensorFlow.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">Lancez une instance du conteneur d'entreprise NVIDIA NGC. Utilisez l'option '-v' pour attacher votre volume de données au conteneur.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">Exécutez votre programme de formation TensorFlow sur le conteneur. L'exemple de commande ci-dessous montre l'exécution d'un exemple de programme d'entraînement ResNet-50 inclus dans l'image conteneur.</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">Suivante : où trouver des informations complémentaires ?</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">La croissance exponentielle du volume des données et la croissance exponentielle du machine learning (ML) et de l'intelligence artificielle (IA) se sont convergentes pour permettre de créer une nouvelle économie avec des défis uniques en matière de développement et d'implémentation. Des quantités massives de données sont généralement stockées dans un data Lake à faible coût, où les ressources de calcul d'IA haute performance telles que les GPU ne peuvent pas y accéder de manière efficace. Dans ce rapport, nous présentons une solution nouvelle dans laquelle les professionnels de la science des données implémentent un hub de données et, d'un simple clic, créent un cache de jeux de données à proximité de leurs ressources de calcul, où qu'elles se trouvent. Ils peuvent ainsi faciliter l'entraînement des modèles haute performance et renforcer la collaboration avec un nouveau hub de version du dataset.</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, Ingénieur marketing et technique, NetApp</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">Santosh Rao, Directeur technique senior, NetApp</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam, Sung-Han Lin, NetApp Jacci Cenci, NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">Cette architecture de référence apporte des lignes directrices aux clients qui créent une infrastructure d'intelligence artificielle reposant sur des systèmes NVIDIA DGX-1 et de stockage NetApp AFF pour les champs d'application du secteur financier. Vous y trouverez des informations sur les workflows généraux utilisés dans le développement de modèles de deep learning pour les scénarios de test et les résultats des services financiers. Il inclut également des recommandations de dimensionnement pour les déploiements client.</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">Août 2021</block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">Cette page décrit la configuration des ressources cloud pour Azure NetApp Files.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">Ressources cloud nécessaires</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">Précédent : configuration logicielle requise.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Configurez Azure NetApp Files</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">Démarrage rapide : configurez Azure NetApp Files et créez un volume NFS</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">Configurez Azure NetApp Files comme décrit à la section<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">Vous pouvez passer outre la section « Créer un volume NFS pour Azure NetApp Files », car vous allez créer des volumes via Trident. Avant de continuer, procédez comme suit :</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">lien</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Inscrivez-vous à Azure NetApp Files et au fournisseur de ressources NetApp (via le shell Azure) (<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>).</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Créer un compte dans Azure NetApp Files (<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>).</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">Configurez un pool de capacité (un minimum de 4 To Standard ou Premium, selon vos besoins) (<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>).le tableau suivant répertorie les configurations réseau requises pour la configuration dans le nuage. Le cluster DASK et Azure NetApp Files doivent se trouver sur le même réseau virtuel Azure (vnet) ou un réseau vnet pêche.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">Ressources</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">Type/version</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">Nœud agent</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3 x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">Nœud de processeur graphique</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">3 x Standard_NC6s_v3</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">Pool de capacité standard</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">Capacité en To</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">Suivant : récapitulatif de l'utilisation des prévisions de taux par clic.</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">Le rapport TR-4851 démontre l'utilisation du stockage objet NetApp StorageGRID en tant que système de gestion et de référentiel de données pour le développement des logiciels de machine learning (ML) et de deep learning (DL). Ce livre blanc décrit le flux et les exigences de développement logiciel de véhicules autonomes, ainsi que les fonctionnalités StorageGRID qui rationalisent le cycle de vie des données. Cette solution s'applique à tout workflow de pipeline de traitement de données à plusieurs étapes standard dans les processus de développement DU ML et du DL.</block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">Configuration NetApp</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">Suivant:Présentation</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">Configurer l'environnement de travail</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">Copiez le<block ref="3a4f8d88ea1eac117f98223609194cb9" prefix=" " category="inline-code"></block><block ref="4931c948234bb20e1915f851691b340a" prefix=" " category="inline-code"></block> comme<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Ouvrez et modifiez<block ref="b35ae5135ebed26881b0747c3c36725d" prefix=" " category="inline-code"></block>. Ce bloc-notes définit des variables pour les informations d'identification, l'emplacement des fichiers et les pilotes d'exécution.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">Si vous suivez les instructions ci-dessus, les seules modifications à apporter sont les suivantes :</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">Pour bénéficier de cette valeur, nous vous leguazio :<block ref="bed2ad53cc10d1f92b477fc7c1476348" prefix=" " category="inline-code"></block></block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">Exemple :<block ref="0ddf9a06edec7d150708463603b95f22" prefix=" " category="inline-code"></block></block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">Changer<block ref="21232f297a57a5a743894a0e4a801fc3" prefix=" " category="inline-code"></block> Pour votre nom d'utilisateur Iguazio :</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph"><block ref="0458c1c280a715ecb31b33b5269e101b" prefix="" category="inline-code"></block></block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">Détails de connexion du système ONTAP : Incluez le nom du volume généré lors de l'installation de Trident. Le paramètre suivant est défini pour un cluster ONTAP sur site :</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Le paramètre suivant est pour Cloud Volumes ONTAP :</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">Créer des images Docker de base</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">Tout ce dont vous avez besoin pour créer un pipeline DE ML est inclus dans la plateforme Iguazio. Le développeur peut définir les spécifications des images Docker nécessaires à l'exécution du pipeline et à l'exécution de la création d'images à partir de Jupyter Notebook. Ouvrez le bloc-notes<block ref="61dfd8901a62e0f1e23dd2f5029d2639" prefix=" " category="inline-code"></block> Et exécuter toutes les cellules.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">Ce bloc-notes crée deux images que nous utilisons dans le pipeline.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text"><block ref="b636b23a5b442c01733e45c199c11f56" prefix="" category="inline-code"></block> Utilisé pour traiter les tâches DE ML.</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text"><block ref="c59e60c5a3880eb8018ae68eaa70621c" prefix="" category="inline-code"></block>. Contient des utilitaires pour la gestion des copies NetApp Snapshot.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">Examinez les ordinateurs portables Jupyter individuels</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">Le tableau suivant répertorie les bibliothèques et les structures que nous avons utilisées pour créer cette tâche. Tous ces composants ont été pleinement intégrés aux contrôles d'accès et de sécurité basés sur les rôles d'Iguazio.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">Bibliothèques/Framework</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">Géré par Iguazio pour l'assemblage, l'exécution et le contrôle d'un pipeline DE ML/IA.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">Nucio</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">Un cadre de fonctions sans serveur intégré à Iguazio. Également disponible en tant que projet open source géré par Iguazio.</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">Framework basé sur Kubernetes pour déployer le pipeline. Il s'agit également d'un projet open-source auquel Iguazio contribue. Il est intégré à Iguazio pour renforcer la sécurité et l'intégration avec le reste de l'infrastructure.</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Un registre Docker fonctionne à la demande sur la plateforme Iguazio. Vous pouvez également le modifier pour vous connecter à votre registre.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud volumes</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">Les systèmes Cloud volumes exécutés sur AWS nous permettent d'accéder à d'importants volumes de données et de créer des copies Snapshot pour les datasets utilisés à des fins d'entraînement.</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident est un projet open source géré par NetApp. Il facilite l'intégration aux ressources de stockage et de calcul dans Kubernetes.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">Nous avons utilisé plusieurs ordinateurs portables pour construire le pipeline DE ML. Chaque ordinateur portable peut être testé individuellement avant d'être rassemblé dans le pipeline. Nous abordons chaque ordinateur portable individuellement après le processus de déploiement de cette application de démonstration.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">Le résultat souhaité est un pipeline qui forme un modèle basé sur une copie Snapshot des données et déploie le modèle pour l'inférence. Un schéma fonctionnel d'un pipeline MLRun terminé est présenté dans l'image suivante.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">Déployer la fonction Data Generation</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">Cette section décrit comment nous avons utilisé les fonctions sans serveur Nucio pour générer des données de périphériques réseau. L'utilisation est adaptée à partir d'un client Iguazio qui a déployé le pipeline et utilisé les services Iguazio pour surveiller et prévoir les défaillances des périphériques réseau.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Site Web de Nucio</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">Nous avons simulé des données provenant de périphériques réseau. Exécution du bloc-notes Jupyter<block ref="c2d07e7698686359c0371f481d2cc628" prefix=" " category="inline-code"></block> Crée une fonction sans serveur qui s'exécute toutes les 10 minutes et génère un fichier parquet avec de nouvelles données. Pour déployer la fonction, exécutez toutes les cellules de ce bloc-notes. Voir la<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> pour passer en revue les composants inconnus de cet ordinateur portable.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">Une cellule avec le commentaire suivant est ignorée lors de la génération de la fonction. Chaque cellule de l'ordinateur portable est supposée faire partie de la fonction. Importez le module Nucio pour l'activer<block ref="85b0176bddfe93e918b8de4cb894780c" prefix=" " category="inline-code"></block>.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">Dans la spécification de la fonction, nous avons défini l'environnement dans lequel la fonction s'exécute, la façon dont elle est déclenchée et les ressources qu'elle consomme.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">Le<block ref="b73982aa3ac6ac19ba867eb2f5819797" prefix=" " category="inline-code"></block> La fonction est appelée par Nucio framework lors de l'initialisation de la fonction.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">Tout code qui ne figure pas dans une fonction est appelé lors de l'initialisation de la fonction. Lorsque vous l'appelez, une fonction de gestionnaire est exécutée. Vous pouvez modifier le nom du gestionnaire et le spécifier dans la spécification de fonction.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">Vous pouvez tester la fonction à partir de l'ordinateur portable avant le déploiement.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">La fonction peut être déployée à partir de l'ordinateur portable ou déployée à partir d'un pipeline ci/CD (adaptation de ce code).</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">Ordinateurs portables Pipeline</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">Ces ordinateurs portables ne sont pas conçus pour être exécutés individuellement pour cette configuration. Il s'agit simplement d'un examen de chaque ordinateur portable. Nous les avons appelés dans le cadre du pipeline. Pour les exécuter individuellement, consultez la documentation MLRun pour les exécuter en tant que travaux Kubernetes.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">snap_cv.ipynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">Cet ordinateur portable gère les copies Snapshot Cloud Volume au début du pipeline. Elle transmet le nom du volume au contexte du pipeline. Cet ordinateur portable appelle un script shell pour gérer la copie Snapshot. Lors de l'exécution dans le pipeline, le contexte d'exécution contient des variables qui aident à localiser tous les fichiers nécessaires à l'exécution. Lors de l'écriture de ce code, le développeur n'a pas à s'inquiéter de l'emplacement du fichier dans le conteneur qui l'exécute. Comme décrit plus loin, cette application est déployée avec toutes ses dépendances, et c'est la définition des paramètres de pipeline qui fournit le contexte d'exécution.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">L'emplacement de copie Snapshot créé est placé dans le contexte MLRun pour être utilisé par étapes dans le pipeline.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">Les trois ordinateurs portables suivants sont exécutés en parallèle.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">data-prep.ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">Les metrics brutes doivent être intégrés à des fonctionnalités pour permettre l'entraînement des modèles. Cet ordinateur portable lit les mesures brutes du répertoire Snapshot et écrit les fonctionnalités d'entraînement des modèles dans le volume NetApp.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">Lors de l'exécution dans le contexte du pipeline, l'entrée<block ref="6ca3f4659530db0c27f67623bd27b304" prefix=" " category="inline-code"></block> Contient l'emplacement de la copie Snapshot.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">description.ipynb</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">Pour visualiser les mesures entrantes, nous déployons une étape de pipeline qui fournit des tracés et des graphiques disponibles via les UI Kubeflow et MLRun. Chaque exécution a sa propre version de cet outil de visualisation.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">Nous surveillons en permanence les indicateurs des anomalies pour y détecter des anomalies. Cet ordinateur portable crée une fonction sans serveur qui génère les fonctionnalités qui doivent exécuter la prédiction des mesures entrantes. Ce bloc-notes appelle la création de la fonction. Le code de fonction se trouve dans le bloc-notes<block ref="ddc05946399cb9a8e617080738240288" prefix=" " category="inline-code"></block>. Notez que nous utilisons le même bloc-notes qu'une étape dans le pipeline à cette fin.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">formation.ipynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">Une fois les fonctions créées, nous déclenchements l'entraînement du modèle. Cette étape permet d'utiliser le modèle à utiliser pour l'inférence. Nous recueillons également des statistiques pour garder le suivi de chaque exécution (expérience).</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">Par exemple, la commande suivante saisit le score de précision dans le contexte de cette expérience. Cette valeur est visible dans Kubeflow et MLRun.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">déploiement-inférence-fonction.ipynb</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">La dernière étape du pipeline consiste à déployer le modèle comme une fonction sans serveur pour l'inférence continue. Ce bloc-notes appelle la création de la fonction sans serveur définie dans<block ref="8484275272e5c25a4b20c092eaed5ed3" prefix=" " category="inline-code"></block>.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">Examiner et créer le pipeline</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">La combinaison de l'exécution de tous les ordinateurs portables dans un pipeline permet à la série d'expériences continue de réévaluer la précision du modèle par rapport aux nouvelles mesures. Tout d'abord, ouvrez le<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> bloc-notes. Nous vous montrerons comment NetApp et Iguazio simplifient le déploiement de ce pipeline DE ML.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">Nous utilisons MLRun pour fournir un contexte et gérer l'allocation des ressources à chaque étape du pipeline. Le service MLRun API s'exécute dans la plateforme Iguazio et constitue le point d'interaction avec les ressources Kubernetes. Chaque développeur ne peut pas demander des ressources directement ; l'API traite les demandes et active les contrôles d'accès.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">Le pipeline peut fonctionner avec NetApp Cloud volumes et les volumes sur site. Cette démonstration a été conçue pour utiliser Cloud volumes, mais vous pouvez voir dans le code l'option d'exécution sur site.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">La première action nécessaire pour transformer un bloc-notes Jupyter en étape Kubeflow consiste à transformer le code en une fonction. Une fonction présente toutes les caractéristiques requises pour exécuter cet ordinateur portable. Lorsque vous faites défiler le bloc-notes, vous pouvez voir que nous définissons une fonction pour chaque étape du pipeline.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">Partie du bloc-notes</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">&lt;code_to_function&gt; (partie du module MLRun)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">Nom de la fonction : nom du projet. permet d'organiser tous les artefacts du projet. Ceci est visible dans l'interface utilisateur MLRun. Nature. Dans ce cas, une tâche Kubernetes. Il peut s'agir de DASK, mpi, sparkk8s, et plus encore. Voir la documentation MLRun pour plus de détails. Fichier. Nom du bloc-notes. Ce peut également être un emplacement dans Git (HTTP).</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">Nom de l'image Docker utilisée à cette étape. Nous avons créé ceci précédemment avec le bloc-notes create-image.ipynb.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_montages et volumes</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">Informations détaillées sur le montage de NetApp Cloud Volume au moment de l'exécution.</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">Nous définissons également des paramètres pour les étapes.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">Une fois que vous avez défini la fonction pour toutes les étapes, vous pouvez construire le pipeline. Nous utilisons le<block ref="98dd4155c9c8287a5a8e1d92417d0a99" prefix=" " category="inline-code"></block> module pour définir cette définition. La différence entre l'utilisation de MLRun et le développement de votre propre bâtiment réside dans la simplification et le raccourcissement du codage.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">Les fonctions que nous avons définies sont converties en composants STEP à l'aide du<block ref="6cebb60f71d9de65143ade7a8388e27a" prefix=" " category="inline-code"></block> Fonction de MLRun.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">Définition de l'étape d'instantané</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">Lancez une fonction Snapshot, sortez et montez le v3io comme source :</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Paramètres</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">Nouvelle tâche</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">NewTask est la définition de l'exécution de la fonction.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(Module MLRun)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">Gestionnaire. Nom de la fonction Python à appeler. Nous avons utilisé le gestionnaire de noms dans l'ordinateur portable, mais il n'est pas nécessaire. params. Les paramètres que nous avons transmis à l'exécution. Dans notre code, nous utilisons Context.get_param («PARAMÈTRE») pour obtenir les valeurs.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">as_step</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">Nom. Nom de l'étape du pipeline Kubeflow. sorties. Il s'agit des valeurs que l'étape ajoute au dictionnaire à la fin de l'étude. Regardez le bloc-notes Snap_cv.ipynb. mount_v3io(). Cette opération permet de configurer l'étape pour monter /User pour l'utilisateur exécutant le pipeline.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">entrées</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">Vous pouvez passer à une étape les sorties d'une étape précédente. Dans ce cas, snap.outputs['napVolumeDetails'] correspond au nom de la copie Snapshot que nous avons créée à l'étape d'instantané.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">chemin_sortie</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">Emplacement permettant de placer des artefacts générant à l'aide du module MLRun log_artefacts.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">Vous pouvez exécuter<block ref="0967a45abd189b49d2e7af9c1df9db9f" prefix=" " category="inline-code"></block> de haut en bas. Vous pouvez ensuite accéder à l'onglet pipelines à partir du tableau de bord Iguazio pour contrôler la progression comme indiqué dans l'onglet Iguazio Dashboard pipelines.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">Comme nous avons enregistré la précision de l'étape d'entraînement à chaque série, nous avons un dossier de précision pour chaque expérience, tel qu'indiqué dans le dossier de précision de l'entraînement.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">Si vous sélectionnez l'étape Snapshot, le nom de la copie Snapshot utilisée pour exécuter cette expérience s'affiche.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">L'étape décrite présente des artéfacts visuels pour explorer les mesures que nous avons utilisées. Vous pouvez développer pour afficher le tracé complet comme illustré dans l'image suivante.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">La base de données de l'API MLRun assure également le suivi des entrées, des sorties et des artefacts pour chaque exécution organisée par projet. L'image suivante présente un exemple d'entrées, de sorties et d'artefacts pour chaque séquence.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">Pour chaque tâche, nous stockons des détails supplémentaires.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun site GitHub</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">Il y a plus d'informations sur MLRun que ce document. Les artefacts al, y compris la définition des étapes et fonctions, peuvent être enregistrés dans la base de données API, versionnés et appelés individuellement ou en tant que projet complet. Les projets peuvent également être enregistrés et transmis à Git pour une utilisation ultérieure. Nous vous encourageons à en savoir plus sur le<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">Next : déployer Grafana Dashboard</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">Cette page décrit la configuration du déploiement de DASK avec RAPIDS sur AKS utilisant Helm.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Mise en place de DASK avec RAPIDS sur AKS à l'aide de Helm</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">Précédent : installez Trident.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Pour configurer le déploiement de DASK avec RAPIDS sur AKS à l'aide de Helm, procédez comme suit :</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">Créer un espace de noms pour l'installation de DASK avec RAPIDS.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">Création d'une demande de volume persistant pour stocker le dataset de taux de clics :</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">Enregistrez le contenu YAML suivant dans un fichier pour créer une demande de volume persistant.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Appliquez le fichier YAML sur votre cluster Kubernetes.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">Cloner le<block ref="d126903117bcd329e601af7057853376" prefix=" " category="inline-code"></block> référentiel (<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>).</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">Modifier<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Et inclure le PVC créé précédemment pour les travailleurs et l'espace de travail Jupyter.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">Accédez au<block ref="47e38535ab0a13ca65c9bba04c686040" prefix=" " category="inline-code"></block> répertoire du référentiel.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Mettez à jour le<block ref="ba05023d0f1b5d4b64b6cad4cf9a7ecd" prefix=" " category="inline-code"></block> Fichier et montage du volume à l'aide de la demande de volume persistant.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">Accédez au répertoire personnel du référentiel et déployez DASK avec trois noeuds de travail sur AKS en utilisant Helm.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">Ensuite, les tiers de performance Azure NetApp Files.</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">Avec la technologie de pointe actuelle, les outils de modélisation pré-entraînés publiés par NVIDIA, AWS, Google et autres, un pipeline de bout en bout avec des modèles complexes peut désormais être mis en place et personnalisé avec une facilité relative.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="doc">Cas d'utilisation</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">Précédent : analytique du centre de support.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">En raison du nombre d'appels traités par ces centres d'assistance, l'évaluation du rendement des appels peut prendre beaucoup de temps si elle est effectuée manuellement. Les méthodes traditionnelles, telles que le comptage des sacs de mots et d'autres méthodes, peuvent atteindre une certaine automatisation, mais ces méthodes ne prennent pas en compte les aspects plus nuancés et le contexte sémantique du langage dynamique. Les techniques de modélisation d'IA peuvent être utilisées pour effectuer certaines de ces analyses plus nuancées de manière automatisée. De plus, avec les outils de modélisation pré-entraînés et publiés par NVIDIA, AWS, Google et autres, un pipeline de bout en bout avec des modèles complexes peut maintenant être mis en place et personnalisé avec une facilité relative.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">Un pipeline de bout en bout pour l'analyse des sentiments des centres de support permet d'analyser les fichiers audio en temps réel lorsque les employés convertisse avec les appelants. Ensuite, ces fichiers audio sont traités pour être utilisés dans le composant parole-texte qui les convertit au format texte. Chaque phrase de la conversation reçoit un libellé indiquant le sentiment (positif, négatif ou neutre).</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">L'analyse des sentiments peut fournir un aspect essentiel des conversations pour évaluer la performance des appels. Ces sentiments ajoutent une profondeur supplémentaire aux interactions entre les employés et les appelants. Le tableau de bord des sentiments assistés par l'IA fournit aux responsables un suivi en temps réel des sentiments au sein d'une conversation, ainsi qu'une analyse rétrospective des appels passés de l'employé.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">Des outils prédéfinis peuvent être combinés de façon puissante afin de créer rapidement un pipeline d'IA de bout en bout pour résoudre ce problème. Dans ce cas, la bibliothèque NVIDIA RIVA peut être utilisée pour effectuer les deux tâches en série : transcription audio et analyse de sentiment. Le premier est un algorithme de traitement du signal d'apprentissage supervisé et le second est un algorithme de classification NLP d'apprentissage supervisé. Ces algorithmes prêts à l'emploi peuvent être ajustés pour toute utilisation pertinente avec les données pertinentes de l'entreprise à l'aide du kit NVIDIA TAO. Cela entraîne la création de solutions plus précises et plus puissantes pour un coût et des ressources réduits. Les clients peuvent intégrer le<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> Infrastructure pour les applications de visioconférence avec accélération graphique dans leur conception de centre de support.</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">Les utilisations suivantes sont au cœur de cette solution. Dans les deux cas, TAO Toolkit permet de régler avec précision les modèles et RIVA pour le déploiement de modèles.</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="list-text">Parole-à-texte</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">Analyse des sentiments</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">Pour analyser les interactions entre les employés et les clients du centre de support, chaque conversation client sous forme d'appels audio peut être exécutée dans le pipeline pour extraire des sentiments de phrase. Ces sentiments peuvent ensuite être vérifiés par un humain pour justifier les sentiments ou les ajuster selon les besoins. Les données étiquetées sont ensuite transmises à l'étape de réglage fin pour améliorer les prédictions de sentiment. Si des données de sentiment étiquetées existent déjà, le réglage fin du modèle peut être accéléré. Dans les deux cas, le pipeline est généralisable à d'autres solutions qui exigent l'ingestion de l'audio et la classification des phrases.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">Les résultats des sentiments d'IA sont soit téléchargés vers une base de données cloud externe, soit vers un système de stockage géré par l'entreprise. Les sorties de sentiment sont transférées de cette base de données plus grande vers le stockage local pour une utilisation dans le tableau de bord qui affiche l'analyse de sentiment pour les gestionnaires. La principale fonctionnalité du tableau de bord consiste à interagir avec l’employé du service client en temps réel. Les responsables peuvent évaluer et fournir des commentaires sur les employés lors de leurs appels avec des mises à jour en direct du sentiment de chaque phrase, ainsi qu'un examen historique des performances passées de l'employé ou des réactions des clients.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">Le <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> Peut continuer à gérer les systèmes de stockage des données même après que le pipeline d'inférence RIVA génère des étiquettes de sentiments. Les résultats de cette IA peuvent être téléchargés vers un système de stockage des données géré par le kit NetApp DataOps. Les systèmes de stockage des données doivent être capables de gérer des centaines d'insertions et de sélectionner chaque minute. Le système de stockage de périphériques local interroge le stockage de données plus important en temps réel pour l'extraction. Le tableau de bord peut également être interrogé sur ses données historiques afin d'optimiser l'expérience qu'il fournit. Le kit NetApp DataOps facilite ces deux utilisations en clonant rapidement les données et en les distribuant dans tous les tableaux de bord.</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">Responsables des employés</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">Ingénieurs/data Scientists</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">Administrateurs IT (sur site, dans le cloud ou hybride)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">Le suivi des sentiments tout au long des conversations est un outil précieux pour évaluer les performances des employés. Grâce au tableau de bord ai, les responsables peuvent voir comment les employés et les appelants changent leurs sentiments en temps réel, ce qui permet des évaluations en direct et des sessions de guidage. De plus, les entreprises peuvent bénéficier de précieux avis de la part de clients engagés dans des conversations vocales, des chatbots de texte et des visioconférences. Cette analytique client exploite les fonctionnalités de traitement multimodal à grande échelle avec des modèles et des workflows d'IA modernes et à la pointe de la technologie.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">En ce qui concerne les données, un grand nombre de fichiers audio sont traités quotidiennement par le centre d'assistance. Le kit NetApp DataOps facilite le traitement des données pour affiner régulièrement les modèles et les tableaux de bord d'analyse de sentiment.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">Les administrateurs INFORMATIQUES profitent également du kit NetApp DataOps car il leur permet de déplacer rapidement des données entre les environnements de déploiement et de production. Les environnements et les serveurs NVIDIA doivent également être gérés et distribués pour permettre l'inférence en temps réel.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">Cnvrg.io (<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>) :</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">CŒUR Cnvrg (plateforme DE ML gratuite)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">Documents Cnvrg</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">Serveurs NVIDIA DGX-1 :</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">Serveurs NVIDIA DGX-1</block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">GPU NVIDIA Tesla V100 à cœurs Tensor</block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">Systèmes NetApp AFF :</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">NetApp Flash Advantage pour AFF</block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">Matrice d'interopérabilité NetApp :</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">Matrice d'interopérabilité NetApp</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">Connectivité réseau d'ONTAP ai :</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Switchs Cisco Nexus 3232C</block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Switchs Mellanox Spectrum 2000</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">DALI</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow : un framework d'apprentissage machine open source pour tous</block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod : le cadre d’apprentissage profond Open source distribué d’Uber pour TensorFlow</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">Optimisation des GPU dans l'écosystème d'exécution du conteneur</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">Dataset et bancs d'essai :</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">Ensemble de données de radiographie du thorax NIH</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaotong Wang, Yifan Peng, le lu, Zhiyong lu, Mohammadadi Bagheri, Ronald Summers, ChestX-ray8: Base de données à rayons X dans les hôpitaux et bancs d'essai sur la classification faiblement supervisée et la localisation des maladies du thorax commun, IEEE CVPR, pp 3462-3471, 2017 TR-4841-0620</block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">Une fois que tout est déployé, exécutez des inférences sur les nouvelles données. Les modèles prédisent si un utilisateur clique sur une publicité en fonction des activités de navigation. Les résultats de la prédiction sont stockés dans un DASK cuDF. Vous pouvez surveiller les résultats avec Prometheus et visualiser dans les tableaux de bord Grafana.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Surveillez DAsk et RAPIDS avec Prometheus et Grafana</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">Précédent : comparaison des temps de formation.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS ai moyen post</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">Pour plus d'informations, reportez-vous à ce document<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">Suivant : gestion des versions de modèles et de datasets avec le kit d'outils NetApp DataOps.</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153-DEPLOY inclut des instructions de déploiement de système de stockage pour un workload d'architecture vérifiée NetApp pour le machine learning (ML) et l'intelligence artificielle (IA) utilisant les systèmes de stockage NetApp AFF A800, les systèmes NVIDIA DGX A100 et les switchs Ethernet NVIDIA Mellanox Spectrum SN3700V 200 Gb. Celui-ci contient également des instructions pour l'exécution des tests de validation</block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">Vous trouverez dans ce livre blanc des instructions pour créer des solutions d'intelligence artificielle (IA) conversationnelles avec la structure NVIDIA Jarvis et NetApp ONTAP ai et Cloud Sync, pour le Retail, et d'autres utilisations. Elle comprend des informations sur les workflows généraux utilisés dans le développement de modèles NLP (Natural Language Processing) pour les assistants virtuels, des scénarios de test validés et des résultats.</block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">Cette page répertorie la configuration logicielle requise pour cette solution.</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">Le tableau suivant répertorie la configuration logicielle requise pour cette solution.</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">Image conteneur RAPIDS et Dapose</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">Référentiel: "Rapidsai/rapidsai" tag: 0.17-cuda11.0-runtime-ubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">Ensuite : conditions des ressources cloud.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">Ce rapport technique fournit des conseils de conception afin que les clients puissent réaliser une analyse des sentiments dans un centre de support global de niveau entreprise en utilisant les technologies de gestion des données NetApp avec un framework logiciel NVIDIA, par le biais de l'apprentissage par transfert et de la discussion sur l'IA.</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">Tr-4910 : analyse du sentiment issue des communications avec le client sur NetApp ai</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Satish Thyagarajan et David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">Ce rapport technique fournit des conseils de conception afin que les clients puissent réaliser une analyse des sentiments dans un centre de support global de niveau entreprise en utilisant les technologies de gestion des données NetApp avec un framework logiciel NVIDIA, par le biais de l'apprentissage par transfert et de la discussion sur l'IA. Cette solution s'applique à tout secteur souhaitant obtenir des informations sur les clients à partir de fichiers vocaux ou texte enregistrés représentant des journaux de conversation, des e-mails et d'autres communications audio ou texte. Nous avons mis en œuvre un pipeline de bout en bout afin de démontrer la reconnaissance vocale automatique, l'analyse des sentiments en temps réel et le réentraînement du modèle de traitement du langage naturel du deep learning. Nous avons également mis en place des fonctionnalités de recyclage sur un cluster de calcul accéléré par processeur graphique grâce au stockage 100 % Flash de NetApp connecté au cloud. Des modèles linguistiques de pointe peuvent être entraînés et optimisés pour inférence rapidement avec le centre de support global. Ils assurent ainsi une expérience client exceptionnelle et permettent d'évaluer de manière objective les performances des employés à long terme.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">L'analyse des sentiments est un domaine d'étude dans le traitement du langage naturel (NLP) par lequel des sentiments positifs, négatifs ou neutres sont extraits du texte. Les systèmes d'IA conversationnels ont été étendus à un niveau d'intégration quasi global, car de plus en plus de gens viennent à les interagir avec eux. L'analyse des sentiments présente de nombreux cas d'utilisation, allant de la détermination de la performance des employés du centre de support lors de conversations avec les appelants à la fourniture de réponses de chatbot automatisées appropriées à la prévision du prix des actions d'une entreprise en fonction des interactions entre les représentants des entreprises et le public lors d'appels trimestriels sur les bénéfices. En outre, l'analyse de sentiment peut être utilisée pour déterminer l'opinion du client sur les produits, les services ou l'assistance fournis par la marque.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">Cette solution de bout en bout utilise des modèles NLP pour effectuer une analyse de confiance de haut niveau qui permet de créer des cadres analytiques de centre de support. Les enregistrements audio sont traités en texte écrit et le sentiment est extrait de chaque phrase de la conversation. Les résultats, regroupés dans un tableau de bord, peuvent être conçus pour analyser les sentiments de conversation, historiquement et en temps réel. Cette solution peut être généralisée à d'autres solutions avec des modalités de données et des besoins de sortie similaires. Grâce aux données appropriées, d'autres cas d'utilisation peuvent être mis en œuvre. Par exemple, les appels sur les bénéfices de l'entreprise peuvent être analysés pour obtenir un sentiment à l'aide du même pipeline de bout en bout. D'autres formes d'analyses du PNL, telles que la modélisation de sujets et la reconnaissance d'entités nommées (NER), sont également possibles en raison de la nature souple du pipeline.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">Ces implémentations d'IA ont été rendues possibles par NVIDIA RIVA, le kit NVIDIA TAO et le kit NetApp DataOps. Les outils NVIDIA sont utilisés pour déployer rapidement des solutions d'IA haute performance à l'aide de modèles et de pipelines prédéfinis. Le kit NetApp DataOps simplifie les tâches de gestion des données pour accélérer le développement.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">En valeur pour le client</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">Les entreprises voient les avantages d'un outil d'évaluation des employés et de réaction des clients pour les conversations texte, audio et vidéo pour l'analyse des sentiments. Les responsables bénéficient des informations présentées dans le tableau de bord, ce qui permet d'évaluer les employés et la satisfaction des clients en fonction des deux côtés de la conversation.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">Par ailleurs, le kit NetApp DataOps gère les versions et l'allocation des données au sein de l'infrastructure du client. Cela entraîne des mises à jour fréquentes des analyses présentées au tableau de bord sans générer des coûts de stockage de données qui ne sont pas unwieldy.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">Ensuite : cas d'utilisation.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">Ce document présente une architecture de calcul et de stockage permettant de déployer les inférence d'intelligence artificielle basée sur processeur graphique sur des contrôleurs de stockage NetApp et des serveurs Lenovo ThinkSystem dans un environnement en périphérie qui répond à l'émergence de scénarios applicatifs.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">Tr-4886 : Inférence d'IA en périphérie - NetApp avec Lenovo ThinkSystem - conception de la solution</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Satish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">Introduction</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">De plus en plus d'entreprises génèrent des volumes massifs de données à la périphérie du réseau. Pour tirer le meilleur parti des capteurs intelligents et des données de l'IoT, les entreprises recherchent une solution de streaming en temps réel qui met à profit l'informatique en périphérie. De ce fait, les tâches de calcul exigeantes sont de plus en plus effectuées à la périphérie, en dehors des data centers. L'inférence d'IA est un moteur de cette tendance. Les serveurs de périphérie offrent une puissance de calcul suffisante pour ces charges de travail, en particulier lorsqu'ils sont utilisés des accélérateurs, mais le stockage est souvent limité, en particulier dans les environnements multiserveurs. Dans ce document, nous vous montrons comment déployer un système de stockage partagé dans l'environnement de périphérie et comment il tire parti des charges de travail d'inférence d'IA sans imposer de baisse des performances.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">Ce document décrit une architecture de référence pour l'inférence d'IA à la périphérie. Elle regroupe plusieurs serveurs Lenovo ThinkSystem Edge avec un système de stockage NetApp pour créer une solution facile à déployer et à gérer. Il est destiné à servir de guide de référence pour les déploiements pratiques dans diverses situations, comme le sol en usine avec plusieurs caméras et capteurs industriels, les systèmes de point de vente dans les transactions au détail ou les systèmes de conduite autonome (FSD) qui identifient les anomalies visuelles des véhicules autonomes.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">Ce document comprend le test et la validation d'une configuration de calcul et de stockage composée du serveur Lenovo ThinkSystem SE350 Edge Server et d'un système de stockage NetApp AFF et EF-Series d'entrée de gamme. Ces architectures de référence constituent une solution efficace et économique pour les déploiements d'IA. Elles fournissent également des services de données complets, une protection des données intégrée, une évolutivité transparente et un stockage de données connecté au cloud avec NetApp ONTAP et le logiciel de gestion des données NetApp SANtricity.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">Ce document est destiné aux publics suivants :</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">Les dirigeants et les architectes d'entreprise qui souhaitent proposer l'IA de manière adéquate à la périphérie.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">Les data Scientists, les ingénieurs de données, les chercheurs d'IA et de machine learning (ML) et les développeurs de systèmes d'IA.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">Les architectes d'entreprise qui conçoivent des solutions pour le développement de modèles et d'applications d'IA/ML.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">Les data Scientists et les ingénieurs d'IA qui recherchent des méthodes efficaces pour déployer les modèles de deep learning (DL) et DE MACHINE LEARNING (ML).</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">Ce serveur Lenovo ThinkSystem, avec NetApp ONTAP ou NetApp SANtricity, est conçu pour gérer l'inférence d'IA sur de grands datasets grâce à la puissance de traitement des GPU avec les processeurs classiques. Cette validation démontre les performances élevées et une gestion optimale des données grâce à une architecture qui utilise des serveurs Lenovo de périphérie SR350 uniques ou multiples interconnectés à un seul système de stockage AFF NetApp, comme l'illustre les deux figures suivantes.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">La présentation de l'architecture logique de la figure suivante montre le rôle des éléments de calcul et de stockage dans cette architecture. Elle indique en particulier les éléments suivants :</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">Les dispositifs de calcul de périphérie exécutant l'inférence sur les données qu'ils reçoivent des caméras, des capteurs, etc.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">Élément de stockage partagé qui répond à plusieurs besoins :</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">Fournit un emplacement central pour les modèles d'inférence et les autres données requises pour effectuer l'inférence. Les serveurs de calcul accèdent directement au stockage et utilisent les modèles d'inférence à l'échelle du réseau sans avoir à les copier localement.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">Les modèles mis à jour sont fournis ici.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">Archive les données d'entrée que les serveurs de périphérie reçoivent pour une analyse ultérieure. Par exemple, si les périphériques sont connectés à des caméras, l'élément de stockage conserve les vidéos capturées par les caméras.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">rouge</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">bleu</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Système de calcul Lenovo</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">Système de stockage NetApp AFF</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">Périphériques exécutant l'inférence sur les entrées des caméras, des capteurs, etc.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">Stockage partagé qui contient les modèles d'inférence et les données de terminaux en périphérie à des fins d'analyse ultérieure.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">Cette solution NetApp et Lenovo offre les avantages suivants :</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">Les GPU ont accéléré le calcul en périphérie.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">Déploiement de plusieurs serveurs de périphérie sauvegardés et gérés à partir d'un stockage partagé.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">Protection fiable des données pour respecter les objectifs de point de récupération (RPO) et de délai de restauration (RTO) faibles, sans perte de données.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">Gestion des données optimisée grâce aux copies et clones NetApp Snapshot pour rationaliser les workflows de développement.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">Utilisation de cette architecture</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">Ce document valide la conception et les performances de l'architecture proposée. Toutefois, nous n'avons pas testé certains éléments logiciels, tels que les conteneurs, la charge de travail ou la synchronisation des données avec le cloud ou le data Center sur site, car ils sont spécifiques à un scénario de déploiement. Il existe ici plusieurs choix.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">Au niveau de la gestion des conteneurs, la gestion des conteneurs Kubernetes est un bon choix et est bien prise en charge dans une version entièrement en amont (Canonical) ou dans une version modifiée adaptée aux déploiements d'entreprise (Red Hat). Le <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> Qui utilise NetApp Trident et le nouveau système ajouté<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> Traçabilité intégrée, fonctions de gestion des données, interfaces et outils pour les data Scientists et les ingénieurs de données à intégrer au stockage NetApp. Kubeflow, le kit DE ML pour Kubernetes, fournit des fonctionnalités d'IA supplémentaires, ainsi qu'une prise en charge des versions de modèles et KFServing sur plusieurs plateformes telles que TensorFlow ou NVIDIA Triton Inférence Server. Autre option : la plateforme NVIDIA EGX, qui fournit la gestion des charges de travail et l'accès à un catalogue de conteneurs d'inférence d'IA compatibles avec les GPU. Toutefois, il peut être nécessaire de mettre en production des efforts et une expertise considérables. Pour ce faire, il faut parfois l'assistance d'un éditeur indépendant de logiciels ou d'un consultant.</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">Le principal avantage de l'inférence d'IA et du calcul en périphérie est la capacité des terminaux à calculer, à traiter et à analyser les données avec un niveau élevé de qualité et sans latence. Ce document présente trop d'exemples d'utilisation de Edge Computing, mais voici quelques exemples bien connus :</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">Automobiles : véhicules autonomes</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">Le classique illustration se trouve dans les systèmes d'assistance à la conduite automobile (ADAS) pour les véhicules autonomes (AV). Pour être un conducteur sûr, l'IA dans les voitures sans chauffeur doit rapidement traiter un grand nombre de données provenant des caméras et des capteurs. Prendre trop de temps pour interpréter un objet et un être humain peut signifier la vie ou la mort, c'est pourquoi il est essentiel de pouvoir traiter ces données aussi près que possible du véhicule. Dans ce cas, un ou plusieurs serveurs de calcul de périphérie gèrent les entrées des caméras, DES RADARS, lidar et autres capteurs, tandis que le stockage partagé contient les modèles d'inférence et stocke les données d'entrée des capteurs.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">Soins de santé : surveillance des patients</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">L'un des plus grands impacts de l'IA et de l'Edge Computing est sa capacité à améliorer la surveillance continue des patients atteints de maladies chroniques dans les établissements de soins à domicile et les unités de soins intensifs. Les données provenant de dispositifs périphériques qui surveillent les niveaux d’insuline, la respiration, l’activité neurologique, le rythme cardiaque et les fonctions gastro-intestinales nécessitent une analyse instantanée des données qui doivent être traitées immédiatement parce qu’il y a peu de temps pour agir afin de sauver la vie d’une personne.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">Vente au détail : paiement sans caissier</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">L'informatique en périphérie peut alimenter l'IA et LE ML afin d'aider les détaillants à réduire les délais d'exécution et à accroître le trafic au pied. Les systèmes sans caissier prennent en charge différents composants, tels que :</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">Authentification et accès. Connecter le client-revendeur physique à un compte validé et autoriser l'accès à l'espace de vente.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">Surveillance des stocks. Utilisation de capteurs, de tags RFID et de systèmes de vision informatique pour confirmer la sélection ou la désélection d'articles par les acheteurs.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">Dans ce cas, chacun des serveurs périphériques gère chaque compteur de réservation et le système de stockage partagé sert de point de synchronisation central.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">Services financiers : sécurité humaine dans les kiosques et prévention de la fraude</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">Les services bancaires exploitent l'IA et l'informatique en périphérie pour innover et créer des expériences bancaires personnalisées. Les kiosques interactifs qui utilisent l'analytique en temps réel et l'inférence d'IA permettent désormais aux clients d'utiliser les guichets automatiques pour se retirer de l'argent, mais ils surveillent de façon proactive les kiosques visant à identifier les risques de sécurité humaine ou de comportements frauduleux. Dans ce scénario, les serveurs de calcul en périphérie et les systèmes de stockage partagé sont connectés à des kiosques et caméras interactifs pour aider les banques à collecter et à traiter des données à l'aide de modèles d'inférence IA.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">Fabrication : industrie 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">La quatrième révolution industrielle (Industrie 4.0) a commencé, ainsi que les nouvelles tendances comme Smart Factory et l'impression 3D. Pour se préparer à un avenir piloté par les données, une communication M2M (machine-to-machine) à grande échelle et l'Internet des objets sont intégrés pour permettre une automatisation accrue sans intervention humaine. Le secteur de la fabrication est déjà hautement automatisé et l'ajout de fonctionnalités d'IA représente une continuation naturelle de la tendance à long terme. L'IA permet d'automatiser les opérations qui peuvent être automatisées avec la vision par ordinateur et d'autres fonctionnalités d'IA. Vous pouvez automatiser le contrôle de qualité ou les tâches qui reposent sur la vision humaine ou la prise de décision pour réaliser des analyses plus rapides des matériaux sur les lignes d'assemblage dans les usines de fabrication afin d'aider les usines à respecter les normes ISO requises en matière de sécurité et de gestion de la qualité. Ici, chaque serveur Edge de calcul est connecté à une matrice de capteurs qui surveille le processus de fabrication et les modèles d'inférence mis à jour sont déplacés vers le stockage partagé, si nécessaire.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">Télécommunications : détection de la rouille, inspection des tours et optimisation du réseau</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">Le secteur des télécommunications utilise la vision par ordinateur et des techniques d'IA pour traiter les images qui détectent automatiquement la rouille et identifient les tours cellulaires qui contiennent de la corrosion et requièrent donc une inspection plus poussée. L'utilisation d'images de drone et de modèles d'IA pour identifier des régions distinctes d'une tour pour analyser la rouille, les fissures de surface et la corrosion a augmenté au cours des dernières années. La demande continue d'augmenter pour les technologies d'IA, qui permettent aux infrastructures de télécommunications et aux tours cellulaires d'être inspectées efficacement, évaluées régulièrement pour vérifier leur dégradation et réparées rapidement si nécessaire.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">En outre, dans le secteur des télécommunications, l'utilisation d'algorithmes d'IA et DE ML permet de prévoir les modèles de trafic de données, de détecter des périphériques compatibles 5G et d'automatiser et d'augmenter la gestion de l'énergie à entrées multiples et à sorties multiples (MIMO). Le matériel MIMO est utilisé dans les tours radio pour augmenter la capacité du réseau, mais cela est fourni avec des coûts d'énergie supplémentaires. Les modèles ML pour le « mode veille MIMO » déployés sur les sites cellulaires permettent de prévoir l'utilisation efficace des radios et de réduire les coûts de consommation d'énergie pour les opérateurs de réseaux mobiles (MNO). Les solutions d'inférence et de calcul en périphérie d'IA permettent aux entreprises non seulement de réduire la quantité de données transmises aux data centers, mais aussi de réduire leur coût total de possession, d'optimiser les opérations réseau et d'améliorer les performances globales des utilisateurs.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">Tr-4841 : système d'exploitation pour l'IA dans le cloud hybride avec mise en cache des données</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">La croissance exponentielle des données et la croissance exponentielle DU ML et de l'IA ont convergé pour créer une économie de zettaoctet dotée de défis uniques en matière de développement et d'implémentation.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">Bien que tous les modèles DE ML aient besoin de données gourmandes en ressources de stockage haute performance, l'implémentation de ce modèle n'est pas beaucoup plus directe, en particulier avec le cloud hybride et les instances de calcul flexibles. Des quantités massives de données sont généralement stockées dans des data Lakes de faible coût, où les ressources de calcul d'IA haute performance telles que les GPU ne peuvent pas y accéder de manière efficace. Ce problème est aggravé dans l'infrastructure du cloud hybride où certaines charges de travail s'exécutent dans le cloud et certaines se trouvent sur site ou dans un environnement HPC différent.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">Dans ce document, nous présentons une solution inédite qui permet aux professionnels DE L'IT et aux ingénieurs de données de créer une plateforme d'IA de cloud hybride véritablement équipée d'un hub de données capable de créer instantanément et automatiquement un cache de leurs jeux de données à proximité de leurs ressources de calcul. où qu'ils soient situés. Par conséquent, l'entraînement des modèles haute performance est non seulement possible, mais de nouveaux avantages sont également créés, notamment la collaboration de plusieurs professionnels de l'IA, qui disposent d'un accès immédiat aux caches, aux versions et aux lignées de dataset dans un hub de version du dataset.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">Suivant : présentation du cas d'utilisation et déclaration du problème</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">La solution proposée dans ce rapport technique a été démontrée pour soutenir la prestation de telles expériences client exceptionnelles. Le défi consiste désormais à s'assurer que les entreprises prennent des mesures pour moderniser leur infrastructure et leurs workflows d'IA.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">Précédent : vidéos et démos.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">L'expérience client étant de plus en plus considérée comme un champ de bataille essentiel de la concurrence, un centre de support mondial avec intelligence artificielle est devenu un composant essentiel que les entreprises de presque tous les secteurs ne peuvent se permettre de négliger. La solution proposée dans ce rapport technique a été démontrée pour soutenir la prestation de telles expériences client exceptionnelles. Le défi consiste désormais à s'assurer que les entreprises prennent des mesures pour moderniser leur infrastructure et leurs workflows d'IA.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">Les meilleures implémentations d'IA dans le service client ne sont pas à remplacer des agents humains. L'IA leur permet plutôt de créer des expériences client exceptionnelles grâce à l'analyse des sentiments en temps réel, à l'escalade des conflits et à un calcul multimodal affectueux pour détecter des indices verbaux, non verbaux et faciaux avec lesquels des modèles d'IA complets peuvent formuler des recommandations à grande échelle et compléter les lacunes d'un agent humain. L'IA permet également une meilleure correspondance entre un client particulier et les agents disponibles actuellement. Grâce à l'IA, les entreprises peuvent extraire un sentiment précieux des clients concernant leurs pensées et impressions sur les produits, services et image de marque du fournisseur.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">La solution peut également être utilisée pour construire des données de séries chronologiques destinées aux agents de support afin de servir de mesure objective d'évaluation des performances. Les enquêtes classiques sur la satisfaction des clients manquent souvent de réponses suffisantes. En recueillant des sentiments à long terme des employés et des clients, les employeurs peuvent prendre des décisions éclairées concernant le rendement des agents de soutien.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">L'association de NetApp, des SFL Scientific, des frameworks d'orchestration open source et de NVIDIA rassemble les dernières technologies en tant que services gérés, tout en offrant une grande flexibilité pour accélérer l'adoption des technologies et améliorer le délai de mise sur le marché des nouvelles applications d'IA/ML. Ces services avancés sont fournis sur site, facilement ports pour les environnements cloud natifs, ainsi que pour les architectures de déploiement hybride.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">Cette page comprend des informations sur la façon dont NetApp peut faire progresser les projets d'IA, notamment des informations sur les conteneurs, Kubernetes, NetApp Trident et plus encore.</block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">Concepts et composants</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">L'intelligence artificielle</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">L'IA est une discipline scientifique informatique dans laquelle les ordinateurs sont entraînés pour imiter les fonctions cognitives de l'esprit humain. Les développeurs d'IA entraînent des ordinateurs pour apprendre et résoudre les problèmes de manière similaire, voire supérieure, à celle des humains. L'apprentissage profond et l'apprentissage machine sont des sous-domaines de l'IA. Les entreprises adoptent de plus en plus l'IA, LE ML et le DL pour répondre à leurs besoins stratégiques. Voici quelques exemples :</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">Analyser d'importants volumes de données pour obtenir des informations stratégiques inexistantes</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">Interagir directement avec les clients à l'aide du traitement du langage naturel</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">Automatisation de divers processus et fonctions métier</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">Les workloads d'entraînement et d'inférence d'IA modernes requièrent des fonctionnalités de calcul parallèle. Par conséquent, les GPU sont de plus en plus utilisés pour exécuter les opérations d'IA, car les capacités de traitement parallèle des GPU sont largement supérieures à celles des processeurs génériques.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">Les conteneurs sont des instances isolées de l'espace utilisateur qui s'exécutent sur un noyau de système d'exploitation hôte partagé. Les conteneurs se généraaffichent de plus en plus rapidement. Les conteneurs offrent bon nombre des avantages de la boxe applicative offerts par les machines virtuelles. Cependant, les couches de l'hyperviseur et du système d'exploitation invité sur lesquelles reposent les machines virtuelles ont été éliminées, les conteneurs sont beaucoup plus légers. La figure suivante montre une visualisation des machines virtuelles par rapport aux conteneurs.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Site Web de Docker</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">Les conteneurs permettent également de packaging efficace des dépendances entre applications, des durées d'exécution, etc., directement avec une application. Le format de conditionnement de conteneurs le plus utilisé est le container Docker. Une application conteneurisée dans le format de conteneur Docker peut être exécutée sur n'importe quel ordinateur capable d'exécuter des conteneurs Docker. Cela est vrai même si les dépendances de l’application ne sont pas présentes sur la machine car toutes les dépendances sont conditionnées dans le conteneur lui-même. Pour plus d'informations, consultez la<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Site Web de Kubernetes</block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes est une plateforme open source d'orchestration de conteneurs distribuée, conçue à l'origine par Google, et désormais gérée par Cloud Native Computing Foundation (CNCF). Kubernetes permet d'automatiser le déploiement, la gestion et l'évolutivité des fonctions pour les applications conteneurisées. Depuis quelques années, Kubernetes devient la plateforme dominante d'orchestration de conteneurs. Bien que les autres formats de conditionnement et les temps d'exécution des conteneurs soient pris en charge, Kubernetes est le plus souvent utilisé comme système d'orchestration pour les conteneurs Docker. Pour plus d'informations, consultez la<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Site Web Trident</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident est un orchestrateur de stockage open source développé et géré par NetApp qui simplifie considérablement la création, la gestion et la consommation du stockage persistant pour les workloads Kubernetes. Trident, une application Kubernetes native, s'exécute directement dans un cluster Kubernetes. Avec Trident, les utilisateurs de Kubernetes (développeurs, data Scientists, administrateurs Kubernetes, etc.) peuvent créer, gérer et interagir avec les volumes de stockage persistant dans le format Kubernetes standard qu'ils connaissent déjà. Ils peuvent également bénéficier des fonctionnalités avancées de gestion des données de NetApp et d'un environnement Data Fabric optimisé par la technologie NetApp. Trident élimine les complexités du stockage persistant et facilite la consommation. Pour plus d'informations, consultez la<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">Site Web de DeepOps</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps est un projet open source de NVIDIA qui, grâce à Ansible, automatise le déploiement de clusters de serveurs GPU conformément aux bonnes pratiques. DeepOps est modulaire et peut être utilisé pour diverses tâches de déploiement. Pour ce document et l'exercice de validation décrit, DeepOps est utilisé pour déployer un cluster Kubernetes composé de nœuds workers de serveurs GPU. Pour plus d'informations, consultez la<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Site web Kubeflow</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow est un kit d'IA et DE ML open source pour Kubernetes qui a été développé à l'origine par Google. Le projet Kubeflow permet de déployer des workflows d'IA et DE ML sur Kubernetes de façon simple, portable et évolutive. Kubeflow s'affranchit des complexités de Kubernetes, ce qui permet aux data Scientists de se concentrer sur les meilleures connaissances―data science. Voir la figure suivante pour une visualisation. Kubeflow s'est beaucoup plus à l'mesure que les services IT d'entreprise sont de plus en plus standardisés sur Kubernetes. Pour plus d'informations, consultez la<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow pipelines</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow pipelines est un composant clé de Kubeflow. Kubeflow pipelines est une plateforme et une norme pour définir et déployer des workflows d'IA et DE ML portables et évolutifs. Pour plus d'informations, reportez-vous à la section<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Site Web de Jupyter</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Un Jupyter Notebook Server est une application web open source qui permet aux data Scientists de créer des documents de type wiki appelés ordinateurs portables Jupyter contenant du code en direct ainsi que des tests descriptifs. Les ordinateurs portables Jupyter sont largement utilisés dans la communauté de l'IA et DU ML afin de documenter, de stocker et de partager des projets d'IA et DE ML. Kubeflow simplifie le provisionnement et le déploiement de Jupyter Notebooks Servers sur Kubernetes. Pour plus d'informations sur les ordinateurs portables Jupyter, visitez le<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Pour plus d'informations sur les ordinateurs portables Jupyter dans le contexte de Kubeflow, consultez le<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>.</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="section-title">Débit d'air Apache</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow est une plateforme de gestion des flux de production open source qui permet de créer des programmes, de planifier et de surveiller des flux de travail d'entreprise complexes. Il est souvent utilisé pour automatiser les workflows ETL et de pipeline de traitement de données, mais ne se limite pas à ces types de flux de travail. Le projet de flux d'air a été lancé par Airbnb mais est depuis devenu très populaire dans l'industrie et est maintenant sous les auspices de la Apache Software Foundation. Le flux d'air est écrit en Python, les flux de production du flux d'air sont créés via des scripts Python, et le flux d'air est conçu selon le principe de « configuration as code ». De nombreux utilisateurs de flux d'air utilisent désormais Kubernetes.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">Graphes acycliques dirigés (DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">Dans le flux d'air, les flux de travail sont appelés graphiques acycliques dirigés (DAG). Les GDAs sont constitués de tâches exécutées dans l'ordre, en parallèle ou une combinaison des deux, en fonction de la définition DAG. Le planificateur de flux d'air exécute des tâches individuelles sur un ensemble de travailleurs, en respectant les dépendances au niveau des tâches spécifiées dans la définition DAG. Les DAG sont définis et créés par le biais de scripts Python.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9 est la dernière génération de logiciel de gestion du stockage de NetApp qui permet à des entreprises comme la vôtre de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP vous permet de gérer et de protéger vos données avec un seul ensemble d'outils, quel que soit leur emplacement. Vous pouvez aussi déplacer vos données librement partout où vous en avez besoin : la périphérie, le cœur ou le cloud. ONTAP 9 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques et pérennisent l'infrastructure sur toutes les architectures de cloud hybride.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">Simplifiez la gestion des données</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">La gestion des données est cruciale pour les opérations IT, car elle vous permet d'utiliser les ressources appropriées pour vos applications et vos datasets. ONTAP inclut les fonctionnalités suivantes pour rationaliser et simplifier vos opérations et réduire le coût total d'exploitation :</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">*La compaction des données à la volée et la déduplication étendue* la compaction des données réduit le gaspillage d'espace dans les blocs de stockage, et la déduplication augmente considérablement la capacité effective.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*Qualité de service (QoS) minimale, maximale et adaptative.* les contrôles de qualité de service granulaires permettent de maintenir les niveaux de performance des applications critiques dans des environnements hautement partagés.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">*ONTAP FabricPool* cette fonctionnalité permet la hiérarchisation automatique des données inactives vers des options de stockage en cloud public et privé, notamment Amazon Web Services (AWS), Azure et le stockage objet NetApp StorageGRID.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">Accélération et protection des données</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP offre des niveaux supérieurs de performances et de protection des données et étend ces fonctionnalités grâce à plusieurs fonctionnalités :</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* Hautes performances et faible latence.* ONTAP offre le débit le plus élevé possible à la latence la plus faible possible.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">*Technologie NetApp ONTAP FlexGroup* Un volume FlexGroup est un conteneur de données haute performance pouvant évoluer de manière linéaire jusqu'à 20 po et 400 milliards de fichiers, fournissant un espace de noms unique qui simplifie la gestion des données.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">*NetApp Volume Encryption*. ONTAP offre un chiffrement natif au niveau du volume avec prise en charge de la gestion des clés à la fois intégrée et externe.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">Une infrastructure pérenne</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9 aide à répondre aux besoins métier en constante évolution :</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">*Évolutivité transparente et continuité de l'activité.* ONTAP prend en charge l'ajout non disruptif de capacité aux contrôleurs et l'évolution scale-out des clusters. Vous pouvez effectuer la mise à niveau vers les technologies les plus récentes, telles que NVMe et FC 32 Gb, sans migration des données ni panne coûteuse.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">*Connexion au cloud.* ONTAP est l'un des logiciels de gestion de stockage les plus connectés au cloud, avec des options de stockage SDS (ONTAP Select) et des instances natives du cloud (NetApp Cloud Volumes Service) dans tous les clouds publics.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">*Intégration avec les applications émergentes* en utilisant la même infrastructure qui prend en charge les applications d'entreprise existantes, ONTAP propose des services de données haute performance pour les plateformes et applications nouvelle génération, comme OpenStack, Hadoop et MongoDB.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">Copies NetApp Snapshot</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">Une copie NetApp Snapshot est une image ponctuelle en lecture seule d'un volume. La consommation d'espace de stockage de l'image est minime et l'impact sur les performances est négligeable, car elle enregistre uniquement les modifications apportées aux fichiers depuis la dernière copie Snapshot, comme illustré dans la figure ci-dessous.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Les copies Snapshot doivent optimiser leur efficacité par rapport à la technologie de virtualisation de base du stockage ONTAP, WAFL (Write Anywhere File Layout). Tout comme une base de données, WAFL utilise des métadonnées pour désigner des blocs de données réels sur le disque. Contrairement à une base de données, WAFL ne remplace pas les blocs existants. Il écrit les données mises à jour sur un nouveau bloc et modifie les métadonnées. C'est parce que ONTAP référence les métadonnées lorsqu'il crée une copie Snapshot, plutôt que de copier des blocs de données, ces copies sont si efficaces. Vous éliminez ainsi les temps de recherche engendrés par d'autres systèmes pour localiser les blocs à copier, et par ailleurs le coût d'une copie.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">Vous pouvez utiliser une copie Snapshot pour restaurer des fichiers ou des LUN individuels, ou pour restaurer l'ensemble du contenu d'un volume. ONTAP compare les informations du pointeur de la copie Snapshot aux données d'un disque pour reconstruire l'objet manquant ou endommagé, sans temps d'indisponibilité ni coûts de performance significatifs.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">Technologie NetApp FlexClone</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">La technologie NetApp FlexClone référence les métadonnées Snapshot pour créer des copies inscriptibles instantanées d'un volume. Les copies partagent les blocs de données avec leurs parents. Aucun stockage n'est utilisé, sauf pour les métadonnées, jusqu'à ce que les modifications soient écrites sur la copie, comme illustré dans la figure ci-dessous. Là où les copies classiques peuvent prendre des minutes, voire des heures, pour créer des copies, FlexClone vous permet de copier même les jeux de données les plus volumineux quasi instantanément. C'est pourquoi il est idéal si vous avez besoin de plusieurs copies de jeux de données identiques (un espace de travail de développement, par exemple) ou de copies temporaires d'un jeu de données (afin de tester une application par rapport à un jeu de données de production).</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">Technologie de réplication des données NetApp SnapMirror</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">Le logiciel NetApp SnapMirror est une solution de réplication unifiée économique et facile à utiliser dans l'environnement Data Fabric. Il réplique les données à haute vitesse sur un WAN ou un LAN. Elle vous assure haute disponibilité et une réplication rapide des données pour les applications de tous types, y compris les applications stratégiques dans les environnements classiques et virtuels. En répliquant vos données sur un ou plusieurs systèmes de stockage NetApp, puis en les mettant régulièrement à jour, vous disposez de données actualisées et accessibles dès que vous en avez besoin. Aucun serveur de réplication externe n'est requis. Voir la figure suivante pour un exemple d'architecture exploitant la technologie SnapMirror.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">Le logiciel SnapMirror valorise l'efficacité du stockage NetApp ONTAP en n'envoyant que les blocs modifiés sur le réseau. Il utilise également la compression réseau intégrée pour accélérer le transfert de données et réduire l'utilisation de la bande passante jusqu'à 70 %. Avec la technologie SnapMirror, vous pouvez exploiter un flux de données de réplication fine pour créer un référentiel unique qui administre les copies du miroir actif et les copies instantanées antérieures, réduisant ainsi le trafic du réseau jusqu'à 50 %.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync est un service NetApp qui permet une synchronisation sûre et rapide des données. Qu'il s'agisse de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage ou IBM Cloud Object Storage, Cloud Sync déplace les fichiers là où vous en avez besoin, rapidement et de manière sécurisée.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">Une fois vos données transférées, elles peuvent être utilisées à la source et à la cible. Cloud Sync synchronise les données à la demande lorsqu'une mise à jour est déclenchée ou que les données sont continuellement synchronisées en fonction d'un planning prédéfini. Toutefois, Cloud Sync déplace uniquement les données modifiées, le temps et les coûts liés à la réplication des données sont donc réduits.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync est un outil SaaS extrêmement simple à configurer et à utiliser. Les transferts de données déclenchés par Cloud Sync sont effectués par des courtiers de données. Les courtiers de données Cloud Sync peuvent être déployés sur site, sur AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP est un logiciel client pour les migrations de données et les informations relatives au système de fichiers de tout type à NetApp et NetApp à NetApp. XCP a été conçu pour évoluer et atteindre des performances maximales en exploitant toutes les ressources système disponibles pour gérer des datasets à grand volume et des migrations haute performance. XCP vous aide à obtenir une visibilité complète sur le système de fichiers avec la possibilité de générer des rapports.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP est disponible dans un pack unique qui prend en charge les protocoles NFS et SMB. XCP inclut un binaire Linux pour les jeux de données NFS et un exécutable Windows pour les jeux de données SMB.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP File Analytics est un logiciel basé sur l'hôte qui détecte les partages de fichiers, exécute les analyses sur le système de fichiers et fournit un tableau de bord pour l'analytique des fichiers. XCP File Analytics est compatible avec les systèmes NetApp et non NetApp et s'exécute sur des hôtes Linux ou Windows pour fournir des analyses des systèmes de fichiers exportés NFS et SMB.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup volumes</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">Un dataset d'entraînement peut être un ensemble de milliards de fichiers. Les fichiers peuvent inclure du texte, de l'audio, de la vidéo et d'autres formes de données non structurées qui doivent être stockées et traitées pour être lues en parallèle. Le système de stockage doit stocker un grand nombre de petits fichiers et doit lire ces fichiers en parallèle pour les E/S séquentielles et aléatoires</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">Un volume FlexGroup est un namespace unique qui comprend plusieurs volumes de membres constitutifs, comme illustré dans la figure suivante. Du point de vue de l'administrateur de stockage, un volume FlexGroup est géré et agit comme un volume NetApp FlexVol. Les fichiers du volume FlexGroup sont alloués aux volumes de membres individuels,et non répartis entre les volumes ou les nœuds. Ils présentent de nombreux atouts :</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">Les volumes FlexGroup fournissent une capacité de plusieurs pétaoctets et une faible latence prévisible pour les charges de travail comportant un grand nombre de métadonnées.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">Ils prennent en charge jusqu'à 400 milliards de fichiers dans le même namespace.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">Ils prennent en charge les opérations parallélisées dans les charges de travail NAS sur les processeurs, les nœuds, les agrégats et les volumes FlexVol constitutifs.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">Suivant : configuration matérielle et logicielle requise.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA ai Enterprise avec NetApp et VMware : où trouver des informations complémentaires</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">Précédent : exemple d'utilisation - travail de formation TensorFlow.</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">Le logiciel de gestion des données NetApp ONTAP : bibliothèque d'informations ONTAP</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA ai Enterprise avec VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, Sr Responsable, NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, Administrateur système, NetApp</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, Ingénieur marketing et technique, NetApp</block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">Vous pouvez modifier le niveau de service d'un volume existant en déplaçant ce volume vers un autre pool de capacité qui utilise le niveau de service souhaité pour le volume. Elle permet de commencer avec un petit dataset et un petit nombre de GPU dans le Tier standard, puis de monter en charge horizontalement ou verticalement jusqu'à Premium Tier en fonction du volume de données et du nombre de GPU.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Tiers de performance Azure NetApp Files</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">Précédent : mise en place de DASK avec RAPIDS sur AKS à l'aide de Helm.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">Vous pouvez modifier le niveau de service d'un volume existant en déplaçant ce volume vers un autre pool de capacité qui utilise le niveau de service souhaité pour le volume. Elle permet de commencer avec un petit dataset et un petit nombre de GPU dans le Tier standard, puis de monter en charge horizontalement ou verticalement jusqu'à Premium Tier en fonction du volume de données et du nombre de GPU. Le niveau Premium offre un débit par téraoctet avec un niveau standard, et il est nécessaire de faire évoluer l'infrastructure sans déplacer de données pour modifier le niveau de service d'un volume.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">Pour modifier de manière dynamique le niveau de service d'un volume, procédez comme suit :</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">Dans la fenêtre change Pool, sélectionnez le pool de capacité vers lequel vous souhaitez déplacer le volume.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Cliquez sur OK.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">Automatisez les changements au niveau des tiers de performance</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">Plusieurs options sont disponibles pour automatiser les modifications des tiers de performance :</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">Le changement de niveau de service dynamique est toujours dans l'aperçu public à ce moment et n'est pas activé par défaut. Pour activer cette fonctionnalité sur l'abonnement Azure, consultez cette documentation sur la procédure à suivre<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">documentation sur les modifications apportées au pool de volumes</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Les commandes de modification du pool de volumes de l'interface de ligne de commande Azure sont fournies dans le<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> et dans l'exemple suivant :</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Cmdlet Set-AzNetAppFilesVolumePool</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell : le<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Modifie le pool d'un volume Azure NetApp Files et est présenté dans l'exemple suivant :</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">Suivant : bibliothèques pour le traitement des données et l'entraînement des modèles.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">L'architecture de cette solution de centre de support s'articule autour des outils préfabriqués de NVIDIA et du kit NetApp DataOps. Les outils NVIDIA sont utilisés pour déployer rapidement des solutions d'IA haute performance à l'aide de modèles et de pipelines prédéfinis. Le kit NetApp DataOps simplifie les tâches de gestion des données pour accélérer le développement.</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">Précédent : cas d'utilisation.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA RIVA</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> Est un kit de développement accéléré par processeur graphique pour concevoir des applications d'IA multimodales qui fournissent des performances en temps réel sur les GPU. Le kit NVIDIA train, Adapt, and Optimize (TAO) offre un moyen plus rapide et plus simple d'accélérer l'entraînement et de créer rapidement des modèles d'IA spécifiques à un domaine, précis et performants.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">Le kit NetApp DataOps est une bibliothèque Python qui simplifie la tâche des développeurs, des data Scientists, des ingénieurs DevOps et des ingénieurs en gestion des données. Cela inclut le provisionnement quasi instantané d'un nouveau volume de données ou d'un nouvel espace de travail JupyterLab, le clonage quasi instantané d'un volume de données ou d'un espace de travail JupyterLab, ainsi que le clonage quasi instantané d'un volume de données ou d'un espace de travail JupyterLab à des fins de traçabilité et de base.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">Diagramme architectural</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">Le schéma suivant illustre l'architecture de la solution. Il existe trois catégories d'environnement principales : le cloud, le cœur et la périphérie. Chacune des catégories peut être géographiquement dispersée. Dans le cloud, par exemple, des magasins d'objets peuvent contenir des fichiers audio dans des compartiments dans différentes régions, tandis que le cœur peut contenir des data centers liés par l'intermédiaire d'un réseau ultra-rapide ou de NetApp Cloud Sync. Les nœuds périphériques indiquent les plates-formes de travail quotidiennes de chaque agent humain, où des microphones et des outils de tableau de bord interactifs sont disponibles pour visualiser le sentiment et collecter des données audio à partir de conversations avec les clients.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">Design du stockage</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">RIVA</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao Toolkit</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">Dans les data centers accélérés par GPU, les entreprises peuvent utiliser NVIDIA<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> Framework pour créer des applications d'IA conversationnelles, vers lesquelles le<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> Se connecte pour le finetuning de modèles et le recyclage à l'aide de techniques d'apprentissage par transfert de L. Ces workflows et applications de calcul sont optimisés par le<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Fournir les meilleures fonctionnalités de gestion des données qu'ONTAP offre. Ce kit permet aux équipes de gestion de données d'entreprise de créer rapidement des prototypes de modèles avec des données structurées et non structurées associées, à l'aide de snapshots et de clones pour la traçabilité, la gestion des versions, les tests A/B, ce qui assure la sécurité et la gouvernance et la conformité réglementaire. Voir la section <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">Cette solution présente les étapes détaillées du traitement des fichiers audio, de l'entraînement des modèles NLP, de l'apprentissage par transfert et de la gestion des données. Le pipeline de bout en bout qui en résulte génère un résumé des sentiments qui s'affiche en temps réel sur les tableaux de bord des agents du support humain.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">Configuration matérielle requise</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">Le tableau suivant répertorie les composants matériels requis pour implémenter la solution. Ils peuvent varier selon la mise en œuvre de la solution et les besoins du client.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">Tests de latence de réponse</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">Temps (millisecondes)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">Le traitement de données</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">Inférence</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">Ces tests de temps de réponse ont été exécutés sur plus de 50,000 fichiers audio pour 560 conversations. Chaque fichier audio a une taille de ~100 Ko en MP3 et de ~1 Mo lorsqu'il est converti en fichier WAV. L'étape de traitement des données convertit des fichiers MP3 en fichiers WAV. Les étapes d'inférence convertissent les fichiers audio en texte et extraient un sentiment du texte. Ces étapes sont toutes indépendantes les unes des autres et peuvent être parallélisées pour accélérer le processus.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">En tenant compte de la latence du transfert des données entre les magasins, les responsables devraient être en mesure de voir les mises à jour de l'analyse des sentiments en temps réel dans une seconde de la fin de la phrase.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">Matériel NVIDIA RIVA</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">De formation</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">Mémoire GPU (ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">Modèles de diffusion en continu : ~5600 Mo modèles sans diffusion en continu : environ 3100 Mo</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">Mémoire GPU (NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">Environ 500 Mo par modèle BERT</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">Matériel du kit d'outils NVIDIA TAO</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">RAM système</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32 GO</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">MÉMOIRE VIVE DU GPU</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8 cœurs</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA (A100, V100 et RTX 30x0)</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100 GO</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">Système de stockage Flash</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">ONTAP 9.9, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP permet de gérer et de protéger les données avec un seul ensemble d'outils, quel que soit leur emplacement. Vous pouvez aussi déplacer vos données librement partout où elles sont nécessaires : la périphérie, le cœur ou le cloud. ONTAP 9.9 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques, et permettent d'utiliser des fonctionnalités d'infrastructure nouvelle génération dans toutes les architectures de cloud hybride.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Est un service NetApp permettant une synchronisation rapide et sécurisée des données, qui vous permet de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site vers l'une des cibles suivantes :</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="list-text">NetApp StorageGRID</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon simple Storage Service (Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System (Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Blob d'Azure</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google Cloud Storage</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM Cloud Object Storage</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync déplace les fichiers là où vous en avez besoin, rapidement et de façon sécurisée. Une fois vos données transférées, elles peuvent être utilisées à la fois sur la source et sur la cible. Cloud Sync synchronise en continu les données en fonction de votre planification prédéfinie et ne déplace que les données modifiées, de sorte que le temps et les coûts liés à la réplication des données sont réduits. Cloud Sync est un outil de type logiciel en tant que service (SaaS) simple à configurer et à utiliser. Les transferts de données déclenchés par Cloud Sync sont effectués par des courtiers de données. Vous pouvez déployer des courtiers de données Cloud Sync sur AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">La suite de stockage objet Software-defined de StorageGRID prend en charge de nombreux cas d'utilisation de manière transparente dans les environnements multiclouds publics, privés et hybrides. Grâce à des innovations de pointe, NetApp StorageGRID stocke, sécurise, protège et préserve les données non structurées à une utilisation polyvalente, y compris la gestion automatisée du cycle de vie sur de longues périodes. Pour plus d'informations, reportez-vous à la section<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> le site.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">Les composants logiciels requis pour implémenter cette solution sont répertoriés dans le tableau suivant. Ils peuvent varier selon la mise en œuvre de la solution et les besoins du client.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">Machine hôte</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">RIVA (anciennement JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">TAO Toolkit (anciennement Transfer Learning Toolkit)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">SYSTÈME D'EXPLOITATION DGX</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">DOTK</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">Logiciel NVIDIA RIVA</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">Pour 19.02 (avec nvidia-docker installé)&gt;=19.03 si vous n'utilisez pas DGX</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">Pilote NVIDIA</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">Plus de 465.19.01 418.40+, 440.33+, 450.51+ et 460.27+ pour les processeurs graphiques du data Center</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">OS de conteneur</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">CcuBLAS</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">Distance</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Serveur d'inférence Triton</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">Logiciel NVIDIA TAO Toolkit</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">python</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;=3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">docker-ce</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">Pour 19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">docker-API</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">kit-conteneur-nvidia</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">Pour 1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">exécution-conteneur-nvidia</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nvidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">pilote nvidia</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">Pour 455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">python-pip</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">Pour 21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nvidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">Dernière version</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">Détails du cas d'utilisation</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">Cette solution s'applique aux cas d'utilisation suivants :</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">L'utilisation de texte à texte commence par l'acquisition de fichiers audio pour les centres de support. Ce son est ensuite traité pour s'adapter à la structure requise par RIVA. Si les fichiers audio n'ont pas déjà été divisés en unités d'analyse, cela doit être fait avant de transmettre l'audio à RIVA. Une fois le fichier audio traité, il est transmis au serveur RIVA en tant qu'appel API. Le serveur utilise l'un des nombreux modèles qu'il héberge et renvoie une réponse. Ce message vocal au texte (fait partie de la reconnaissance vocale automatique) renvoie une représentation textuelle de l'audio. À partir de là, le pipeline passe à la partie analyse de sentiment.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">Pour l'analyse des sentiments, la sortie du texte de la reconnaissance vocale automatique sert d'entrée à la classification de texte. La classification de texte est le composant NVIDIA permettant de classer le texte dans n'importe quelle catégorie. Les catégories de sentiments varient de positif à négatif pour les conversations du centre de support. Les performances des modèles peuvent être évaluées à l'aide d'un jeu de retenue pour déterminer la réussite de l'étape de réglage précis.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">Catalogue NVIDIA NGC</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">Un pipeline similaire est utilisé à la fois pour l'analyse de la parole au texte et de l'opinion dans la boîte à outils TAO. La différence majeure réside dans l'utilisation d'étiquettes nécessaires au réglage précis des modèles. Le pipeline TAT Toolkit commence par le traitement des fichiers de données. Puis les modèles pré-entraînés (provenant du<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>) sont affinée à l'aide des données du centre de support. Les modèles optimisés sont évalués en fonction des metrics de performance correspondants. S'ils sont plus performants que les modèles pré-entraînés, ils sont déployés sur le serveur RIVA.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">Suivant : considérations de conception.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">Toutes les entreprises, quelle que soit leur taille et tous les secteurs, se tournent vers l'intelligence artificielle (IA), le machine learning (ML) et le deep learning (DL) pour résoudre des problèmes concrets, proposer des produits et des services innovants et se démarquer sur un marché de plus en plus concurrentiel. Alors que les entreprises ont de plus en plus recours à l'IA, AU ML et au DL, elles sont confrontées à de nombreux défis, notamment l'évolutivité des workloads et la disponibilité des données. Ces difficultés peuvent être résolues via l'utilisation de la solution NetApp ai Control plane.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">Cette solution permet de cloner rapidement un espace de noms de données. Vous pouvez par ailleurs définir et implémenter des workflows d'entraînement d'IA, DE ML et de DL pour intégrer la création quasi instantanée de données et de modèles de base à des fins de traçabilité et de gestion des versions. Avec cette solution, vous pouvez suivre l'entraînement de chaque modèle individuel sur le(s) dataset(s) exact(s) auquel le modèle a été entraîné et/ou validé. Enfin, cette solution vous permet de provisionner rapidement des espaces de travail Jupyter Notebook avec un accès à des jeux de données volumineux.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">Cette solution cible les data Scientists et les ingénieurs de données, une expertise minimale de NetApp ou de NetApp ONTAP est requise. Avec cette solution, les fonctions de gestion des données peuvent être exécutées à l'aide d'outils et d'interfaces simples et familiers. De plus, cette solution utilise des composants entièrement open source et libres. Par conséquent, si vous disposez déjà d'un système de stockage NetApp dans votre environnement, vous pouvez implémenter cette solution dès aujourd'hui. Si vous souhaitez essayer cette solution, mais que vous ne disposez pas encore de système de stockage NetApp, rendez-vous sur<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>, Et vous pouvez être opérationnel avec une solution de stockage NetApp basée sur le cloud en un rien de temps.</block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">Détails sur le déploiement et la validation de la solution</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">Les sections suivantes abordent les détails du déploiement et de la validation de la solution.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">Suivant : déploiement ONTAP ai</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Déploiement Kubernetes</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">Pour déployer et configurer votre cluster Kubernetes avec NVIDIA DeepOps, effectuez les tâches suivantes à partir d'un hôte de démarrage du déploiement :</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">Page de démarrage</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">Téléchargez NVIDIA DeepOps en suivant les instructions sur le<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Guide de déploiement Kubernetes</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">Déployez Kubernetes dans votre cluster en suivant les instructions du<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">Pour que le déploiement Kubernetes de DeepOps fonctionne, le même utilisateur doit exister sur tous les nœuds maîtres et workers Kubernetes.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">Si le déploiement échoue, modifiez la valeur de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> à faux dans<block ref="399db550c3eadd49b7f0681bf65049a0" prefix=" " category="inline-code"></block> et répétez l'étape 2. Le<block ref="3d9043b4bfb5ecceda4eaf60e73c2655" prefix=" " category="inline-code"></block> tâche, qui s'exécute uniquement lorsque la valeur de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> Est vrai, dépend du module récupérer Ansible, qui présente des problèmes connus d'utilisation de la mémoire. Ces problèmes d'utilisation de la mémoire peuvent parfois entraîner l'échec de la tâche. Si la tâche échoue en raison d'un problème de mémoire, le reste de l'opération de déploiement ne s'effectue pas correctement.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">Si le déploiement se termine correctement une fois que vous avez modifié la valeur de<block ref="66254ff5dfd1102c045888913b8e188d" prefix=" " category="inline-code"></block> à<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block>, vous devez ensuite copier manuellement<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> D'un nœud maître Kubernetes vers l'hôte de démarrage du déploiement Vous pouvez trouver l'emplacement du<block ref="11afbd066a1d25fe61fdae1c673a278e" prefix=" " category="inline-code"></block> sur un nœud maître spécifique en exécutant le<block ref="c768a64827ad16455d7c655ea5ae91ff" prefix=" " category="inline-code"></block> commandez directement sur ce nœud.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">Suivant : déploiement Cnvrg.io</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Pour exécuter une tâche ai et ML multinœud synchrone dans votre cluster Kubernetes, exécutez les tâches répertoriées sur cette page sur l'hôte de démarrage du déploiement. Ce processus vous permet de exploiter les données stockées sur un volume NetApp et d'utiliser plus de GPU que n'en fournir un seul nœud de travail.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">Exécutez un workload d'IA distribué synchrone</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Pour exécuter une tâche d'IA et DE ML à plusieurs nœuds synchrones dans votre cluster Kubernetes, exécutez les tâches suivantes sur l'hôte de démarrage du déploiement. Ce processus vous permet de exploiter les données stockées sur un volume NetApp et d'utiliser plus de GPU que n'en fournir un seul nœud de travail. Reportez-vous à la figure suivante pour obtenir une description d'une tâche d'IA distribuée synchrone.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">Les tâches distribuées synchrones permettent d'améliorer les performances et la précision de l'entraînement par rapport aux tâches distribuées asynchrones. Un examen des avantages et inconvénients des emplois synchrones par rapport aux emplois asynchrones est hors du champ d'application de ce document.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">Les commandes d'exemple suivantes montrent la création d'un travailleur qui participe à l'exécution distribuée synchrone du même travail de banc d'essai TensorFlow qui a été exécuté sur un seul nœud dans l'exemple de la section <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. Dans cet exemple spécifique, seul un travailleur est déployé car le travail est exécuté sur deux nœuds worker.</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">Cet exemple de déploiement utilisateur nécessite huit GPU, et peut donc s'exécuter sur un seul nœud worker GPU doté d'au moins huit GPU. Si les nœuds workers GPU disposent de plus de huit GPU, afin d'optimiser les performances, il est possible que vous souhaitiez augmenter ce nombre afin qu'il soit égal au nombre de GPU dont bénéficient les nœuds workers. Pour en savoir plus sur les déploiements Kubernetes, rendez-vous sur le<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">Un déploiement Kubernetes est créé dans cet exemple, car ce travailleur conteneurisé ne s'en serait jamais achevé seul. C'est pourquoi il n'est pas logique de le déployer via la construction de tâches Kubernetes. Si votre travailleur est conçu ou écrit de manière à le compléter seul, il peut être judicieux d'utiliser la structure de travail pour déployer votre travailleur.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">Le pod spécifié dans cet exemple de spécification de déploiement est donné un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>. Cette valeur signifie que le pod utilise la pile réseau du nœud du worker hôte au lieu de la pile de réseau virtuel que Kubernetes crée habituellement pour chaque pod. Cette annotation est utilisée dans ce cas car la charge de travail spécifique repose sur Open MPI, NCCL et Horovod pour exécuter la charge de travail de façon synchrone distribuée. Par conséquent, elle nécessite l'accès à la pile réseau de l'hôte. Une discussion sur Open MPI, NCCL et Horovod n'est pas dans le cadre du présent document. Si cela est ou non<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> l'annotation est nécessaire dépend des exigences de la charge de travail spécifique que vous exécutez. Pour plus d'informations sur le<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> voir<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">Confirmez que le déploiement de collaborateur que vous avez créé à l'étape 1 a été lancé avec succès. Les exemples de commandes suivants confirment qu'un seul pod worker a été créé pour le déploiement, comme indiqué dans la définition du déploiement, et que ce pod s'exécute actuellement sur l'un des nœuds workers GPU.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">Créez un travail Kubernetes pour un master qui démarre, participe et suit l'exécution du travail multinœud synchrone. Les commandes d'exemple suivantes créent un master qui démarre, participe à et assure le suivi de l'exécution distribuée synchrone du même travail de banc d'essai TensorFlow qui a été exécuté sur un seul nœud dans l'exemple de la section <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">Cet exemple de tâche maître demande huit GPU, puis peut être exécuté sur un seul nœud worker GPU doté d'au moins huit GPU. Si les nœuds workers GPU disposent de plus de huit GPU, afin d'optimiser les performances, il est possible que vous souhaitiez augmenter ce nombre afin qu'il soit égal au nombre de GPU dont bénéficient les nœuds workers.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">Le pod maître spécifié dans cet exemple de définition de travail est donné un<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>, tout comme le pod de travailleur a été donné<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> valeur de<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> à l'étape 1. Voir l'étape 1 pour plus de détails sur la raison pour laquelle cette valeur est nécessaire.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">Vérifiez que le travail principal que vous avez créé à l'étape 3 fonctionne correctement. L'exemple de commande suivant confirme qu'un module maître unique a été créé pour le travail, comme indiqué dans la définition du travail, et que ce pod s'exécute actuellement sur l'un des nœuds workers GPU. Vous devriez également voir que le pod de worker que vous avez initialement vu à l'étape 1 est toujours en cours d'exécution et que les pods master et worker exécutent sur différents nœuds.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">Confirmez que le travail principal que vous avez créé à l'étape 3 s'est terminé avec succès. L'exemple de commandes suivant confirme que le travail a été terminé avec succès.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">Supprimez le déploiement de collaborateur lorsque vous n'en avez plus besoin. L'exemple de commandes suivant montre la suppression de l'objet de déploiement de travail qui a été créé à l'étape 1.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">Lorsque vous supprimez l'objet de déploiement worker, Kubernetes supprime automatiquement les pods workers associés.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*Facultatif:* nettoyez les artefacts du travail principal. Les exemples de commandes suivants montrent la suppression de l'objet de travail maître créé à l'étape 3.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">Lorsque vous supprimez l'objet de travail maître, Kubernetes supprime automatiquement les modules maîtres associés.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">Suivant : test des performances.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">Cette page décrit les tâches que vous devez réaliser pour déployer un cluster Kubernetes dans lequel implémenter la solution NetApp ai Control plane. Si vous disposez déjà d'un cluster Kubernetes, vous pouvez ignorer cette section tant que vous exécutez une version de Kubernetes prise en charge par Kubeflow et NetApp Trident.</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">Cette section décrit les tâches que vous devez réaliser pour déployer un cluster Kubernetes dans lequel implémenter la solution NetApp ai Control plane. Si vous disposez déjà d'un cluster Kubernetes, vous pouvez ignorer cette section tant que vous exécutez une version de Kubernetes prise en charge par Kubeflow et NetApp Trident. Pour obtenir la liste des versions Kubernetes prises en charge par Kubeflow, voir la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Pour obtenir la liste des versions de Kubernetes prises en charge par Trident, consultez le<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">Pour les déploiements Kubernetes sur site intégrant des nœuds bare-Metal avec processeurs graphiques NVIDIA, NetApp recommande l'utilisation de l'outil de déploiement DeepOps Kubernetes de NVIDIA. Cette section décrit le déploiement d'un cluster Kubernetes avec DeepOps.</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">Vous avez déjà configuré des nœuds Kubernetes bare-Metal (par exemple, un système NVIDIA DGX qui fait partie d'un pod ONTAP ai) conformément aux instructions de configuration standard.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">Site GitHub DeepOps</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">Vous avez installé un système d'exploitation pris en charge sur tous les nœuds maîtres et workers Kubernetes et sur un hôte de démarrage du déploiement. Pour obtenir la liste des systèmes d'exploitation pris en charge par DeepOps, reportez-vous au<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">Utilisez NVIDIA DeepOps pour installer et configurer Kubernetes</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">Téléchargez NVIDIA DeepOps en suivant les instructions sur le<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Page Guide de déploiement Kubernetes</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">Déployez Kubernetes dans votre cluster en suivant les instructions du<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> Sur le site GitHub NVIDIA DeepOps.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">Ensuite : présentation du déploiement et de la configuration de NetApp Trident.</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">Tr-4785 : déploiement de l'IA avec NetApp E-Series et BeeGFS</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Radu, Daniel Landes, Nathan Swartz, Amine Bennani, NetApp</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">Les applications d'intelligence artificielle (IA), de machine learning (ML) et de deep learning (DL) impliquent des datasets volumineux et des calculs importants. Pour exécuter correctement ces charges de travail, vous avez besoin d'une infrastructure agile qui vous permet de faire évoluer horizontalement les nœuds de calcul et de stockage de manière transparente. Ce rapport comprend des étapes pour exécuter un modèle d'entraînement d'IA dans un mode distribué, qui permet une évolutivité scale-out transparente des nœuds de calcul et de stockage. Il inclut également plusieurs metrics de performance pour démontrer comment une solution alliant le stockage NetApp E-Series et le système de fichiers parallèle BeeGFS fournit une solution simple, flexible et économique pour les workloads d'IA.</block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Configuration du cluster Kubernetes</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">Cette section comprend deux parties pour le déploiement dans le Cloud et sur site, respectivement.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">Configuration de Cloud Deployment Kubernetes</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">Grâce à NetApp Cloud Manager, vous pouvez définir la connexion au cluster Iguazio Kubernetes. Trident requiert l'accès à plusieurs ressources au sein du cluster pour rendre le volume disponible.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">Pour activer l'accès, procurez-vous le fichier de configuration Kubernetes à partir d'un des nœuds Iguazio. Le fichier se trouve sous<block ref="c94d2475115399d9803ef7d9f1fc7b59" prefix=" " category="inline-code"></block> Téléchargez ce fichier sur votre bureau.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">Accédez à découverte du cluster à configurer.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Téléchargez le fichier de configuration Kubernetes. Voir l'image suivante.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Déployez Trident et associez un volume au cluster. Consultez l'image suivante sur la définition et l'attribution d'un volume persistant au cluster Iguazio.ce processus crée un volume persistant dans le cluster Kubernetes d'Iguazio. Avant de pouvoir l'utiliser, vous devez définir une demande de volume persistant.</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">Configuration Kubernetes de déploiement sur site</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">Pour l'installation sur site de NetApp Trident, consultez la section<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> pour plus d'informations. Une fois votre cluster Kubernetes configuré et installé NetApp Trident, vous pouvez vous connecter à Trident au cluster Iguazio pour activer les fonctionnalités de gestion des données NetApp, comme l'utilisation de copies Snapshot de vos données et de votre modèle.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Suivant : définissez une demande de volume persistant</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">Le rapport TR-4859 décrit le processus de déploiement d'une solution de système de fichiers parallèle complète basée sur la pile logicielle Spectrum Scale d'IBM. Le rapport TR-4859 est conçu pour fournir des informations détaillées sur l'installation de l'évolutivité Spectrum, la validation de l'infrastructure et la gestion de la configuration.</block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">Déploiement de VMware Virtual Infrastructure sur NetApp HCI avec le moteur de déploiement NetApp (déploiement automatisé)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">Conditions préalables au déploiement NDE</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">Liste de contrôle de la configuration requise pour NetApp HCI</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">Consulter le<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> Pour consulter les exigences et recommandations relatives à NetApp HCI avant de commencer le déploiement.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">Configuration et configuration requises pour le réseau et les commutateurs</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">Préparez les ID VLAN requis</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">Configuration de commutateurs</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">Conditions requises pour l'adresse IP pour NetApp HCI et VMware</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">Exigences relatives au DNS et au respect des délais</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">Préparations finales</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">Exécution de NDE</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">Avant d'exécuter le moteur de déploiement NetApp, vous devez terminer le rack et la pile de tous les composants, configurer les switchs réseau et vérifier toutes les conditions préalables. Si vous prévoyez d'autoriser le moteur de déploiement NetApp, vous pouvez exécuter le moteur de déploiement NetApp en vous connectant à l'adresse de gestion d'un nœud de stockage unique.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">Le moteur de déploiement NetApp effectue les tâches suivantes pour mettre un système HCI en ligne :</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">Installe le nœud de stockage (logiciel NetApp Element) sur au moins deux nœuds de stockage.</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">Installe l'hyperviseur VMware sur au moins deux nœuds de calcul.</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">Installe VMware vCenter pour gérer l'ensemble de la pile NetApp HCI.</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">Installe et configure le nœud de gestion du stockage NetApp (nœud M) et l'agent de surveillance NetApp.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">Cette validation utilise le moteur de déploiement NetApp pour configurer automatiquement toutes les adresses. Vous pouvez également configurer DHCP dans votre environnement ou attribuer manuellement des adresses IP pour chaque nœud de stockage et nœud de calcul. Ces étapes ne sont pas décrites dans ce guide.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">Comme nous l'avons mentionné précédemment, cette validation utilise une configuration à deux câbles pour les nœuds de calcul.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">Les étapes détaillées du moteur de déploiement NetApp ne sont pas couvertes dans ce document.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">Guide de déploiement</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">Pour obtenir des instructions détaillées sur le déploiement de la plateforme NetApp HCI de base, consultez le<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">Une fois que NDE a terminé, connectez-vous à vCenter et créez un Port Group distribué<block ref="b792ce2538db0b838bb1f2cd727d3417" prefix=" " category="inline-code"></block> Pour que le réseau NFS soit utilisé par ONTAP Select et l'application.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">Suivant : configuration de NetApp H615c (déploiement manuel)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SE350 et les détails du provisionnement de stockage.</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">Précédent : plan de test.</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">La figure suivante présente la configuration de test. Nous avons utilisé le système de stockage NetApp AFF C190 et deux serveurs Lenovo ThinkSystem SE350 (chacun avec un accélérateur NVIDIA T4). Ces composants sont connectés via un commutateur réseau 10GbE. Le stockage réseau contient des datasets de validation/test et des modèles pré-entraînés. Les serveurs fournissent des fonctionnalités de calcul, et le stockage est accessible via le protocole NFS.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SE350 et les détails du provisionnement de stockage. Le tableau suivant répertorie les composants de base de l'architecture de la solution.</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 serveurs SE350 chacun avec une carte graphique NVIDIA T4</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">Chaque serveur contient un processeur Intel Xeon D-2123IT avec quatre cœurs physiques fonctionnant à 2,20 GHz et 128 Go de RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">Système de stockage NetApp AFF d'entrée de gamme (paire HA)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">Le logiciel NetApp ONTAP 9</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">SSD 24x 960 Go</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">Un groupe d'interface par contrôleur, avec quatre adresses IP logiques pour les points de montage</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">Le tableau suivant répertorie la configuration du stockage : AFF C190 avec 24 emplacements de disque 2RU.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">Contrôleur</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Agrégat</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">Volume FlexGroup</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">Agrégez-les</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">Volumétrique</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">Point de montage du système d'exploitation</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Contrôleur 1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Agr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/Netapplenovo_ai_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8,42 Tio</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TO</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Contrôleur 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Agr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">Le dossier /netappLenovo_ai_fg contient les ensembles de données utilisés pour la validation du modèle.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">La figure ci-dessous présente la configuration de test. Nous avons utilisé le système de stockage NetApp EF280 et deux serveurs Lenovo ThinkSystem SE350 (chacun avec un accélérateur NVIDIA T4). Ces composants sont connectés via un commutateur réseau 10GbE. Le stockage réseau contient des datasets de validation/test et des modèles pré-entraînés. Les serveurs fournissent des fonctionnalités de calcul, et le stockage est accessible via le protocole NFS.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">Le tableau ci-dessous répertorie la configuration de stockage de la baie EF280.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">Groupe de volumes</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volumétrie</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">Méthode de connexion</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">Volume 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TO</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 vers LUN iSCSI 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">Volume 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 vers la LUN iSCSI 1</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-DEPLOY inclut des instructions de déploiement de systèmes de stockage pour un workload d'architecture vérifiée NetApp (NVA) pour le machine learning (ML) et l'intelligence artificielle (IA) à l'aide de systèmes de stockage NetApp AFF A800, de systèmes NVIDIA DGX A100 et de switchs réseau NVIDIA Mellanox. Celui-ci contient également des instructions pour l'exécution des tests de validation une fois le déploiement terminé.</block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">Tr-4915 : déplacement des données avec les workflows E-Series et BeeGFS pour l'IA et l'analytique</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">Cody Harryman et Ryan rodine, NetApp</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">Le rapport TR-4915 explique comment déplacer des données depuis n'importe quel référentiel de données vers un système de fichiers BeeGFS reposant sur un système de stockage SAN NetApp E-Series. Pour les applications d'intelligence artificielle (IA) et de machine learning (ML), il peut être nécessaire de déplacer de grands jeux de données dépassant plusieurs pétaoctets de données vers leurs clusters BeeGFS pour le développement de modèles. Ce document décrit comment le réaliser en utilisant les outils NetApp XCP et NetApp Cloud Sync.</block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">Cette page récapitule les avantages de Azure NetApp Files en matière de formation distribuée ou à grande échelle.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">Récapitulatif de l'utilisation des prédictions de taux par clic</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">Précédent : ressources cloud requises.</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">Fichiers de clic sur un téraoctet</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo ai Lab</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">Il s'agit d'un cas d'utilisation basé sur le cloud public<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> jeu de données de<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. Avec les récentes avancées des plates-formes ET des applications DE ML, une grande attention se porte maintenant sur l'apprentissage à grande échelle. Le taux de clics (CTR) est défini comme le nombre moyen de clics par cent impressions de publicités en ligne (exprimé en pourcentage). Elle est largement adoptée comme indicateur clé dans différents secteurs d'activité et champs d'application, notamment le marketing digital, la vente au détail, l'e-commerce et les fournisseurs de services. Voici quelques exemples d'utilisation de CTR comme mesure importante pour le trafic potentiel des clients :</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google Analytics</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">Rang d'annonce</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">*Marketing numérique:* in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR peut être utilisé pour évaluer la manière dont bien un annonceur ou les mots-clés, annonces, et les listes libres sont en cours de réalisation. Un CTR élevé est une bonne indication que les utilisateurs trouvent vos annonces et listes utiles et pertinentes. CTR contribue également à votre mot clé CTR attendu, qui est un composant de<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* E-commerce:* en plus de tirer parti<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>, il y a au moins quelques statistiques de visiteurs dans un back-end de commerce électronique. Bien que ces statistiques ne semblent pas utiles à première vue, elles sont généralement faciles à lire et peuvent être plus précises que d'autres informations. Les ensembles de données de première partie composés de ces statistiques sont propriétaires et sont donc les plus pertinents pour les vendeurs, les acheteurs et les plates-formes de commerce électronique. Ces ensembles de données peuvent être utilisés pour établir des bancs d'essai, en comparant les résultats à l'année dernière et à la veille, en élaborant une série chronologique pour une analyse plus approfondie.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">*Retail:* les détaillants Brick-et-mortier peuvent mettre en corrélation le nombre de visiteurs et le nombre de clients avec le CTR. Le nombre de clients est visible depuis leur historique des points de vente. Le CTR sur les sites Web des détaillants ou le trafic publicitaire peut entraîner les ventes susmentionnées. Les programmes de fidélité sont un autre cas d'utilisation, car les clients redirigés depuis des publicités en ligne ou d'autres sites Web peuvent se joindre pour gagner des récompenses. Les détaillants peuvent acquérir des clients par le biais de programmes de fidélité et enregistrer des comportements liés aux histoires de vente pour élaborer un système de recommandations qui non seulement prédit les comportements d'achat des consommateurs dans différentes catégories, mais également personnalise les bons de réduction et diminue le nombre de départs.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">*Fournisseurs de services:* les entreprises de télécommunications et les fournisseurs de services Internet disposent d'une abondance de données de télémétrie utilisateur de première partie pour des cas d'utilisation instructifs de l'IA, DU ML et de l'analytique. Par exemple, un opérateur télécom peut utiliser quotidiennement ses journaux d'historique de domaine de premier niveau pour affiner les modèles existants afin de générer une segmentation de l'audience à jour, d'anticiper le comportement des clients et de collaborer avec les annonceurs pour placer des publicités en temps réel et améliorer l'expérience en ligne. Dans ce flux de travail de marketing axé sur les données, CTR est une mesure importante pour refléter les conversions.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Criteo Terabyte cliquez sur journaux</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">Dans le cadre du marketing numérique,<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> Sont désormais le dataset de référence pour évaluer l'évolutivité des plateformes ET des algorithmes DE ML. En prédisant le taux de clics, un annonceur peut sélectionner les visiteurs qui sont les plus susceptibles de répondre aux annonces, analyser leur historique de navigation, et montrer les annonces les plus pertinentes en fonction des intérêts de l'utilisateur.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">La solution proposée dans ce rapport technique présente les avantages suivants :</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Avantages de Azure NetApp Files dans le cadre d'une formation distribuée ou à grande échelle</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RAPIDES, traitement de données CUDA (cuDF, cuPy, etc.) et algorithmes DE ML (cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">Le cadre informatique parallèle DASK pour la formation distribuée</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">Un workflow complet basé SUR RAPIDS dans l'IA et Azure NetApp Files démontre l'amélioration drastique du temps d'entraînement des modèles forestiers aléatoires de deux ordres de grandeur. Cette amélioration est très significative par rapport à l'approche Pandas classique lors du traitement des journaux de clics du monde réel avec 45 Go de données tabulaires structurées (en moyenne) chaque jour. Cela équivaut à un DataFrame contenant environ vingt milliards de lignes. Dans ce rapport technique, nous allons présenter la configuration de l'environnement de cluster, l'installation de la structure et de la bibliothèque, le chargement et le traitement des données, les méthodes conventionnelles par rapport à la formation distribuée, la visualisation et la surveillance, et comparer les résultats critiques de l'exécution de bout en bout.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">Ensuite : installez et configurez le cluster aks.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">Détails des tests pour la section 4.10</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">Cette section contient des détails sur les tests pour la section <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">Soumettre les travaux dans l'ordre suivant pour<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>:</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1 charge de travail mise en attente</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2 workloads mis en file d'attente</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">Deux workloads demandent deux GPU</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">Deux workloads demandent chacun deux GPU</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">Supprimez ensuite toutes les charges de travail de<block ref="ae7ccf7b1a6a1a023f611a294572a900" prefix=" " category="inline-code"></block>:</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">Voir la section <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>, pour les discussions sur le scénario de test en cours.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan rodine, NetApp</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">Ce document explique en détail comment concevoir une solution de systèmes de fichiers parallèles StorNext avec les systèmes de stockage NetApp E-Series. Cette solution présente les baies 100 % Flash NetApp EF280, les baies NVMe 100 % Flash NetApp EF300, les baies NVMe 100 % Flash EF600 et les systèmes hybrides NetApp E5760. Il offre une caractérisation des performances basée sur le banc d'essai Frametest, un outil largement utilisé pour les tests dans l'industrie des médias et du divertissement.</block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">Pour cette validation, nous avons procédé à l'inférence pour une détection d'images à l'aide d'un jeu d'images brutes. Nous avons ensuite effectué la même tâche d'inférence sur le même jeu d'images avec l'obfuscation Protopia ajoutée avant l'inférence. Nous avons répété la tâche en utilisant différentes valeurs ALPHA pour le composant d'obfuscation Protopia.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">Comparaison de la précision d'inférence</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">Pour cette validation, nous avons procédé à l'inférence pour une détection d'images à l'aide d'un jeu d'images brutes. Nous avons ensuite effectué la même tâche d'inférence sur le même jeu d'images avec l'obfuscation Protopia ajoutée avant l'inférence. Nous avons répété la tâche en utilisant différentes valeurs ALPHA pour le composant d'obfuscation Protopia. Dans le contexte de l'obfuscation Protopia, la valeur ALPHA représente la quantité d'obfuscation appliquée, avec une valeur ALPHA plus élevée représentant un niveau d'obfuscation plus élevé. Nous avons ensuite comparé la précision d'inférence sur ces différentes exécutions.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">Les deux tableaux suivants détaillent nos cas d'utilisation et présentent les résultats.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia travaille directement avec les clients pour déterminer la valeur ALPHA appropriée pour un cas d'utilisation spécifique.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">Coffrets de finition (PyTorch) -</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">Jeu de données</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">Jeu de données FDDB</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">Obfuscation Protopia</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">ALPHA</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">Précision</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">Non</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">S/O</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Oui.</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">Suivant : vitesse d'obfuscation.</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">Le fonctionnement et les performances de ce système ont été validées à l'aide d'outils de banc d'essai TensorFlow. Le dataset ImageNet utilisé pour entraîner le modèle ResNet-50, qui est un modèle d'apprentissage profond connu des réseaux neuronaux convolutifs (CNN) pour la classification d'images. RESNET-50 offre des résultats d'entraînement précis avec un temps de traitement plus rapide, ce qui nous permet d'obtenir une demande suffisante en matière de stockage.</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">Cette section décrit comment homologue du réseau VNet AKS au réseau VNet Azure NetApp Files.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">Peer AKS vnet et Azure NetApp Files vnet</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">Création précédente d'un sous-réseau délégué pour Azure NetApp Files.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">Pour passer le réseau VNet AKS à Azure NetApp Files VNet, procédez comme suit :</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">Entrez les réseaux virtuels dans le champ de recherche.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">Sélectionnez<block ref="c5d2d918f55de1b8309376bc0310c265" prefix=" " category="inline-code"></block> Cliquez dessus et saisissez Peerings dans le champ de recherche.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">Cliquez sur +Ajouter.</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">Saisissez les descripteurs suivants :</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">Le nom de la liaison de peering est<block ref="5d43607a5a0ebb50f3ea9348485daa15" prefix=" " category="inline-code"></block>.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">Indice de connexion et Azure NetApp Files vnet en tant que partenaire de peering vnet.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">Laissez toutes les sections non astérisque avec les valeurs par défaut.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Cliquez sur Ajouter.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">Pour plus d'informations, voir<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">Ensuite, installez Trident.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">Connectez-vous à des API tierces en tant que moteur de traitement</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">Nous avons connecté les API tierces suivantes en tant que moteur de traitement pour répondre aux questions :</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">API WeatherStack</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: renvoie la météo, la température, la pluie et la neige dans un endroit donné.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">API Yelp Fusion</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: renvoie les informations de magasin les plus proches dans un emplacement donné.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">Kit de développement logiciel eBay Python</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: renvoie le prix d'un article donné.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">Voici la démonstration de l'assistant de vente au détail NetApp</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">Soumission des travaux dans l'interface de ligne de commande Run:ai</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">Cette section fournit des informations détaillées sur les commandes Basic Run:ai que vous pouvez utiliser pour exécuter n'importe quel travail Kubernetes. Elle est divisée en trois parties selon le type de charge de travail. Les workloads d'IA/AM/AP peuvent être divisés en deux types génériques :</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* Sessions de formation sans surveillance*. Lorsque ces types de charges de travail sont évoqués, le data Scientist prépare une charge de travail autonome et l'envoie pour exécution. Lors de l'exécution, le client peut examiner les résultats. Ce type de charge de travail est souvent utilisé en production ou lorsqu'il s'agit du développement du modèle, auquel aucune intervention humaine n'est requise.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">*Sessions de construction interactives*. Avec ce type de charges de travail, un data Scientist ouvre une session interactive avec Bash, Jupyter Notebook, PyChARM distant ou des IDE similaires. Ce dernier accède directement aux ressources GPU. Nous incluons un troisième scénario pour l'exécution de charges de travail interactives avec des ports connectés pour révéler un port interne pour l'utilisateur du conteneur.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">Charges de travail d'entraînement sans assistance</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">Une fois les projets et l'allocation de GPU, vous pouvez exécuter n'importe quel workload Kubernetes à l'aide de la commande suivante sur la ligne de commande :</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">Cette commande lance une tâche d'entraînement automatique pour TEAM-a avec une allocation d'un GPU unique. La tâche est basée sur un exemple d'image docker,<block ref="1f2da2a856d7277c86fd9f58e93ae507" prefix=" " category="inline-code"></block>. Nous avons nommé le travail<block ref="b10f762d9445989813486accc082c6f1" prefix=" " category="inline-code"></block>. Vous pouvez ensuite contrôler la progression du travail en exécutant la commande suivante :</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">La figure suivante montre le résultat du<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> commande. Les États typiques que vous pouvez voir incluent les suivants :</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text"><block ref="8627ca3ad23f4fb9adc6ba05047004c6" prefix="" category="inline-code"></block>. Le conteneur docker est téléchargé depuis le référentiel cloud.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text"><block ref="2d13df6f8b5e4c5af9f87e0dc39df69d" prefix="" category="inline-code"></block>. Le travail est en attente d'être programmé.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text"><block ref="5bda814c4aedb126839228f1a3d92f09" prefix="" category="inline-code"></block>. La tâche est en cours d'exécution.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">Pour obtenir un état supplémentaire de votre travail, exécutez la commande suivante :</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">Pour afficher les journaux du travail, exécutez le<block ref="13be9f2fcfc2532531562b1e0c6dd431" prefix=" " category="inline-code"></block> commande :</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">Dans cet exemple, vous devriez voir le journal d'une session d'apprentissage profond en cours d'exécution, y compris la période d'entraînement actuelle, la date d'arrivée prévue, la valeur de la fonction de perte, la précision et le temps écoulé pour chaque étape.</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">Vous pouvez afficher l'état du cluster dans l'interface utilisateur Run:ai à<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. Sous tableaux de bord &gt; Présentation, vous pouvez surveiller l'utilisation des GPU.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">Pour arrêter cette charge de travail, exécutez la commande suivante :</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">lancement de charges de travail d'entraînement non surveillées</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">Cette commande arrête la charge de travail d'entraînement. Vous pouvez vérifier cette action en exécutant<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> encore. Pour plus de détails, voir<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">Workloads de construction interactifs</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">Après avoir configuré des projets et affecté des GPU, vous pouvez exécuter un workload de construction interactif à l'aide de la commande suivante sur la ligne de commande :</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">Le travail est basé sur un exemple de python d'image docker. Nous avons nommé le chantier 1.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">Le<block ref="1f21ac5e64afff9d56d5047ace21ffd8" prefix=" " category="inline-code"></block> drapeau signifie que le travail n'a pas de début ou de fin Il incombe au chercheur de fermer le poste. L'administrateur peut définir une limite de temps pour les travaux interactifs au terme desquels ils sont résiliés par le système.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">Le<block ref="41edd6984c1a14599f6d54cd297a423e" prefix=" " category="inline-code"></block> Flag alloue un GPU unique à ce travail. La commande et l'argument fournis sont<block ref="f18e9c054b4fccbc27cd764cb472a213" prefix=" " category="inline-code"></block>. Vous devez fournir une commande, ou le conteneur démarre et se ferme immédiatement.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">Les commandes suivantes fonctionnent de la même manière que les commandes décrites dans la <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text"><block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix="" category="inline-code"></block>: Affiche le nom, l'état, l'âge, le nœud, l'image, Le projet, l'utilisateur et les processeurs graphiques pour la réalisation de tâches.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text"><block ref="1051ced5efff9d2868a1edd38f951e6e" prefix="" category="inline-code"></block>: Affiche l'état supplémentaire sur le build de job 1.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text"><block ref="624c1f4b1937b32c12cfa1346cb037f9" prefix="" category="inline-code"></block>: Arrête la charge de travail interactive build1.pour obtenir un shell bash au conteneur, la commande suivante :</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">Ceci fournit un shell direct dans l'ordinateur. Les data Scientists peuvent ensuite développer ou affiner leurs modèles dans le conteneur.</block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">démarrage et utilisation de workloads de construction interactifs</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">Vous pouvez afficher l'état du cluster dans l'interface utilisateur Run:ai à<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. Pour plus de détails, voir<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">Charges de travail interactives avec des ports connectés</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">Entrée</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">Comme extension des charges de travail de construction interactives, vous pouvez révéler les ports internes de l'utilisateur du conteneur lors du démarrage d'un conteneur à l'aide de l'interface de ligne de commande Run:ai. Ce procédé est utile pour les environnements cloud, avec des ordinateurs portables Jupyter ou pour la connexion à d'autres microservices.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Permet l'accès aux services Kubernetes depuis l'extérieur du cluster Kubernetes. Vous pouvez configurer l'accès en créant un ensemble de règles qui définissent les connexions entrantes qui atteignent quels services.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">Pour une meilleure gestion de l'accès externe aux services d'un cluster, nous vous recommandons d'installer les administrateurs du cluster<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Et configurer LoadBalancer.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">Pour utiliser Ingress as a service type, exécutez la commande suivante pour définir le type de méthode et les ports lors de l'envoi de votre workload :</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">Une fois le conteneur démarré avec succès, exécutez<block ref="cfd2ddb98fc396c2e8a48e9ad76dbb58" prefix=" " category="inline-code"></block> pour voir le<block ref="8d6518907bf83f7ae243a42bc2d2daba" prefix=" " category="inline-code"></block> Pour accéder au Jupyter Notebook. L'URL se compose du noeud final d'entrée, du nom du travail et du port. Par exemple, voir<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">lancement d'une charge de travail de construction interactive avec des ports connectés</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">Pour plus de détails, voir<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">Suivant : optimiser l'utilisation des clusters</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">Cette section décrit en détail les étapes nécessaires au déploiement de cette solution.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">Déploiement de l'analyse des sentiments du centre de support</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">Précédent : considérations de conception.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">Le déploiement de la solution implique les composants suivants :</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">Configuration NGC</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">Serveur NVIDIA RIVA</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">Kit d'outils NVIDIA TAO</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">Exporter des modèles TAO vers RIVA</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">Pour effectuer le déploiement, procédez comme suit :</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">Kit NetApp DataOps : analyse des sentiments des centres de support</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">Pour utiliser le<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, effectuez les opérations suivantes :</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP installer la boîte à outils.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">Configuration de la gestion des données</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">Configuration NGC : analyse du sentiment du centre de support</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NVIDIA NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">Pour configurer<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>, effectuez les opérations suivantes :</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">Télécharger le contrôleur NGC.</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">Ajoutez votre répertoire actuel au chemin d'accès.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">Vous devez configurer l'interface de ligne de commandes NGC pour que vous puissiez exécuter les commandes. Entrez la commande suivante, y compris votre clé API lorsque vous y êtes invité.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">ici</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Pour les systèmes d'exploitation qui ne sont pas basés sur Linux, rendez-vous sur<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">Serveur NVIDIA RIVA : analyse des sentiments des centres de support</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">Pour configurer<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>, effectuez les opérations suivantes :</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">Téléchargez les fichiers RIVA de NGC.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Initialiser LA configuration RIVA <block ref="b57bfc797452f0a8f165771280704dc4" prefix="(" category="inline-code"></block>).</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Démarrez LE serveur RIVA <block ref="9578e0f1e91365703f275dd0aa9dd913" prefix="(" category="inline-code"></block>).</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Démarrez le client RIVA <block ref="98e192e15ed3b76551ab5ef8d11ef1e8" prefix="(" category="inline-code"></block>).</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFMPEG</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Dans le client RIVA, installez la bibliothèque de traitement audio (<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">Démarrez le<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> serveur.</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Exécutez le bloc-notes RIVA Inférence Pipeline.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">Kit NVIDIA TAO : analyse des sentiments du centre de support</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">Pour configurer la boîte à outils NVIDIA TAO, procédez comme suit :</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">virtualisé</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">Préparez et activez un<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> Pour la boîte à outils TAO.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">packages requis</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">Installer le<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">Tirez manuellement l'image utilisée pendant l'entraînement et le réglage précis.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">Exécutez l'ordinateur portable TAT Fine Tuning.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">Exporter des modèles TAO vers RIVA : prendre en charge l'analyse des sentiments des centres de support</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Modèles TAO Toolkit à RIVA</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">À utiliser<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>, effectuez les opérations suivantes :</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">Enregistrez des modèles dans le portable TAT Fine Tuning.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">Copier des modèles entraînés TAO dans le répertoire de modèle RIVA.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">Les obstacles au déploiement</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">Voici quelques points à garder à l'esprit lors du développement de votre propre solution :</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">Le kit NetApp DataOps est installé en premier pour assurer le fonctionnement optimal du système de stockage des données.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC doit être installé avant toute autre chose, car il authentifie le téléchargement des images et des modèles.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">RIVA doit être installé avant la boîte à outils TAO. L'installation DE RIVA configure le démon docker pour extraire les images si nécessaire.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">DGX et docker doivent avoir un accès à Internet pour télécharger les modèles.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">Suivant : résultats de la validation.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick et David Arnette, NetApp</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">La conception NVA-1156 décrit une architecture vérifiée NetApp pour les workloads de machine learning (ML) et d'intelligence artificielle (IA) à l'aide des systèmes de stockage NVMe NetApp EF600, du système de fichiers parallèle BeeGFS, des systèmes NVIDIA DGX A100 et des switchs IB NVIDIA Mellanox QM8700 200 Gbit/s. Cette conception est dotée d'une architecture entièrement basée sur IB 200 Gbit/s pour la structure d'interconnexion des clusters de stockage et de calcul. Elle offre ainsi aux clients une architecture entièrement basée sur IB pour les charges de travail hautes performances. Ce document inclut également les résultats des tests de performance pour l'architecture mise en œuvre.</block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">Cette page décrit comment nous avons utilisé Pandas et DASK DataFrames pour charger les données de journaux de clic du dataset Criteo Terabyte. Le cas d'utilisation est pertinent dans la publicité numérique pour les échanges publicitaires afin de créer les profils des utilisateurs en prédisant si les annonces seront cliqué ou si l'échange n'utilise pas un modèle précis dans un pipeline automatisé.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Charger Criteo Click Logs Day 15 dans Pandas et former un modèle de forêt aléatoire de scikit</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">Précédent : bibliothèques pour le traitement des données et l'entraînement des modèles.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">Cette section décrit comment nous avons utilisé Pandas et DASK DataFrames pour charger les données de journaux de clic du dataset Criteo Terabyte. Le cas d'utilisation est pertinent dans la publicité numérique pour les échanges publicitaires afin de créer les profils des utilisateurs en prédisant si les annonces seront cliqué ou si l'échange n'utilise pas un modèle précis dans un pipeline automatisé.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Nous avons chargé les données du jour 15 à partir du jeu de données Click Logs, soit un total de 45 Go. Exécution de la cellule suivante dans le bloc-notes Jupyter<block ref="687d69c323eb8500d21df9bfb49c3b55" prefix=" " category="inline-code"></block> Crée un Pandas DataFrame contenant les 50 premiers millions de lignes et génère un modèle aléatoire d'apprentissage de forêt de scikit.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">documentation officielle d'apprentissage du kit de science</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">Pour effectuer une prédiction à l'aide d'un modèle de forêt aléatoire entraîné, exécutez le paragraphe suivant dans ce bloc-notes. Nous avons effectué le dernier million de lignes à partir du jour 15 comme jeu de tests pour éviter toute duplication. La cellule calcule également la précision de la prévision, définie comme le pourcentage d'occurrences que le modèle prédit avec précision si un utilisateur clique ou non sur une annonce. Pour passer en revue tous les composants inconnus de cet ordinateur portable, reportez-vous au<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">Suivant: Charger jour 15 à DASK et former un modèle de forêt aléatoire de DASk cuML.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">Ce document suit le code MLPerf Inférence v0.7, le code et les règles MLPerf Inférence v1.1. Nous avons exécuté des bancs d'essai conçus pour l'inférence à la périphérie, comme définis dans les tableaux présentés dans cette section.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">Plan de test</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">règles</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">Ce document suit l'Inférence MLPerf v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, MLPerf Inférence v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, et<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. Nous avons exécuté des bancs d'essai MLPerf conçus pour l'inférence à la périphérie, comme défini dans le tableau suivant.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">De service</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Tâche</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">Taille QSL</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">Qualité</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">La contrainte de latence multiflux</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">Vision</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">Classification des images</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Reset50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNET (224 x 224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">99 % de FP32</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50 ms.</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">Détection d'objet (grande taille)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD- ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO (1200 x 1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66 ms.</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">Détection d'objet (petite taille)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD : MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO (300 x 300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">Segmentation des images médicales</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">NON-ET 3D</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">Brages 2019 (224 x 224 x 160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">99 % et 99.9 % du FP32</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">s/o</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">Voix</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">Parole au texte</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Lirispeech dev-Clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">Langue</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">Traitement de la langue</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">BERT</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">Squad v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">Le tableau suivant présente des scénarios de banc d'essai pour Edge.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">Scénarios</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">Classification des images</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">Flux unique, hors ligne, flux multiples</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">Flux unique, hors ligne</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">Nous avons réalisé ces bancs d'essai à l'aide de l'architecture de stockage en réseau développée lors de cette validation et avons comparé les résultats à ceux des exécutions locales sur les serveurs de périphérie préalablement soumis à MLPerf. La comparaison consiste à déterminer l'impact du stockage partagé sur les performances d'inférence.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">Systèmes NVIDIA DGX</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">Système NVIDIA DGX-1<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">GPU NVIDIA V100 à cœurs Tensor<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NVIDIA NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">Exécutez :solution d'orchestration de conteneurs d'IA</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">Run :présentation des produits d'IA<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">Run:documentation d'installation ai<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Soumission de travaux dans l'interface de ligne de commande Run:ai<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">Allocation de fractions GPU dans l'interface de ligne de commande Run:ai<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">Rapport technique<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">Démonstration sous forme abrégée<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">Référentiel GitHub<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">Fiche technique NetApp AFF A-Series<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">Avantages du Flash NetApp pour les systèmes FAS 100 % Flash<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">Bibliothèque d'informations ONTAP 9<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">Rapport technique sur NetApp ONTAP FlexGroup volumes<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et connectivité réseau Cisco<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">Guide de déploiement d'ONTAP ai avec DGX-1 et réseau Cisco<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">Guide de conception d'ONTAP ai avec DGX-1 et réseau Mellanox<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">Guide de conception de ONTAP ai avec DGX-2<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">L'architecture NetApp ONTAP ai, développée et vérifiée par NetApp et NVIDIA, est optimisée par les systèmes NVIDIA DGX et les systèmes de stockage NetApp connectés au cloud. Et présente plusieurs avantages pour les SERVICES IT :</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">Propose plusieurs options de stockage pour répondre à des exigences variées de coûts et de performance</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP ai intègre étroitement les systèmes DGX et de stockage NetApp AFF A800 avec une connectivité réseau optimale. Les systèmes NetApp ONTAP ai et DGX simplifient les déploiements d'IA en éliminant la complexité et les approximations. Les clients peuvent commencer avec un déploiement de petite taille, puis évoluer sans interruption d'activité, tout en gérant intelligemment leurs données de la périphérie au cœur, et jusqu'au cloud, et inversement.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp ai Control plane est une solution complète d'IA, DE MACHINE LEARNING et de deep learning (DL) et de gestion des tests pour les data Scientists et les ingénieurs de données. Alors que les entreprises ont de plus en plus recours à l'IA, elles sont confrontées à de nombreux défis, notamment l'évolutivité des workloads et la disponibilité des données. NetApp ai Control plane répond à ces challenges grâce à des fonctionnalités telles que le clonage rapide d'un namespace de données comme Git repo. Il définit et met en œuvre des workflows d'entraînement d'IA qui incluent la création quasi instantanée de données et de références de modèles pour la traçabilité et la gestion des versions. NetApp ai Control plane vous permet de répliquer de manière transparente des données entre plusieurs sites et régions, et de provisionner rapidement des espaces de travail Jupyter Notebook avec un accès à des datasets volumineux.</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">Run :l'IA a conçu la première plateforme mondiale d'orchestration et de virtualisation pour les infrastructures d'IA. En retirant les charges de travail du matériel sous-jacent, Run:ai crée un pool partagé de ressources GPU qui peut être provisionné de manière dynamique. Il est ainsi possible d'orchestrer efficacement les workloads d'IA et d'optimiser l'utilisation des GPU. Les data Scientists peuvent utiliser de façon transparente des quantités massives de puissance GPU pour améliorer et accélérer leurs recherches. Les équipes IT conservent un contrôle inter-site centralisé et une visibilité en temps réel sur le provisionnement des ressources, la mise en file d'attente et l'utilisation. La plateforme Run:IA repose sur Kubernetes, pour une intégration simple avec les workflows IT et de data science.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">La plateforme Run:ai offre plusieurs avantages :</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">*Accélération du temps vers l'innovation* en utilisant le pool de ressources Run:ai, la mise en file d'attente et les mécanismes de priorisation avec un système de stockage NetApp, les chercheurs ne sont plus aux problèmes de gestion de l'infrastructure et peuvent se concentrer exclusivement sur la science des données. Exécution :les clients qui possèdent des solutions d'IA et NetApp augmentent la productivité en exécutant autant de workloads que nécessaire, sans goulot d'étranglement au niveau du calcul ou du pipeline de données.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">*Productivité accrue de l'équipe.* les algorithmes Run:ai Equiéquité garantissent que tous les utilisateurs et équipes obtiennent leur juste part de ressources. Les stratégies relatives aux projets prioritaires peuvent être prédéfinies et la plateforme permet une allocation dynamique des ressources d'un utilisateur ou d'une équipe à l'autre, ce qui permet aux utilisateurs d'accéder rapidement aux ressources GPU convoitées.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">*Amélioration de l'utilisation des GPU.* le planificateur Run:ai permet aux utilisateurs d'utiliser facilement des GPU fractionnaires, des GPU entiers et plusieurs nœuds de GPU pour l'entraînement distribué sur Kubernetes. De cette façon, les workloads d'IA s'exécutent en fonction de vos besoins, pas de la capacité. Les équipes de data science sont en mesure d'exécuter davantage d'expériences d'IA sur la même infrastructure.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">Exécutez : installation ai</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Pour installer Run:ai, procédez comme suit :</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">Installez le cluster Kubernetes à l'aide de DeepOps et configurez la classe de stockage par défaut de NetApp.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">Préparez les nœuds GPU :</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">Vérifiez que les pilotes NVIDIA sont installés sur les nœuds GPU.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">Vérifiez-le<block ref="03550f513b5eb839088628d4a360b865" prefix=" " category="inline-code"></block> est installé et configuré comme exécution docker par défaut.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">Installer Run:ai :</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">Exécution : interface d'administration d'IA</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">Connectez-vous au<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> pour créer le cluster.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">Téléchargez le créé<block ref="6b351eac623bdfae151b8db2b05a8131" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Appliquer la configuration de l'opérateur au cluster Kubernetes.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">Vérifiez l'installation :</block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">Accédez à<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">Accédez au tableau de bord Présentation.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Installation de Run:ai sur un cluster Kubernetes sur site</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Installation de la CLI Run:ai</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">Vérifiez que le nombre de GPU situé en haut à droite indique le nombre attendu de GPU et de nœuds GPU dans la liste des serveurs.pour plus d'informations sur le déploiement Run:ai, consultez<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> et<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">Ensuite : lancez des tableaux de bord et des vues d'IA</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">Cette section décrit les différents composants de cette solution à prendre en compte lors de sa conception.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">Considérations relatives à la conception</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">Conception du réseau et des ressources de calcul</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">En fonction des restrictions liées à la sécurité des données, toutes les données doivent rester dans l'infrastructure du client ou dans un environnement sécurisé.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">Conception du stockage</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">Le kit NetApp DataOps sert de service principal pour la gestion des systèmes de stockage. Le kit DataOps est une bibliothèque Python qui facilite le clonage quasi instantané d'un volume de données ou d'un espace de travail JupyterLab par exemple, des développeurs, des data Scientists, et des ingénieurs DevOps, Et le snapshots quasi-instantané d'un volume de données ou d'un espace de travail JupyterLab à des fins de traçabilité ou de base. Cette bibliothèque Python peut fonctionner comme un utilitaire de ligne de commande ou une bibliothèque de fonctions pouvant être importées dans n'importe quel programme Python ou ordinateur portable Jupyter.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">Meilleures pratiques RIVA</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">de meilleures pratiques sur les données</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA présente plusieurs avantages généraux<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Pour utiliser RIVA :</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">*Utilisez des formats audio sans perte si possible.* l'utilisation de codecs avec perte tels que MP3 peut réduire la qualité.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">*Augmenter les données de formation.* l'ajout de bruit de fond aux données de formation audio peut d'abord diminuer la précision tout en augmentant la robustesse.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">*Limiter la taille du vocabulaire en cas d'utilisation de texte gratté.* de nombreuses sources en ligne contiennent des fautes de frappe ou des pronoms auxiliaires et des mots peu communs. La suppression de ces éléments peut améliorer le modèle de langue.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">*Utilisez un taux d'échantillonnage minimum de 16 kHz si possible.* toutefois, essayez de ne pas rééchantillonner, car cela diminue la qualité audio.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">Outre ces meilleures pratiques, il est nécessaire que les clients privilégient la collecte d'un dataset d'échantillon représentatif, avec des étiquettes précises pour chaque étape du pipeline. En d'autres termes, le dataset exemple doit refléter de manière proportionnelle les caractéristiques spécifiées présentées dans un dataset cible. De la même façon, les annotations du dataset ont la responsabilité d'équilibrer la précision et la vitesse d'étiquetage, de sorte que la qualité et la quantité des données soient optimisées. Par exemple, cette solution de centre de support nécessite des fichiers audio, du texte étiqueté et des étiquettes de sentiment. La nature séquentielle de cette solution signifie que les erreurs du début du pipeline sont propagées jusqu'à la fin Si les fichiers audio sont de mauvaise qualité, les transcriptions de texte et les libellés de sentiment seront aussi.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">Cette propagation d'erreur s'applique également aux modèles entraînés sur ces données. Si les prévisions de sentiment sont exactes à 100 % mais que le modèle de parole à texte fonctionne mal, alors le pipeline final est limité par les transcriptions audio à texte initiales. Il est essentiel que les développeurs considèrent les performances de chaque modèle individuellement et comme un composant d'un pipeline plus vaste. Dans ce cas particulier, l'objectif final est de développer un pipeline capable de prédire avec précision le sentiment. Par conséquent, la mesure globale sur laquelle évaluer le pipeline est la précision des sentiments, que la transcription de la parole vers le texte affecte directement.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">Le kit NetApp DataOps complète le pipeline de contrôle de la qualité des données grâce à la technologie de clonage quasi-instantané. Chaque fichier étiqueté doit être évalué et comparé aux fichiers étiquetés existants. La distribution de ces contrôles de qualité sur différents systèmes de stockage des données permet de réaliser ces vérifications rapidement et efficacement.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">Suivant : déploiement de l'analyse des sentiments du centre de support.</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">Lors de la création de vos propres pipelines d'IA et DE ML, la configuration de l'intégration, de la gestion, de la sécurité et de l'accessibilité des composants d'une architecture représente un véritable défi. Le fait de donner aux développeurs accès à leur environnement et de le contrôler constitue un autre ensemble de défis.</block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">L'association de NetApp et d'Iguazio rassemble ces technologies en tant que services gérés afin d'accélérer l'adoption de technologies et d'améliorer le délai de mise sur le marché des nouvelles applications d'IA/ML.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Exemple de Jupyter Notebooks et Kubeflow pipelines</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">Exemple de carnets de bord et de pipelines</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">Le<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Peut être utilisé avec Kubeflow. Grâce au kit NetApp Data Science Toolkit avec Kubeflow, il offre les avantages suivants :</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">Les data Scientists peuvent effectuer des opérations avancées de gestion des données NetApp directement depuis un ordinateur portable Jupyter.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">Les opérations avancées de gestion des données NetApp peuvent être intégrées aux workflows automatisés grâce à la structure Kubeflow pipelines.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Exemples Kubeflow</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">Reportez-vous à la<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Section du référentiel GitHub pour le kit NetApp Data Science pour plus d'informations sur l'utilisation du kit avec Kubeflow.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">Suivant : déploiement du flux d'air Apache.</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Sauvegarde des données vers un volume persistant provisionné par Trident</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident est un projet open source entièrement pris en charge et conçu pour vous aider à répondre aux exigences de persistance sophistiquées de vos applications conteneurisées. Vous pouvez lire et écrire des données sur un volume persistant Kubernetes persistant provisionné par Trident avec le Tiering des données, le chiffrement, la technologie NetApp Snapshot, la conformité et les performances élevées proposés par le logiciel de gestion des données NetApp ONTAP.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">Réutilisation des ESV dans un espace de noms existant</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">Documentation NetApp Trident</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">Pour les projets d'IA plus volumineux, il est possible que les conteneurs soient plus efficaces pour lire et écrire les données sur le même volume persistant Kubernetes. Pour réutiliser une demande de volume persistant Kubernetes, l'utilisateur doit avoir déjà créé une demande de volume persistant. Voir la<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> Pour plus de détails sur la création d'une demande de volume persistant. Voici un exemple de réutilisation d'un PVC existant :</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">Exécutez la commande suivante pour afficher le statut de cette tâche<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block> pour projet<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>:</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">Vous devriez voir le PV /tmp/pvc1mount monté sur<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> travail<block ref="0af7ab68caa77febc818c6ac2cfdbce2" prefix=" " category="inline-code"></block>. Ainsi, plusieurs conteneurs peuvent être lus depuis le même volume, ce qui est utile lorsque plusieurs modèles concurrents sont en cours de développement ou en production. Les data Scientists peuvent élaborer un ensemble de modèles, puis combiner les résultats de prédiction par vote à la majorité ou d'autres techniques.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">Pour accéder au shell du conteneur, procédez comme suit :</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">Vous pouvez ensuite vérifier le volume monté et accéder à vos données dans le conteneur.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">Cette fonctionnalité de réutilisation des volumes virtuels fonctionne avec des volumes NetApp FlexVol et des volumes NetApp ONTAP FlexGroup. Les ingénieurs de données peuvent ainsi utiliser des options de gestion des données plus flexibles et plus robustes pour exploiter votre Data Fabric optimisée par NetApp.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">Cette section répertorie les ordinateurs portables Jupyter et d'autres ressources utiles pour cette solution.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">Vidéos et démonstrations</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">Précédent : résultats de la validation.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">« Support-Center-sentiment-analyse-pipeline.ipynb »</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">“Support-Center-Model-Transfer-Learning-and-Fine-Tuning.ipynb”</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">Deux ordinateurs portables contiennent le pipeline d'analyse des sentiments :<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> et <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. Ensemble, ces ordinateurs portables montrent comment développer un pipeline permettant d'ingérer les données du data Center et d'extraire les sentiments à partir de chaque phrase à l'aide de modèles de deep learning les plus sophistiqués sur les données de l'utilisateur.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">Centre de soutien - Pipeline d'analyse de sentiment.ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">Cet ordinateur portable contient le pipeline RIVA d'inférence pour l'importation de fichiers audio, la conversion en texte et l'extraction de sentiments à utiliser dans un tableau de bord externe. Le jeu de données est automatiquement téléchargé et traité si ce n'est pas déjà fait. La première section du bloc-notes est la parole en texte qui gère la conversion de fichiers audio en texte. La section analyse de sentiment est suivie de la section analyse de sentiment qui extrait des sentiments pour chaque phrase de texte et affiche ces résultats dans un format similaire au tableau de bord proposé.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">Cet ordinateur portable doit être exécuté avant l'entraînement et le réglage précis du modèle car le jeu de données MP3 doit être téléchargé et converti au format approprié.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Centre de support - modèle de formation et affinage.ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">L'environnement virtuel TAO Toolkit doit être configuré avant d'exécuter l'ordinateur portable (voir la section boîte à outils TAO dans la vue d'ensemble des commandes pour les instructions d'installation).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">Cet ordinateur portable s'appuie sur le kit d'outils TAO pour affiner les modèles de deep learning sur les données clients. Comme pour le précédent bloc-notes, celui-ci est divisé en deux sections pour les composants parole-à-texte et analyse de sentiment. Chaque section passe par le traitement des données, l'entraînement et le réglage des modèles, l'évaluation des résultats et l'exportation des modèles. Enfin, vous avez la fin du déploiement de vos deux modèles plus adaptés à RIVA.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">Dans cette section, nous étudions le scénario dans lequel plusieurs équipes soumettent des charges de travail pour dépasser leurs quotas. De cette façon, nous démontrons comment l'algorithme Run:ai d'équité alloue des ressources de cluster en fonction du rapport des quotas prédéfinis.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">Objectifs de ce scénario de test :</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">Montrer le mécanisme de mise en file d'attente lorsque plusieurs équipes demandent des GPU sur leur quota.</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">Montrer comment le système distribue une juste part du cluster entre plusieurs équipes qui surpartagent leur quota d'après le rapport entre leurs quotas, de sorte que l'équipe disposant du quota supérieur puisse obtenir une plus grande part de la capacité disponible.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">À la fin de <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, deux charges de travail sont mises en file d'attente : une pour<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et un pour<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>. Cette section décrit les workloads supplémentaires mis en file d'attente.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">Détails des tests pour la section 4.10</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">Pour plus de détails, y compris les soumissions de travaux, les images de conteneur utilisées et les séquences de commandes exécutées, voir <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">Lorsque tous les travaux sont soumis conformément à la section <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>, le tableau de bord du système le montre<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block>,<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block>, et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Tous ont plus de GPU que leur quota prédéfini.<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Occupe quatre GPU de plus que son soft quota (quatre) prédéfini, alors que<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Chacun d'eux occupent deux GPU de plus que leur soft quota (deux). Le rapport des GPU sur-quotas alloués est égal à celui de leur quota prédéfini. En effet, le système a utilisé le quota prédéfini comme référence en priorité et provisionné en conséquence lorsque plusieurs équipes demandent plus de GPU, ce qui dépasse leur quota. Un tel équilibrage automatique de la charge garantit équité et priorisation lorsque les équipes de data science d'entreprise sont activement engagées dans le développement et la production de modèles d'IA.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">Le système commence à mettre hors file d'attente les charges de travail des autres équipes.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">L'ordre de la démise en file d'attente est déterminé selon des algorithmes d'équité, de telle sorte que<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block> Obtenir la même quantité de GPU sur-quota (puisqu'ils ont un quota similaire), et<block ref="9320270de4ff6824ae7a21f729fb7d44" prefix=" " category="inline-code"></block> Double quantité de GPU dans la mesure où le quota est deux fois plus élevé que celui de<block ref="238ff8d9192e9c01e50a8d6d21f1607b" prefix=" " category="inline-code"></block> et<block ref="3b40d1328b825dda4b761a8e534669b7" prefix=" " category="inline-code"></block>.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">Toute l'allocation est effectuée automatiquement.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">Par conséquent, le système doit se stabiliser sur les États suivants :</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU alloués</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8/4</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">Quatre GPU par rapport au quota. File d'attente vide.</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">Deux GPU sur le quota. Une charge de travail mise en file d'attente</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">N'utilisez pas du tout des GPU, aucun workload mis en attente.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">La figure suivante montre l'allocation des GPU par projet dans le temps dans le tableau de bord Run:ai Analytics <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, et <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. Chaque ligne de la figure indique le nombre de GPU provisionnés pour une équipe de data science donnée à tout moment. Le système obtient ainsi l'allocation dynamique de GPU en fonction des charges de travail envoyées. Cette approche permet aux équipes de dépasser les quotas en présence de GPU disponibles dans le cluster, puis d'anticiper les tâches par équité avant d'atteindre la stabilité des quatre équipes.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">Suivant : sauvegarde des données dans un volume persistant provisionné par Trident</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA ai Enterprise avec NetApp et VMware - utilise le logiciel NVIDIA NGC - Configuration</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">Précédent : utilisation du logiciel NVIDIA NGC.</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">Cette section décrit les tâches de configuration initiales à effectuer pour utiliser le logiciel NVIDIA NGC d'entreprise dans un environnement NVIDIA ai Enterprise.</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">Avant d'effectuer les étapes décrites dans cette section, nous supposons que vous avez déjà déployé le logiciel hôte d'entrée d'entreprise NVIDIA ai en suivant les instructions du <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> page.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">Créez une machine virtuelle Ubuntu Guest avec vGPU</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">Guide de déploiement de NVIDIA ai Enterprise</block>
  <block id="1d7d5c692ef1d70e3217e93bb16af99e" category="paragraph">Tout d'abord, vous devez créer une machine virtuelle Ubuntu 20.04 invitée avec vGPU. Pour créer une machine virtuelle invitée Ubuntu 20.04 avec vGPU, suivez les instructions du <block ref="f5168fb76d8813fb2707289c4637d2ea" category="inline-link-macro-rx"></block>.</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">Téléchargez et installez le logiciel invité NVIDIA</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">Vous devez ensuite installer le logiciel invité NVIDIA requis sur la machine virtuelle invitée que vous avez créée à l'étape précédente. Pour télécharger et installer le logiciel NVIDIA invité nécessaire sur la machine virtuelle invitée, suivez les instructions des sections 5.1-5.4 du <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">Lors de l'exécution des tâches de vérification décrites dans la section 5.4, il se peut que vous deviez utiliser une balise de version d'image du conteneur CUDA différente car l'image du conteneur CUDA a été mise à jour depuis l'écriture du guide. Dans notre validation, nous avons utilisé NVIDIA/cuda:11.0.3-base-ubuntu20.04 ».</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">Télécharger le ou les conteneurs Framework d'IA/d'analytique</block>
  <block id="12a93794571377dc80b4be8c2f22349c" category="paragraph">Vous devez ensuite télécharger les images de conteneur d'IA ou d'analytique requises depuis NVIDIA NGC afin qu'elles soient disponibles dans votre VM invité. Pour télécharger les conteneurs de structure dans la machine virtuelle invitée, suivez les instructions du <block ref="26bd3715eff2817a0154bee58d883e27" category="inline-link-macro-rx"></block>.</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">Installez et configurez le kit NetApp DataOps</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">Vous devez ensuite installer le kit NetApp DataOps Toolkit pour les environnements traditionnels sur la machine virtuelle invitée. Le kit NetApp DataOps permet de gérer les volumes de données scale-out sur votre système ONTAP directement depuis le terminal au sein du serveur virtuel invité. Pour installer le kit NetApp DataOps Toolkit sur la machine virtuelle invitée, effectuez les tâches suivantes.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">Installer pip.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">Déconnectez-vous du terminal de machine virtuelle invité, puis reconnectez-vous.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">Configuration du kit NetApp DataOps. Pour effectuer cette étape, vous aurez besoin des informations d'accès à l'API pour votre système ONTAP. Vous devrez peut-être les obtenir de votre administrateur du stockage.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">Créer un modèle de machine virtuelle invité</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">Enfin, vous devez créer un modèle de machine virtuelle basé sur la machine virtuelle invitée. Vous pouvez utiliser ce modèle pour créer rapidement des machines virtuelles invitées à utiliser le logiciel NVIDIA NGC.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">Pour créer un modèle de machine virtuelle basé sur votre machine virtuelle invitée, connectez-vous à VMware vSphere, cliquez sur le nom de la machine virtuelle invitée, sélectionnez « Cloner », choisissez « Cloner vers modèle... », puis suivez l'assistant.</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">Suivant : exemple d'utilisation - travail de formation TensorFlow.</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">Cette section aborde les concepts et les composants associés à la mise en cache de données dans un flux DE TRAVAIL DE ML.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">Apprentissage machine</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">L'APPRENTISSAGE MACHINE est en passe de devenir essentiel pour de nombreuses entreprises et organisations à travers le monde. Par conséquent, LES équipes IT et DevOps doivent aujourd'hui relever les défis liés à la standardisation des workloads DE ML et au provisionnement des ressources cloud, sur site et de calcul hybride qui prennent en charge les workflows dynamiques et intensifs requis par les pipelines de ML et les pipelines.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">Apprentissage machine basé sur un conteneur et Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">Les conteneurs sont des instances isolées de l'espace utilisateur qui s'exécutent sur un noyau de système d'exploitation hôte partagé. Les conteneurs se sont de plus en plus rapidement adoption. Les conteneurs offrent bon nombre des avantages de la boxe applicative offerts par les machines virtuelles. Cependant, les couches de l'hyperviseur et du système d'exploitation invité sur lesquelles reposent les machines virtuelles ont été éliminées, les conteneurs sont beaucoup plus légers.</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">Les conteneurs permettent également de packaging efficace des dépendances entre applications, des durées d'exécution, etc. Directement avec une application. Le format de conditionnement de conteneurs le plus utilisé est le container Docker. Une application conteneurisée dans le format de conteneur Docker peut être exécutée sur n'importe quel ordinateur capable d'exécuter des conteneurs Docker. Cela est vrai même si les dépendances de l’application ne sont pas présentes sur la machine, car toutes les dépendances sont emballées dans le conteneur lui-même. Pour plus d'informations, consultez la<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">Kubernetes, l'orchestrateur de conteneur le plus populaire, permet aux data Scientists de lancer des travaux et des pipelines flexibles basés sur des conteneurs. Elle permet également aux équipes chargées de l'infrastructure de gérer et de contrôler les workloads DE ML dans un environnement cloud et géré unique. Pour plus d'informations, consultez la<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">Cnvrg.io est un système d'exploitation d'IA qui transforme la façon dont les entreprises gèrent, évoluent et accélèrent le développement de l'IA et de la data science dans la recherche jusqu'à la production. Conçue par les data Scientists, la plateforme basée sur le code First offre aux data Scientists une grande flexibilité pour une exécution sur site ou dans le cloud. Avec la gestion des modèles, la division MLOps et les solutions continues DE ML, cnvrg.io propose aux équipes de science des données des technologies de pointe afin qu'elles puissent consacrer moins de temps au DevOps et se concentrer sur les algorithmes réels. Depuis l'utilisation de cnvrg.io, les équipes de différents secteurs ont obtenu davantage de modèles en production, ce qui a eu pour conséquence une plus grande valeur commerciale.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">Méta-planificateur cnvrg.io</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg. l'e/s dispose d'une architecture unique qui permet AUX INGÉNIEURS ET AUX DÉPARTEMENTS INFORMATIQUES d'associer différentes ressources de calcul au même plan de contrôle et de permettre à cnvrg.io de gérer les tâches DE ML dans l'ensemble des ressources. Cela signifie qu'ELLE peut connecter plusieurs clusters Kubernetes sur site, des serveurs de machine virtuelle et des comptes cloud, et exécuter des workloads DE ML sur toutes les ressources, comme l'illustre la figure suivante.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">Cache des données cnvrg.io</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">grâce à sa technologie de mise en cache des données, cnvrg.io permet aux data scientists de définir des versions de datasets actives et inactives. Par défaut, les jeux de données sont stockés dans une base de données de stockage objet centralisée. Les data Scientists peuvent ensuite mettre en cache une version de données spécifique sur la ressource de calcul sélectionnée pour gagner du temps lors du téléchargement et ainsi augmenter LE DÉVELOPPEMENT DU ML et la productivité. Les datasets qui sont mis en cache et ne sont pas utilisés pendant quelques jours sont automatiquement supprimés du protocole NFS sélectionné. La mise en cache et la suppression du cache peuvent être réalisées en un clic. Aucun codage ni AUCUNE tâche n'est requise POUR LE DevOps.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">Flux cnvrg.io et pipelines DE ML</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">Cnvrg.io écoulements est un outil de construction de pipelines DE ML de production. Chaque composant d'un flux est un script/code exécuté sur un calcul sélectionné avec une image docker de base. Cette conception permet aux data Scientists et aux ingénieurs de créer un pipeline unique capable d'exécuter à la fois sur site et dans le cloud. cnvrg.io garantit le déplacement des données, des paramètres et des artefacts entre les différents composants. En outre, chaque flux est surveillé et suivi pour une science des données 100 % reproductible.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">CŒUR cnvrg.io</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">Le CŒUR cnvrg.io est une plateforme gratuite pour la communauté des sciences des données afin d'aider les data Scientists à se concentrer davantage sur l'informatique et moins sur le DevOps. L'infrastructure flexible DU CŒUR permet aux data Scientists d'utiliser n'importe quel langage, framework d'IA ou environnement de calcul, qu'ils se trouvent sur site ou dans le cloud pour qu'ils puissent faire ce qu'ils font de mieux en créant des algorithmes. Le CŒUR cnvrg.io peut être facilement installé à l'aide d'une seule commande sur tout cluster Kubernetes.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP ai est une architecture de référence de data Center pour les workloads D'AM et d'AP qui utilisent les systèmes de stockage NetApp AFF et les systèmes NVIDIA DGX avec des GPU Tesla V100. ONTAP ai repose sur le protocole de fichiers NFS standard plus de 100 Gb Ethernet, offrant ainsi aux clients une infrastructure DE ML/DL haute performance qui utilise des technologies de data Center standard afin de réduire les frais d'implémentation et d'administration. L'utilisation d'un réseau et de protocoles standardisés permet l'intégration d'ONTAP ai aux environnements de cloud hybride tout en maintenant la cohérence et la simplicité opérationnelles. En tant que solution d'infrastructure prévalidée, ONTAP ai réduit les délais de déploiement et les risques, et réduit considérablement la surcharge administrative, ce qui permet aux clients d'accélérer le retour sur investissement.</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident est un orchestrateur de stockage open source développé et géré par NetApp qui simplifie considérablement la création, la gestion et la consommation du stockage persistant pour les workloads Kubernetes. Trident est une application native de Kubernetes qui s'exécute directement dans un cluster Kubernetes. Avec Trident, les utilisateurs de Kubernetes (développeurs, data Scientists, administrateurs Kubernetes, etc.) peuvent créer, gérer et interagir avec les volumes de stockage persistant dans le format Kubernetes standard qu'ils connaissent déjà. Ils peuvent également bénéficier des fonctionnalités avancées de gestion des données de NetApp et d'un environnement Data Fabric optimisé par la technologie NetApp. Trident élimine les complexités du stockage persistant et facilite la consommation. Pour plus d'informations, consultez la<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID est une plateforme de stockage objet Software-defined conçue pour répondre à ces besoins avec un stockage simple et similaire à celui du cloud, accessible via le protocole S3. StorageGRID est un système scale-out conçu pour prendre en charge plusieurs nœuds sur plusieurs sites connectés par Internet, quelle que soit la distance. Grâce au moteur de règles intelligent de StorageGRID, les utilisateurs ont la possibilité de choisir des objets de codage d'effacement sur l'ensemble des sites pour assurer la résilience géographique ou la réplication d'objets entre les sites distants, afin de minimiser la latence d'accès au réseau WAN. Avec cette solution, StorageGRID propose un excellent data Lake de stockage objet primaire de cloud privé.</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">Le logiciel de gestion des données NetApp Cloud Volumes ONTAP permet de contrôler et de protéger les données utilisateur et d'optimiser l'efficacité du stockage, tout en bénéficiant de la flexibilité des fournisseurs de cloud public tels que AWS, Google Cloud Platform et Microsoft Azure. Cloud Volumes ONTAP est un logiciel de gestion des données natif cloud basé sur le logiciel de stockage NetApp ONTAP. Il offre aux utilisateurs une plateforme de stockage universelle haute performance qui répond à leurs besoins cloud. En utilisant le même logiciel de gestion du stockage dans le cloud et sur site, les utilisateurs bénéficient de l'avantage d'un environnement Data Fabric sans devoir former les équipes IT à des méthodes entièrement nouvelles de gestion des données.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">Si le client s'intéresse aux modèles de déploiement de cloud hybride, Cloud Volumes ONTAP offre des fonctionnalités et des performances exceptionnelles dans la plupart des clouds publics, afin d'offrir à ses utilisateurs une expérience cohérente et transparente, quel que soit l'environnement.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">Suivant : configuration matérielle et logicielle requise</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">Résultats de la validation</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">Pour exécuter une demande d'inférence exemple, procédez comme suit :</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">Obtenir un shell pour le conteneur client/pod.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">Exécuter un exemple de demande d'inférence.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">Cette requête d'inférence appelle<block ref="e8121e2c92eb0c17d4d331407502d266" prefix=" " category="inline-code"></block> modèle utilisé pour la reconnaissance d'images. D'autres clients peuvent également envoyer des demandes d'inférence simultanément en suivant une approche similaire et en appelant le modèle approprié.</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151-DESIGN décrit une architecture vérifiée NetApp pour les workloads de machine learning et d'intelligence artificielle à l'aide des systèmes de stockage NetApp AFF A800, des systèmes NVIDIA DGX A100 et des switchs réseau NVIDIA Mellanox. Il inclut également les résultats des tests d'évaluation pour l'architecture mise en œuvre.</block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">Où trouver des informations supplémentaires, des accusés de réception et l'historique des versions</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">NetApp Kubernetes pour les conteneurs : NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia ai - Inférence confidentielle</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">Documentation NVIDIA Triton Inférence Server</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">Coffrets en PyTorch</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, responsable produits senior, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, Ingénieur marketing et technique, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, directeur technique et professeur, Protopia ai</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">Historique des versions du document</block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">À mai 2022</block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NVIDIA ai Enterprise avec NetApp et VMware - utilise le logiciel NVIDIA NGC</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">Utilisez le logiciel NVIDIA NGC</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">Précédent : configuration initiale.</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">Cette section décrit les tâches à effectuer afin d'utiliser le logiciel NVIDIA NGC d'entreprise dans un environnement NVIDIA ai Enterprise.</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">Suivant : Configuration.</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">Nous avons effectué une comparaison simple des performances dans le cadre de la création de cette solution. Nous avons exécuté plusieurs tâches standard de banc d'essai NetApp avec Kubernetes, et nous avons comparé les résultats du banc d'essai avec les sous-activités qui ont été réalisées à l'aide d'une simple commande Docker run.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">Test des performances</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">Nous avons effectué une comparaison simple des performances dans le cadre de la création de cette solution. Nous avons exécuté plusieurs tâches standard de banc d'essai NetApp ai avec Kubernetes, et nous avons comparé les résultats du banc d'essai avec les sous-activités qui ont été réalisées à l'aide d'une simple commande Docker run. Nous n'avons pas constaté de différence notable au niveau des performances. Nous en avons donc conclu que l'utilisation de Kubernetes pour orchestrer les tâches d'entraînement d'IA conteneurisées n'avait pas de conséquences négatives sur les performances. Pour consulter les résultats de cette comparaison, consultez le tableau suivant.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">Banc d'essai</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker Run (images/s)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes (images/s)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">TensorFlow à un nœud</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">Données synthétiques</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">TensorFlow distribué synchrone à deux nœuds</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">Tr-4858 : solution d'orchestration NetApp avec Run:ai</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-Han Lin, NetApp Yaron Goldberg, Run:ai</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">Les systèmes de stockage NetApp AFF combinent performances optimales et fonctionnalités de pointe pour la gestion des données dans le cloud hybride. NetApp et Run:ai se sont associés pour présenter les fonctionnalités uniques de la solution NetApp ONTAP ai pour les workloads d'intelligence artificielle (IA) et de machine learning (ML), qui offre des performances, une fiabilité et un support haute performance. Exécution :l'orchestration ai des workloads d'IA ajoute une plateforme Kubernetes de planification et d'utilisation des ressources afin d'aider les chercheurs à gérer et à optimiser l'utilisation des GPU. Associée aux systèmes NVIDIA DGX, la solution combinée de NetApp, NVIDIA et Run:ai fournit une pile d'infrastructure dédiée aux workloads d'IA d'entreprise. Ce rapport technique fournit des recommandations aux clients qui conçoivent des systèmes d'IA pour divers champs d'application et dans plusieurs secteurs d'activité. Vous y trouverez des informations sur le déploiement d'Run:ai et un système de stockage NetApp AFF A800, et sert d'architecture de référence pour déployer rapidement des initiatives d'IA de manière simple.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">Les architectes d'entreprise qui conçoivent des solutions pour le développement de modèles et de logiciels d'IA pour des cas d'utilisation basés sur Kubernetes, tels que les microservices conteneurisés</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">Data Scientists qui recherchent des méthodes efficaces pour atteindre leurs objectifs de développement de modèles dans un environnement en cluster comprenant plusieurs équipes et projets</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">Les ingénieurs de données sont chargés de maintenir et d'exécuter des modèles de production</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">Dirigeants, décideurs IT et responsables qui veulent créer une expérience optimale en matière d'utilisation des ressources des clusters Kubernetes et accélérer le time-to-market des initiatives d'IA</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328 : la stratégie d'IA de NetApp basée sur NVIDIA Jarvis</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-Han Lin, NetApp Davide Onofrio, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">La gamme NVIDIA DGX comprend les premiers systèmes basés sur l'intelligence artificielle intégrée (IA) conçus pour l'IA d'entreprise. Les systèmes de stockage NetApp AFF combinent performances optimales et fonctionnalités de pointe pour la gestion des données dans le cloud hybride. NetApp et NVIDIA se sont associés pour créer l'architecture de référence NetApp ONTAP ai, une solution clé en main qui prend en charge les workloads d'IA et de machine learning (ML), tout en offrant des performances et une fiabilité exceptionnelles.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">Ce livre blanc fournit des recommandations aux clients qui conçoivent des systèmes d'IA pour divers champs d'application dans différents secteurs d'activité. Elle inclut des informations sur le déploiement du système à l'aide de NVIDIA Jarvis. Les tests ont été réalisés avec une station NVIDIA DGX et un système de stockage NetApp AFF A220.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">Les architectes d'entreprise qui conçoivent des solutions pour le développement de modèles et de logiciels d'IA dans le cadre de l'élaboration d'outils d'IA, tels que l'assistant de détail virtuel</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">Les data Scientists à la recherche de moyens efficaces pour atteindre les objectifs de développement de la modélisation linguistique</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">Les ingénieurs de données sont chargés de maintenir et de traiter les données texte telles que les questions des clients et les transcriptions des dialogues</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">Dirigeants, décideurs IT et responsables qui veulent transformer les échanges d'expérience d'IA et accélérer le time-to-market des initiatives d'IA</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files :</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Architecture des solutions pour Azure NetApp Files</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">Trident pour le stockage persistant pour les conteneurs :</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files et Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">DASK and RAPIDS :</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">DASK</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Installer DASK</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">API DASK</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">DASK machine Learning</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Diagnostic distribué DASK</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="doc">Personnalisez les États et les flux pour le cas d'utilisation Vente au détail</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">Vous pouvez personnaliser les États et les flux de Dialog Manager pour vos cas d'utilisation spécifiques. Dans notre exemple de vente au détail, nous avons les quatre fichiers yaml suivants pour diriger la conversation selon différentes intentions.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">Se la liste suivante des noms de fichier et la description de chaque fichier :</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text"><block ref="ef7c28f5093b59a07761555c8914df26" prefix="" category="inline-code"></block>: Définit les principaux flux et États de conversation et dirige le flux vers les trois autres fichiers yaml si nécessaire.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text"><block ref="dfc9a806326d590aa4ccf49aa6909cda" prefix="" category="inline-code"></block>: Contient des États liés à des questions de détail ou de points d'intérêt. Le système fournit soit les informations du magasin le plus proche, soit le prix d'un article donné.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text"><block ref="6e08d9d65c68d5f447f4fd239052c12e" prefix="" category="inline-code"></block>: Contient des États relatifs aux questions météorologiques. Si l'emplacement ne peut pas être déterminé, le système pose une question de suivi pour clarifier.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text"><block ref="b7dc1d2ced2caa9352158983c5ffeda1" prefix="" category="inline-code"></block>: Gère les cas où les intentions des utilisateurs ne tombent pas dans les trois fichiers yaml ci-dessus. Après l'affichage d'un message d'erreur, le système revient à accepter les questions de l'utilisateur. Les sections suivantes contiennent les définitions détaillées de ces fichiers yaml.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail_flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">météo_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">error_flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">Ensuite, connectez-vous à des API tierces en tant que moteur de traitement</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP ai et Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">L'architecture NetApp ONTAP ai, optimisée par les systèmes NVIDIA DGX et les systèmes de stockage NetApp connectés au cloud, a été développée et vérifiée par NetApp et NVIDIA. Et présente plusieurs avantages pour les SERVICES IT :</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">Propose toute une gamme d'options de stockage pour répondre à différents besoins de performance et de pointsNetApp ONTAP ai intègre étroitement les systèmes DGX et de stockage NetApp AFF A220 avec une connectivité réseau optimale. Les systèmes NetApp ONTAP ai et DGX simplifient les déploiements d'IA en éliminant la complexité et les approximations. Les clients peuvent commencer avec un déploiement de petite taille, puis évoluer sans interruption d'activité, tout en gérant intelligemment leurs données de la périphérie au cœur, et jusqu'au cloud, et inversement.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync vous permet de déplacer facilement des données sur différents protocoles, qu'il s'agisse de deux partages NFS, de deux partages CIFS ou d'un partage de fichiers et d'Amazon S3, Amazon Elastic File System (EFS) ou Azure Blob Storage. Avec le mode actif-actif, vous pouvez continuer à travailler avec la source et la cible en même temps, en synchronisant les modifications de données de manière incrémentielle lorsque nécessaire. Cloud Sync vous permet de déplacer et de synchroniser progressivement les données entre tous les systèmes source et cible, qu'ils soient sur site ou dans le cloud, et vous offre de nouvelles façons d'utiliser les données. La migration des données entre des systèmes sur site, l'intégration dans le cloud et la migration vers le cloud, ou encore la collaboration et l'analytique, sont toutes des opérations qui deviennent facilement réalisables. La figure ci-dessous montre les sources et destinations disponibles.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">Dans les systèmes d'IA conversationnels, les développeurs peuvent utiliser Cloud Sync pour archiver l'historique des conversations du cloud vers les data centers afin de permettre l'entraînement en ligne des modèles de traitement du langage naturel (NLP). En formant des modèles permettant de reconnaître des intentions plus nombreuses, le système d'IA conversationnel sera mieux équipé pour gérer des questions plus complexes de la part des utilisateurs finaux.</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> Est un framework de bout en bout pour la création de services d'IA conversationnels. Elle comprend les services optimisés pour les processeurs graphiques suivants :</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">Reconnaissance vocale automatique (ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">Compréhension du langage naturel (NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">Intégration avec des services d'exécution spécifiques à un domaine</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">Texte à parole (TTS)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">Vision par ordinateur (CV)les services basés à Jarvis font appel à des modèles de deep learning sophistiqués pour gérer la tâche complexe et complexe qui consiste à gérer l'IA conversationnelle en temps réel. Pour permettre une interaction naturelle en temps réel avec un utilisateur final, les modèles doivent réaliser le calcul en moins de 300 millisecondes. Les interactions naturelles sont difficiles, ce qui nécessite une intégration sensorielle multimodale. Les pipelines modèles sont également complexes et nécessitent une coordination entre les services susmentionnés.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis est un framework d'application entièrement accéléré qui permet de créer des services d'IA multimodaux et d'exploiter un pipeline d'apprentissage profond de bout en bout. Le cadre de Jarvis inclut des modèles, des outils et des services d'IA pré-entraînés, optimisés pour la parole, la vision et les tâches de la NLU. Outre les services d'IA, Jarvis vous permet de fusionner simultanément la vision, le son et d'autres entrées de capteur afin de fournir des fonctionnalités telles que les conversations multi-utilisateurs et multi-contexte dans des applications telles que les assistants virtuels, la diarisation multi-utilisateurs et les assistants du centre d'appels.</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> Est un kit Python open source permettant de créer, d'entraîner et d'affiner les modèles d'IA à accélération par processeur graphique, en utilisant des API (interfaces de programmation des applications) simples d'utilisation. Nemo exécute des ressources de calcul de précision mixte avec des cœurs Tensor dans les processeurs graphiques NVIDIA. Il peut facilement évoluer jusqu'à plusieurs GPU pour offrir les meilleures performances d'entraînement possibles. Nemo est utilisé pour concevoir des modèles pour les applications ASR, NLP et TTS en temps réel, telles que les transcriptions d'appels vidéo, les assistants vidéo intelligents et le support automatisé des centres d'appels dans différents secteurs industriels, y compris la santé, les finances, le commerce de détail et les télécommunications.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Nous avons utilisé Nemo pour former des modèles qui reconnaissent les intentions complexes des questions des utilisateurs dans l'historique des conversations archivées. Cette formation étend les capacités de l'assistant virtuel au détail au-delà de ce que Jarvis soutient comme prestation.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">Sommaire de l'utilisation du commerce de détail</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">Avec NVIDIA Jarvis, nous avons construit un assistant de vente au détail virtuel qui accepte les commentaires vocaux ou texte et répond aux questions relatives à la météo, aux points d'intérêt et aux prix des stocks. Le système d'IA sur laquelle vous discutez peut mémoriser le flux de conversation, par exemple, posez une question de suivi si l'utilisateur n'a pas précisé le lieu par météo ou les points d'intérêt. Le système reconnaît également des entités complexes telles que « la nourriture thaïlandaise » ou « la mémoire des ordinateurs portables ». Il comprend des questions de langage naturel comme « la semaine prochaine à Los Angeles sera-t-elle pluviale ? » Vous trouverez une démonstration de l'assistant virtuel de vente au détail dans<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">Cette page présente la technologie utilisée dans cette solution.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft et NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">Depuis mai 2019, Microsoft propose un service de portail Azure propriétaire natif pour les services de fichiers NFS et SMB d'entreprise basés sur la technologie NetApp ONTAP. Ce développement est régi par un partenariat stratégique entre Microsoft et NetApp, et étend encore davantage la portée des services de données ONTAP à Azure.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Le service Azure NetApp Files est un service de stockage de fichiers hautes performances et mesuré. Azure NetApp Files prend en charge tous les types de charges de travail et est extrêmement disponible par défaut. Vous pouvez sélectionner des niveaux de service et de performances et configurer des copies Snapshot via le service. Azure NetApp Files est un service Azure propriétaire pour la migration et l'exécution des workloads de fichiers d'entreprise les plus exigeants dans le cloud, y compris les bases de données, SAP et les applications de calcul haute performance sans modifier le code.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">Et présente plusieurs avantages pour les SERVICES IT :</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">Propose plusieurs tiers de stockage pour répondre à des exigences variées de coûts et de performance</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Présentation de DASK et NVIDIA RAPIDS</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">DASK est un outil informatique parallèle open source qui permet de faire évoluer les bibliothèques Python sur plusieurs machines et d'accélérer le traitement de grandes quantités de données. Il fournit une API similaire aux bibliothèques Python conventionnelles à thread unique, telles que Pandas, NumPy et scikit-Learn. Par conséquent, les utilisateurs Python natifs n'ont pas à modifier un grand nombre de leur code existant en vue d'utiliser les ressources sur l'ensemble du cluster.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS est une suite de bibliothèques open source qui permet d'exécuter facilement les workflows D'AM et d'analytique de bout en bout sur les GPU. Avec DASK, il vous permet de passer facilement d'une station de travail GPU (évolutivité verticale) à des clusters multi-nœuds et multi-processeurs graphiques (évolutivité horizontale).</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">Pour le déploiement de DASK sur un cluster, vous pouvez utiliser Kubernetes pour l'orchestration des ressources. Vous pouvez également augmenter ou réduire les nœuds workers selon les besoins process, ce qui peut vous aider à optimiser la consommation des ressources du cluster, comme le montre la figure suivante.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">Ensuite : configuration logicielle requise.</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">Cette section décrit le chargement des journaux Criteo Click jour 15 dans Pandas et la formation d'un modèle de forêt aléatoire d'apprentissage scikit. Dans cet exemple, nous avons effectué le chargement de DataFrame avec DASK cuDF et formé un modèle de forêt aléatoire dans DASk cuML.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Charger le jour 15 à DASK et former un modèle forestier aléatoire de DASk cuML</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">Précédent: Charger Criteo cliquez sur Logs Day 15 dans Pandas et former un modèle de forêt aléatoire de scikit.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">“Comparaison du temps de formation.”</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">D'une manière similaire à la section précédente, chargez Criteo Click Logs Day 15 dans Pandas et entraînez un modèle de forêt aléatoire d'apprentissage de scikit. Dans cet exemple, nous avons effectué le chargement de DataFrame avec DASK cuDF et formé un modèle de forêt aléatoire dans DASk cuML. Nous avons comparé les différences en termes de temps et d'échelle d'entraînement dans la section <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dAsk_RF.ipynb</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">Cet ordinateur portable importe<block ref="2ea9510c37f7f89e4941ff75f62f21cb" prefix=" " category="inline-code"></block>,<block ref="7bdff0c624ecc34cd492f58859b5a599" prefix=" " category="inline-code"></block>, et le nécessaire<block ref="b2015e522a418c3350d3af1da8790aeb" prefix=" " category="inline-code"></block> bibliothèques, comme illustré dans l'exemple suivant :</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Lancez DASK client().</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">Si le cluster est configuré correctement, vous pouvez afficher l'état des nœuds workers.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">Dans notre cluster AKS, l'état suivant s'affiche :</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">Notez que DASK utilise le paradigme d'exécution paresseux : plutôt que d'exécuter le code de traitement instantanément, DASK construit plutôt un graphe acyclique dirigé (DAG) d'exécution. DAG contient un ensemble de tâches et leurs interactions dont chaque employé a besoin pour s'exécuter. Cette disposition signifie que les tâches ne sont pas exécutées tant que l'utilisateur n'a pas dit à DASK de les exécuter d'une manière ou d'une autre. Avec DASK, vous disposez de trois options principales :</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">*Call Compute() sur un DataFrame.* cet appel traite toutes les partitions, puis renvoie les résultats au planificateur pour l'agrégation finale et la conversion en cuDF DataFrame. Cette option doit être utilisée avec parcimonie et avec des résultats fortement réduits, à moins que le nœud du planificateur ne manque de mémoire.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">*Call persistent() sur un DataFrame.* cet appel exécute le graphique, mais, au lieu de renvoyer les résultats au nœud du planificateur, il les maintient dans le cluster en mémoire afin que l'utilisateur puisse réutiliser ces résultats intermédiaires dans le pipeline sans avoir besoin de réexécuter le même traitement.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">*Call head() sur un DataFrame.* tout comme avec cuDF, cet appel renvoie 10 enregistrements au nœud du planificateur. Cette option permet de vérifier rapidement si votre DataFrame contient le format de sortie souhaité ou si les enregistrements eux-mêmes ont un sens, selon votre traitement et votre calcul.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">Par conséquent, à moins que l'utilisateur n'appelle l'une ou l'autre de ces actions, les travailleurs restent inactifs en attendant que le planificateur lance le traitement. Ce modèle d'exécution paresseux est courant dans les infrastructures informatiques modernes parallèles et distribuées telles qu'Apache Spark.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">Le paragraphe suivant forme un modèle de forêt aléatoire en utilisant DASK cuML pour le calcul accéléré par GPU distribué et calcule la précision de prévision des modèles.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">Suivant : surveillez le DASK à l'aide du tableau de bord natif des flux de tâches.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">Cette section présente les différents composants techniques nécessaires pour compléter cette solution.</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">Précédent : catégories de solutions</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">Protopia</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia ai offre une solution logicielle unique et discrète pour l'inférence confidentielle sur le marché actuel. La solution Protopia offre une protection sans précédent pour les services d'inférence en minimisant l'exposition des informations sensibles. L'IA n'est alimentée que les informations qui figurent dans les enregistrements de données. Il est primordial de mener à bien la tâche à bien et rien de plus. La plupart des tâches d'inférence n'utilisent pas toutes les informations qui existent dans chaque enregistrement de données. Que votre IA consomme des images, de la voix, des vidéos ou même des données tabulaires structurées, Protopia fournit uniquement ce dont le service d'inférence a besoin. La technologie de base brevetée fait appel à un bruit mathématiquement choisi pour transformer les données avec beaucoup de place et pour brouiller les informations qui ne sont pas nécessaires à un service DE ML donné. Cette solution ne masque pas les données ; elle modifie plutôt la représentation des données en utilisant un bruit aléatoire adapté.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">La solution Protopia formule le problème de la modification de la représentation en tant que méthode d'optimisation des perturbations à base de gradient qui conserve toujours les informations pertinentes dans l'espace de la fonction d'entrée par rapport à la fonctionnalité du modèle. Ce processus de détection s'exécute comme un pass d'ajustement à la fin de l'entraînement du modèle DE ML. Une fois que le pass génère automatiquement un ensemble de distributions de probabilité, une transformation des données à faible surcharge applique des échantillons de bruit de ces distributions aux données, l'obfusant avant de les transmettre au modèle pour l'inférence.</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">L'architecture de référence NetApp ONTAP ai, optimisée par les systèmes DGX A100 et les systèmes de stockage connectés au cloud de NetApp, a été développée et vérifiée par NetApp et NVIDIA. Et présente plusieurs avantages pour les services IT :</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP ai intègre étroitement les systèmes DGX A100 et de stockage NetApp AFF A800 avec une connectivité réseau optimale. ONTAP ai simplifie les déploiements d'IA en éliminant la complexité et les approximations. Les clients peuvent commencer avec une petite infrastructure, puis évoluer sans interrompre l'activité, tout en gérant intelligemment leurs données de la périphérie au cœur, et jusqu'au cloud, et inversement.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">La figure suivante montre plusieurs variations de la gamme de solutions ONTAP ai avec les systèmes DGX A100. Les performances du système AFF A800 sont vérifiées avec un maximum de huit systèmes DGX A100. En ajoutant des paires de contrôleurs de stockage au cluster ONTAP, l'architecture peut évoluer vers plusieurs racks pour prendre en charge de nombreux systèmes DGX A100 et des pétaoctets de capacité de stockage avec des performances linéaires. Cette approche flexible permet d'ajuster les ratios de calcul/stockage de manière indépendante, en fonction de la taille des modèles d'apprentissage profond utilisés et des metrics de performance requis.</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153 : NetApp ONTAP ai avec des systèmes NVIDIA DGX A100 et des switchs Ethernet Mellanox Spectrum.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">Pour plus d'informations sur ONTAP ai, rendez-vous sur<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP permet de gérer et de protéger les données avec un seul ensemble d'outils, quel que soit leur emplacement. Vous pouvez aussi déplacer vos données librement partout où elles sont nécessaires : la périphérie, le cœur ou le cloud. ONTAP 9.11 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques, et permettent d'utiliser des fonctionnalités d'infrastructure nouvelle génération dans toutes les architectures de cloud hybride.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">Le kit NetApp DataOps est une bibliothèque Python qui facilite le clonage quasi instantané d'un volume de données ou d'un espace de travail JupyterLab par exemple, des développeurs, des data Scientists, et des ingénieurs DevOps, Et de réaliser quasi-instantanément des snapshots d'un volume de données ou d'un espace de travail JupyterLab pour la traçabilité ou l'établissement de base. Cette bibliothèque Python peut fonctionner comme un utilitaire de ligne de commande ou une bibliothèque de fonctions que vous pouvez importer dans n'importe quel programme Python ou ordinateur portable Jupyter.</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton Inférence Server est un logiciel d'inférence open source qui permet de standardiser le déploiement et l'exécution des modèles afin d'assurer l'IA rapide et évolutive en production. Triton Inférence Server rationalise l'inférence d'IA en permettant aux équipes de déployer, d'exécuter et de faire évoluer les modèles d'IA entraînés à partir de n'importe quelle infrastructure basée sur le processeur ou le processeur graphique. Triton Inférence Server prend en charge toutes les structures majeures, telles que TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO, etc. Triton s'intègre à Kubernetes pour l'orchestration et l'évolutivité que vous pouvez utiliser dans toutes les principales plateformes d'IA et Kubernetes de cloud public. Il est également intégré à de nombreuses solutions logicielles MLOps.</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> Est un framework DE ML open source. Il s'agit d'une bibliothèque Tensor optimisée pour le deep learning, qui utilise les GPU et les processeurs. Le paquet PyTorch contient des structures de données pour les tenseurs multidimensionnels qui fournissent de nombreux utilitaires pour la sérialisation efficace des tenseurs entre autres utilitaires utiles. Il dispose également d'un homologue CUDA qui vous permet d'exécuter vos calculs Tensor sur un GPU NVIDIA offrant des capacités de calcul. Dans cette validation, nous utilisons la bibliothèque OpenCV-Python (cv2) pour valider notre modèle tout en tirant parti des concepts de vision informatique les plus intuitifs de Python.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Service Astra Control</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">La gamme NetApp Astra propose des services de stockage et de gestion des données respectueuse des applications pour les applications Kubernetes sur site et dans le cloud public, optimisés par les technologies NetApp de stockage et de gestion des données. Il vous permet de sauvegarder facilement les applications Kubernetes, de migrer des données vers un autre cluster et de créer instantanément des clones d'applications de travail. Si vous devez gérer les applications Kubernetes s'exécutant dans un cloud public, consultez la documentation de<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>. Astra Control Service est un service géré par NetApp qui permet la gestion des données intégrant la cohérence applicative des clusters Kubernetes dans Google Kubernetes Engine (GKE) et Azure Kubernetes Service (AKS).</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="section-title">NetApp Astra Trident</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> À partir de NetApp, est un orchestrateur de stockage dynamique open source pour Docker et Kubernetes qui simplifie la création, la gestion et la consommation du stockage persistant. Trident, une application Kubernetes native, s'exécute directement dans un cluster Kubernetes. Trident permet de déployer de manière transparente des images de conteneur d'apprentissage profond sur un système de stockage NetApp et offre une expérience haute performance pour les déploiements de conteneurs d'IA. Les utilisateurs de Kubernetes (développeurs DE ML, data Scientists, etc.) peuvent créer, gérer et automatiser l'orchestration et le clonage pour exploiter des fonctionnalités avancées de gestion des données optimisées par la technologie NetApp.</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> Est un service NetApp qui permet une synchronisation sûre et rapide des données. Qu'il s'agisse de transférer des fichiers entre des partages de fichiers NFS ou SMB sur site, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon simple Storage Service (Amazon S3), Amazon Elastic File System (Amazon EFS), Azure Blob, Google Cloud Storage, Ou IBM Cloud Object Storage, Cloud Sync déplace les fichiers là où vous en avez besoin, rapidement et de manière sécurisée. Une fois vos données transférées, elles peuvent être utilisées à la source et à la cible. Cloud Sync synchronise en continu les données en fonction de votre planification prédéfinie, en ne déplaçant que les données modifiées, de sorte que le temps et les coûts liés à la réplication des données sont réduits. Cloud Sync est un outil SaaS extrêmement simple à configurer et à utiliser. Les transferts de données déclenchés par Cloud Sync sont effectués par des courtiers de données. Vous pouvez déployer des courtiers de données Cloud Sync sur AWS, Azure, Google Cloud Platform ou sur site.</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">Le bon sens des données cloud avec NetApp</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">Reposant sur de puissants algorithmes d'IA, <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> permet d'automatiser le contrôle et la gouvernance des données dans l'ensemble de votre environnement de données. Vous pouvez facilement identifier les économies réalisables, identifier les problèmes de conformité et de confidentialité, et trouver des opportunités d'optimisation. Le tableau de bord Cloud Data Sense vous permet d'identifier les données dupliquées pour éliminer la redondance, mapper les données personnelles, non personnelles et sensibles, et activer des alertes en cas de données sensibles ou d'anomalie.</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">Suivant : plan de test et de validation.</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow est capable de provisionner rapidement de nouveaux serveurs Jupyter Notebook pour agir en tant qu'espaces de travail de data Scientist. Pour provisionner un nouveau serveur Jupyter Notebook avec Kubeflow, exécutez les tâches répertoriées sur cette page.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">Provisionner un espace de travail Jupyter Notebook pour un usage Data Scientist ou Developer</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow est capable de provisionner rapidement de nouveaux serveurs Jupyter Notebook pour agir en tant qu'espaces de travail de data Scientist. Pour provisionner un nouveau serveur Jupyter Notebook avec Kubeflow, effectuez les tâches suivantes. Pour plus d'informations sur les ordinateurs portables Jupyter dans le contexte Kubeflow, reportez-vous au<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Dans le tableau de bord central Kubeflow, cliquez sur serveurs portables dans le menu principal pour accéder à la page d'administration des serveurs Jupyter Notebook.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">Cliquez sur Nouveau serveur pour provisionner un nouveau serveur Jupyter Notebook.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">Donnez un nom à votre nouveau serveur, choisissez l'image Docker sur laquelle vous voulez que votre serveur soit basé, et spécifiez la quantité de CPU et de RAM à réserver par votre serveur. Si le champ espace de noms est vide, utilisez le menu Sélectionner espace de noms dans l'en-tête de la page pour choisir un espace de noms. Le champ espace de noms est alors automatiquement renseigné avec l'espace de noms choisi.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">Dans l'exemple suivant, le<block ref="aec502449511a35e8b040af72693bf5c" prefix=" " category="inline-code"></block> l'espace de noms est choisi. En outre, les valeurs par défaut pour l'image Docker, la CPU et la RAM sont acceptées.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">Spécifiez les détails du volume de l'espace de travail. Si vous choisissez de créer un nouveau volume, ce volume ou cette demande de volume persistant est provisionné à l'aide de la classe de stockage par défaut. Comme une classe de stockage utilisant Trident a été désignée comme classe de stockage par défaut dans la section <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, Le volume ou la demande de volume persistant est provisionné avec Trident. Ce volume est automatiquement monté comme espace de travail par défaut dans le conteneur Jupyter Notebook Server. Tous les ordinateurs portables créés par un utilisateur sur le serveur qui ne sont pas enregistrés dans un volume de données distinct sont automatiquement enregistrés dans ce volume d'espace de travail. Par conséquent, les ordinateurs portables sont persistants entre les redémarrages.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">Ajout de volumes de données. L'exemple suivant indique un PVC existant nommé 'pb-fg-all' et accepte le point de montage par défaut.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">*Facultatif:* Demandez que le nombre de processeurs graphiques souhaité soit alloué à votre serveur d'ordinateur portable. Dans l'exemple suivant, un GPU est demandé.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">Cliquez sur lancer pour approvisionner votre nouveau serveur d'ordinateur portable.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">Attendez que le serveur de votre ordinateur portable soit entièrement approvisionné. Cette opération peut prendre plusieurs minutes si vous n'avez jamais provisionné de serveur à l'aide de l'image Docker que vous avez spécifiée, car l'image doit être téléchargée. Lorsque votre serveur a été entièrement provisionné, une coche verte s'affiche dans la colonne État de la page d'administration du serveur Jupyter Notebook.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">Cliquez sur connexion pour vous connecter à votre nouvelle interface Web de serveur.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">Vérifiez que le volume du dataset spécifié à l'étape 6 est monté sur le serveur. Notez que ce volume est monté par défaut dans l'espace de travail par défaut. Du point de vue de l'utilisateur, ce n'est qu'un autre dossier dans l'espace de travail. L'utilisateur, qui est probablement un spécialiste des données et non un expert en infrastructure, n'a pas besoin de posséder de compétences en stockage pour utiliser ce volume.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">Ouvrez un terminal et, en supposant qu'un nouveau volume a été demandé à l'étape 5, exécutez<block ref="109faa0d3af468439c8966d496020840" prefix=" " category="inline-code"></block> Pour confirmer qu'un nouveau volume persistant provisionné avec Trident est monté en tant qu'espace de travail par défaut.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">Le répertoire d’espace de travail par défaut est le répertoire de base avec lequel vous êtes présenté lorsque vous accédez pour la première fois à l’interface Web du serveur. Par conséquent, tout artefact que vous créez via l'interface Web est stocké sur ce volume persistant provisionné par Trident.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">À l'aide du terminal, exécutez<block ref="21c52f2a2730f054205ebdf40f536e5a" prefix=" " category="inline-code"></block> Pour vérifier que le nombre correct de GPU a été attribué au serveur d'ordinateur portable. Dans l'exemple suivant, un GPU a été affecté au serveur d'ordinateurs portables comme demandé à l'étape 7.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">Suivant : exemple de carnets et de pipelines.</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">Cette page décrit les étapes de configuration du cluster AKS.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">Installez et configurez le cluster AKS</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">Précédent : récapitulatif de l'utilisation des prévisions de taux par clic.</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">Pour installer et configurer le cluster AKS, reportez-vous à la page Web<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> puis procédez comme suit :</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">Lors de la sélection du type de nœud (nœuds du système [CPU] ou du worker [GPU]), sélectionnez ce qui suit :</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">Les nœuds du système primaire doivent être de type Standard DS2v2 <block ref="917718fb2e3dcf94043ea14d44580bc2" prefix="(" category="inline-code"></block> trois nœuds par défaut).</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">Ajoutez ensuite le nœud de travail Standard_NC6s_v3 pool (trois nœuds minimum) pour le groupe d'utilisateurs (pour les nœuds GPU) nommé<block ref="2e7ef525fb562d2f68920b0bf6f58b81" prefix=" " category="inline-code"></block>.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">Le déploiement prend entre 5 et 10 minutes. Lorsque l'opération est terminée, cliquez sur Connect to Cluster.</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">Pour vous connecter au cluster AKS nouvellement créé, installez les éléments suivants à partir de votre environnement local (ordinateur portable/pc) :</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">Instructions fournies pour votre système d'exploitation</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">L'outil de ligne de commande Kubernetes à l'aide de<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Installez l'interface de ligne de commande Azure</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">L'interface de ligne de commandes Azure, comme décrit dans le document,<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">Pour accéder au cluster AKS à partir du terminal, entrez<block ref="f7ac81b64d50d201c173fb8dcf70f266" prefix=" " category="inline-code"></block> et entrez les informations d'identification.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Entrez<block ref="33ba05f3df928c75694839078d97b2e4" prefix=" " category="inline-code"></block>.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">Si les six nœuds sont actifs, comme illustré dans l'exemple suivant, votre cluster AKS est prêt et connecté à votre environnement local</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">Créez ensuite un sous-réseau délégué pour Azure NetApp Files.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">Les données existent dans trois États : au repos, en transit et dans le calcul. Un service d'inférence d'IA doit contenir des données non menaces lors de l'intégralité du processus. La protection des données pendant l'inférence est essentielle. En effet, le processus peut exposer des informations privées aux clients externes et à l'entreprise fournissant le service d'inférence.</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">Précédent : vitesse d'obfuscation.</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">Les données existent dans trois États : au repos, en transit et dans le calcul. Un service d'inférence d'IA doit contenir des données non menaces lors de l'intégralité du processus. La protection des données pendant l'inférence est essentielle. En effet, le processus peut exposer des informations privées aux clients externes et à l'entreprise fournissant le service d'inférence. Protopia ai est une solution logicielle unique non-intégrée pour l'inférence confidentielle de l'IA sur le marché actuel. Avec Protopia, l'IA est alimenté uniquement les informations transformées dans les dossiers de données, essentielles pour mener à bien les tâches d'IA et DE ML. Cette transformation stochastique n'est pas une forme de masquage et est basée sur la modification mathématiquement de la représentation des données à l'aide d'un bruit adapté.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">Les systèmes de stockage NetApp dotés des fonctionnalités ONTAP offrent des performances identiques ou supérieures au stockage SSD local. Associés au kit NetApp DataOps, ils offrent les avantages suivants aux data Scientists, aux ingénieurs de données, aux développeurs d'IA/AM et aux décideurs IT d'entreprise ou d'entreprise :</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">Protection et gouvernance des données pour la reprise après incident, la continuité de l'activité et les exigences réglementaires.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Appel simplifié à des opérations de gestion des données ; prise rapide de copies Snapshot d'espaces de travail de data Scientists pour la sauvegarde et la traçabilité à partir du kit NetApp DataOps Toolkit dans des ordinateurs portables Jupyter.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">La solution NetApp et Protopia offre une architecture flexible et scale-out, idéale pour les déploiements d'inférence d'IA haute performance. Il protège les données et garantit la confidentialité des informations sensibles pour lesquelles les exigences d'inférence d'IA confidentielles peuvent être respectées grâce à des pratiques d'IA responsables dans les déploiements sur site et dans le cloud hybride.</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">Suivant : où trouver des informations supplémentaires, des accusés de réception et l'historique des versions ?</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Déployez Grafana Dashboard</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">Après le déploiement de tout, nous inférons les nouvelles données. Les modèles prévoient une défaillance sur l'équipement du périphérique réseau. Les résultats de la prédiction sont conservés dans une table de timeseries d'Iguazio. Vous pouvez visualiser les résultats avec Grafana dans la plate-forme intégrée à la politique de sécurité et d'accès aux données d'Iguazio.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">Vous pouvez déployer le tableau de bord en important le fichier JSON fourni dans les interfaces de Grafana.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Pour vérifier que le service Grafana est exécuté, consultez la section Services.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">Si ce n'est pas le cas, déployez une instance à partir de la section Services :</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">Cliquez sur Nouveau service.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">Sélectionnez Grafana dans la liste.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">Acceptez les valeurs par défaut.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">Cliquez sur étape suivante.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">Entrez votre ID utilisateur.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">Cliquez sur Save Service.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">Cliquez sur appliquer les modifications en haut.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">Pour déployer le tableau de bord, téléchargez le fichier<block ref="5399022d93458a73556ae80388186793" prefix=" " category="inline-code"></block> Via l'interface Jupyter.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">Ouvrez Grafana à partir de la section Services et importez le tableau de bord.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Cliquez sur Télécharger<block ref="b31ec5f19793e2b7103acd7336754a1c" prefix=" " category="inline-code"></block> Et sélectionnez le fichier que vous avez téléchargé précédemment <block ref="5399022d93458a73556ae80388186793" prefix="(" category="inline-code"></block>). Le tableau de bord s'affiche une fois le téléchargement terminé.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">Déployer la fonction nettoyage</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">Lorsque vous générez un grand nombre de données, il est important de préserver la propreté et l'organisation des données. Pour ce faire, déployez la fonction de nettoyage avec le<block ref="11652556f686b20fd51b96992986630e" prefix=" " category="inline-code"></block> bloc-notes.</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">Avantages</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp et Iguazio accélèrent et simplifient le déploiement des applications d'IA et DE ML en créant dans des frameworks essentiels, comme Kubeflow, Apache Spark et TensorFlow, avec des outils d'orchestration comme Docker et Kubernetes. En unifiant le pipeline de données de bout en bout, NetApp et Iguazio réduisent la latence et la complexité inhérentes à de nombreuses charges de travail informatiques avancées, afin de combler l'écart entre le développement et les opérations. Les data Scientists peuvent exécuter des requêtes sur d'importants jeux de données et partager en toute sécurité les données et les modèles algorithmiques avec les utilisateurs autorisés au cours de la phase d'entraînement. Une fois que les modèles conteneurisés sont prêts pour la production, vous pouvez facilement les déplacer d'environnements de développement à des environnements opérationnels.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NetApp EF-Series ai avec NVIDIA</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">Présentation des solutions d'infrastructure convergée EF-Series ai de NetApp et NVIDIA.</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="section-title">EF-Series ai avec les systèmes NVIDIA DGX A100 et BeeGFS</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">Guide de conception</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">Guide de déploiement</block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">Guide de déploiement BeeGFS</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">Ce rapport vous explique comment cloner rapidement un espace de noms de données. Vous découvrirez comment définir et implémenter des workflows d'entraînement d'IA pour intégrer la création quasi instantanée de données et de modèles de base à des fins de traçabilité et de gestion des versions. Il montre également comment répliquer des données de manière transparente entre plusieurs sites et régions, et déployer rapidement des espaces de travail Jupyter Notebook à l'aide de jeux de données volumineux.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">Tr-4798 : plan de contrôle pour l'IA de NetApp</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">Toutes les entreprises, quelle que soit leur taille et leurs secteurs, se tournent vers l'intelligence artificielle (IA), le machine learning (ML) et le deep learning (DL) pour résoudre des problèmes concrets, proposer des produits et des services innovants et se démarquer sur un marché de plus en plus concurrentiel. Alors que les entreprises ont de plus en plus recours à l'IA, AU ML et au DL, elles sont confrontées à de nombreux défis, notamment l'évolutivité des workloads et la disponibilité des données. Ce document explique comment relever ces défis en utilisant NetApp ai Control plane, une solution qui associe les fonctionnalités de gestion des données NetApp aux outils et frameworks open source les plus répandus.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">Ce rapport vous explique comment cloner rapidement un espace de noms de données. Il vous montre également comment répliquer de manière fluide les données entre plusieurs sites et régions pour créer un pipeline de données d'IA/AM/AP cohérent et unifié. Vous y trouverez également des informations sur la définition et l'implémentation des workflows d'entraînement d'IA, DE ML et de DL pour créer quasi instantanément des données et des modèles de base à des fins de traçabilité et de gestion des versions. Avec cette solution, vous pouvez suivre l'entraînement des modèles jusqu'au dataset exact où on a utilisé pour entraîner et/ou valider le modèle. Enfin, ce document vous montre comment provisionner rapidement des espaces de travail Jupyter Notebook avec accès à des jeux de données volumineux.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">La solution de système de fichiers parallèle entièrement prise en charge par NetApp, BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">Remarque : pour un entraînement distribué de style HPC à grande échelle impliquant un grand nombre de serveurs GPU qui nécessitent un accès partagé au même dataset, ou si vous avez besoin/préférez un système de fichiers parallèle, consultez le document <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. Ce rapport technique décrit comment inclure <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> Dans le cadre du plan de contrôle d'IA NetApp. Cette solution est conçue pour s'adapter de quelques systèmes NVIDIA DGX A100 à un superPOD de 140 nœuds.</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">Le plan de contrôle de l'IA de NetApp est destiné aux data Scientists et aux ingénieurs de données. L'expertise minimale de NetApp ou de NetApp ONTAP® est donc requise. Avec cette solution, les fonctions de gestion des données peuvent être exécutées à l'aide d'outils et d'interfaces simples et familiers. Si votre environnement dispose déjà d'un système de stockage NetApp, vous pouvez tester le plan NetApp ai Control dès aujourd'hui. Si vous souhaitez tester la solution, mais que vous ne disposez pas encore de système de stockage NetApp, rendez-vous sur<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>, Vous pouvez être opérationnel avec une solution de stockage NetApp dans le cloud en quelques minutes. La figure suivante fournit une visualisation de la solution.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">Suivant : concepts et composants.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Azure NetApp Files, RAPIDS et DASK accélèrent et simplifient le déploiement du traitement DE ML et de la formation à grande échelle, intégrés avec les outils d'orchestration tels que Docker et Kubernetes. En unifiant le pipeline de données de bout en bout, cette solution réduit la latence et la complexité inhérentes à de nombreuses charges de travail informatiques avancées, afin de combler efficacement l'écart entre le développement et les opérations.</block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS et DASK accélèrent et simplifient le déploiement du traitement DE ML et de la formation à grande échelle en intégrant les outils d'orchestration tels que Docker et Kubernetes. En unifiant le pipeline de données de bout en bout, cette solution réduit la latence et la complexité inhérentes à de nombreuses charges de travail informatiques avancées, afin de combler efficacement l'écart entre le développement et les opérations. Les data Scientists peuvent exécuter des requêtes sur d'importants jeux de données et partager en toute sécurité les données et les modèles algorithmiques avec d'autres utilisateurs au cours de la phase d'entraînement.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">En créant un modèle d'entraînement distribué complet et un pipeline de données dans le cloud, nous avons mis en avant deux ordres d'amélioration considérable au niveau du temps d'exécution total des workflows, par rapport à une approche open source classique qui n'exploite pas les frameworks de calcul et de traitement des données accélérés par GPU.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">L'association de NetApp, Microsoft, des frameworks d'orchestration open source et NVIDIA rassemble les dernières technologies en tant que services gérés, tout en offrant une grande flexibilité pour accélérer l'adoption de technologies et améliorer le délai de mise sur le marché de nouvelles applications d'IA et DE ML. Ces services avancés sont fournis dans un environnement cloud natif facilement porté pour les architectures de déploiement sur site ainsi que pour les architectures de déploiement hybrides.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">Pour cette validation, nous avons appliqué l'obfuscation Protopia à une image de 1920 x 1080 pixels cinq fois et mesuré le temps nécessaire à l'étape d'obfuscation pour effectuer chaque fois.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">Vitesse d'obfuscation</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">Précédent : comparaison de la précision d'inférence.</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">Pour cette validation, nous avons appliqué l'obfuscation Protopia à une image de 1920 x 1080 pixels cinq fois et mesuré le temps nécessaire à l'étape d'obfuscation pour effectuer chaque fois. Nous avons utilisé PyTorch s'exécutant sur un seul GPU NVIDIA V100 pour appliquer l'obfuscation, et nous avons éliminé le cache GPU entre les exécutions. L'étape d'obfuscation a pris respectivement 5,47 ms, 5,27 ms, 4,54 ms, 5,24 ms et 4,84 ms pour effectuer l'ensemble des cinq passages. La vitesse moyenne était de 5,072 ms.</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NetApp ONTAP ai avec NVIDIA</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">Présentation des solutions d'infrastructure convergée ONTAP ai de NetApp et NVIDIA.</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NetApp ONTAP ai avec les systèmes NVIDIA DGX A100</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="list-text"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="983044e3ba861493c43c08b9285c3125" category="list-text"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NetApp ONTAP ai avec les systèmes NVIDIA DGX A100 et les switchs Ethernet Mellanox Spectrum</block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="list-text"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="list-text"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">Cette page explique comment surveiller DASK à l'aide du tableau de bord natif des flux de tâches.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">Surveiller le DASK à l'aide du tableau de bord des flux de tâches natifs</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">Précédent: Charger jour 15 à DASK et former un modèle de forêt aléatoire de DASk cuML.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Planificateur distribué DASK</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">Le<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> fournit des commentaires en direct sous deux formes :</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">Un tableau de bord interactif contenant de nombreux tracés et tableaux avec des informations en direct</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">Barre de progression adaptée à une utilisation interactive dans les consoles ou les ordinateurs portables</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">Dans notre cas, la figure suivante montre comment surveiller la progression de la tâche, y compris les octets stockés, le flux de tâches avec une répartition détaillée du nombre de flux et la progression par nom de tâche avec les fonctions associées exécutées. Dans notre cas, étant donné que nous avons trois nœuds workers, il y a trois principaux segments de flux et les codes de couleurs indiquent des tâches différentes dans chaque flux.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">Vous avez la possibilité d'analyser des tâches individuelles et d'examiner le temps d'exécution en millisecondes ou d'identifier tout obstacle ou obstacle. Par exemple, la figure suivante montre les flux de tâches pour le stade d'ajustement du modèle forestier aléatoire. Il y a beaucoup plus de fonctions exécutées, y compris le bloc unique pour le traitement de DataFrame, _construct_rf pour l'adaptation de la forêt aléatoire, et ainsi de suite. La plupart du temps a été consacré à des opérations DataFrame en raison de la grande taille (45 Go) des données d'une journée provenant des journaux Criteo Click.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">Suivant : comparaison des temps de formation.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">Présentation de la configuration</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Installation d'Iguazio</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio peut être installé sur site ou sur un fournisseur cloud. Le provisionnement peut être effectué à la demande et géré par Iguazio ou par le client. Iguazio propose, dans les deux cas, une application de déploiement (Provazio) pour déployer et gérer des clusters.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">cette page</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">Pour une installation sur site, reportez-vous à la section<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> pour la configuration des ressources de calcul, de réseau et de stockage. Le déploiement sur site d'Iguazio est assuré par Iguazio sans frais supplémentaires pour le client. Voir<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> Pour les configurations de serveurs DNS et SMTP. La page d'installation de Provazio est illustrée ci-dessous.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">Suivant : configuration du cluster Kubernetes</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">La solution NetApp ai Control plane ne dépend pas de ce matériel spécifique.</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">La solution NetApp ai Control plane ne dépend pas de ce matériel spécifique. La solution est compatible avec toute appliance de stockage physique, instance Software-defined ou service cloud NetApp, prise en charge par Trident. À titre d'exemple, on peut citer un système de stockage NetApp AFF, Azure NetApp Files, NetApp Cloud Volumes Service, une instance de stockage Software-defined NetApp ONTAP Select ou une instance NetApp Cloud Volumes ONTAP. De plus, la solution peut être implémentée sur n'importe quel cluster Kubernetes, tant que la version Kubernetes utilisée est prise en charge par Kubeflow et NetApp Trident. Pour obtenir la liste des versions Kubernetes prises en charge par Kubeflow, voir la<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Pour obtenir la liste des versions de Kubernetes prises en charge par Trident, consultez le<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. Pour plus de détails sur l'environnement utilisé pour valider la solution, reportez-vous aux tableaux suivants.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">Composant d'infrastructure</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">Système d'exploitation</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">Hôte de démarrage du déploiement</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Nœuds maîtres Kubernetes</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Nœuds workers Kubernetes</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Nœuds workers GPU Kubernetes</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1 (bare-Metal)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5 (basé sur Ubuntu 18.04.2 LTS)</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1 paire HA</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">Composant logiciel</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Graphique Helm à flux d'air Apache</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">19.03.12</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">Fonctionnalité de déploiement Trident depuis la succursale maître à compter de la validation <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>; Toutes les autres fonctionnalités de la version 21.03</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">Assistance</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">Contactez NetApp</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp ne propose pas de support pour les flux d'air Apache, Docker, Kubeflow, Kubernetes ou NVIDIA DeepOps. Si vous souhaitez une solution entièrement prise en charge avec des fonctionnalités similaires à la solution NetApp ai Control plane, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> À propos des solutions d'IA/ML entièrement prises en charge que NetApp propose conjointement avec ses partenaires.</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">Suivant : déploiement Kubernetes.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">Déploiement de l'application</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">Les sections suivantes décrivent comment installer et déployer l'application.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">Suivant : procurez-vous le code sur GitHub</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">Cette section décrit les tâches nécessaires pour terminer la validation.</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">Pour exécuter les tâches décrites dans cette section, vous devez avoir accès à un hôte Linux ou MacOS avec les outils suivants installés et configurés :</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (configuré pour l'accès à un cluster Kubernetes existant)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">Des instructions d'installation et de configuration sont disponibles<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>.</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">Des instructions d'installation sont disponibles<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>.</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">Scénario 1 : inférence à la demande dans JupyterLab</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">Créez un namespace Kubernetes pour les workloads d'inférence d'IA/DE ML.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">NetApp DataOps Toolkit permet de provisionner un volume persistant pour le stockage des données sur lesquelles vous souhaitez procéder à l'inférence.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">Utilisez le kit NetApp DataOps pour créer un nouvel espace de travail JupyterLab. Montez le volume persistant créé à l'étape précédente en utilisant le<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> option. Allouez des GPU NVIDIA à l'espace de travail si nécessaire à l'aide de<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> option.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">Dans l'exemple suivant, le volume persistant<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> Est monté sur le conteneur de l'espace de travail JupyterLab à<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>. Lors de l'utilisation d'images de conteneur Jupyter officiel de projet,<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> Est présenté comme le répertoire de niveau supérieur dans l'interface Web de JupyterLab.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">Accédez à l'espace de travail JupyterLab à l'aide de l'URL spécifiée dans la sortie du<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> commande. Le répertoire de données représente le volume persistant monté dans l'espace de travail.</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">Ouvrez le<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> directory et télécharge les fichiers sur lesquels l'inférence doit être effectuée. Lorsque les fichiers sont chargés dans le répertoire de données, ils sont automatiquement stockés sur le volume persistant monté sur l'espace de travail. Pour télécharger des fichiers, cliquez sur l'icône Télécharger des fichiers, comme illustré dans l'image suivante.</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">Retournez au répertoire de premier niveau et créez un nouveau bloc-notes.</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">Ajoutez le code d'inférence à l'ordinateur portable. L'exemple suivant montre le code d'inférence pour un cas d'utilisation de détection d'image.</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">Ajoutez Protopia obfuscation à votre code d'inférence. Protopia travaille directement avec les clients pour fournir une documentation spécifique à l'utilisation et n'est pas dans le cadre du présent rapport technique. L'exemple suivant montre le code d'inférence pour un cas d'utilisation de détection d'image avec Protopia obfuscation ajouté.</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">Scénario 2 – inférence par lots sur Kubernetes</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">Remplissez le nouveau volume persistant avec les données sur lesquelles vous souhaitez procéder à l'inférence.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">Fonctionnalités du kit de données NetApp Data Mover S3</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">Il existe plusieurs méthodes pour charger des données sur un volume persistant. Si vos données sont actuellement stockées dans une plateforme de stockage objet compatible S3, comme NetApp StorageGRID ou Amazon S3, vous pouvez utiliser<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>. Une autre méthode simple consiste à créer un espace de travail JupyterLab, puis à télécharger des fichiers via l'interface Web de JupyterLab, comme indiqué dans les étapes 3 à 5 de la section «<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. »</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">Créez une tâche Kubernetes pour la tâche d'inférence des lots. L'exemple suivant montre une tâche d'inférence par lot pour un cas d'utilisation de détection d'image. Ce travail effectue l'inférence sur chaque image d'un ensemble d'images et écrit les metrics de précision d'inférence sur le mode stdout.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">Vérifiez que la tâche d'inférence a été correctement terminée.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">Ajoutez Protopia obfuscation à votre travail d'inférence. Vous trouverez des instructions spécifiques à chaque cas pour ajouter des objets de Protopia directement à partir de Protopia, qui ne sont pas dans le cadre de ce rapport technique. L'exemple suivant montre un travail d'inférence par lot pour un cas d'utilisation de détection de face avec l'obfuscation Protopia ajouté à l'aide d'une valeur ALPHA de 0.8. Cette tâche applique l'obfuscation de Protopia avant d'effectuer l'inférence pour chaque image d'un ensemble d'images, puis écrit les metrics de précision de l'inférence dans le système.</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">« Comparaison de la précision de l'inférence ».</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">Nous avons répété cette étape pour les valeurs ALPHA 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9 et 0.95. Les résultats sont présentés dans la <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">Scénario 3 – NVIDIA Triton Inférence Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">Utilisez le kit NetApp DataOps Toolkit pour provisionner un volume persistant à utiliser comme référentiel de modèles pour le serveur NVIDIA Triton Inférence.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">format</block>
  <block id="97be18cb741b4fd763ebe22e034705fa" category="list-text">Stockez votre modèle sur le nouveau volume persistant dans un<block ref="bfcdc35d352d3deff6efdd3b8b2ac7ac" category="inline-link-rx"></block> C'est reconnu par le serveur NVIDIA Triton Inférence Server.</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">Il existe plusieurs méthodes pour charger des données sur un volume persistant. Une méthode simple consiste à créer un espace de travail JupyterLab, puis à télécharger des fichiers via l'interface Web de JupyterLab, comme indiqué dans les étapes 3 à 5 de la section «<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. ”</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">Utilisez le kit NetApp DataOps pour déployer une nouvelle instance NVIDIA Triton Inférence Server.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Utilisez un SDK client Triton pour effectuer une tâche d'inférence. L'extrait de code Python suivant utilise le SDK client Triton Python pour effectuer une tâche d'inférence pour un cas d'utilisation de détection de visage. Cet exemple appelle l'API Triton et transmet une image pour l'inférence. Le serveur Triton Inférence reçoit ensuite la requête, appelle le modèle et renvoie la sortie d'inférence dans le cadre des résultats de l'API.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">Ajoutez Protopia obfuscation à votre code d'inférence. Vous trouverez des instructions propres à chaque cas pour ajouter des obfuscations Protopia directement à partir de Protopia ; cependant, ce processus n'est pas dans le cadre de ce rapport technique. L'exemple suivant montre le même code Python que celui indiqué à l'étape 5 précédente, mais avec l'obfuscation Protopia ajouté.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Notez que l'obfuscation Protopia est appliquée à l'image avant de la transmettre à l'API Triton. Ainsi, l'image non obfusquée ne quitte jamais la machine locale. Seule l'image masquée est transmise sur le réseau. Ce flux de production s'applique aux cas où les données sont collectées dans une zone de confiance, mais doivent ensuite être transférées en dehors de cette zone de confiance pour l'inférence. Sans l'obfuscation Protopia, il n'est pas possible d'implémenter ce type de flux de travail sans que des données sensibles quittent la zone de confiance.</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">Ensuite, comparaison de la précision d'inférence.</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">Cette page contient des vidéos et des didacticiels.</block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">Vidéos et démonstrations sur le cloud hybride, la virtualisation et les conteneurs</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">Visionnez les vidéos et démonstrations suivantes portant sur des fonctionnalités spécifiques des solutions de cloud hybride, de virtualisation et de conteneurs.</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">Outils NetApp ONTAP pour VMware vSphere</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">Outils ONTAP pour VMware - Présentation</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">Provisionnement des datastores iSCSI VMware avec ONTAP</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">Provisionnement des datastores VMware NFS avec ONTAP</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">VMware Cloud sur AWS avec AWS FSX pour NetApp ONTAP</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">Stockage connecté à un invité Windows avec ONTAP FSX utilisant iSCSI</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">Stockage connecté par un invité Linux avec FSX ONTAP à l'aide de NFS</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="example-title">Économies en termes de coût total de possession de VMware Cloud sur AWS avec Amazon FSX pour NetApp ONTAP</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="example-title">VMware Cloud sur AWS datastore supplémentaire avec Amazon FSX pour NetApp ONTAP</block>
  <block id="1709b8b454125c7d55fd44e302c8aee3" category="example-title">VMware Cloud sur AWS migration avec FSxN, VMware HCX</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">Azure VMware Services sur Azure avec Azure NetApp Files (ANF)</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="example-title">Solution Azure VMware datastore supplémentaire avec Azure NetApp Files</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="example-title">Solution de reprise après incident Azure VMware avec Cloud Volumes ONTAP, SnapCenter et JetStream</block>
  <block id="875970986c8d6a0d19f47ed744bf33e1" category="example-title">Migration de la solution Azure VMware avec ANF, VMware HCX</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="example-title">Plug-in SnapCenter pour VMware vSphere</block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">Le logiciel SnapCenter est une plateforme qui permet de coordonner et de gérer facilement et en toute sécurité la protection de vos données sur l'ensemble des applications, bases de données et systèmes de fichiers.</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">Le plug-in SnapCenter pour VMware vSphere vous permet d'effectuer des sauvegardes, des restaurations et des liaisons pour les machines virtuelles, ainsi que des opérations de sauvegarde et de montage pour les datastores enregistrés auprès de SnapCenter directement dans VMware vCenter.</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link-macro">Présentation du plug-in NetApp SnapCenter pour VMware vSphere</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">Pour plus d'informations sur le plug-in NetApp SnapCenter pour VMware vSphere, consultez le <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>.</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">Plug-in SnapCenter pour VMware vSphere : conditions requises pour la solution</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">Plug-in SnapCenter pour VMware vSphere : déploiement</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">Plug-in SnapCenter pour VMware vSphere - Workflow de sauvegarde</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">Plug-in SnapCenter pour VMware vSphere : restaurez les flux de travail</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - flux de travail de restauration SQL</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="example-title">NetApp avec VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu permet aux clients de déployer, d'administrer et de gérer leur environnement Kubernetes via vSphere ou VMware Cloud Foundation. Cette gamme de produits VMware permet aux clients de gérer tous leurs clusters Kubernetes pertinents à partir d'un seul plan de contrôle en choisissant l'édition VMware Tanzu qui répond le mieux à leurs besoins.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">Présentation de VMware Tanzu</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">Pour plus d'informations sur VMware Tanzu, reportez-vous au<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. Cette revue couvre les cas d'utilisation, les ajouts disponibles et plus d'informations sur VMware Tanzu.</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link">Comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 1</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link">Comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 2</block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link">Comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 3</block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="example-title">NetApp avec Red Hat OpenShift</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">Red Hat OpenShift, une plateforme Kubernetes d'entreprise, vous permet d'exécuter des applications basées sur des conteneurs avec une stratégie de cloud hybride ouverte. Disponible en tant que service cloud sur des clouds publics de premier plan ou en tant que logiciel autogéré, Red Hat OpenShift offre aux clients la flexibilité dont ils ont besoin pour concevoir leur solution basée sur des conteneurs.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Présentation de Red Hat OpenShift</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Pour plus d'informations sur Red Hat OpenShift, consultez ce document<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. Pour en savoir plus sur Red Hat OpenShift, consultez également la documentation produit et les options de déploiement.</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">Migration des charges de travail - Red Hat OpenShift avec NetApp</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="inline-link">Red Hat OpenShift Deployment sur RHV : Red Hat OpenShift avec NetApp</block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">Cette page décrit les étapes du déploiement d'un stockage NVMe/FC NetApp ONTAP pour les datastores VMFS dans un environnement VMware vSphere.</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">Datastore VMFS vSphere - NVMe/FC avec ONTAP</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">Description de la tâche</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">Cette section décrit la création d'un datastore VMFS avec un stockage ONTAP utilisant NVMe/FC.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">Pour le provisionnement automatisé, utilisez l'un des scripts suivants : <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, ou <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">Ce dont vous avez besoin</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">Compétences de base requises pour gérer un environnement vSphere et ONTAP.</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">Présentation de base du protocole NVMe/FC</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">Un système de stockage ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) exécutant {ontap_version}</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">Identifiants ONTAP (nom du SVM, ID d'utilisateur et mot de passe)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">WWPN ONTAP pour l'hôte, la cible et les SVM et informations relatives aux LUN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">Une fiche de configuration FC remplie</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">Serveur vCenter</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">Informations sur les hôtes vSphere ({vsphere_version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">Commutateur(s) de structure</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">Avec des ports de données FC ONTAP et des hôtes vSphere connectés.</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">Avec la fonctionnalité NPIV (N_port ID Virtualization) activée.</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">Créer une seule zone cible d'initiateur.</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">Créer une zone pour chaque initiateur (zone initiateur unique).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">Pour chaque zone, inclure une cible faisant l'interface logique (WWPN) FC ONTAP pour les SVM. Il devrait y avoir au minimum deux interfaces logiques par nœud et par SVM. N'utilisez pas le WWPN des ports physiques.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">Provisionner le datastore VMFS</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Matrice d'interopérabilité (IMT)</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">Vérifiez la compatibilité avec le<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">Vérifiez que la configuration NVMe/FC est prise en charge.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">Tâches ONTAP</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">Vérifiez la licence ONTAP pour FCP.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>Utilisez le<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande et vérifiez si NVMe_of est répertorié. Utiliser<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> pour ajouter une licence.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">Vérifier que le protocole NVMe est activé sur le SVM</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">Configuration des SVM pour NVMe</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">Vérifier que les interfaces logiques NVMe/FC sont disponibles sur les SVM.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">Utiliser<block ref="e38d07be71f760e81ec7c17103cd57db" prefix=" " category="inline-code"></block> Pour vérifier l'adaptateur FCP.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">Lorsqu'un SVM est créé avec l'interface utilisateur graphique, les interfaces logiques font partie de ce processus.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">Pour renommer l'interface réseau, utilisez la commande<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">Créez un espace de noms et un sous-système NVMe</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">Tâches VMware vSphere</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">Informations sur l'adaptateur de stockage</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">Vérifiez que les pilotes HBA sont installés. Les pilotes déployés sont prêts à l'emploi pour les HBA pris en charge par VMware. Ils doivent être visibles à l'adresse <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">Effectuez les tâches d'installation et de validation du pilote NVMe hôte vSphere</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">Créer un datastore VMFS</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp fournit de nombreuses bonnes pratiques et solutions pour un environnement de virtualisation robuste, à la fois sur site et dans le cloud.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">Solutions NetApp pour la virtualisation</block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">Cette page décrit les étapes du déploiement d'un datastore VMFS FC NetApp ONTAP dans un environnement VMware vSphere.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">Datastore VMFS vSphere - stockage Fibre Channel back-end avec ONTAP</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">Cette section décrit la création d'un datastore VMFS avec un stockage ONTAP Fibre Channel (FC).</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">Les compétences de base nécessaires à la gestion d'un environnement vSphere et d'ONTAP</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">Un système de stockage ONTAP (FAS/AFF/CVO/ONTAP Select/ASA) exécutant {ontap_version}</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">WWPN ONTAP des informations relatives à l'hôte, à la cible et aux SVM et aux LUN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">La fiche de configuration FC remplie</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">Informations d'identification du serveur vCenter</block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">Informations sur les hôtes vSphere</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vsphere_version}</block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">Avec ports de données FC ONTAP connectés et hôtes vSphere</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">Avec la fonctionnalité NPIV (N_port ID Virtualization) activée</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">Créer une seule zone cible d'initiateur.</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">Pour chaque zone, inclure une cible faisant l'interface logique (WWPN) FC ONTAP pour les SVM. Il devrait y avoir au minimum deux interfaces logiques par nœud et par SVM. N'utilisez pas le WWPN des ports physiques.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">Un outil ONTAP pour VMware vSphere est déployé, configuré et prêt à l'emploi.</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">Provisionnement d'un datastore VMFS</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">Pour provisionner un datastore VMFS, procédez comme suit :</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">Vérifier la compatibilité avec le<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">La configuration FCP est prise en charge</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">Vérifiez que le <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">Vérifiez que vous disposez d'une licence ONTAP pour FCP.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">Utilisez le<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande permettant de vérifier que FCP est répertorié.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">Utiliser<block ref="79868b45624cf0644299a1019c0f9dc9" prefix=" " category="inline-code"></block> pour ajouter la licence.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">S'assurer que le protocole FCP est activé sur le SVM</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">Vérifier le FCP sur un SVM existant.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">Configurer FCP sur un SVM existant.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">Créer s nouveau SVM avec le FCP</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">Vérifier que les interfaces logiques FCP sont disponibles sur un SVM.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">Lorsqu'un SVM est créé avec l'interface utilisateur graphique, les interfaces logiques font partie de ce processus.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">Pour renommer les interfaces réseau, utilisez<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">Créer et mapper une LUN.</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> Ignorez cette étape si vous utilisez les outils ONTAP pour VMware vSphere.</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">Tâches VMware vSphere</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">Vérifiez que les pilotes HBA sont installés. Les adaptateurs HBA pris en charge par VMware disposent de pilotes déployés clé en main et doivent être visibles dans <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">Provisionnement d'un datastore VMFS avec les outils ONTAP</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">Cette page décrit les meilleures pratiques relatives à l'implémentation d'une solution de stockage NetApp ONTAP dans un environnement VMware vSphere.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="doc">Et des meilleures pratiques</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">Fonctionnalités du datastore et du protocole vSphere</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="list-text">NFS</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">Valeurs maximales de configuration VMware</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Capacités/fonctionnalités</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Format</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">Mappage de périphériques VMFS ou bruts (RDM)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS ou RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Nombre maximal de datastores ou de LUN</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 monte le NFS par défaut. MaxVolumes est 8. Utilisez les outils ONTAP pour VMware vSphere et augmentez jusqu'à 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Taille maximale des datastores</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TO</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">Volume FlexVol de 100 To ou supérieur avec FlexGroup volume</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TO</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profondeur de file d'attente optimale par LUN ou par système de fichiers</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">Le tableau suivant répertorie les fonctionnalités de stockage VMware prises en charge.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacité/fonctionnalité</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">Stockage vMotion</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">Haute disponibilité VMware</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Storage Distributed Resource Scheduler (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Logiciel de sauvegarde VMware vStorage APIs for Data protection (VADP)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) ou mise en cluster de basculement au sein d'une machine virtuelle</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Oui*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">Non pris en charge</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolérance aux pannes</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Gestionnaire de reprise de site</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Machines virtuelles à provisionnement fin (disques virtuels)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Oui ce paramètre est défini par défaut pour toutes les machines virtuelles sur NFS lorsqu'elles n'utilisent pas VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Chemins d'accès multiples natifs VMware</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configuration de Windows Server Failover Clustering</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">Le tableau suivant répertorie les fonctionnalités de gestion du stockage ONTAP prises en charge.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Déduplication des données</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">D'économies sur la baie</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">Économies au niveau du datastore</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Provisionnement fin</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Datastore ou RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Datastore</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Redimensionnement datastore</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Évoluer uniquement</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Croissance, croissance automatique et réduction des volumes</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Plug-ins SnapCenter pour applications Windows, Linux (invités)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Contrôle et configuration de l'hôte à l'aide des outils ONTAP pour VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Provisionnement avec les outils ONTAP pour VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">Le tableau suivant répertorie les fonctionnalités de sauvegarde prises en charge.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">Copies Snapshot ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM pris en charge par les sauvegardes répliquées</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">SnapMirror volume</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Accès image VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Logiciel de sauvegarde VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Logiciel de sauvegarde VADP, vSphere client et le navigateur du datastore du client Web vSphere</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Accès niveau fichier VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Logiciel de sauvegarde VADP, Windows uniquement</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Logiciels de sauvegarde VADP et applications tierces</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularité NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Datastore ou VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Sélection d'un protocole de stockage</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Les systèmes exécutant le logiciel ONTAP prennent en charge les principaux protocoles de stockage. Les clients peuvent ainsi choisir ce qui convient le mieux à leur environnement, en fonction de l'infrastructure réseau planifiée et du personnel. Les tests effectués par NetApp n'ont généralement pas permis de faire la différence entre les protocoles s'exécutant à des vitesses de ligne similaires. Il est donc préférable de se concentrer sur votre infrastructure réseau et sur les capacités des équipes par rapport aux performances des protocoles bruts.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Les facteurs suivants peuvent être utiles lors de l'examen d'un choix de protocole :</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">*Environnement client actuel.* même si les équipes INFORMATIQUES sont généralement compétentes en matière de gestion de l'infrastructure IP Ethernet, elles ne sont pas toutes qualifiées pour la gestion d'une structure SAN FC. Cependant, l'utilisation d'un réseau IP générique non conçu pour le trafic de stockage peut ne pas fonctionner correctement. Considérez l'infrastructure de réseau que vous avez en place, toutes les améliorations planifiées, ainsi que les compétences et la disponibilité du personnel pour les gérer.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Simplicité d'installation.* au-delà de la configuration initiale de la structure FC (commutateurs et câblage supplémentaires, segmentation et vérification de l'interopérabilité des HBA et des micrologiciels), les protocoles de bloc exigent également la création et le mappage de LUN, ainsi que la découverte et le formatage par le système d'exploitation invité. Une fois les volumes NFS créés et exportés, ils sont montés par l'hôte ESXi et prêts à être utilisés. Avec NFS, il n'a pas de qualification de matériel ni de firmware à gérer.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* Facilité de gestion.* avec les protocoles SAN, si plus d'espace est nécessaire, plusieurs étapes sont nécessaires, y compris l'expansion d'un LUN, de recanning pour découvrir la nouvelle taille, puis de développer le système de fichiers). Bien que la croissance d'une LUN soit possible, la réduction de la taille d'une LUN n'est pas possible et la restauration de l'espace inutilisé peut nécessiter un effort supplémentaire. NFS facilite le dimensionnement et le redimensionnement peut être automatisé par le système de stockage. LE SYSTÈME SAN permet de réclamer de l'espace via les commandes TRIM/UNMAP du système d'exploitation invité. L'espace des fichiers supprimés est ainsi renvoyé à la baie. Ce type de récupération d'espace est plus difficile avec les datastores NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Transparence de l'espace de stockage.* l'utilisation du stockage est généralement plus facile à voir dans les environnements NFS parce que le provisionnement fin renvoie immédiatement des économies. De même, les économies de déduplication et de clonage sont immédiatement disponibles pour les autres VM dans le même datastore ou pour les autres volumes du système de stockage. La densité des machines virtuelles est également meilleure généralement dans un datastore NFS, ce qui permet d'améliorer les économies de déduplication et de réduire les coûts de gestion en utilisant moins de datastores à gérer.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Disposition des datastores</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link-macro">Hôte ESXi recommandé et autres paramètres ONTAP recommandés</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">Les systèmes de stockage ONTAP offrent une grande flexibilité de création de datastores pour les machines virtuelles et les disques virtuels. Bien que la plupart des meilleures pratiques relatives à ONTAP soient appliquées lors du provisionnement de datastores pour vSphere (voir la section dans cette section) <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>), voici quelques lignes directrices supplémentaires à prendre en compte :</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">La taille correcte des datastores de volumes FlexVol est d'environ 4 To à 8 To. Cette taille constitue un bon équilibre pour les performances, la facilité de gestion et la protection des données. Démarrer petit (4 To, par exemple) et étendre le datastore en fonction des besoins (jusqu'à 100 To maximum). Les datastores plus petits peuvent être plus rapides à restaurer depuis la sauvegarde ou après un incident, et déplacés rapidement dans l'ensemble du cluster. Envisagez d'utiliser la fonction de dimensionnement automatique de ONTAP pour augmenter et réduire automatiquement le volume en fonction des modifications de l'espace utilisé. Les outils ONTAP de l'assistant de provisionnement des datastores VMware vSphere utilisent la taille automatique par défaut pour les nouveaux datastores. Vous pouvez également personnaliser davantage les seuils d'extension et de réduction ainsi que la taille maximale et minimale, avec System Manager ou la ligne de commandes.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Les anciens systèmes d'exploitation invités (OS) devaient s'aligner sur le système de stockage pour obtenir des performances et une efficacité du stockage optimales. Cependant, les systèmes d'exploitation actuels pris en charge par les fournisseurs de Microsoft et de distributeurs Linux tels que Red Hat ne nécessitent plus d'ajustements pour aligner la partition du système de fichiers sur les blocs du système de stockage sous-jacent dans un environnement virtuel. Si vous utilisez un ancien système d'exploitation pouvant nécessiter un alignement, recherchez dans la base de connaissances de support NetApp des articles utilisant « alignement de machines virtuelles » ou demandez une copie du rapport TR-3747 à un contact partenaire ou commercial NetApp.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">Évitez les utilitaires de défragmentation de l'OS invité, car cela n'améliore pas les performances et affecte l'efficacité du stockage et l'utilisation de l'espace de copie Snapshot. Envisagez également de désactiver l'indexation des recherches sur le système d'exploitation invité pour les postes de travail virtuels.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP s'est leader du marché en proposant des fonctionnalités innovantes d'efficacité du stockage qui vous permettent d'exploiter au maximum votre espace disque utilisable. Les systèmes AFF renforcent cette efficacité avec la compression et la déduplication à la volée par défaut. Les données sont dédupliquées sur tous les volumes d'un agrégat. Ainsi, vous n'avez plus besoin de regrouper des systèmes d'exploitation similaires et des applications similaires au sein d'un même datastore pour optimiser les économies.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">Tr-3633 : bases de données Oracle sur Data ONTAP</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">Dans certains cas, vous n'aurez même pas besoin d'un datastore. Pour obtenir des performances et une gestion optimales, évitez d'utiliser un datastore pour des applications d'E/S élevées telles que les bases de données et certaines applications. Prenez plutôt en compte les systèmes de fichiers invités, tels que les systèmes de fichiers NFS ou iSCSI, gérés par l'invité ou par RDM. Pour une assistance spécifique aux applications, consultez les rapports techniques de NetApp pour votre application. Par exemple :<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> dispose d'une section sur la virtualisation avec des détails utiles.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Les disques de première classe (ou des disques virtuels améliorés) permettent de gérer des disques gérés par vCenter indépendamment d'une machine virtuelle dotée de vSphere 6.5 et versions ultérieures. Lorsqu'elles sont principalement gérées par API, elles peuvent être utiles avec vvols, en particulier lorsqu'elles sont gérées par les outils OpenStack ou Kubernetes. Ils sont pris en charge par ONTAP ainsi que par les outils ONTAP pour VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migration des datastores et des machines virtuelles</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Lorsque vous migrez des machines virtuelles depuis un datastore existant sur un autre système de stockage vers ONTAP, voici quelques principes à prendre en compte :</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Utilisez Storage vMotion pour déplacer la masse de vos machines virtuelles vers ONTAP. Cette approche n'assure pas seulement une exécution sans interruption des machines virtuelles. Elle permet également d'exploiter des fonctionnalités d'efficacité du stockage de ONTAP, comme la déduplication et la compression à la volée, pour traiter les données lors de leur migration. Envisagez d'utiliser les fonctionnalités de vCenter pour sélectionner plusieurs machines virtuelles dans la liste d'inventaire, puis planifiez la migration (utilisez la touche Ctrl tout en cliquant sur actions) à un moment opportun.</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">Bien que vous puissiez planifier avec soin une migration vers des datastores de destination appropriés, il est souvent plus simple de les migrer en bloc, puis de les organiser ultérieurement, si nécessaire. Si vos besoins en matière de protection des données sont spécifiques, par exemple en matière de planifications Snapshot, vous pouvez utiliser cette approche pour orienter votre migration vers d'autres datastores.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La plupart des machines virtuelles et leur stockage peuvent être migrées lors de l'exécution (à chaud), mais pour migrer le stockage attaché (hors datastore) tel qu'un ISO (ISO), une LUN ou des volumes NFS à partir d'un autre système de stockage, il peut exiger une migration à froid.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">Les machines virtuelles qui nécessitent une migration plus minutieuse incluent les bases de données et les applications qui utilisent le stockage associé. En général, considérez l’utilisation des outils de l’application pour gérer la migration. Pour Oracle, envisagez d'utiliser des outils Oracle tels que RMAN ou ASM pour migrer les fichiers de base de données. Voir<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> pour en savoir plus. De même, pour SQL Server, envisagez d'utiliser soit SQL Server Management Studio, soit des outils NetApp tels qu'SnapManager pour SQL Server, soit SnapCenter.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">Les outils ONTAP pour VMware vSphere</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">Lors de l'utilisation de vSphere avec des systèmes exécutant le logiciel ONTAP, la meilleure pratique la plus importante consiste à installer et à utiliser les outils ONTAP pour le plug-in VMware vSphere (anciennement Virtual Storage Console). Ce plug-in vCenter simplifie la gestion du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que ce soit via SAN ou NAS. Il tire parti des bonnes pratiques pour le provisionnement des datastores et optimise les paramètres des hôtes ESXi pour les délais entre les chemins d'accès multiples et les HBA (ces paramètres sont décrits dans l'annexe B). Comme il s'agit d'un plug-in vCenter, il est disponible pour tous les clients Web vSphere qui se connectent au serveur vCenter.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">Le plug-in permet également d'utiliser d'autres outils ONTAP dans les environnements vSphere. Elle vous permet d'installer le plug-in NFS pour VMware VAAI, qui permet l'allègement de la charge de copies vers ONTAP pour les opérations de clonage de VM, la réservation d'espace pour les fichiers disques virtuels non volumineux et la redirection des copies Snapshot ONTAP.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">Le plug-in est également l'interface de gestion de nombreuses fonctions de VASA Provider pour ONTAP, prenant en charge la gestion basée sur des règles de stockage avec vvols. Une fois les outils ONTAP pour VMware vSphere enregistrés, utilisez-le pour créer des profils de capacité de stockage, les mapper au stockage, et assurez-vous que le datastore est conforme aux profils au fil du temps. Vasa Provider fournit également une interface pour créer et gérer les datastores vvol.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">En règle générale, NetApp recommande d'utiliser les outils ONTAP pour l'interface VMware vSphere dans vCenter afin de provisionner les datastores classiques et vvols pour garantir le respect de bonnes pratiques.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Réseau général</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configuration des paramètres réseau lors de l'utilisation de vSphere avec des systèmes exécutant le logiciel ONTAP est simple et similaire à celle d'autres configurations réseau. Voici quelques points à prendre en compte :</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">Trafic du réseau de stockage séparé des autres réseaux Un réseau distinct peut être obtenu à l'aide d'un VLAN dédié ou de commutateurs distincts pour le stockage. Si le réseau de stockage partage des chemins physiques, tels que des liaisons ascendantes, vous pouvez avoir besoin de la qualité de service ou de ports supplémentaires pour garantir une bande passante suffisante. Ne connectez pas les hôtes directement au stockage ; utilisez les commutateurs pour disposer de chemins redondants et laissez VMware HA fonctionner sans intervention.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Les trames Jumbo peuvent être utilisées si vous le souhaitez et prises en charge par votre réseau, en particulier lors de l'utilisation d'iSCSI. Si elles sont utilisées, assurez-vous qu'elles sont configurées de manière identique sur tous les périphériques réseau, VLAN, etc. Dans le chemin entre le stockage et l'hôte ESXi. Vous pourriez voir des problèmes de performances ou de connexion. La MTU doit également être définie de manière identique sur le switch virtuel ESXi, le port VMkernel et également sur les ports physiques ou les groupes d'interface de chaque nœud ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp recommande uniquement la désactivation du contrôle de flux réseau sur les ports réseau du cluster dans un cluster ONTAP. NetApp ne recommande pas d'autres recommandations sur les meilleures pratiques pour les ports réseau restants utilisés pour le trafic de données. Vous devez activer ou désactiver si nécessaire. Voir<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> pour plus d'informations sur le contrôle de flux.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Lorsque les baies de stockage ESXi et ONTAP sont connectées aux réseaux de stockage Ethernet, NetApp recommande de configurer les ports Ethernet auxquels ces systèmes se connectent en tant que ports de périphérie RSTP (Rapid Spanning Tree Protocol) ou en utilisant la fonctionnalité Cisco PortFast. NetApp recommande d'activer la fonction de jonction Spanning-Tree PortFast dans les environnements qui utilisent la fonction Cisco PortFast et dont le agrégation VLAN 802.1Q est activée soit au serveur ESXi, soit aux baies de stockage ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp recommande les meilleures pratiques suivantes pour l'agrégation de liens :</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">Le tableau suivant fournit un récapitulatif des éléments de configuration réseau et indique l'emplacement d'application des paramètres.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Élément</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">VMware ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Commutateur</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nœud</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Adresse IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">Non**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Agrégation de liens</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Commutateur virtuel</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">Non*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">Groupes de ports VMKernel et VM</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Contrôle de flux</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Spanning Tree</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (pour les trames jumbo)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Commutateur virtuel et port VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Oui (défini sur max)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Oui (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Groupes de basculement</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Oui (créer)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Oui (sélectionner)</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Ces périphériques ont leur propre adresse IP pour la gestion, mais ces adresses ne sont pas utilisées dans le contexte du réseau de stockage VMware ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">Dans vSphere, il existe trois façons d'utiliser les LUN de stockage bloc :</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Avec les datastores VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Avec mappage de périphériques bruts (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">En tant que LUN accessible et contrôlée par un initiateur logiciel à partir d'un système d'exploitation invité de machine virtuelle</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS est un système de fichiers en cluster hautes performances qui fournit des datastores sous forme de pools de stockage partagés. Les datastores VMFS peuvent être configurés avec des LUN accessibles via des espaces de noms FC, iSCSI, FCoE ou NVMe accessibles via le protocole NVMe/FC. VMFS permet d'accéder simultanément aux LUN classiques par chaque serveur ESX d'un cluster. La taille de LUN maximale du ONTAP est généralement de 16 To. Par conséquent, un datastore VMFS 5 de 64 To (voir le premier tableau de cette section) est créé avec quatre LUN de 16 To (tous les systèmes SAN prennent en charge la taille de LUN VMFS de 64 To maximum). Dans la mesure où l'architecture LUN ONTAP ne dispose pas de petites profondeurs de files d'attente individuelles, les datastores VMFS en ONTAP peuvent évoluer plus largement qu'avec les architectures de baies traditionnelles de manière relativement simple.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere inclut la prise en charge intégrée de plusieurs chemins d'accès aux périphériques de stockage, appelés chemins d'accès multiples natifs (NMP). NMP peut détecter le type de stockage pour les systèmes de stockage pris en charge et configure automatiquement la pile NMP afin de prendre en charge les capacités du système de stockage utilisé.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">Les protocoles NMP et ONTAP prennent en charge le protocole ALUA (Asymmetric Logical Unit Access) pour négocier des chemins optimisés et non optimisés. Dans ONTAP, un chemin optimisé pour le protocole ALUA suit un chemin d'accès direct aux données, utilisant un port cible sur le nœud qui héberge la LUN accédée. ALUA est activé par défaut dans vSphere et ONTAP. Le NMP reconnaît le cluster ONTAP en tant que ALUA, et il utilise le plug-in ALUA de type baie de stockage <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) et sélectionne le plug-in de sélection de chemin de tourniquet <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 prend en charge jusqu'à 256 LUN et jusqu'à 1,024 chemins d'accès aux LUN au total. Les LUN et les chemins au-delà de ces limites ne sont pas visibles par ESXi. En supposant un nombre maximum de LUN, la limite de chemin autorise quatre chemins par LUN. Dans un cluster ONTAP plus grand, il est possible d'atteindre la limite de chemin avant la limite de LUN. Pour résoudre cette limitation, ONTAP prend en charge le mappage de LUN sélectif (SLM) dans la version 8.3 et les versions ultérieures.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM est activé par défaut. Sauf si vous utilisez des ensembles de ports, aucune configuration supplémentaire n'est requise.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Pour les LUN créées avant Data ONTAP 8.3, appliquez manuellement SLM en exécutant le<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Commande permettant de supprimer les nœuds présentant les rapports LUN et de limiter l'accès des LUN au nœud propriétaire de la LUN et à son partenaire haute disponibilité.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Des protocoles de bloc (iSCSI, FC et FCoE) accèdent aux LUN à l'aide d'identifiants de LUN, de numéros de série et de noms uniques. Les protocoles FC et FCoE utilisent des noms mondiaux (WWN et WWPN) et iSCSI utilise les noms qualifiés iSCSI (IQN). Le chemin vers les LUN à l'intérieur du stockage n'a aucun sens avec les protocoles de bloc et n'est pas présenté au niveau du protocole. Par conséquent, un volume contenant uniquement des LUN n'a pas besoin d'être monté en interne et un chemin de jonction n'est pas nécessaire pour les volumes contenant les LUN utilisées dans les datastores. Le sous-système NVMe dans ONTAP fonctionne de la même manière.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">D'autres meilleures pratiques à prendre en compte :</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Vérifier qu'une interface logique (LIF) est créée pour chaque SVM sur chaque nœud du cluster ONTAP pour optimiser la disponibilité et la mobilité. La meilleure pratique du SAN de ONTAP est d'utiliser deux ports physiques et LIF par nœud, un pour chaque structure. ALUA sert à analyser les chemins et à identifier les chemins (directs) optimisés actifs/actifs au lieu de chemins non optimisés actifs. ALUA est utilisé pour FC, FCoE et iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">Pour les réseaux iSCSI, utilisez plusieurs interfaces réseau VMkernel sur différents sous-réseaux du réseau avec le regroupement de cartes réseau lorsque plusieurs commutateurs virtuels sont présents. Vous pouvez également utiliser plusieurs cartes réseau physiques connectées à plusieurs commutateurs physiques pour fournir la haute disponibilité et un débit accru. La figure suivante fournit un exemple de connectivité multivoie. Dans ONTAP, configurez soit un groupe d'interface en mode unique pour basculement avec deux liaisons ou plus connectées à deux ou plusieurs switchs, soit au moyen de LACP ou d'une autre technologie d'agrégation de liens avec des groupes d'interfaces multimode afin d'assurer la haute disponibilité et les avantages de l'agrégation de liens.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Si le protocole CHAP (Challenge-Handshake Authentication Protocol) est utilisé dans ESXi pour l'authentification de la cible, il doit également être configuré dans ONTAP à l'aide de l'interface de ligne de commande <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) Ou avec System Manager (modifier la sécurité de l'initiateur sous Storage &gt; SVM &gt; SVM Settings &gt; protocoles &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour créer et gérer des LUN et des igroups. Le plug-in détermine automatiquement les WWPN des serveurs et crée les igroups appropriés. Il configure également les LUN en fonction des meilleures pratiques et les mappe avec les groupes initiateurs appropriés.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">mode de compatibilité physique et virtuelle</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Utilisez des RDM avec soin, car ils peuvent être plus difficiles à gérer, et ils utilisent également des chemins d'accès limités comme décrit précédemment. Les LUN ONTAP prennent en charge les deux<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guide de configuration d'hôte NVMe/FC de ONTAP</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Pour en savoir plus sur l'utilisation de NVMe/FC avec vSphere 7.0, consultez cette<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> et<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>La figure suivante décrit la connectivité multivoie d'un hôte vSphere vers un LUN ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere permet aux clients d'utiliser des baies NFS de classe entreprise pour fournir un accès simultané aux datastores à tous les nœuds d'un cluster ESXi. Comme mentionné dans la section datastore, la facilité d'utilisation et la visibilité sur l'efficacité du stockage présentent des avantages avec NFS avec vSphere.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Nous vous recommandons les meilleures pratiques suivantes lorsque vous utilisez ONTAP NFS avec vSphere :</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">Utiliser une interface logique (LIF) unique pour chaque SVM sur chaque nœud du cluster ONTAP. Les recommandations précédentes d'une LIF par datastore ne sont plus nécessaires. Bien que l'accès direct (LIF et datastores sur le même nœud) soit le meilleur, ne vous inquiétez pas pour l'accès indirect, car l'effet sur les performances est généralement minimal (en microsecondes).</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Étant donné qu'il n'existe pas de conversion automatique de datastore entre NFS v3 et NFS v4.1, créez un nouveau datastore NFSv4.1 et utilisez Storage vMotion pour migrer les machines virtuelles vers le nouveau datastore.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">Reportez-vous aux notes du tableau interopérabilité NFS v4.1 dans le<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> Pour les niveaux de correctifs VMware ESXi spécifiques requis pour la prise en charge.</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">Protocole d'accès : nfs3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Spéc. Correspondance client : 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Règle d'accès RO : sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">Règle d'accès RW : sys</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superutilisateur : sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">Si vous utilisez le plug-in NetApp NFS pour VMware VAAI, le protocole doit être défini en tant que<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> lorsque la règle export-policy est créée ou modifiée. Le protocole NFSv4 est requis pour que le déchargement des copies VAAI fonctionne et que vous spécifiez le protocole comme<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Inclut automatiquement les versions NFSv3 et NFSv4.</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Utilisez les outils ONTAP pour VMware vSphere (meilleure pratique la plus importante) :</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilisez les outils ONTAP pour VMware vSphere pour provisionner les datastores, car cela simplifie automatiquement la gestion des règles d'exportation.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilisez la fonction de montage du plug-in pour appliquer les datastores existants aux nouveaux serveurs.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Lorsque vous n'utilisez pas les outils ONTAP pour VMware vSphere, utilisez une export policy unique pour tous les serveurs ou pour chaque cluster de serveurs où un contrôle d'accès supplémentaire est nécessaire.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Bien que ONTAP offre une structure d'espace de noms de volume flexible permettant d'organiser les volumes dans une arborescence à l'aide de jonctions, cette approche n'a aucune valeur pour vSphere. Il crée un répertoire pour chaque machine virtuelle à la racine du datastore, quelle que soit la hiérarchie de l'espace de noms du stockage. Il est donc recommandé de simplement monter le Junction path pour les volumes pour vSphere au volume root du SVM, c'est-à-dire comment les outils ONTAP pour VMware vSphere provisionne les datastores. Sans chemins de jonction imbriqués, aucun volume ne dépend d'aucun volume autre que le volume root et que mettre un volume hors ligne ou le détruire, même intentionnellement, n'affecte pas le chemin d'accès aux autres volumes.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">Une taille de bloc de 4 Ko convient parfaitement aux partitions NTFS sur les datastores NFS. La figure suivante décrit la connectivité d'un hôte vSphere vers un datastore NFS ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">Le tableau suivant répertorie les versions NFS et les fonctionnalités prises en charge.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Fonctionnalités de vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion et Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Haute disponibilité</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolérance aux pannes</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Profils hôtes</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS de stockage</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Contrôle des E/S du stockage</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volumes virtuels</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Accélération matérielle (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Authentification Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Oui (optimisé avec vSphere 6.5 et versions ultérieures pour prendre en charge AES et krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Prise en charge des chemins d'accès</block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8 ajoute la prise en charge des datastores FlexGroup dans vSphere, ainsi que les outils ONTAP pour VMware vSphere version 9.8. FlexGroup simplifie la création de datastores volumineux et crée automatiquement un certain nombre de volumes constitutifs afin d'optimiser les performances d'un système ONTAP. Utilisez FlexGroup avec vSphere pour créer un datastore vSphere unique et évolutif tout en bénéficiant de la puissance d'un cluster ONTAP complet.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">En plus des tests exhaustifs sur les charges de travail vSphere, ONTAP 9.8 propose également un nouveau mécanisme d'allègement de la charge de données pour les datastores FlexGroup. Un moteur de copie amélioré permet de copier des fichiers entre les composants en arrière-plan tout en permettant l'accès à la source et à la destination. Plusieurs copies utilisent les clones de fichiers instantanément disponibles dans un composant, si nécessaire, en fonction des évolutions.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">ONTAP 9.8 propose également de nouvelles mesures de performance basées sur les fichiers (IOPS, débit et latence) pour les fichiers FlexGroup. Ces metrics sont également consultables dans le tableau de bord et les rapports des machines virtuelles de ONTAP pour VMware vSphere. Les outils ONTAP pour le plug-in VMware vSphere vous permettent également de définir des règles de qualité de service (QoS) en combinant des IOPS minimales et/ou maximales. Ils peuvent être définis au sein de toutes les machines virtuelles d'un datastore ou individuellement pour des machines virtuelles spécifiques.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">Voici quelques meilleures pratiques supplémentaires que NetApp a développées :</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">Utilisez les valeurs par défaut de provisionnement FlexGroup. Les outils ONTAP pour VMware vSphere sont recommandés, car ils créent et montés FlexGroup dans vSphere, mais ONTAP System Manager ou la ligne de commandes peuvent être utilisés pour des besoins particuliers. Ensuite, utilisez les valeurs par défaut, telles que le nombre de membres constitutifs par nœud, car c'est ce qui a été testé avec vSphere.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">Lors du dimensionnement d'un datastore FlexGroup, n'oubliez pas que le FlexGroup est constitué de plusieurs petits volumes FlexVol qui créent un espace de noms plus important. Par conséquent, dimensionnez le datastore pour qu'il soit au moins 8x de la taille de votre plus grande machine virtuelle. Par exemple, si votre environnement contient une machine virtuelle de 6 To, sa taille FlexGroup n'est pas inférieure à 48 To.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">Autoriser FlexGroup à gérer l'espace du datastore. La taille automatique et le dimensionnement souple ont été testés avec les datastores vSphere. Si la capacité totale du datastore est proche de celle maximale, utilisez les outils ONTAP pour VMware vSphere ou un autre outil pour redimensionner le volume FlexGroup. FlexGroup permet d'équilibrer la capacité et les inodes entre les composants, en hiérarchisant les fichiers d'un dossier (VM) vers le même composant si la capacité le permet.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">La prise en charge du datastore FlexGroup vSphere a été testée jusqu'à 1500 machines virtuelles dans la version 9.8.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">Utilisez le plug-in NFS pour VMware VAAI pour la copie auxiliaire. Notez que même si le clonage est amélioré dans un datastore FlexGroup, ONTAP ne fournit pas d'avantages significatifs en termes de performances par rapport à la copie d'hôte ESXi lors de la copie de machines virtuelles entre des volumes FlexVol et/ou FlexGroup.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">Utilisez les outils ONTAP pour VMware vSphere 9.8 pour surveiller les performances des machines virtuelles FlexGroup à l'aide de metrics de ONTAP (tableau de bord et rapports sur les machines virtuelles), et pour gérer la qualité de service sur des machines virtuelles individuelles. Ces metrics ne sont pas encore disponibles via les commandes ou les API ONTAP.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">À ce moment-là, la qualité de service (IOPS max/min) peut être définie sur des machines virtuelles individuelles ou sur toutes les machines virtuelles d'un datastore. La définition de la qualité de service sur toutes les VM remplace tous les paramètres distincts par VM. Les paramètres ne s'étendent pas ultérieurement aux nouvelles machines virtuelles ou aux machines virtuelles migrées ; définissez la qualité de service sur les nouvelles machines virtuelles ou appliquez à nouveau la qualité de service à toutes les machines virtuelles du datastore.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">Le plug-in SnapCenter pour VMware vSphere version 4.4 prend en charge la sauvegarde et la restauration des machines virtuelles dans un datastore FlexGroup sur le système de stockage primaire. Même si SnapMirror peut être utilisé manuellement pour répliquer un FlexGroup sur un système secondaire, le distributeur sélectif n° 4.4 ne gère pas les copies secondaires.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Si possible, utilisez toujours les outils ONTAP pour provisionner les datastores et les volumes. Cela vérifie que les volumes, les chemins de jonction, les LUN, les igroups, les règles d'exportation, et d'autres paramètres sont configurés de manière compatible.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Meilleures pratiques opérationnelles</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">Datastores et protocoles</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM prend en charge iSCSI, Fibre Channel et NFS version 3 avec ONTAP 9 lors de l'utilisation d'une réplication basée sur les baies via SRA. SRM ne prend pas en charge la réplication basée sur la baie pour NFS version 4.1 avec des datastores traditionnels ou vvols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Pour confirmer la connectivité, vérifiez toujours que vous pouvez monter et démonter un nouveau datastore test sur le site de reprise sur incident à partir du cluster ONTAP de destination. Testez chaque protocole que vous envisagez d'utiliser pour la connectivité du datastore. L'une des meilleures pratiques est d'utiliser les outils ONTAP pour créer votre datastore de test, car elle effectue toutes les automatisations du datastore telles que dirigées par SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">Les protocoles SAN doivent être homogènes pour chaque site. Vous pouvez combiner les protocoles NFS et SAN, mais les protocoles SAN ne doivent pas être combinés dans un même site. Par exemple, vous pouvez utiliser FCP sur le site A et iSCSI sur le site B. Vous ne devez pas utiliser FCP et iSCSI sur le site A. La raison en est que SRA ne crée pas de groupes initiateurs mixtes sur le site de reprise et SRM ne filtre pas la liste des initiateurs donnée à SRA.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">Il a été recommandé aux guides précédents de créer la LIF vers la localisation des données. C'est-à-dire toujours monter un datastore à l'aide d'une LIF située sur le nœud qui détient physiquement le volume. Ce n'est plus une exigence dans les versions modernes de ONTAP 9. Dans la mesure du possible, et si des informations d'identification du cluster sont fournies, les outils ONTAP choisissent toujours d'équilibrer la charge entre les LIF locales des données, mais ils ne doivent pas garantir de haute disponibilité ou de performances élevées.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">NetApp ONTAP 9 peut être configuré de manière à supprimer automatiquement les copies Snapshot afin de préserver la continuité en cas de manque d'espace lorsque la fonction de dimensionnement automatique ne peut pas fournir suffisamment de capacité d'urgence. Le paramètre par défaut de cette fonctionnalité ne supprime pas automatiquement les copies Snapshot créées par SnapMirror. Si les copies Snapshot de SnapMirror sont supprimées, la SRA de NetApp ne peut pas inverser et resynchroniser la réplication pour le volume affecté. Pour empêcher ONTAP de supprimer les copies Snapshot SnapMirror, configurez la fonctionnalité de suppression automatique de Snapshot afin qu'elle puisse essayer.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">Centre de documentation ONTAP 9</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">La taille automatique du volume doit être définie sur<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Pour les volumes contenant les datastores SAN et<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Pour les datastores NFS. Reportez-vous à la<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> pour la syntaxe spécifique.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM et vVols</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">Depuis SRM 8.3, la protection des machines virtuelles à l'aide de datastores vvols est prise en charge. Les planifications SnapMirror sont exposées aux règles de stockage de VM par le VASA Provider lorsque la réplication de vvols est activée dans le menu des paramètres des outils ONTAP, comme indiqué dans les captures d'écran suivantes.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">L'exemple suivant montre l'activation de la réplication vvols.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La capture d'écran suivante fournit un exemple de planifications SnapMirror affichées dans l'assistant de création de règles de stockage de machine virtuelle.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">Le fournisseur ONTAP VASA prend en charge le basculement vers des systèmes de stockage différents. Par exemple, le système peut basculer d'un système ONTAP Select à un emplacement de périphérie vers un système AFF dans le data Center central. Indépendamment de la similarité de stockage, vous devez toujours configurer les mappages des règles de stockage et les mappages inversés des règles de stockage de machines virtuelles grâce à la réplication, afin de garantir que les services fournis sur le site de reprise répondent aux attentes et aux exigences de votre entreprise. La capture d'écran suivante met en évidence un exemple de mappage de règles.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Créez des volumes répliqués pour les datastores vvols</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">À la différence des précédents datastores vvols, les datastores vvols répliqués doivent être créés dès le début avec une réplication activée, et ils doivent utiliser des volumes pré-créés sur les systèmes ONTAP avec des relations SnapMirror. Cela nécessite de pré-configurer des éléments tels que le peering de cluster et de SVM. Ces activités doivent être réalisées par votre administrateur ONTAP, car elles permettent de séparer très facilement les responsabilités qui gèrent les systèmes ONTAP sur plusieurs sites et celles qui sont principalement responsables des opérations vSphere.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">Cette exigence est nouvelle pour le compte de l'administrateur vSphere. Les volumes étant créés hors du cadre des outils ONTAP, il n'est pas tenu de suivre les modifications apportées par votre administrateur ONTAP tant que la période de redécouverte planifiée n'est pas au moment de la prochaine découverte. C'est pourquoi il est recommandé de toujours exécuter la redécouverte chaque fois que vous créez un volume ou une relation SnapMirror à utiliser avec vvols. Il vous suffit de cliquer avec le bouton droit sur l'hôte ou le cluster et de sélectionner les outils NetApp ONTAP &gt; mettre à jour les données hôte et de stockage, comme indiqué dans la capture d'écran ci-dessous.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Il faut faire preuve de prudence lorsqu'il s'agit de vVvols et SRM. Ne mélangez jamais des machines virtuelles protégées et non protégées dans le même datastore vVvols. Cela s'explique par le fait que, lorsque vous utilisez SRM pour basculer vers votre site de reprise sur incident, seules les machines virtuelles qui font partie du groupe de protection sont mises en ligne sur le site de reprise sur incident. Par conséquent, lorsque vous reprotégez (repassez de SnapMirror de la reprise sur incident à la production), vous pouvez remplacer les machines virtuelles qui n'étaient pas basculées et qui pouvaient contenir des données précieuses.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">À propos des paires de baies</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">Un gestionnaire de matrices est créé pour chaque paire de matrices. Avec les outils SRM et ONTAP, chaque association de baie s'effectue au sein d'un SVM, même si vous utilisez les identifiants du cluster. Vous pouvez ainsi segmenter les flux de travail de reprise après incident entre des locataires, en fonction des SVM qu'ils ont affectés à la gestion. Vous pouvez créer plusieurs gestionnaires de baies pour un cluster donné, et ils peuvent être de nature asymétrique. Vous pouvez « Fan-Out » ou « Fan-In » sur différents clusters ONTAP 9. Par exemple, il peut y avoir des SVM-A et SVM-B dans le Cluster-1 en cours de réplication vers SVM-C dans le Cluster-2, SVM-D dans le Cluster-3 ou vice-versa.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Lors de la configuration des paires de baies dans SRM, vous devez toujours les ajouter à SRM de la même manière que vous les avez ajoutés à ONTAP Tools : autrement dit, ils doivent utiliser le même nom d'utilisateur, mot de passe et LIF de gestion. Cette exigence garantit que SRA communique correctement avec la baie. La copie d'écran suivante montre comment un cluster peut s'afficher dans les outils ONTAP et comment il peut être ajouté à un gestionnaire de baies.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">À propos des groupes de réplication</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Les groupes de réplication contiennent des ensembles logiques de machines virtuelles qui sont restaurées ensemble. Le fournisseur VASA, un outil de ONTAP, crée automatiquement des groupes de réplication pour vous. Étant donné que la réplication SnapMirror de ONTAP se produit au niveau du volume, toutes les machines virtuelles d'un volume se trouvent dans le même groupe de réplication.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">Il existe plusieurs facteurs à prendre en compte dans les groupes de réplication et dans la manière dont vous distribuez les machines virtuelles sur les volumes FlexVol. Le regroupement d'ordinateurs virtuels similaires dans un même volume peut augmenter l'efficacité du stockage avec les anciens systèmes ONTAP qui n'offrent pas de déduplication au niveau des agrégats, mais le regroupement augmente la taille du volume et réduit la simultanéité des E/S du volume. Le meilleur équilibre entre performances et efficacité du stockage peut être obtenu dans les systèmes ONTAP modernes en distribuant les machines virtuelles aux volumes FlexVol du même agrégat, exploitant ainsi la déduplication au niveau de l'agrégat et une mise en parallèle des E/S plus importante sur plusieurs volumes. Vous pouvez restaurer des VM dans les volumes simultanément, car un groupe de protection (voir ci-dessous) peut contenir plusieurs groupes de réplication. Cependant, cette disposition présente un inconvénient : les blocs peuvent être transmis à plusieurs reprises via le réseau, car ce volume ne prend pas en compte la déduplication globale.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Dernier point à prendre en compte pour les groupes de réplication : chacun d'entre eux est, par nature, un groupe de cohérence logique (à ne pas confondre avec les groupes de cohérence SRM). En effet, toutes les machines virtuelles du volume sont transférées ensemble à l'aide du même snapshot. Ainsi, si vous disposez de machines virtuelles qui doivent être cohérentes les unes avec les autres, envisagez de les stocker dans le même FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">À propos des groupes de protection</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Les groupes de protection définissent les VM et les datastores dans des groupes restaurés à partir du site protégé. Le site protégé est là où existent les VM configurées dans un groupe de protection pendant les opérations stables. Il est important de noter que même si SRM peut afficher plusieurs gestionnaires de baies pour un groupe de protection, un groupe de protection ne peut pas s'étendre sur plusieurs gestionnaires de baies. Pour cette raison, vous ne devez pas couvrir les fichiers de machine virtuelle sur plusieurs datastores sur différents SVM.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">À propos des plans de reprise</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Les plans de reprise définissent les groupes de protection qui sont restaurés au cours du même processus. Plusieurs groupes de protection peuvent être configurés dans le même plan de reprise. Par ailleurs, pour activer davantage d'options pour l'exécution des plans de reprise, un seul groupe de protection peut être inclus dans plusieurs plans de restauration.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Les plans de restauration permettent aux administrateurs SRM de définir les flux de travail de restauration en affectant des VM à un groupe de priorité compris entre 1 (le plus élevé) et 5 (le plus faible), dont la valeur par défaut est 3 (moyen). Au sein d'un groupe de priorités, les VM peuvent être configurés pour les dépendances.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">Par exemple, votre entreprise peut disposer d'une application stratégique de niveau 1 qui repose sur un serveur Microsoft SQL pour sa base de données. Vous décidez donc de placer vos machines virtuelles dans le groupe de priorité 1. Au sein du groupe de priorité 1, vous commencez à planifier la commande afin d'obtenir des services. Vous devez probablement démarrer votre contrôleur de domaine Microsoft Windows avant votre serveur Microsoft SQL, qui devra être en ligne avant votre serveur d'applications, etc. Vous ajouterez toutes ces machines virtuelles au groupe de priorités, puis définissez les dépendances, car les dépendances s'appliquent uniquement à un groupe de priorités donné.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp recommande fortement de travailler avec vos équipes en charge des applications pour comprendre l'ordre des opérations requises dans un scénario de basculement et pour élaborer vos plans de reprise en conséquence.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Tester le basculement</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">Il est recommandé de toujours effectuer un basculement de test dès que la configuration d'un stockage protégé d'ordinateurs virtuels modifie. Ainsi, en cas d'incident, vous pouvez vous assurer que site Recovery Manager peut restaurer les services avec la cible RTO prévue.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp recommande également de confirmer occasionnellement les fonctionnalités des applications chez l'invité, en particulier après la reconfiguration du stockage des machines virtuelles.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Lors de l'exécution d'une opération de restauration test, un réseau de bulles de test privé est créé sur l'hôte ESXi pour les machines virtuelles. Cependant, ce réseau n'est pas automatiquement connecté à aucune carte réseau physique et ne fournit donc pas de connectivité entre les hôtes ESXi. Pour permettre la communication entre les machines virtuelles s'exécutant sur différents hôtes ESXi lors du test de reprise après incident, un réseau privé physique est créé entre les hôtes ESXi du site de reprise après incident. Pour vérifier que le réseau de test est privé, le réseau de bulles de test peut être séparé physiquement ou à l'aide de VLAN ou de balisage VLAN. Ce réseau doit être isolé du réseau de production car les machines virtuelles sont restaurées. En effet, ils ne peuvent pas être placés sur le réseau de production avec des adresses IP qui pourraient entrer en conflit avec les systèmes de production réels. Lors de la création d'un plan de reprise d'activité dans SRM, le réseau test créé peut être sélectionné comme réseau privé afin de connecter les VM à pendant le test.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Une fois le test validé et n'est plus nécessaire, effectuez une opération de nettoyage. Le nettoyage en cours d'exécution renvoie l'état initial des machines virtuelles protégées à leur état initial et réinitialise le plan de restauration en mode prêt.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Considérations relatives au basculement</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Il y a plusieurs autres considérations lorsqu'il s'agit de basculer sur un site en plus de l'ordre des opérations mentionné dans ce guide.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Vous devrez peut-être résoudre ce problème en tenant compte des différences de réseau entre les sites. Certains environnements peuvent utiliser les mêmes adresses IP réseau à la fois sur le site primaire et sur le site de reprise après incident. Cette fonctionnalité est appelée VLAN (Virtual LAN) étendu ou configuration réseau étendu. Dans d'autres environnements, il est parfois nécessaire d'utiliser différentes adresses IP réseau (par exemple, sur différents VLAN) sur le site primaire par rapport au site de reprise.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware offre plusieurs moyens de résoudre ce problème. Pour la première, des technologies de virtualisation de réseau comme VMware NSX-T Data Center extraient la pile réseau des couches 2 à 7 de l'environnement d'exploitation, afin d'offrir des solutions plus portables. Pour en savoir plus sur les options NSX-T avec SRM<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">SRM vous permet également de modifier la configuration réseau d'une machine virtuelle lors de sa restauration. Cette reconfiguration inclut des paramètres tels que les adresses IP, l'adresse de passerelle et les paramètres du serveur DNS. Différents paramètres réseau, qui sont appliqués aux machines virtuelles individuelles lors de leur restauration, peuvent être spécifiés dans les paramètres de propriété d'une machine virtuelle dans le plan de reprise.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">Pour configurer SRM de façon à appliquer différents paramètres réseau à plusieurs machines virtuelles sans devoir modifier les propriétés de chacune d'entre elles dans le plan de reprise, VMware fournit un outil appelé dr-ip-customizer. Pour plus d’informations sur l’utilisation de cet utilitaire, reportez-vous à la documentation de VMware<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Reprotéger</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Après une restauration, le site de reprise devient le nouveau site de production. Comme l'opération de reprise a rompue la réplication SnapMirror, le nouveau site de production n'est pas protégé contre un futur incident. Il est recommandé de protéger le nouveau site de production sur un autre site immédiatement après une restauration. Si le site de production d'origine est opérationnel, l'administrateur VMware peut utiliser le site de production d'origine comme nouveau site de reprise pour protéger le nouveau site de production, ce qui inversera efficacement la direction de la protection. La reprotection est disponible uniquement en cas de défaillance majeure. Par conséquent, les serveurs vCenter d'origine, les serveurs ESXi, les serveurs SRM et les bases de données correspondantes doivent être récupérables. S'ils ne sont pas disponibles, un nouveau groupe de protection et un nouveau plan de récupération doivent être créés.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Du rétablissement</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Une opération de retour arrière est fondamentalement un basculement dans une direction différente de celle précédente. Il est recommandé de vérifier que le site d'origine fonctionne à un niveau de fonctionnalité acceptable avant de tenter un retour arrière ou, en d'autres termes, un basculement vers le site d'origine. Si le site d'origine est toujours compromis, vous devez reporter la restauration jusqu'à ce que la défaillance soit suffisamment remédiée.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Une autre meilleure pratique de restauration consiste à toujours effectuer un basculement de test après avoir terminé la reprotection et avant de procéder à la restauration finale. Cela vérifie que les systèmes en place sur le site initial peuvent mener à bien l'opération.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Reprotéger le site d'origine</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">Après le retour arrière, vous devez confirmer auprès de tous les détenteurs de parts que leurs services ont été rendus normaux avant d'exécuter à nouveau la reprotection,</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">La reprotection après le retour arrière reprend l'état où il était au début, avec la réplication SnapMirror à nouveau en cours d'exécution depuis le site de production vers le site de reprise.</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">Dans ONTAP 9, les composants physiques d'un cluster sont visibles pour les administrateurs du cluster, mais ils ne sont pas directement visibles pour les applications et les hôtes qui utilisent le cluster.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologies de réplication</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">Dans ONTAP 9, les composants physiques d'un cluster sont visibles pour les administrateurs du cluster, mais ils ne sont pas directement visibles pour les applications et les hôtes qui utilisent le cluster. Les composants physiques offrent un pool de ressources partagées à partir duquel les ressources logiques du cluster sont créées. Les applications et les hôtes accèdent aux données uniquement au moyen de SVM qui contiennent des volumes et des LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Chaque SVM NetApp est traité comme une baie dans VMware vCenter site Recovery Manager. SRM prend en charge certaines dispositions de réplication baie à baie (ou SVM à SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Une seule machine virtuelle ne peut pas héberger de données (Virtual machine Disk (VMDK) ou RDM) sur plusieurs baies SRM pour les raisons suivantes :</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM ne voit que la SVM, pas un contrôleur physique individuel.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Un SVM peut contrôler les LUN et les volumes répartis sur plusieurs nœuds dans un cluster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Meilleure pratique</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Pour déterminer la prise en charge, conservez cette règle à l'esprit : pour protéger une machine virtuelle via SRM et NetApp SRA, tous les composants de la machine virtuelle doivent exister sur un seul SVM. Cette règle s'applique aussi bien au site protégé que au site de reprise.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Dispositions SnapMirror prises en charge</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Les figures suivantes présentent les scénarios de disposition des relations SnapMirror pris en charge par SRM et SRA. Chaque machine virtuelle des volumes répliqués est propriétaire de données sur une seule baie SRM (SVM) sur chaque site.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Mises en page de Array Manager prises en charge</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Lorsque vous utilisez la réplication basée sur la baie (ABR) dans SRM, les groupes de protection sont isolés vers une seule paire de baies, comme l'illustre la capture d'écran suivante. Dans ce scénario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> et<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> sont associés à<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> et<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> sur le site de reprise. Cependant, vous ne pouvez sélectionner qu'une des deux paires de matrices lorsque vous créez un groupe de protection.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Présentations non prises en charge</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Les configurations non prises en charge possèdent des données (VMDK ou RDM) sur plusieurs SVM appartenant à une machine virtuelle individuelle. Dans les exemples présentés dans les figures suivantes,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection avec SRM car<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Possède des données sur deux SVM.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Toute relation de réplication dans laquelle un volume NetApp individuel est répliqué depuis un SVM source vers plusieurs destinations dans un même SVM ou dans différents SVM, est appelée « Fan-Out » de SnapMirror. La réplication « Fan-Out » n'est pas prise en charge par SRM. Dans l'exemple illustré dans la figure suivante,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Ne peut pas être configuré pour la protection dans SRM car elle est répliquée avec SnapMirror dans deux emplacements différents.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror en cascade</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM ne prend pas en charge le cascade des relations SnapMirror, dans lesquelles un volume source est répliqué sur un volume de destination, et ce volume de destination est également répliqué avec SnapMirror vers un autre volume de destination. Dans le scénario illustré dans la figure suivante, SRM ne peut pas être utilisé pour le basculement entre des sites.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror et SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">Le logiciel NetApp SnapVault permet de sauvegarder les données d'entreprise sur disque entre les systèmes de stockage NetApp. SnapVault et SnapMirror peuvent coexister dans un même environnement, mais SRM prend en charge le basculement de uniquement les relations SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">L'adaptateur NetApp SRA prend en charge le<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> type de règle.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault a été entièrement reconstruit pour ONTAP 8.2. Bien que les anciens utilisateurs de Data ONTAP 7-mode trouvent des similarités, des améliorations majeures ont été apportées dans cette version d'SnapVault. Une avancée majeure est la capacité à préserver l'efficacité du stockage sur les données primaires au cours des transferts SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">L'architecture SnapVault de ONTAP 9 réplique au niveau du volume et non au niveau du qtree, comme c'est le cas avec 7-mode SnapVault. Dans ce cas, la source d'une relation SnapVault doit être un volume, et ce volume doit être répliqué sur son propre volume sur le système secondaire SnapVault.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">Dans un environnement où SnapVault est utilisé, des copies Snapshot spécialement nommées sont créées sur le système de stockage primaire. Selon la configuration mise en œuvre, les copies Snapshot nommées peuvent être créées sur le système principal par un programme SnapVault ou par une application telle que NetApp Active IQ Unified Manager. Les copies Snapshot nommées qui sont créées sur le système primaire sont ensuite répliquées vers la destination SnapMirror, et depuis cet emplacement sont archivées sur la destination SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Un volume source peut être créé dans une configuration en cascade, dans laquelle un volume est répliqué vers une destination SnapMirror dans le site de reprise après incident, et depuis ce volume est copié vers une destination SnapVault. Un volume source peut également être créé au sein d'une relation « fan-out » où une destination est une destination SnapMirror et l'autre destination est une destination SnapVault. Toutefois, SRA ne reconfigurez pas automatiquement la relation SnapVault pour utiliser le volume de destination SnapMirror comme source du coffre-fort en cas de basculement ou d'inversion de réplication SRM.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Pour connaître les dernières informations concernant SnapMirror et SnapVault pour ONTAP 9, consultez<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Si SnapVault et SRM sont utilisés dans le même environnement, NetApp recommande d'utiliser une configuration SnapMirror vers SnapVault en cascade dans laquelle les sauvegardes SnapVault sont normalement exécutées à partir de la destination SnapMirror sur le site de reprise après incident. En cas d'incident, cette configuration rend le site principal inaccessible. Le fait de conserver la destination SnapVault sur le site de reprise permet de reconfigurer les sauvegardes SnapVault après le basculement, de sorte que les sauvegardes SnapVault puissent continuer sur le site de reprise.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">Dans un environnement VMware, chaque datastore dispose d'un identifiant unique universel (UUID) et chaque machine virtuelle possède un ID d'objet géré unique (MOID). Ces identifiants ne sont pas gérés par SRM lors du basculement ou de la restauration. Étant donné que les UID et les MOID de machine virtuelle ne sont pas maintenus lors du basculement par SRM, toutes les applications qui dépendent de ces ID doivent être reconfigurées après le basculement SRM. NetApp Active IQ Unified Manager, qui coordonne la réplication SnapVault avec l'environnement vSphere, est un exemple d'application.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La figure suivante décrit une configuration SnapMirror vers SnapVault en cascade. Si la destination SnapVault se trouve sur le site de reprise après incident ou sur un site tertiaire non affecté par une panne sur le site primaire, l'environnement peut être reconfiguré afin de permettre la continuité des sauvegardes après le basculement.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">La figure suivante décrit la configuration après l'utilisation de SRM pour renvoyer la réplication SnapMirror vers le site primaire. L'environnement a également été reconfiguré de façon à ce que les sauvegardes SnapVault s'effectuent à partir d'une source SnapMirror. Cette configuration est « Fan-Out » de SnapMirror SnapVault.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Une fois que SRM a effectué une restauration et une seconde inversion des relations SnapMirror, les données de production sont de nouveau sur le site principal. Ces données sont désormais protégées de la même manière qu'avant le basculement vers le site de reprise après incident, via les sauvegardes SnapMirror et SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Utilisation de qtrees dans les environnements site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Les qtrees sont des répertoires spéciaux qui permettent l'application de quotas de système de fichiers pour NAS. ONTAP 9 permet la création de qtrees et peut exister dans les volumes répliqués avec SnapMirror. Toutefois, SnapMirror ne permet pas la réplication de qtrees individuels ni de réplication au niveau qtree. Toute la réplication SnapMirror se fait au niveau du volume uniquement. C'est pour cette raison que NetApp ne recommande pas l'utilisation de qtrees avec SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Environnements FC et iSCSI mixtes</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Grâce à la prise en charge des protocoles SAN (FC, FCoE et iSCSI), ONTAP 9 propose des services LUN, à savoir la création de LUN et leur mappage vers les hôtes associés. Dans la mesure où le cluster compte plusieurs contrôleurs, il existe plusieurs chemins logiques gérés par les E/S multivoies vers une LUN individuelle. L'accès ALUA (Asymmetric Logical Unit Access) est utilisé sur les hôtes pour que le chemin optimisé vers un LUN soit sélectionné et activé pour le transfert de données. Si ce chemin change (par exemple, en raison du déplacement du volume qui y est associé), ONTAP 9 reconnaît automatiquement cette modification et s'ajuste de façon non disruptive. S'il devient indisponible, ONTAP peut également basculer sans interruption sur un autre chemin.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM et NetApp SRA prennent en charge l'utilisation du protocole FC sur un site et le protocole iSCSI sur l'autre site. Il ne prend pas en charge la combinaison de datastores FC et de datastores iSCSI dans le même hôte ESXi ou d'hôtes différents dans le même cluster. Cette configuration n'est pas prise en charge avec SRM car, pendant le basculement SRM ou le basculement de test, SRM inclut tous les initiateurs FC et iSCSI des hôtes ESXi dans la demande.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM et SRA prennent en charge les protocoles FC et iSCSI mixtes entre les sites protégés et de reprise. Cependant, chaque site ne doit pas être configuré avec un seul protocole, FC ou iSCSI, et non avec les deux protocoles sur le même site. Si il est nécessaire de configurer les protocoles FC et iSCSI sur le même site, NetApp recommande que certains hôtes utilisent iSCSI et d'autres hôtes utilisent FC. Dans ce cas, NetApp recommande également de configurer les mappages de ressources SRM de sorte que les VM soient configurés pour basculer vers un groupe d'hôtes ou un autre.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Volumes virtuels (vvols) et gestion basée sur des règles de stockage (SPBM)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">À propos de vVvols et SPBM</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp a été un partenaire de conception précoce avec VMware dans le développement de vSphere Virtual volumes (vvols), en fournissant des informations architecturales et une prise en charge précoce pour vvols et VMware vSphere API for Storage Awareness (VASA). Cette approche a non seulement permis d'intégrer la gestion granulaire du stockage des machines virtuelles à VMFS, mais également d'automatiser le provisionnement du stockage via une gestion basée sur des règles de stockage (SPBM pour Storage Policy Based Management en anglais).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">Grâce à la gestion du stockage basée sur des règles, une structure sert de couche d'abstraction entre les services de stockage disponibles pour votre environnement de virtualisation et les éléments de stockage provisionnés via des règles. Cette approche permet aux architectes du stockage de concevoir des pools de stockage dont les capacités sont facilement utilisable par les administrateurs de machines virtuelles. Les administrateurs peuvent ensuite répondre aux exigences des charges de travail des machines virtuelles par rapport aux pools de stockage provisionnés, ce qui permet un contrôle granulaire des divers paramètres au niveau de chaque machine virtuelle ou disque virtuel.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP est leader du secteur du stockage dans l'évolutivité de vvols, en gérant des centaines de milliers de vvols dans un seul cluster, alors que les fournisseurs de baies d'entreprise et de baies Flash plus petites prennent en charge aussi peu que plusieurs milliers de vvols par baie. NetApp pilotant également l'évolution de la gestion granulaire des machines virtuelles avec des fonctionnalités à venir en matière de prise en charge de vvols 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">Pour plus d'informations sur les volumes virtuels VMware vSphere, SPBM et ONTAP, voir<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="3e23a542d0c1cb3dc87ca41f7ec8dc9c" category="doc">Plug-in NetApp SnapCenter pour VMware vSphere - Workflow de restauration SQL Server</block>
  <block id="d16efdedacbd64c8b85d50f0b58e4c60" category="inline-link-macro">Précédent : informations complémentaires : plug-in SnapCenter pour VMware vSphere - Restauration du flux de travail.</block>
  <block id="553f0bde4f032f393b8659c8440bae26" category="paragraph"><block ref="553f0bde4f032f393b8659c8440bae26" category="inline-link-macro-rx"></block></block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">Cette page décrit les fonctionnalités d'efficacité du stockage ONTAP.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">Fonctionnalités d'efficacité du stockage ONTAP</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">Efficacité du stockage</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">Même si NetApp a été le premier à proposer la déduplication pour les charges de travail de production, cette innovation n'a pas été la dernière en ce domaine. Elle a commencé avec les copies ONTAP Snapshot, un mécanisme de protection des données peu performant, sans impact sur les performances et la technologie FlexClone, afin d'effectuer instantanément des copies de lecture/écriture des machines virtuelles pour la production et la sauvegarde. NetApp a continué à proposer des fonctionnalités en ligne, notamment la déduplication, la compression et la déduplication des blocs « zéro », afin d'exploiter tout le stockage provenant de disques SSD très coûteux. Plus récemment, ONTAP a ajouté la compaction afin de renforcer l'efficacité du stockage.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">*La déduplication de blocs « zéro » en ligne.* élimine l'espace perdu grâce aux blocs « zéro ».</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">*Compression en ligne.* compresse les blocs de données pour réduire la quantité de stockage physique nécessaire.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">*La déduplication à la volée.* supprime les blocs entrants avec les blocs existants sur le disque.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">*Compaction des données en ligne.* permet de mettre en place des opérations d'E/S et des fichiers plus petits dans chaque bloc physique.</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">Fonctionnalités d'efficacité du stockage</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">Vous pouvez exécuter la déduplication, la compression et la compaction des données de manière indépendante ou simultanément pour réaliser des économies d'espace optimales sur un volume FlexVol. L'association de ces fonctionnalités a permis à des clients d'obtenir des économies allant jusqu'à 5:1 pour VSI et jusqu'à 30:1 pour VDI.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">Gains d'efficacité grâce à la déduplication, à la compression et à la compaction des données</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">Pour plus d'informations sur l'efficacité du stockage ONTAP, consultez<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> Dans le centre de documentation ONTAP 9.</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">Documentation des produits VMware<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">Documentation produit NetApp<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Pour en savoir plus sur les informations données dans ce livre blanc, consultez ces documents et/ou sites web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Informations supplémentaires</block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">Tr-4597 : VMware vSphere pour ONTAP<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">Tr-4400 : volumes virtuels VMware vSphere avec ONTAP<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">Tr-4015 Guide des meilleures pratiques en matière de configuration de SnapMirror pour ONTAP 9<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">Créateur d'utilisateurs RBAC pour ONTAP<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">Outils ONTAP pour les ressources VMware vSphere<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">Documentation VMware site Recovery Manager<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">Reportez-vous à la<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> Le site de support NetApp vous assure que les versions de produits et de fonctionnalités mentionnées dans le présent document sont prises en charge par votre environnement. NetApp IMT définit les composants et versions de produits qu'il est possible d'utiliser pour créer des configurations prises en charge par NetApp. Les résultats spécifiques dépendent de l'installation de chaque client conformément aux spécifications publiées.</block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">Cette page décrit les étapes du déploiement d'un datastore VMFS FCoE de stockage NetApp ONTAP dans un environnement VMware vSphere.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">Datastore VMFS vSphere - protocole de stockage Fibre Channel over Ethernet avec ONTAP</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">Cette section aborde la création d'un datastore VMFS avec le protocole de transport Fibre Channel over Ethernet (FCoE) vers le stockage ONTAP.</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">Un système de stockage ONTAP (FAS/AFF/CVO/ONTAP Select) exécutant {ontap_version}</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">Une combinaison FCoE prise en charge</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">Une fiche de configuration remplie</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">Avec des ports de données FC ONTAP ou des hôtes vSphere connectés</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">Segmentation FC/FCoE configurée</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">Commutateur(s) réseau</block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">Prise en charge de FCoE</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">Prise en charge de DCB</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">Trames Jumbo pour FCoE</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">L'outil ONTAP pour VMware vSphere est déployé, configuré et prêt à l'emploi</block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">Provisionnement d'un datastore VMFS</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">Vérifiez que la configuration FCoE est prise en charge</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">Utilisez le<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande pour vérifier que le FCP est répertorié.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">Utiliser<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> pour ajouter une licence.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">Vérifier que le protocole FCP est activé sur le SVM</block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">Créer un nouveau SVM avec le FCP</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">Vérifier que les interfaces logiques FCP sont disponibles sur le SVM.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">Lorsque le SVM est créé avec l'interface utilisateur graphique, les interfaces logiques font partie de ce processus.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">Pour renommer l'interface réseau, utilisez<block ref="976ec076dd60d4d6296585d0275e7fbc" prefix=" " category="inline-code"></block>.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">Créer et mapper une LUN</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>; Ignorez cette étape si vous utilisez les outils ONTAP pour VMware vSphere.</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">informations sur l'adaptateur de stockage</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">Vérifiez que les pilotes HBA sont installés. Les pilotes déployés clé en main sur les HBA pris en charge par VMware doivent être visibles dans <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">Cette page décrit les étapes du déploiement d'un datastore NetApp ONTAP NFS version 3 dans un environnement VMware vSphere.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">Datastore vSphere NFS - version 3 avec ONTAP</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">Création du datastore NFS version 3 avec stockage NAS ONTAP.</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">Les compétences de base nécessaires à la gestion d'un environnement vSphere et d'ONTAP.</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">Un système de stockage ONTAP (FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files) qui exécute ONTAP 9.8 ou une version ultérieure</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">Identifiants ONTAP (nom du SVM, ID utilisateur, mot de passe)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">Informations sur le port réseau ONTAP, le SVM et le LUN pour NFS</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">Une fiche de configuration NFS remplie</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">Informations sur les hôtes vSphere pour vSphere 7.0 ou version ultérieure</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">Informations IP de l'adaptateur NFS VMKernel</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">Grâce aux ports de données du système ONTAP et aux hôtes vSphere connectés</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">VLAN(s) configurés(s) pour NFS</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(Facultatif) agrégation de liens configurée pour les ports de données réseau ONTAP</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">Étapes</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">Vérifiez la compatibilité avec le<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">Vérifiez que la configuration NFS est prise en charge.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">Effectuez les tâches ONTAP et vSphere suivantes.</block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">Vérifiez la licence ONTAP pour NFS.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">Utilisez le<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande et vérifiez que NFS est répertorié.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">Suivez le workflow de configuration NFS.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">Suivre le workflow de la configuration client NFS pour vSphere.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">Référence</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">Fonctionnalités du datastore et du protocole vSphere : NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">Une fois ces tâches effectuées, le datastore NFS est prêt à consommer pour le provisionnement des machines virtuelles.</block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">Cette page décrit les fonctionnalités de cloud hybride disponibles pour ONTAP et VMware vSphere.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">Cloud hybride avec ONTAP et vSphere</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">À propos du cloud hybride</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">Que vous soyez utilisé pour un cloud privé sur site, une infrastructure de cloud public ou un cloud hybride qui associe le meilleur des deux, les solutions ONTAP vous aident à créer votre Data Fabric pour rationaliser et optimiser la gestion des données. Commencez par des systèmes 100 % Flash haute performance, puis coupler les avec des systèmes de stockage sur disque ou cloud pour la protection des données et le cloud computing.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Vous pouvez choisir entre des clouds Azure, AWS, IBM ou Google pour optimiser les coûts et éviter l'enfermement propriétaire. Bénéficiez de la prise en charge avancée des technologies OpenStack et de conteneur, selon vos besoins.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">La protection des données est souvent la première chose que les clients essaient au moment de leur transition vers le cloud. La protection peut être aussi simple que la réplication asynchrone des données clés ou aussi complexe qu'un site complet de sauvegarde à chaud. La protection des données repose principalement sur la technologie NetApp SnapMirror.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">Certains clients choisissent de déplacer des workloads complets vers le cloud. Cette approche peut être plus complexe que l'utilisation du cloud pour la protection des données, mais ONTAP facilite la transition, car vous n'avez pas à réécrire vos applications pour utiliser le stockage basé dans le cloud. ONTAP dans le cloud fonctionne à l'instar de ONTAP sur site. Votre système ONTAP sur site offre des fonctionnalités d'efficacité des données qui vous permettent de stocker davantage de données dans un espace physique moindre et de hiérarchiser rarement les données utilisées vers un stockage moins coûteux. Que vous utilisiez une configuration dans le cloud hybride ou que vous déplaiez l'ensemble de vos charges de travail vers le cloud, ONTAP optimise la performance et l'efficacité du stockage.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">NetApp propose également des solutions de sauvegarde cloud (SnapMirror Cloud, Cloud Backup Service et Cloud Sync), ainsi que des outils de Tiering du stockage et d'archivage (FabricPool) pour ONTAP afin de réduire les dépenses d'exploitation et d'exploiter la portée du cloud.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">La figure suivante fournit un exemple d'utilisation du cloud hybride.</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">Cloud hybride</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP et le cloud</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">Pour plus d'informations sur ONTAP et les clouds hybrides, consultez<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> Dans le Centre de documentation ONTAP 9.</block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">Cette page décrit les étapes du déploiement d'un datastore NetApp ONTAP NFS version 4 dans un environnement VMware vSphere.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">Datastore vSphere NFS - version 4.1 avec ONTAP</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">Cette section décrit la création d'un datastore NFS version 4.1 avec stockage NAS ONTAP.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">Les compétences de base nécessaires à la gestion d'un environnement vSphere et d'ONTAP</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">Système de stockage ONTAP (FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files) exécutant {ontap_version}</block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">Informations sur l'hôte(s) vSphere {vsphere_version}</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">Grâce aux ports de données réseau du système ONTAP, aux hôtes vSphere et aux connexions</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">Outils ONTAP pour VMware vSphere déployés, configurés et prêts à l'emploi</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">Matrice d'interopérabilité (IMT).</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">Vérifier la compatibilité avec le<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">Effectuez les tâches ONTAP et vSphere ci-dessous.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">Vérifier la licence ONTAP pour NFS</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">Usethe<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande pour vérifier si NFS est répertorié.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">Suivez le workflow de configuration NFS</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">Suivez le workflow NFS client Configuration for vSphere.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">Stockage unifié ONTAP</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">À propos du stockage unifié</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">Les systèmes qui exécutent le logiciel ONTAP sont unifiés de plusieurs façons. Cette approche, auparavant appelée à prendre en charge les protocoles NAS et SAN sur un seul système de stockage, et ONTAP continue d'être une plateforme SAN leader en plus de sa puissance initiale dans le stockage NAS. Une machine virtuelle de stockage (SVM) est une structure logique qui permet aux clients d'accéder aux systèmes exécutant le logiciel ONTAP. Les SVM peuvent transmettre simultanément les données par le biais de plusieurs protocoles d'accès aux données via des interfaces logiques (LIF). Les SVM fournissent un accès aux données de niveau fichier via les protocoles NAS, tels que CIFS et NFS, et un accès aux données de niveau bloc via les protocoles SAN, tels que iSCSI, FC/FCoE et NVMe. Les SVM peuvent fournir des données aux clients SAN et NAS de façon indépendante et simultanément.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">Stockage unifié</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent le logiciel ONTAP sont généralement moins coûteux pour VSI que les baies d'entreprise classiques et offrent cependant des fonctionnalités avancées d'efficacité du stockage permettant de gérer l'infrastructure VDI au sein du même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour améliorer les performances, une baie SATA pour l'archivage et des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualisation du stockage</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">Pour plus d'informations sur les SVM, le stockage unifié et l'accès aux clients, voir<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> Dans le centre de documentation ONTAP 9.</block>
  <block id="6f3666cf392f9aa79924b94f433b64ed" category="doc">Plug-in NetApp SnapCenter pour VMware vSphere - déploiement sur VMware</block>
  <block id="a1dd31a3dca44eb1fe27b895521130ae" category="inline-link-macro">Next : informations complémentaires - Plug-in SnapCenter pour VMware vSphere - prérequis à la solution.</block>
  <block id="874d68c7d23e9e2e452ff6efaf757dee" category="paragraph"><block ref="874d68c7d23e9e2e452ff6efaf757dee" category="inline-link-macro-rx"></block></block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">Cette page offre la prise en charge du datastore NFS dans l'environnement VMware vSphere.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">Provisionnement traditionnel du stockage de fichiers vSphere avec ONTAP</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere prend en charge les protocoles NFS suivants, tous deux prenant en charge ONTAP.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS version 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS version 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">Cette comparaison des versions client NFS</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">Si vous avez besoin d'aide pour sélectionner la version NFS appropriée pour vSphere, vérifiez <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">Cette section fournit des conseils sur les fonctionnalités prises en charge par des versions spécifiques de ONTAP et vSphere. NetApp recommande de confirmer une combinaison spécifique de versions avec la matrice d'interopérabilité NetApp.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="doc">Informations spécifiques à la version de ONTAP et vSphere</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">Cette section fournit des conseils sur les fonctionnalités prises en charge par des versions spécifiques de ONTAP et vSphere. NetApp recommande de confirmer une combinaison spécifique de versions avec le<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">Versions d'ONTAP</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">Au moment de la publication, NetApp prend intégralement en charge ces gammes de versions :</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">Prise en charge de vSphere et ESXi</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP prend en charge de manière étendue les hôtes vSphere ESXi. Les quatre principales gammes de versions décrites (9.5, 9.6, 9.7 et 9.8) sont totalement prises en charge en tant que plateformes de stockage de données pour les dernières versions de vSphere, notamment les versions 6.0, 6.5 et 7.0 (mises à jour disponibles pour ces versions). L'interopérabilité NFS v3 est définie de manière générale, et NetApp prend en charge tous les clients, y compris les hyperviseurs, conformes à la norme NFS v3. La prise en charge de NFSv4.1 est limitée à vSphere 6.0 à 7.0.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">Pour les environnements SAN, NetApp effectue un test complet des composants SAN. De manière générale, NetApp prend en charge les serveurs rack X86-64 standard, ainsi que les serveurs Cisco UCS et les adaptateurs Ethernet standard pour les connexions iSCSI. Les environnements FC, FCoE et NVMe/FC bénéficient d'une prise en charge plus spécifique en raison du micrologiciel et des pilotes de HBA requis.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">Toujours vérifier le<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> pour confirmer la prise en charge d'une configuration matérielle et logicielle spécifique.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plug-in NFS pour VMware VAAI</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">Ce plug-in pour les hôtes ESXi aide à déplacer les opérations vers ONTAP à l'aide de VAAI. La dernière version, 1.1.2, inclut la prise en charge des datastores NFSv4.1, y compris Kerberos (krb5 et krb5i). Il est pris en charge avec ESXi 6.0, 6.5 et 7.0 avec ONTAP 9.5-9.8.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">Vasa Provider</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">Le fournisseur VASA de NetApp prend en charge le provisionnement et la gestion de vVol (voir Section 3.7). Les dernières versions de VASA Provider prennent en charge ESXi 6.0, 6.5 et 7.0 avec ONTAP 9.5-9.8.</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">Les outils ONTAP pour VMware vSphere sont essentiels pour gérer le stockage ONTAP avec vSphere (il s'agit d'une meilleure pratique). La dernière version, 9.8, est prise en charge par vSphere 6.5 et 7.0 avec ONTAP 9.5-9.8.</block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">Ce document présente les fonctions de sécurité des produits des outils ONTAP pour VMware vSphere.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353 : outils ONTAP pour VMware vSphere - sécurité produit</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tulledge, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">Activités de développement sécurisées</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">L'ingénierie logicielle associée aux outils NetApp ONTAP pour VMware vSphere exploite les activités de développement sécurisées suivantes :</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modélisation des menaces.* le but de la modélisation des menaces est de découvrir des défauts de sécurité dans une fonction, un composant ou un produit au début du cycle de vie du développement logiciel. Un modèle de menace est une représentation structurée de toutes les informations qui affectent la sécurité d'une application. En substance, c'est une vision de l'application et de son environnement par le biais du principe de sécurité.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Dynamic application Security Testing (DAST).* cette technologie est conçue pour détecter les conditions vulnérables sur les applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels avec des logiciels open-source (OSS), vous devez corriger les vulnérabilités de sécurité qui pourraient être associées à tout OSS intégré à votre produit. Il s'agit d'un effort continu car une nouvelle version OSS peut avoir une nouvelle vulnérabilité découverte signalée à tout moment.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Analyse des vulnérabilités* l'analyse des vulnérabilités a pour but de détecter les vulnérabilités de sécurité courantes et connues dans les produits NetApp avant leur publication auprès des clients.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel similaire à des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Fonctionnalités de sécurité du produit</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">Les outils NetApp ONTAP pour VMware vSphere comprennent les fonctions de sécurité suivantes dans chaque version.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Bannière de connexion.* SSH est désactivé par défaut et n'autorise que les connexions à une seule fois si elles sont activées à partir de la console VM. La bannière de connexion suivante s'affiche une fois que l'utilisateur a saisi un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*AVERTISSEMENT:* l'accès non autorisé à ce système est interdit et sera poursuivi par la loi. En accédant à ce système, vous convenez que vos actions peuvent être surveillées si vous soupçonnez une utilisation non autorisée.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Une fois que l'utilisateur a terminé sa connexion via le canal SSH, le texte suivant s'affiche :</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Contrôle d'accès basé sur les rôles (RBAC).* deux types de contrôles RBAC sont associés aux outils ONTAP :</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilèges de serveur vCenter natif</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilèges spécifiques au plug-in vCenter. Pour plus de détails, voir<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canaux de communication cryptés.* toutes les communications externes se produisent sur HTTPS en utilisant la version 1.2 de TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Exposition minimale au port.* seuls les ports nécessaires sont ouverts sur le pare-feu.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">Le tableau suivant décrit les détails du port ouvert.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">N° de port TCP v4/v6</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Direction</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Fonction</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">entrant</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Connexions HTTPS pour l'API REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Connexions HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Connexions HTTPS utilisées pour les connexions SOAP sur https ce port doit être ouvert pour permettre à un client de se connecter au serveur API ONTAP Tools.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (désactivé par défaut)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Connexions HTTPS - VP et SRA - connexions internes à partir du bouclage uniquement</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Connexions HTTPS - VP et SRA utilisés pour SOAP sur des connexions https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">Paquets de déroutement SNMP VP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">diffusion interne uniquement</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Port de base de données Derby, uniquement entre cet ordinateur et lui-même, connexions externes non acceptées -- connexions internes uniquement</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidirectionnel</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Utilisé pour les connexions aux clusters ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">article de la base de connaissances</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Prise en charge des certificats signés de l'autorité de certification (CA).* les outils ONTAP pour VMware vSphere prennent en charge les certificats signés de l'autorité de certification. Voir ceci<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Audit Logging.* les offres de support peuvent être téléchargées et sont extrêmement détaillées. Les outils ONTAP consigne toutes les activités de connexion et de déconnexion de l'utilisateur dans un fichier journal distinct. Les appels d'API VASA sont connectés à un journal d'audit VASA dédié (local cxf.log).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont respectées :</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Les mots de passe ne sont pas enregistrés dans des fichiers journaux.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Les mots de passe ne sont pas communiqués en texte brut.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Les mots de passe sont configurés lors du processus d'installation lui-même.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">L'historique des mots de passe est un paramètre configurable.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">L'âge minimum du mot de passe est défini sur 24 heures.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">La saisie automatique des champs de mot de passe est désactivée.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Les outils ONTAP crypte toutes les informations d'identification stockées à l'aide de la fonction de hachage SHA256.</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">Novembre 2021</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">Depuis près de vingt ans, le logiciel NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere. Il continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion, tout en réduisant les coûts. Ce document présente la solution ONTAP pour vSphere, comprenant les dernières informations sur les produits et les meilleures pratiques, afin de rationaliser le déploiement, de réduire les risques et de simplifier la gestion.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">Tr-4597 : VMware vSphere pour ONTAP</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">(Karl Konnerth, NetApp.</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des listes de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Non seulement elles sont les seules pratiques prises en charge dans chaque environnement, mais elles constituent généralement les solutions les plus simples qui répondent aux besoins de la plupart des clients.</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">Ce document se concentre sur les fonctionnalités des dernières versions de ONTAP (9.x) exécutées sur vSphere 6.0 ou version ultérieure. Voir la section <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> pour obtenir des détails sur des versions spécifiques.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">Pourquoi choisir ONTAP pour vSphere ?</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">Pour plusieurs raisons, des dizaines de milliers de clients ont choisi ONTAP comme solution de stockage pour vSphere. Par exemple, un système de stockage unifié prenant en charge à la fois les protocoles SAN et NAS, des fonctionnalités robustes de protection des données à l'aide de copies NetApp Snapshot compactes, une multitude d'outils pour vous aider à gérer vos données d'application. En utilisant un système de stockage distinct de l'hyperviseur, vous pouvez décharger de nombreuses fonctions et optimiser votre investissement dans les systèmes hôtes vSphere. En plus de s'assurer que les ressources de vos hôtes sont concentrées sur les charges de travail applicatives, vous évitez également l'impact aléatoire sur les performances des applications en provenance des opérations de stockage.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">L'association de ONTAP et de vSphere permet de réduire les dépenses liées au matériel hôte et aux logiciels VMware. Vous pouvez également protéger vos données à moindre coût grâce à des performances élevées et prévisibles. Les charges de travail virtualisées étant mobiles, vous pouvez explorer différentes approches à l'aide de Storage vMotion afin de déplacer des ordinateurs virtuels entre des datastores VMFS, NFS ou vvols, le tout sur un même système de stockage.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Voici les principaux facteurs dont la valeur aujourd'hui est :</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">*Stockage unifié.* les systèmes qui exécutent le logiciel ONTAP sont unifiés de plusieurs façons significatives. À l'origine, cette approche était appelée protocoles NAS et SAN, et ONTAP continue d'être une plateforme SAN de premier plan en plus de ses capacités d'origine dans le stockage NAS. Dans le monde de vSphere, cette approche peut également se traduire par un système unifié d'infrastructure de postes de travail virtuels (VDI) avec une infrastructure de serveurs virtuels (VSI). Les systèmes qui exécutent le logiciel ONTAP sont généralement moins coûteux pour VSI que les baies d'entreprise classiques et offrent cependant des fonctionnalités avancées d'efficacité du stockage permettant de gérer l'infrastructure VDI au sein du même système. ONTAP unifie également une grande variété de supports de stockage, des SSD aux SATA, et peut s'étendre facilement au cloud. Il n'est pas nécessaire d'acheter une baie Flash pour améliorer les performances, une baie SATA pour l'archivage et des systèmes distincts pour le cloud. ONTAP les lie tous ensemble.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">*Volumes virtuels et gestion basée sur des règles de stockage.* NetApp a été un partenaire de conception précoce avec VMware dans le développement de vSphere Virtual volumes (vvols), en fournissant des entrées architecturales et une prise en charge précoce pour vvols et VMware vSphere API for Storage Awareness (VASA). Cette approche a non seulement permis une gestion granulaire du stockage des machines virtuelles à VMFS, mais elle a également pris en charge l'automatisation du provisionnement du stockage via la gestion basée sur des règles de stockage. Cette approche permet aux architectes du stockage de concevoir des pools de stockage dont les capacités sont facilement utilisable par les administrateurs de machines virtuelles. ONTAP est leader du secteur du stockage en matière d'évolutivité vvol, en gérant des centaines de milliers de vvols dans un seul cluster, alors que les fournisseurs de baies d'entreprise et de baies Flash de plus petite taille prennent en charge à peine plusieurs milliers de vvols par baie. NetApp pilotant également l'évolution de la gestion granulaire des ordinateurs virtuels avec des fonctionnalités à venir en matière de prise en charge de vvols 3.0.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*Efficacité du stockage.* bien que NetApp ait été le premier à fournir une déduplication pour les charges de travail de production, cette innovation n'a pas été la première ou la dernière en ce domaine. Elle a commencé avec les copies ONTAP Snapshot, un mécanisme de protection des données peu performant, sans impact sur les performances et la technologie FlexClone, afin d'effectuer instantanément des copies de lecture/écriture des machines virtuelles pour la production et la sauvegarde. NetApp a continué à proposer des fonctionnalités en ligne, notamment la déduplication, la compression et la déduplication des blocs « zéro », afin d'exploiter tout le stockage provenant de disques SSD très coûteux. Plus récemment, ONTAP a ajouté la possibilité de stocker des opérations d'E/S et des fichiers de petite taille dans un bloc de disque à l'aide de la compaction. L'association de ces fonctionnalités a permis à des clients d'obtenir des économies allant jusqu'à 5:1 pour VSI et jusqu'à 30:1 pour VDI.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud hybride.* qu'il soit utilisé pour le cloud privé sur site, une infrastructure de cloud public ou un cloud hybride qui associe le meilleur des deux types de clouds, les solutions ONTAP vous aident à créer votre Data Fabric pour rationaliser et optimiser la gestion des données. Commencez par des systèmes 100 % Flash haute performance, puis coupler les avec des systèmes de stockage sur disque ou cloud pour la protection des données et le cloud computing. Vous pouvez choisir entre des clouds Azure, AWS, IBM ou Google pour optimiser les coûts et éviter l'enfermement propriétaire. Bénéficiez de la prise en charge avancée des technologies OpenStack et de conteneur, selon vos besoins. NetApp propose également des solutions de sauvegarde cloud (SnapMirror Cloud, Cloud Backup Service et Cloud Sync), ainsi que des outils de Tiering du stockage et d'archivage (FabricPool) pour ONTAP afin de réduire les dépenses d'exploitation et d'exploiter la portée du cloud.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">*Et plus.* tirez parti des performances extrêmes des baies NetApp AFF A-Series pour accélérer votre infrastructure virtualisée tout en gérant les coûts. Assurez la continuité totale de l'activité, qu'il s'agisse de la maintenance ou des mises à niveau, ou du remplacement complet de votre système de stockage à l'aide de clusters ONTAP scale-out. Protégez vos données au repos avec les fonctionnalités de chiffrement NetApp, sans frais supplémentaires. Assurez-vous que les performances respectent les niveaux de service grâce à des fonctionnalités de qualité de service très avancées. Ils font tous partie de la vaste gamme de fonctionnalités fournies par ONTAP, le logiciel de gestion des données d'entreprise leader du secteur.</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">Contactez-nous</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">Avez-vous des commentaires sur ce rapport technique ?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">Envoyez-les nous à l'adresse doccomments@netapp.com et incluez le document TR-4597 dans la ligne d'objet.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis son introduction au data Center moderne en 2002. Elle continue également d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">Tr-4900 : VMware site Recovery Manager avec NetApp ONTAP 9</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">ONTAP pour vSphere</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere depuis son introduction au data Center moderne en 2002. Elle continue également d'ajouter des fonctionnalités innovantes pour simplifier la gestion tout en réduisant les coûts. Ce document présente la solution ONTAP pour VMware site Recovery Manager (SRM), le logiciel de reprise après incident leader du marché de VMware, notamment les dernières informations sur les produits et les meilleures pratiques pour rationaliser le déploiement, réduire les risques et simplifier la gestion au quotidien.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Les meilleures pratiques complètent d'autres documents, tels que des guides et des outils de compatibilité. Ils sont développés en fonction de tests effectués en laboratoire et d'une vaste expérience sur le terrain par les ingénieurs et les clients NetApp. Dans certains cas, les meilleures pratiques recommandées peuvent ne pas être adaptées à votre environnement. Cependant, ce sont généralement les solutions les plus simples qui répondent aux besoins des plus clients.</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">Ce document est axé sur les fonctionnalités des dernières versions d'ONTAP 9 utilisées conjointement avec les versions prises en charge des outils ONTAP pour VMware vSphere (notamment NetApp Storage Replication adapter [SRA] et VASA Provider [VP]), ainsi que VMware site Recovery Manager 8. 4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">Pourquoi utiliser ONTAP avec SRM ?</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">Les plateformes de gestion des données NetApp optimisées par le logiciel ONTAP constituent certaines des solutions de stockage les plus utilisées pour SRM. Les raisons sont nombreuses : une plateforme de gestion des données sécurisée, hautes performances et unifiée (NAS et SAN ensemble) qui offre des services spécialisés dans l'efficacité du stockage, la colocation, le contrôle de la qualité de services, la protection des données à l'aide de copies Snapshot compactes et la réplication avec SnapMirror. Exploitez l'intégration native du multicloud hybride pour protéger vos charges de travail VMware et bénéficier de nombreux outils d'automatisation et d'orchestration à portée de main.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">Lorsque vous utilisez SnapMirror pour la réplication basée sur la baie, vous bénéficiez de l'une des technologies ONTAP les plus abouties et les plus matures. SnapMirror vous permet de transférer les données de manière sécurisée et efficace en copiant uniquement les blocs du système de fichiers modifiés, et non les machines virtuelles entières ou les datastores. Même ces blocs tirent parti des économies d'espace, telles que la déduplication, la compression et la compaction. Les systèmes ONTAP modernes utilisent désormais SnapMirror, indépendant de la version, pour vous permettre de sélectionner plus de flexibilité vos clusters source et cible. SnapMirror est véritablement devenu l'un des outils les plus puissants disponibles pour la reprise après incident.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Que vous utilisiez des datastores NFS, iSCSI ou Fibre Channel classiques (désormais avec prise en charge des datastores vvols), SRM constitue une offre commerciale performante qui tire parti des fonctionnalités ONTAP pour la reprise après incident ou la planification et l'orchestration de la migration de data Center.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Comment SRM exploite ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM exploite les technologies avancées de gestion des données des systèmes ONTAP en l'intégrant aux outils ONTAP pour VMware vSphere, une appliance virtuelle qui englobe trois composants principaux :</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande ce plug-in lorsque vous utilisez vSphere avec les systèmes exécutant le logiciel ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">Le fournisseur VASA pour ONTAP prend en charge la structure VMware vStorage APIs for Storage Awareness (VASA). Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols) et la gestion des profils de capacité de stockage (y compris les fonctionnalités de réplication vvols) ainsi que les performances individuelles de VM vvols. Il fournit également des alarmes pour la surveillance de la capacité et la conformité avec les profils. Utilisé conjointement avec SRM, le fournisseur VASA pour ONTAP permet la prise en charge des machines virtuelles basées sur vvols sans avoir à installer un adaptateur SRA sur le serveur SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA est utilisée en association avec SRM pour gérer la réplication des données des machines virtuelles entre les sites de production et de reprise après incident pour les datastores VMFS et NFS traditionnels, et pour les tests non disruptives des répliques de DR. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Après avoir installé et configuré les adaptateurs SRA sur le serveur SRM pour la protection des datastores non-vvols et/ou la réplication vvols activée dans les paramètres de VASA Provider, vous pouvez commencer la tâche de configuration de votre environnement vSphere pour la reprise après incident.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">Les fournisseurs SRA et VASA proposent une interface de commande et de contrôle pour le serveur SRM afin de gérer les volumes FlexVol ONTAP contenant vos machines virtuelles VMware, ainsi que la réplication SnapMirror les protégeant.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">À partir de SRM 8.3, un nouveau chemin de contrôle SRM vvols Provider a été introduit dans le serveur SRM, ce qui lui a permis de communiquer avec le serveur vCenter et, par le biais de celui-ci, au VASA Provider sans avoir besoin d'une SRA. Ainsi, le serveur SRM a pu mieux contrôler le cluster ONTAP qu'auparavant. En effet, VASA fournit une API complète pour une intégration étroitement couplée.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM peut tester votre plan de reprise après incident sans interrompre l'activité grâce à la technologie FlexClone propriétaire de NetApp, pour créer des clones quasi instantanés de vos datastores protégés sur votre site de reprise après incident. SRM crée un sandbox afin de tester en toute sécurité afin que votre entreprise et vos clients soient protégés en cas d'incident, vous assurant ainsi la confiance de votre entreprise dans la capacité à exécuter un basculement lors d'un incident.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">En cas d'incident véritable ou même de migration planifiée, SRM vous permet d'envoyer les modifications de dernière minute au jeu de données via une mise à jour SnapMirror finale (si vous le souhaitez). Il interrompt ensuite le miroir et monte le datastore sur vos hôtes de reprise après incident. À ce stade, vos machines virtuelles peuvent être automatiquement alimentées dans l'ordre de votre stratégie prédéfinie.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM avec ONTAP et autres cas d'utilisation : cloud hybride et migration</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">NetApp Private Storage dans Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">En intégrant votre déploiement de SRM aux fonctionnalités avancées de gestion des données de ONTAP, vous pouvez améliorer l'évolutivité et les performances par rapport aux options de stockage local. Elle apporte cependant la flexibilité du cloud hybride. Grâce au cloud hybride, vous pouvez réaliser des économies en transférant les blocs de données non utilisés de votre baie haute performance vers votre hyperscaler préférée, via FabricPool, qui peut être un magasin S3 sur site tel que NetApp StorageGRID. Vous pouvez également utiliser SnapMirror pour les systèmes basés en périphérie avec ONTAP Select l'infrastructure de reprise après incident Software-defined ou basée dans le cloud à l'aide de Cloud Volumes ONTAP (CVO) ou<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Pour créer une pile de services de stockage, de réseau et de calcul entièrement intégrée dans le cloud, Amazon Web Services (AWS), Microsoft Azure et Google Cloud Platform (GCP)</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">Vous pouvez ensuite effectuer un basculement de test au sein du data Center d'un fournisseur de services clouds avec une empreinte de stockage quasi nulle grâce à FlexClone. La protection de votre entreprise peut à présent être plus économique que jamais.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM peut également être utilisé pour exécuter des migrations planifiées en utilisant SnapMirror pour transférer efficacement vos machines virtuelles d'un data Center à un autre ou même au sein d'un même data Center, que vous le soyez propriétaire ou via plusieurs fournisseurs de services partenaires NetApp.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter site Recovery Manager est une offre de reprise après incident qui assure une orchestration automatisée et des tests sans interruption de plans de reprise après incident centralisés, afin de simplifier la gestion de la reprise après incident pour toutes les applications virtualisées.</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">En déployant SRM sur les systèmes NetApp ONTAP, vous pouvez considérablement réduire les coûts et la complexité de la reprise après incident. Grâce à ses dispositifs de stockage évolutifs, haute performance et faciles à gérer, et à ses offres logicielles robustes, NetApp offre des solutions flexibles de gestion du stockage et des données qui prennent en charge les environnements vSphere.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">Les recommandations et les meilleures pratiques fournies dans ce guide ne sont pas une solution universelle. Ce document comprend un ensemble de meilleures pratiques et de recommandations qui vous aident à planifier, déployer et gérer vos plans de reprise après incident SRM. Consultez un expert VMware local NetApp pour planifier et déployer des environnements VMware vCenter site Recovery sur du stockage NetApp. Les experts NetApp VMware peuvent rapidement identifier les besoins et demandes des environnements vSphere et adapter la solution de stockage en conséquence.</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent à autoriser une sélection facultative de snapshots cohérents avec des machines virtuelles, tirant parti de la capacité de l'hyperviseur à suspendre les E/S avant d'effectuer un snapshot VMware.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">Autres fonctionnalités de vSphere</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">Protection des données</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">La sauvegarde et la restauration rapide de vos machines virtuelles font partie des grands atouts de ONTAP pour vSphere. C'est facile à gérer au sein de vCenter grâce au plug-in SnapCenter pour VMware vSphere. Utilisez les copies Snapshot pour effectuer des copies rapides de votre machine virtuelle ou de votre datastore sans affecter les performances, puis envoyez-les à un système secondaire à l'aide de SnapMirror pour la protection des données hors site à plus long terme. Cette approche réduit l'espace de stockage et la bande passante réseau en stockant uniquement les informations modifiées.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">recommandé</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter vous permet de créer des règles de sauvegarde qui peuvent être appliquées à plusieurs tâches. Ces règles peuvent définir des fonctionnalités de planification, de conservation, de réplication et autres. Ils continuent à autoriser une sélection facultative de snapshots cohérents avec des machines virtuelles, tirant parti de la capacité de l'hyperviseur à suspendre les E/S avant d'effectuer un snapshot VMware. Cependant, en raison de l'impact des snapshots VMware sur les performances, ils ne sont généralement pas recommandés sauf si vous devez suspendre le système de fichiers invité. Utilisez plutôt les copies Snapshot de ONTAP pour une protection générale, et utilisez des outils applicatifs tels que les plug-ins SnapCenter pour protéger les données transactionnelles comme SQL Server ou Oracle. Ces copies Snapshot sont différentes des snapshots VMware (cohérence) et conviennent à une protection à long terme. Les snapshots VMware ne sont que de<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> pour une utilisation à court terme en raison de performances et d'autres effets.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Ces plug-ins offrent des fonctionnalités étendues pour protéger les bases de données dans les environnements physiques et virtuels. VSphere permet de protéger les bases de données SQL Server ou Oracle dans lesquelles les données sont stockées sur des LUN RDM, des LUN iSCSI directement connectées au système d'exploitation invité ou des fichiers VMDK dans des datastores VMFS ou NFS. Les plug-ins permettent de spécifier différents types de sauvegardes de bases de données, de prendre en charge les sauvegardes en ligne ou hors ligne, et de protéger les fichiers de bases de données avec les fichiers journaux. Outre la sauvegarde et la restauration, ces plug-ins prennent également en charge le clonage des bases de données à des fins de développement ou de test.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">La figure suivante représente un exemple de déploiement SnapCenter.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Pour des fonctionnalités améliorées de reprise sur incident, utilisez l'outil NetApp SRA pour ONTAP avec VMware site Recovery Manager. Outre la prise en charge de la réplication de datastores sur un site de reprise après incident, il permet également d'effectuer des tests sans interruption dans l'environnement de reprise après incident en clonant les datastores répliqués. L'automatisation intégrée à SRA simplifie également la reprise après incident et la reprotection de la production après panne.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Enfin, pour obtenir le plus haut niveau de protection des données, pensez à une configuration VMware vSphere Metro Storage Cluster (vMSC) utilisant NetApp MetroCluster. VMSC est une solution certifiée VMware qui combine la réplication synchrone à la mise en cluster basée sur baie, offrant les mêmes avantages qu'un cluster haute disponibilité, mais distribuée sur des sites distincts pour une protection contre les incidents sur site. NetApp MetroCluster permet de réaliser des configurations économiques pour la réplication synchrone avec restauration transparente depuis n'importe quel composant de stockage défaillant, et récupération par commande unique en cas d'incident sur le site. VMSC est décrit plus en détail dans<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Réclamations d'espace</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">L'espace peut être récupéré pour d'autres utilisations lorsque les machines virtuelles sont supprimées d'un datastore. Avec les datastores NFS, l'espace est immédiatement récupéré lorsqu'une machine virtuelle est supprimée (cette approche n'a bien évidemment de sens que lorsque le volume est provisionné, c'est-à-dire que la garantie du volume est définie sur aucune). Cependant, lorsque les fichiers sont supprimés du système d'exploitation invité de la machine virtuelle, l'espace n'est pas automatiquement récupéré avec un datastore NFS. Pour les datastores VMFS basés sur des LUN, ESXi ainsi que le système d'exploitation invité peuvent émettre des primitives VAAI UNMAP vers le stockage (encore une fois, lors de l'utilisation du provisionnement fin) pour récupérer de l'espace. Selon la version, ce support est manuel ou automatique.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">Récupération de l'espace de stockage</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">c'est ça</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">Dans vSphere 5.5 et versions ultérieures, le<block ref="6f8212383775d45bd700d7b24be4f64e" prefix=" " category="inline-code"></block> la commande est remplacée par le<block ref="d92a762ce0274ace04ac012fc760e989" prefix=" " category="inline-code"></block> Commande, qui spécifie le nombre de blocs libres (voir VMware KB)<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> pour plus d'informations). Dans vSphere 6.5 et les versions ultérieures, lors de l'utilisation de VMFS 6, l'espace doit être automatiquement récupéré de manière asynchrone (voir la<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> Dans la documentation vSphere), mais peut également être exécutée manuellement si nécessaire. La commande UNMAP automatique est prise en charge par ONTAP, et les outils ONTAP pour VMware vSphere le définissent comme une priorité faible. N'oubliez pas que, lorsque vous provisionnez une LUN pour l'utiliser en tant que datastore VMFS, vous devez activer manuellement l'option d'allocation d'espace sur la LUN. Lors de l'utilisation des outils ONTAP pour VMware vSphere, la LUN est automatiquement configurée pour prendre en charge la réclamation d'espace et aucune autre action n'est requise. Voir<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> article de la base de connaissances pour en savoir plus.</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">Clonage des VM et des datastores</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">Le clonage d'un objet de stockage vous permet de créer rapidement des copies pour ensuite les utiliser, par exemple le provisionnement de machines virtuelles supplémentaires, les opérations de sauvegarde/restauration, etc. Dans vSphere, vous pouvez cloner une machine virtuelle, un disque virtuel, un volume virtuel ou un datastore. Une fois cloné, l'objet peut être davantage personnalisé, souvent par le biais d'un processus automatisé. VSphere prend en charge les clones de copie complète ainsi que les clones liés, pour assurer le suivi séparé des modifications apportées à l'objet d'origine.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">Les clones liés permettent un gain d'espace considérable, mais ils augmentent la quantité d'E/S que vSphere gère pour la machine virtuelle, ce qui affecte les performances de cette machine virtuelle, et peut-être de l'hôte dans son ensemble. C'est pourquoi les clients de NetApp utilisent souvent des clones basés sur les systèmes de stockage pour bénéficier des avantages des deux environnements : une utilisation efficace du stockage et une meilleure performance.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La figure suivante représente le clonage ONTAP.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Le clonage peut être déchargé sur les systèmes qui exécutent le logiciel ONTAP via plusieurs mécanismes, en général au niveau de la machine virtuelle, du volume ou du datastore. Ces champs d'application incluent :</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">Vvols avec le fournisseur NetApp vSphere APIs for Storage Awareness (VASA). Les clones ONTAP sont utilisés pour prendre en charge les copies vvol Snapshot gérées par vCenter, qui sont peu gourmandes en espace avec un minimum d'effets d'E/S pour les créer et les supprimer. Les machines virtuelles peuvent également être clonées via vCenter, qui sont également déchargées vers ONTAP, que ce soit dans un datastore/volume unique ou entre les datastores/volumes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonage et migration de vSphere à l'aide des API vSphere – intégration de baies (VAAI). Les opérations de clonage de VM peuvent être déchargées sur ONTAP dans les environnements SAN et NAS (NetApp fournit un plug-in ESXi pour que VAAI for NFS). VSphere ne décharge les opérations sur les machines virtuelles inactives (désactivées) dans un datastore NAS, tandis que les opérations sur les machines virtuelles fortement sollicitées (clonage et stockage vMotion) sont également déchargées pour le système SAN. ONTAP utilise l'approche la plus efficace selon la source, la destination et les licences des produits installés. Cette fonctionnalité est également utilisée par VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (utilisé avec VMware site Recovery Manager). Ici, des clones sont utilisés pour tester la restauration de la réplique de reprise après incident sans interruption.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Sauvegarde et restauration à l'aide d'outils NetApp tels que SnapCenter. Les clones de machine virtuelle sont utilisés pour vérifier les opérations de sauvegarde ainsi que pour monter une sauvegarde de machine virtuelle, de sorte que les fichiers individuels puissent être copiés.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">Le clonage ONTAP Offloaded peut être appelé par les outils VMware, NetApp et tiers. Les clones déchargés sur ONTAP présentent plusieurs avantages. Elles sont peu gourmandes en espace dans la plupart des cas, et n'ont besoin que de systèmes de stockage pour modifier les objets. Cela n'a aucun impact supplémentaire sur les performances en lecture et en écriture. Dans certains cas, le partage des blocs dans des caches haute vitesse améliore les performances. Ils délester également le serveur ESXi de la charge des cycles CPU et des E/S réseau. Il est possible de décharger des copies dans un data store traditionnel grâce à un volume FlexVol, de manière rapide et efficace avec une licence FlexClone, mais les copies entre volumes FlexVol peuvent être plus lentes. Si vous maintenez les modèles de machine virtuelle comme source de clones, envisagez de les placer dans le volume du datastore (utilisez les dossiers ou les bibliothèques de contenu pour les organiser) afin de créer des clones rapides et compacts.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">Vous pouvez également cloner un volume ou une LUN directement au sein de ONTAP afin de cloner un datastore. Grâce aux datastores NFS, la technologie FlexClone peut cloner un volume entier. Le clone peut être exporté depuis ONTAP et monté par ESXi en tant qu'autre datastore. Pour les datastores VMFS, ONTAP peut cloner une LUN au sein d'un volume ou d'un volume complet, y compris une ou plusieurs LUN au sein de celle-ci. Une LUN contenant un VMFS doit être mappée sur un groupe d'initiateurs ESXi, puis une nouvelle signature définie par ESXi doit être montée et utilisée comme datastore standard. Pour certains cas d'utilisation temporaire, un VMFS cloné peut être monté sans nouvelle signature. Une fois le datastore cloné, les ordinateurs virtuels internes peuvent être enregistrés, reconfigurés et personnalisés comme s'ils étaient individuellement clonés.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">Dans certains cas, des fonctionnalités supplémentaires sous licence peuvent être utilisées pour améliorer le clonage, telles que SnapRestore pour la sauvegarde ou FlexClone. Ces licences sont souvent incluses dans les packs de licence sans frais supplémentaires. Une licence FlexClone est requise pour les opérations de clonage vvol et pour la prise en charge des copies Snapshot gérées d'un volume virtuel (qui sont déchargées de l'hyperviseur vers ONTAP). Une licence FlexClone peut également améliorer certains clones VAAI lorsqu'ils sont utilisés dans un datastore/volume (création de copies instantanées et compactes à la place de copies de bloc). Elle est également utilisée par SRA pour tester la restauration d'une réplique de reprise après incident et SnapCenter pour les opérations de clonage, et pour parcourir les copies de sauvegarde afin de restaurer des fichiers individuels.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">Efficacité du stockage et provisionnement fin</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp s'est élevé à la pointe de l'innovation en matière d'efficacité du stockage, avec notamment la première déduplication pour les charges de travail primaires et la compaction des données à la volée qui améliore la compression et stocke de façon efficace les petits fichiers et les E/S. ONTAP prend en charge la déduplication à la volée et en arrière-plan, ainsi que la compression à la volée et en arrière-plan.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">La figure suivante décrit l'effet combiné des fonctions d'efficacité du stockage ONTAP.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">Voici quelques recommandations sur l'utilisation de l'efficacité du stockage ONTAP dans un environnement vSphere :</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">Le volume des économies de déduplication de données réalisées dépend de la similarité des données. Avec ONTAP 9.1 et les versions antérieures, la déduplication des données était appliquée au niveau du volume, mais avec la déduplication de l'agrégat dans ONTAP 9.2 et versions ultérieures, les données sont dédupliquées entre tous les volumes d'un agrégat dans les systèmes AFF. Vous n'avez plus besoin de regrouper des systèmes d'exploitation similaires et des applications similaires au sein d'un même datastore afin d'optimiser les économies.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">Pour bénéficier des avantages de la déduplication dans un environnement de blocs, les LUN doivent être provisionnées à fin. Bien que la LUN soit toujours perçue par l'administrateur de la machine virtuelle en termes de capacité provisionnée, les économies de déduplication sont renvoyées vers le volume afin qu'il soit utilisé pour d'autres besoins. NetApp recommande de déployer ces LUN dans des volumes FlexVol qui également font l'objet d'un provisionnement fin (les outils ONTAP pour VMware vSphere dimensionnez le volume à environ 5 % plus grand que la LUN).</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">Le provisionnement fin est également recommandé (et constitue la valeur par défaut) pour les volumes NFS FlexVol. Dans un environnement NFS, les économies de déduplication sont immédiatement visibles pour les administrateurs du stockage et des machines virtuelles avec des volumes à provisionnement fin.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">Le provisionnement fin s'applique également aux machines virtuelles, où NetApp recommande généralement des VMDK à provisionnement fin plutôt qu'thick. Lors de l'utilisation du provisionnement fin, veillez à surveiller l'espace disponible à l'aide des outils ONTAP pour VMware vSphere, ONTAP ou d'autres outils disponibles afin d'éviter les problèmes de manque d'espace.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">Notez que le provisionnement fin avec les systèmes ONTAP n'a aucune incidence sur les performances. Les données sont écrites sur l'espace disponible de sorte que les performances d'écriture et de lecture sont optimisées. Malgré ce fait, certains produits tels que la mise en cluster de basculement Microsoft ou d'autres applications à faible latence peuvent nécessiter un provisionnement garanti ou fixe, et il est judicieux de suivre ces exigences pour éviter des problèmes de support.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">Pour des économies optimales, envisagez de planifier la déduplication en arrière-plan sur des systèmes sur disque dur ou la déduplication en arrière-plan automatique sur les systèmes AFF. Cependant, les processus planifiés utilisent des ressources système en cours d'exécution. De cette manière, idéalement, ils doivent être programmés pendant les heures moins actives (par exemple, les week-ends) ou d'être plus fréquemment exécutés afin de réduire la quantité de données modifiées à traiter. La déduplication automatique en arrière-plan sur les systèmes AFF a beaucoup moins d'impact sur les activités prioritaires. La compression en arrière-plan (pour les systèmes sur disque dur) consomme également des ressources. Elle doit donc être considérée uniquement pour les charges de travail secondaires dont les besoins de performances sont limités.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Article de la base de connaissances</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">Les systèmes AFF de NetApp utilisent principalement des fonctionnalités d'efficacité du stockage à la volée. Lorsque les données sont déplacées vers eux à l'aide des outils NetApp qui utilisent la réplication de blocs, tels que 7-mode transition Tool, SnapMirror ou Volume Move, il peut être utile d'exécuter des scanners de compression et de compaction en vue d'optimiser le gain d'efficacité. Consultez ce support NetApp<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">Les copies Snapshot peuvent verrouiller les blocs qui pourraient être réduits par la compression ou la déduplication. Lorsque vous utilisez l'efficacité en arrière-plan planifiée ou des scanners à usage unique, assurez-vous qu'ils s'exécutent et qu'ils sont terminés avant la prochaine copie Snapshot. Vérifiez les copies Snapshot et la conservation pour vous assurer que seules les copies Snapshot nécessaires sont conservées, en particulier avant l'exécution d'une tâche d'arrière-plan ou d'analyse.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">Le tableau suivant fournit des conseils en matière d'efficacité du stockage pour les charges de travail virtualisées sur différents types de stockage ONTAP :</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">Charge de travail</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">Recommandations en matière d'efficacité du stockage</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">Disques durs</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI et SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">Pour les charges de travail primaires et secondaires, utiliser :</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">Compression à la volée évolutive</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">Déduplication à la volée</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">Déduplication en arrière-plan</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">Compaction des données à la volée</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">Pour les charges de travail primaires, utiliser :</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">Pour les charges de travail secondaires, utiliser :</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">Compression adaptative en arrière-plan</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">La qualité de service (QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">Les systèmes qui exécutent le logiciel ONTAP peuvent utiliser la fonctionnalité de QoS du stockage de ONTAP pour limiter le débit en Mbit/s et/ou E/S par seconde (IOPS) pour différents objets de stockage tels que des fichiers, des LUN, des volumes, ou des SVM entiers.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">Les limites de débit permettent de contrôler les charges de travail inconnues ou de test avant le déploiement pour s'assurer qu'elles n'affectent pas les autres charges de travail. Elles peuvent également être utilisées pour contraindre une charge de travail dominante après son identification. Des niveaux minimaux de service basés sur des IOPS sont également pris en charge pour assurer des performances prévisibles pour les objets SAN d'ONTAP 9.2 et pour les objets NAS d'ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Avec un datastore NFS, une politique de qualité de services peut s'appliquer à tout le volume FlexVol ou à tous les fichiers VMDK de l'environnement IT. Avec les datastores VMFS utilisant des LUN ONTAP, les règles de QoS peuvent être appliquées au volume FlexVol contenant les LUN ou les LUN individuels, mais pas aux fichiers VMDK individuels, car ONTAP ne connaît pas le système de fichiers VMFS. Lors de l'utilisation de vvols, il est possible de définir une qualité de service minimale et/ou maximale sur des machines virtuelles individuelles en utilisant le profil de capacité de stockage et la règle de stockage des machines virtuelles.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">Le débit maximal de QoS sur un objet peut être défini en Mbit/s et/ou IOPS. Si les deux sont utilisés, la première limite atteinte est appliquée par ONTAP. Une charge de travail peut contenir plusieurs objets et une règle de QoS peut être appliquée à un ou plusieurs workloads. Lorsqu'une règle est appliquée à plusieurs workloads, celle-ci partage la limite totale de la règle. Les objets imbriqués ne sont pas pris en charge (par exemple, les fichiers d'un volume ne peuvent pas chacun avoir leur propre stratégie). La valeur minimale de qualité de service ne peut être définie que dans les IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Les outils suivants sont actuellement disponibles pour la gestion des règles de QoS de ONTAP et leur application aux objets :</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">INTERFACE DE LIGNE DE COMMANDES DE ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP System Manager</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit d'outils NetApp PowerShell pour ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Outils ONTAP pour VMware vSphere VASA Provider</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Pour affecter une politique de QoS à un VMDK sur NFS, suivez les consignes suivantes :</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La politique doit être appliquée au<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> qui contient l'image réelle du disque virtuel, pas le<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (fichier de descripteur de disque virtuel) ou<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (Fichier de descripteur de machine virtuelle).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">N'appliquez pas de règles aux autres fichiers VM tels que les fichiers d'échange virtuels <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Lors de l'utilisation du client Web vSphere pour trouver des chemins de fichiers (datastore &gt; fichiers), notez qu'il combine les informations de l'<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> et<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> et montre simplement un fichier avec le nom du<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> mais la taille du<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Autres<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> dans le nom du fichier pour obtenir le chemin correct.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Pour affecter une QoS à une LUN, y compris VMFS et RDM, le SVM ONTAP (affiché comme vServer), le chemin LUN et le numéro de série peuvent être obtenus du menu systèmes de stockage de la page d'accueil des outils ONTAP pour VMware vSphere. Sélectionner le système de stockage (SVM), puis les objets associés &gt; SAN. Utilisez cette approche lors de la spécification de QoS à l'aide de l'un des outils ONTAP.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">Il est possible de définir une qualité de service minimale et maximale facilement sur une machine virtuelle basée sur des volumes grâce aux outils ONTAP pour VMware vSphere ou Virtual Storage Console 7.1 et versions ultérieures. Lors de la création du profil de capacité de stockage pour le conteneur vVol, spécifiez une valeur d'IOPS max et/ou min sous la capacité de performances, puis référencez ce SCP avec la règle de stockage de la machine virtuelle. Utilisez cette règle lors de la création de la machine virtuelle ou appliquez-la à une machine virtuelle existante.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Les datastores FlexGroup offrent des fonctionnalités QoS améliorées lors de l'utilisation des outils ONTAP pour VMware vSphere 9.8 et versions ultérieures. Vous pouvez facilement définir la qualité de service sur toutes les machines virtuelles d'un datastore ou sur des machines virtuelles spécifiques. Consultez la section FlexGroup de ce rapport pour plus d'informations.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">QoS ONTAP et SIOC VMware</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">La QoS ONTAP et la fonctionnalité VMware vSphere Storage I/O Control (SIOC) sont des technologies complémentaires que les administrateurs vSphere et du stockage peuvent utiliser ensemble pour gérer les performances des VM vSphere hébergées sur des systèmes exécutant le logiciel ONTAP. Chaque outil a ses propres forces, comme le montre le tableau suivant. En raison des différents champs d'application de VMware vCenter et de ONTAP, certains objets peuvent être vus et gérés par un système et non par l'autre.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Propriété</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">QoS de ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">SIOC VMware</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Lorsqu'il est actif</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La règle est toujours active</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Actif en cas de conflit (latence du datastore supérieure au seuil)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Type d'unités</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mo/sec</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, partages</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Étendue vCenter ou des applications</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Plusieurs environnements vCenter, d'autres hyperviseurs et applications</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Un seul serveur vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">Définir la qualité de service sur la machine virtuelle ?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK sur NFS uniquement</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK sur NFS ou VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">Définir la qualité de service sur la LUN (RDM) ?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">Définir la QoS sur LUN (VMFS) ?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">Définir la qualité de service sur le volume (datastore NFS) ?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">Qualité de service définie sur un SVM (locataire) ?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">Approche basée sur des règles ?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Oui. Elles peuvent être partagées par toutes les charges de travail dans la règle ou appliquées en totalité à chaque charge de travail dans la règle.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Oui, avec vSphere 6.5 et versions ultérieures.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Licence requise</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Inclus avec ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise plus</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">Planificateur de ressources distribué de stockage VMware</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware Storage Distributed Resource Scheduler (SDRS) est une fonctionnalité vSphere qui place les machines virtuelles sur un stockage en fonction de la latence d'E/S actuelle et de l'utilisation de l'espace. Il déplace ensuite la machine virtuelle ou les VMDK sans interruption entre les datastores d'un cluster de datastores (également appelé pod), en sélectionnant le meilleur datastore pour placer la machine virtuelle ou les VMDK dans le cluster de datastore. Un cluster de datastores est un ensemble de datastores similaires qui sont agrégés dans une unité de consommation unique du point de vue de l'administrateur vSphere.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">Avec LES SDRS associés aux outils NetApp ONTAP pour VMware vSphere, vous devez d'abord créer un datastore avec le plug-in, utiliser vCenter pour créer le cluster de datastore, puis y ajouter le datastore. Une fois le cluster datastore créé, des datastores supplémentaires peuvent être ajoutés au cluster datastore directement à partir de l'assistant de provisionnement sur la page Détails.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Les autres meilleures pratiques ONTAP en matière DE SDRS sont les suivantes :</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Tous les datastores du cluster doivent utiliser le même type de stockage (SAS, SATA ou SSD, par exemple), être tous des datastores VMFS ou NFS et disposer des mêmes paramètres de réplication et de protection.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Envisagez d'utiliser DES DTS en mode par défaut (manuel). Cette approche vous permet d'examiner les recommandations et de décider s'il faut les appliquer ou non. Notez les effets suivants des migrations VMDK :</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Lorsque DES DTS déplacent des VMDK entre les datastores, les économies d'espace éventuelles obtenues grâce au clonage ou à la déduplication ONTAP sont perdues. Vous pouvez réexécuter la déduplication pour récupérer ces économies.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">Une fois QUE LES DTS ont déplacé les VMDK, NetApp recommande de recréer les copies Snapshot sur le datastore source, car l'espace est autrement verrouillé par la machine virtuelle qui a été déplacée.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Le déplacement des VMDK entre les datastores du même agrégat n'a que peu d'avantages et LES DTS n'ont pas de visibilité sur d'autres charges de travail qui pourraient partager l'agrégat.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">Gestion de stockage basée sur des règles et vVols</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">Les API VMware vSphere pour Storage Awareness (VASA) permettent à un administrateur du stockage de configurer des datastores avec des fonctionnalités bien définies et de permettre à l'administrateur des VM de les utiliser chaque fois que nécessaire pour provisionner des machines virtuelles sans avoir à interagir les unes avec les autres. Il est intéressant de considérer cette approche afin de voir comment elle peut rationaliser vos opérations de stockage de virtualisation et éviter de nombreuses tâches triviales.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Avant de procéder à VASA, les administrateurs des VM pouvaient définir des règles de stockage des VM, mais ils devaient travailler avec l'administrateur du stockage pour identifier les datastores appropriés, souvent à l'aide de la documentation ou des conventions de nom. Grâce à VASA, l'administrateur du stockage peut définir un éventail de fonctionnalités de stockage, notamment la performance, le Tiering, le chiffrement et la réplication. Un ensemble de capacités pour un volume ou un ensemble de volumes est appelé « profil de capacité de stockage » (SCP).</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">Le SCP prend en charge la qualité de service minimale et/ou maximale pour les données vVvols d'une machine virtuelle. La QoS minimale est prise en charge uniquement sur les systèmes AFF. Les outils ONTAP pour VMware vSphere comprennent un tableau de bord affichant des performances granulaires de machine virtuelle et une capacité logique pour vVvols sur les systèmes ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La figure suivante représente le tableau de bord des outils ONTAP pour VMware vSphere 9.8 vvols.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">Une fois le profil de capacité de stockage défini, il peut être utilisé pour provisionner les machines virtuelles à l'aide de la règle de stockage qui identifie ses exigences. Le mappage entre la stratégie de stockage de la machine virtuelle et le profil de capacité de stockage du datastore permet à vCenter d'afficher la liste des datastores compatibles à sélectionner. C'est ce que l'on appelle la gestion du stockage basée sur des règles.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">Vasa fournit la technologie permettant d'interroger le stockage et de renvoyer un ensemble de fonctionnalités de stockage vers vCenter. Les fournisseurs de VASA fournissent la traduction entre les API et les constructions du système de stockage et les API VMware que vCenter comprend. NetApp VASA Provider pour ONTAP est proposé dans le cadre des outils ONTAP pour la machine virtuelle de l'appliance VMware vSphere. Le plug-in vCenter fournit l'interface de provisionnement et de gestion des datastores vvol, ainsi que la possibilité de définir des profils de capacité de stockage (SCPS).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP prend en charge les datastores VMFS et NFS vvol. L'utilisation de vvols avec des datastores SAN apporte certains des avantages de NFS tels que la granularité au niveau des VM. Voici quelques meilleures pratiques à prendre en compte, et vous trouverez des informations supplémentaires dans le<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un datastore vvol peut être constitué de plusieurs volumes FlexVol sur plusieurs nœuds de cluster. L'approche la plus simple est un datastore unique, même si les volumes ont des capacités différentes. Grâce à la gestion du stockage basée sur des règles, un volume compatible est utilisé pour la machine virtuelle. Cependant, ces volumes doivent tous faire partie d'un seul SVM ONTAP et être accessibles via un seul protocole. Une LIF par nœud suffit pour chaque protocole. Évitez d'utiliser plusieurs versions de ONTAP dans un datastore vvol unique car les capacités de stockage peuvent varier d'une version à l'autre.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilisez les outils ONTAP pour le plug-in VMware vSphere pour créer et gérer des datastores vvol. En plus de gérer le datastore et son profil, il crée automatiquement un terminal de protocole permettant d'accéder aux vvols si nécessaire. Si les LUN sont utilisées, notez que les terminaux PE sont mappés à l'aide des ID de LUN 300 et supérieurs. Vérifiez que le paramètre système avancé de l'hôte ESXi est défini<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Autorise un ID de LUN supérieur à 300 (la valeur par défaut est 1,024). Pour ce faire, sélectionnez l'hôte ESXi dans vCenter, puis l'onglet configurer et Rechercher<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Dans la liste des paramètres système avancés.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">N'installez pas ni ne migrez de VASA Provider, vCenter Server (appliance ou base Windows), ou les outils ONTAP pour VMware vSphere lui-même vers un datastore vvols, car ils sont ensuite interdépendants et limitent votre capacité à les gérer en cas de panne de courant ou d'autre perturbation du data Center.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">Sauvegarder régulièrement la machine virtuelle de VASA Provider. Au moins, créez des copies Snapshot toutes les heures du data store traditionnel qui contient VASA Provider. Pour en savoir plus sur la protection et la restauration de VASA Provider, consultez cette section<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La figure suivante montre les composants de vvols.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migration et sauvegarde dans le cloud</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP permet également la prise en charge étendue du cloud hybride en fusionnant les systèmes de votre cloud privé sur site avec des capacités de cloud public. Voici quelques solutions clouds NetApp qui peuvent être utilisées en association avec vSphere :</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">*Cloud volumes.* NetApp Cloud Volumes Service pour AWS ou GCP et Azure NetApp Files pour ANF offrent des services de stockage gérés multi-protocoles hautes performances dans les principaux environnements de cloud public. Ils peuvent être utilisés directement par les invités de machine virtuelle VMware Cloud.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">*Cloud Volumes ONTAP.* le logiciel de gestion des données NetApp Cloud Volumes ONTAP permet de contrôler et de protéger les données et d'optimiser l'efficacité du stockage, tout en bénéficiant de la flexibilité du cloud de votre choix. Cloud Volumes ONTAP est un logiciel de gestion des données cloud basé sur le logiciel de stockage NetApp ONTAP. Utilisez-les conjointement avec Cloud Manager pour déployer et gérer des instances Cloud Volumes ONTAP avec vos systèmes ONTAP sur site. Profitez des fonctionnalités SAN NAS et iSCSI avancées grâce à la gestion unifiée des données, notamment les copies Snapshot et la réplication SnapMirror.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Services cloud.* utilisez Cloud Backup Service ou SnapMirror Cloud pour protéger les données des systèmes sur site qui utilisent un stockage de cloud public. Cloud Sync vous aide à migrer et à synchroniser vos données sur les systèmes NAS, les magasins d'objets et le stockage Cloud Volumes Service.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">Stockage d'un plus grand nombre de copies Snapshot de vos machines virtuelles</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">*FabricPool.* FabricPool offre un Tiering simple et rapide pour les données ONTAP. Les blocs non sollicités de copies Snapshot peuvent être migrés vers un magasin d'objets dans des clouds publics ou privés StorageGRID et sont automatiquement rappelés lors de l'accès aux données ONTAP. Vous pouvez également utiliser le Tier objet comme troisième niveau de protection pour les données déjà gérées par SnapVault. Cette approche peut vous permettre de<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> Sur les systèmes de stockage ONTAP primaires et/ou secondaires.</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* utilisez le stockage Software-defined NetApp pour étendre votre cloud privé sur Internet aux sites et bureaux distants, où vous pouvez utiliser ONTAP Select pour prendre en charge les services de blocs et de fichiers ainsi que les mêmes fonctionnalités de gestion de données vSphere que votre data Center d'entreprise.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">Lors de la conception de vos applications basées sur une VM, pensez à la mobilité future du cloud. Par exemple, plutôt que de placer les fichiers d'application et de données en même temps que les fichiers de données, utilisez une exportation LUN ou NFS distincte. Cela vous permet de migrer la machine virtuelle et les données séparément vers des services cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Chiffrement pour les données vSphere</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">Aujourd'hui, les exigences croissantes en matière de protection des données au repos sont liées au chiffrement. Bien que l’accent initial était mis sur l’information financière et sur la santé, il y a de plus en plus d’intérêt à protéger toutes les informations, qu’elles soient stockées dans des fichiers, des bases de données ou d’autres types de données.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">Les systèmes qui exécutent le logiciel ONTAP simplifient la protection de toutes les données au repos. NetApp Storage Encryption (NSE) utilise des lecteurs de disque à chiffrement automatique avec ONTAP pour protéger les données SAN et NAS. NetApp propose également NetApp Volume Encryption et NetApp Aggregate Encryption comme une approche logicielle simple pour le chiffrement des volumes sur tous les disques. Ce chiffrement logiciel ne nécessite pas de lecteurs de disque spéciaux ou de gestionnaires de clés externes et est disponible pour les clients ONTAP sans frais supplémentaires. Vous pouvez procéder à une mise à niveau et commencer à l'utiliser sans perturber vos clients ou applications. Elles sont validées par la norme FIPS 140-2 de niveau 1, y compris le gestionnaire de clés intégré.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Il existe plusieurs approches de protection des données des applications virtualisées qui s'exécutent sur VMware vSphere. L'une d'elles consiste à protéger les données avec les logiciels internes à la machine virtuelle au niveau du système d'exploitation invité. Les nouveaux hyperviseurs, tels que vSphere 6.5, prennent désormais en charge le cryptage au niveau des machines virtuelles. Cependant, le chiffrement logiciel NetApp est simple et facile :</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">*Aucun effet sur la CPU du serveur virtuel.* certains environnements de serveurs virtuels nécessitent chaque cycle CPU disponible pour leurs applications, mais les tests ont montré que jusqu'à 5x ressources CPU sont nécessaires avec le cryptage au niveau de l'hyperviseur. Même si le logiciel de chiffrement prend en charge les instructions AES-ni d'Intel pour décharger une charge de travail de chiffrement (comme le fait le chiffrement logiciel NetApp), cette approche peut ne pas être possible du fait de la nécessité de nouveaux processeurs non compatibles avec des serveurs plus anciens.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Gestionnaire de clés intégré inclus.* le chiffrement logiciel NetApp inclut un gestionnaire de clés intégré sans frais supplémentaires, ce qui simplifie les prises en main sans serveurs de gestion des clés haute disponibilité complexes à acheter et à utiliser.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*Aucun effet sur l'efficacité du stockage.* les techniques d'efficacité du stockage comme la déduplication et la compression sont largement utilisées aujourd'hui et sont essentielles pour exploiter les supports disque Flash de façon rentable. Toutefois, les données cryptées ne sont en général pas dédupliquées ou compressées. Le cryptage du stockage et du matériel NetApp fonctionne à un niveau inférieur et permet l'utilisation totale des fonctionnalités d'efficacité du stockage NetApp, contrairement aux autres approches.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Chiffrement granulaire simple des datastores.* avec NetApp Volume Encryption, chaque volume bénéficie de sa propre clé AES 256 bits. Si vous devez le modifier, utilisez une seule commande. Cette approche est idéale si vous disposez de plusieurs locataires ou si vous devez prouver votre chiffrement indépendant pour différents services ou applications. Ce chiffrement est géré au niveau du datastore, ce qui est bien plus simple que de gérer des machines virtuelles individuelles.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">Il est facile de commencer avec le chiffrement logiciel. Une fois la licence installée, il vous suffit de configurer le gestionnaire de clés intégré en spécifiant une phrase secrète, puis de créer un volume ou de déplacer un volume côté stockage pour activer le chiffrement. NetApp travaille à ajouter une prise en charge plus intégrée des fonctionnalités de cryptage dans les prochaines versions de ses outils VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager permet d'avoir une grande visibilité sur les machines virtuelles de votre infrastructure virtuelle et assure la surveillance et le dépannage des problèmes de stockage et de performances dans votre environnement virtuel.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Un déploiement d'infrastructure virtuelle standard sur ONTAP comporte divers composants répartis sur les couches de calcul, de réseau et de stockage. Tout ralentissement des performances dans une application VM peut survenir en raison de la combinaison de latences rencontrées par les différents composants au niveau des couches respectives.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La capture d'écran suivante présente la vue des machines virtuelles Active IQ Unified Manager.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager présente le sous-système sous-jacent d'un environnement virtuel dans une vue topologique afin de déterminer si un problème de latence a eu lieu dans le nœud de calcul, le réseau ou le stockage. La vue indique également l'objet spécifique qui provoque le décalage des performances lors de la réalisation des étapes correctives et de la résolution du problème sous-jacent.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La capture d'écran suivante montre la topologie étendue AIQUM.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp a développé un ensemble de paramètres de chemins d'accès multiples de l'hôte ESXi et de délai d'expiration de la carte HBA afin que son comportement soit correct avec ONTAP suite à des tests effectués par NetApp. Ils sont facilement configurés à l'aide des outils ONTAP pour VMware vSphere. Dans le tableau de bord Résumé, cliquez sur Modifier les paramètres dans le portlet systèmes hôtes ou cliquez avec le bouton droit de la souris sur l'hôte dans vCenter, puis accédez aux outils ONTAP &gt; définir les valeurs recommandées. Voici les paramètres d'hôte actuellement recommandés avec la version 9.8.</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Paramètres hôte*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valeur recommandée par NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Redémarrer requis*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configuration avancée ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAccélérationde la localisation</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">Laisser comme défini (la valeur par défaut de VMware est 1)</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">Laisser comme défini (la valeur par défaut de VMware est 0, mais elle n'est pas nécessaire pour VMFS6). Pour plus d'informations, voir <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Paramètres NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">Net.TcpipeHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 ou version ultérieure, défini sur 32. Toutes les autres configurations NFS, définies sur 30</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">Net.TcpipeHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Défini sur 512 Mo pour la plupart des versions vSphere 6.X. Défini sur 1024 Mo pour 6.5U3, 6.7U3 et 7.0 ou version ultérieure.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">VSphere 6.0 ou version ultérieure et 256 toutes les autres configurations NFS, définis sur 64.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6.0 ou version ultérieure, défini sur 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 ou version ultérieure, défini sur 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Définissez sur 10 pour l'ensemble des configurations NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Définissez sur 12 pour l'ensemble des configurations NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Définissez sur 5 pour l'ensemble des configurations NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">Sunrpc.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7.0 ou version ultérieure, défini sur 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Paramètres FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Stratégie de sélection de chemin</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Définissez-le sur RR (Round Robin) lorsque des chemins FC avec ALUA sont utilisés. Défini sur FIXE pour toutes les autres configurations. La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés. La valeur FIXÉE est pour les anciennes configurations non ALUA et contribue à empêcher les E/S proxy En d'autres termes, il contribue à empêcher les E/S de se diriger vers l'autre nœud d'une paire haute disponibilité dans un environnement doté de Data ONTAP 7-mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Définissez sur 32 pour toutes les configurations. La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Définissez sur 8 pour toutes les configurations. La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Délais d'expiration de la carte HBA FC Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Utilisez la valeur par défaut.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Délais de connexion HBA FC QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Paramètres iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Définissez à RR (Round Robin) pour tous les chemins iSCSI. La définition de cette valeur sur RR permet d'équilibrer la charge sur l'ensemble des chemins actifs/optimisés.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Définissez sur 32 pour toutes les configurations. La définition de cette valeur permet d'éviter les erreurs d'E/S.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1 : l'option de configuration avancée NFS MaxQueueDepth peut ne pas fonctionner comme prévu avec VMware vSphere ESXi 7.0.1 et VMware vSphere ESXi 7.0.2. Veuillez vous reporter à <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Lors de la création de volumes et de LUN ONTAP FlexVol, les outils ONTAP permettent également de spécifier certains paramètres par défaut :</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Outil ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Paramètre par défaut*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Réserve Snapshot (-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Réserve fractionnaire (-réserve fractionnaire)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Mise à jour de l'heure d'accès (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Faux</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Lecture minimum (-min-lecture anticipée)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">Copies Snapshot planifiées</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Efficacité du stockage</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Activé</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garantie de volume</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Aucune (provisionnement fin)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Taille automatique du volume</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">augmenter_réduire</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Réservation d'espace par LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Désactivé</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Allocation d'espace de la LUN</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">Autres considérations relatives à la configuration des chemins d'accès multiples des hôtes</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">Bien qu'elles ne soient pas configurées à l'heure actuelle par les outils ONTAP disponibles, NetApp suggère de prendre en compte les options de configuration suivantes :</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">Dans les environnements hautes performances ou lors des tests de performances avec un seul datastore LUN, envisagez de modifier le paramètre d'équilibrage de charge de la règle de sélection de chemin Round-Robin (VMW_PSP_RR) entre la valeur de 1000 IOPS par défaut et la valeur de 1. Voir VMware KB<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Plug-ins et règles de sélection de chemin</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">Dans vSphere 6.7 mise à jour 1, VMware a introduit un nouveau mécanisme d'équilibrage de la charge de latence pour la PSP Round Robin. La nouvelle option prend en compte la bande passante d'E/S et la latence de chemin lors de la sélection du chemin optimal pour les E/S. Il peut être bénéfique de l'utiliser dans des environnements dotés d'une connectivité de chemin non équivalente, comme les cas où il y a plus de sauts réseau sur un chemin que l'autre ou lors de l'utilisation d'un système de baie SAN de NetApp. Voir<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="10408567d24e2dd65731b1e2f0508a5d" category="doc">Plug-in NetApp SnapCenter pour VMware vSphere - critères requis pour la solution</block>
  <block id="0a70bb0111bccb302f68cc327b0527f8" category="inline-link-macro">Précédent : informations complémentaires - Plug-in SnapCenter pour VMware vSphere - déploiement.</block>
  <block id="dc69c4899210bca949880d9753e92b35" category="paragraph"><block ref="dc69c4899210bca949880d9753e92b35" category="inline-link-macro-rx"></block></block>
  <block id="8eaab69b7b060fb16ac9ba9484edb36e" category="inline-link-macro">Suivant - informations complémentaires - Plug-in SnapCenter pour VMware vSphere - Workflow de sauvegarde.</block>
  <block id="4602e4aeb078cfce115f5bcaf3d65ba7" category="paragraph"><block ref="4602e4aeb078cfce115f5bcaf3d65ba7" category="inline-link-macro-rx"></block></block>
  <block id="e7f47d4d003703cc37a3f472bf362522" category="doc">Plug-in NetApp SnapCenter pour VMware vSphere - Workflow de sauvegarde</block>
  <block id="b80c59ad5be93a14a5e884c9617272bd" category="inline-link-macro">Précédent : informations complémentaires - Plug-in SnapCenter pour VMware vSphere - conditions requises pour la solution.</block>
  <block id="b8c179b73c48ccf857c179c753fc7866" category="paragraph"><block ref="b8c179b73c48ccf857c179c753fc7866" category="inline-link-macro-rx"></block></block>
  <block id="7889fbe4fe01425f9ecdef9442f812b8" category="inline-link-macro">Suivant - informations complémentaires - Plug-in SnapCenter pour VMware vSphere - Restaurer le flux de travail.</block>
  <block id="907647e9678147c153e1b1f855122048" category="paragraph"><block ref="907647e9678147c153e1b1f855122048" category="inline-link-macro-rx"></block></block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">Les fonctionnalités ONTAP pour vSphere</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">Protocoles</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">Caractéristiques</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">De nombreuses fonctionnalités de ONTAP sont utiles pour la gestion des charges de travail virtualisées. Certains qui nécessitent des licences de produit supplémentaires sont décrits dans la section suivante. D'autres sont packagées en outils autonomes, certains pour ONTAP, etc. Pour l'ensemble de la gamme NetApp.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">Voici plus d'informations sur les fonctions de base de ONTAP :</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">*Efficacité du stockage.* ONTAP prend en charge la déduplication et la compression en arrière-plan et à la volée, la déduplication des blocs « zéro » et la compaction des données.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">*Déplacement de volumes et de LUN.* permet le déplacement sans interruption de volumes et de LUN prenant en charge les datastores vSphere et vvols au sein du cluster ONTAP afin d'équilibrer les performances et les capacités ou de prendre en charge la maintenance et les mises à niveau sans interruption.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">*QoS.* la qualité de service permet de gérer les performances d'une LUN, d'un volume ou d'un fichier individuel. Cette fonction peut être utilisée pour limiter une machine virtuelle inconnue ou dominante, ou pour garantir qu'une machine virtuelle importante obtient suffisamment de ressources de performance.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">*FabricPool.* cette fonctionnalité transfère automatiquement les données les plus utilisées au niveau du bloc vers un magasin d'objets distinct, ce qui permet de libérer un stockage Flash coûteux.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">Les API REST de ONTAP</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Modules Ansible</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">Licences ONTAP</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">Certaines fonctionnalités de ONTAP utiles pour la gestion des charges de travail virtualisées requièrent une licence supplémentaire, disponible sans frais supplémentaires, dans un bundle de licences ou à la carte. Pour de nombreux clients, l'approche la plus rentable consiste à disposer d'un pack de licences. Voici les licences clés pertinentes pour vSphere et comment elles sont utilisées :</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">*FlexClone.* FlexClone permet des clones instantanés et compacts des volumes et des fichiers ONTAP. Ce clonage est utilisé lors de la gestion des opérations sur le système de stockage par les API de stockage VMware vSphere – intégration de baies (VAAI), pour la vérification et la restauration des sauvegardes (logiciel SnapCenter), et pour le clonage de vvols et les copies Snapshot. Voici comment les utiliser :</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI est pris en charge par ONTAP pour les copies déchargées lors de la prise en charge des opérations de clonage et de migration vSphere (Storage vMotion). La licence FlexClone permet la création de clones rapides dans un volume NetApp FlexVol. Toutefois, s'il n'est pas sous licence, elle autorise toujours les clones à l'aide de copies de bloc plus lentes.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">Une licence FlexClone est requise pour la fonctionnalité vvols. Il permet le clonage de vvols dans un seul datastore ou entre datastores. Il permet également de réaliser des copies Snapshot gérées par vSphere de vvols, qui sont déchargées dans le système de stockage.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">L'adaptateur de réplication de stockage (SRA) est utilisé avec VMware site Recovery Manager, et une licence FlexClone est requise pour tester la reprise dans les environnements NAS et SAN. SRA peut être utilisé sans FlexClone pour les workflows de détection, de restauration et de reprotection.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">*SnapRestore.* la technologie SnapRestore permet de récupérer instantanément un volume sans copier de données. Elle est requise par les outils de sauvegarde et de restauration NetApp, tels que SnapCenter, où elle est utilisée pour monter le datastore pour les opérations de vérification et de restauration.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">*SnapMirror.* la technologie SnapMirror permet une réplication simple et rapide des données entre les systèmes ONTAP sur site et dans le cloud. SnapMirror prend en charge la flexibilité de version de la réplication logique avec les performances de la réplication bloc, en envoyant uniquement les données modifiées vers le système secondaire. Les données peuvent être protégées à l'aide de stratégies de mise en miroir et/ou de copie en miroir, ce qui permet la reprise après incident et la conservation à long terme des données pour la sauvegarde. SnapMirror prend en charge les relations asynchrones et synchrones, et ONTAP 9.8 introduit un basculement transparent des applications avec la continuité de l'activité SnapMirror.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror est requis pour la réplication de SRA avec site Recovery Manager. SnapCenter doit également permettre la réplication des copies Snapshot sur un système de stockage secondaire.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">*SnapCenter.* le logiciel SnapCenter fournit une plateforme unifiée et évolutive ainsi qu'une suite de plug-ins assurant la cohérence de la protection des données et de la gestion des clones au niveau des applications. Une licence SnapCenter est comprise dans les packs de licence de protection des données pour les systèmes AFF et FAS. Le plug-in SnapCenter pour VMware vSphere est un produit gratuit si vous utilisez les systèmes de stockage suivants : FAS, AFF, Cloud Volumes ONTAP ou ONTAP Select. Cependant, des licences SnapRestore et FlexClone sont requises.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">*MetroCluster.* NetApp MetroCluster est une solution de réplication synchrone qui associe haute disponibilité et reprise après incident dans un campus ou une zone métropolitaine, afin d'offrir une protection contre les incidents sur site et pannes matérielles. Il fournit des solutions avec une restauration transparente en cas de défaillance, sans perte de données (RPO 0) et une restauration rapide (RTO en quelques minutes). Il est utilisé dans les environnements vSphere dans le cadre d'une configuration vSphere Metro Storage Cluster.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">Outils de virtualisation pour ONTAP</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp propose plusieurs outils logiciels autonomes pouvant être utilisés avec ONTAP et vSphere pour gérer votre environnement virtualisé. Les outils suivants sont inclus avec la licence ONTAP sans frais supplémentaires. Voir la Figure 1 pour une description du fonctionnement de ces outils dans votre environnement vSphere.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figure suivante représente les outils ONTAP pour vSphere.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3b0a496a8cf35e38aa2e2195dec2f94" category="doc">Plug-in NetApp SnapCenter pour VMware vSphere - Restauration des flux de travail</block>
  <block id="eee0a010c96cd5f8a48024b64979138a" category="inline-link-macro">Précédent : informations complémentaires - Plug-in SnapCenter pour VMware vSphere - Workflow de sauvegarde.</block>
  <block id="db5a03b9e1de0d20dc54468940b207eb" category="paragraph"><block ref="db5a03b9e1de0d20dc54468940b207eb" category="inline-link-macro-rx"></block></block>
  <block id="5f01983db70d04ee21145e7d21902fb2" category="inline-link-macro">Suivant - informations complémentaires - Plug-in SnapCenter pour VMware vSphere - Workflow de restauration SQL.</block>
  <block id="724a2f2542f99df4a44d9ad7cfb15363" category="paragraph"><block ref="724a2f2542f99df4a44d9ad7cfb15363" category="inline-link-macro-rx"></block></block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">Cette page décrit les étapes du déploiement d'un datastore VMFS iSCSI pour le stockage NetApp ONTAP dans un environnement VMware vSphere.</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">Datastore VMFS vSphere - stockage iSCSI back-end avec ONTAP</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">Cette section décrit la création d'un datastore VMFS avec un stockage iSCSI ONTAP.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">Les compétences de base nécessaires à la gestion d'un environnement vSphere et d'ONTAP.</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">Informations relatives au port réseau ONTAP, au SVM et aux LUN pour iSCSI</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">Une fiche de configuration iSCSI remplie</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">Informations IP de l'adaptateur iSCSI VMKernel</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">Grâce aux ports de données du système ONTAP et aux hôtes vSphere connectés</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">VLAN(s) configurés(s) pour iSCSI</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">Vérifiez que la configuration iSCSI est prise en charge.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">Vérifiez la licence ONTAP pour iSCSI</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">Utilisez le<block ref="684590f66f47755afa88d3f70f9f25ad" prefix=" " category="inline-code"></block> Commande pour vérifier si iSCSI est répertorié.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">Utiliser<block ref="b7dcb36bf321df4a59507f6e4d0e13fb" prefix=" " category="inline-code"></block> pour ajouter la licence.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">Vérifier que le protocole iSCSI est activé sur le SVM</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">Vérifier que les interfaces logiques réseau iSCSI sont disponibles sur le SVM.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">Lorsqu'un SVM est créé via l'interface utilisateur graphique, les interfaces réseau iSCSI sont également créées.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">Utilisez le<block ref="ba500174804680d403063e56bca3cea6" prefix=" " category="inline-code"></block> commande pour afficher ou apporter des modifications à l'interface réseau.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">Deux interfaces réseau iSCSI par nœud sont recommandées.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">Créez une interface réseau iSCSI.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> Vous pouvez utiliser la stratégie de service blocs de données par défaut.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">Vérifiez que le service Data-iscsi est inclus dans la stratégie de service.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> Vous pouvez utiliser<block ref="4e5efd8167f08c488fa3bc6f718e7db8" prefix=" " category="inline-code"></block> à vérifier.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">Vérifiez que les trames Jumbo sont activées.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">Créer et mapper la LUN.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> Ignorez cette étape si vous utilisez les outils ONTAP pour VMware vSphere. Répétez cette procédure pour chaque LUN.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">Vérifiez qu'au moins une carte réseau est disponible pour le VLAN iSCSI. Deux cartes réseau sont à privilégier pour de meilleures performances et une meilleure tolérance aux pannes.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">Identifier le nombre de cartes réseau physiques disponibles sur l'hôte vSphere.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">Configurez l'initiateur iSCSI.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> Un cas d'utilisation typique est un initiateur iSCSI logiciel.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">Vérifiez que la pile TCPIP pour iSCSI est disponible</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">Vérifiez que les groupes de ports iSCSI sont disponibles</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">Nous utilisons généralement un seul commutateur virtuel avec plusieurs ports de liaison ascendante.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">Utilisez le mappage de carte 1:1.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">Vérifiez que les adaptateurs iSCSI VMKernel sont activés pour correspondre au nombre de cartes réseau et que les adresses IP sont attribuées.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">Reliez la carte logicielle iSCSI aux adaptateurs VMKernel iSCSI.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">Provisionnement du datastore VMFS avec les outils ONTAP</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. Répétez cette étape pour tous les datastores.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">Vérifier la prise en charge de l'accélération matérielle.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">Une fois ces tâches terminées, le datastore VMFS est prêt à utiliser pour le provisionnement des machines virtuelles.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">PlayBook Ansible</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">Le flux de travail de SRM est significativement différent lors de l'utilisation de la réplication vvols à partir de ce qui est utilisé avec SRA et les datastores traditionnels.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Dépannage de SRM lors de l'utilisation de la réplication de vvols</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">Le flux de travail de SRM est significativement différent lors de l'utilisation de la réplication vvols à partir de ce qui est utilisé avec SRA et les datastores traditionnels. Par exemple, il n'existe pas de concept de gestionnaire de baie. Comme c'est le cas,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> et<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> les commandes ne sont jamais vues.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Lors du dépannage, il est utile de comprendre les nouveaux flux de travail répertoriés ci-dessous :</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer : détecte les accords de réplication entre deux domaines de défaillance.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain : détecte la hiérarchie du domaine de pannes.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup : détecte les groupes de réplication présents dans les domaines source ou cible.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup : synchronise les données entre la source et la cible.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica : détecte le point dans le temps des répliques sur une cible.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart : démarre le basculement de test.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop : met fin au basculement de test.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup : promeut un groupe actuellement en cours de test à la production.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PreparFailoverReplicationTM : prépare une reprise après sinistre.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup : exécute la reprise après incident.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup : lance la réplication inverse.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer : recherche les conteneurs (ainsi que les hôtes ou les groupes de réplication) susceptibles de satisfaire une demande de provisionnement avec une règle donnée.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata : recherche les métadonnées de toutes les ressources du fournisseur VASA, l'utilisation des ressources peut être renvoyée comme réponse à la fonction queryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">L'erreur la plus courante lors de la configuration de la réplication vvols est une incapacité à découvrir les relations SnapMirror. En effet, les volumes et les relations SnapMirror sont créés en dehors de la purView des outils ONTAP. Il est donc recommandé de toujours s'assurer que votre relation SnapMirror est totalement initialisée et que vous avez exécuté une redécouverte dans les outils ONTAP sur les deux sites avant de tenter de créer un datastore vvols répliqué.</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">Cette page décrit les avantages de l'automatisation de la fonctionnalité ONTAP de base dans un environnement VMware vSphere.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">Introduction à l'automatisation pour ONTAP et vSphere</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">Automatisation avec VMware</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">Depuis les premiers jours de VMware ESX, l'automatisation fait partie intégrante de la gestion des environnements VMware. La possibilité de déployer une infrastructure en tant que code et d'étendre les pratiques aux opérations de cloud privé permet de réduire les problèmes liés à l'évolutivité, à la flexibilité, au provisionnement automatique et à l'efficacité.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">L'automatisation peut être organisée selon les catégories suivantes :</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">*Déploiement d'infrastructure virtuelle*</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">*Fonctionnement de la machine invité*</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">*Opérations dans le cloud*</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">Les administrateurs disposent de nombreuses options pour automatiser leur infrastructure. Qu'il s'agisse d'utiliser des fonctionnalités vSphere natives, telles que des profils d'hôtes ou des spécifications de personnalisation des machines virtuelles vers des API disponibles sur les composants logiciels VMware, les systèmes d'exploitation et les systèmes de stockage NetApp, la documentation et les conseils fournis sont considérables.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 et versions ultérieures prennent en charge certaines API VMware vSphere pour l'intégration de baies (VAAI) lorsque l'hôte ESX exécute ESX 4.1 ou une version ultérieure. VAAI est un ensemble d'API qui permettent la communication entre les hôtes VMware vSphere ESXi et les périphériques de stockage. Ces fonctionnalités permettent de décharger l'hôte ESX vers le système de stockage et d'augmenter le débit du réseau. L'hôte ESX active ces fonctionnalités automatiquement dans l'environnement adéquat. Vous pouvez déterminer dans quelle mesure votre système utilise des fonctions VAAI en consultant les statistiques contenues dans les compteurs VAAI.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">Le point de départ le plus courant pour l'automatisation du déploiement d'un environnement VMware consiste à provisionner des datastores basés sur des blocs ou des fichiers. Il est important de définir les exigences des tâches réelles avant de développer l'automatisation correspondante.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">Pour plus d'informations sur l'automatisation des environnements VMware, consultez les ressources suivantes :</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp Pub</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. Gestion et automatisation de la configuration NetApp.</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">Communauté Ansible Galaxy pour VMware</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. Ensemble de ressources Ansible pour VMware.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">Ressources VMware {code}</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. Ressources nécessaires à la conception de solutions pour le Software-Defined Data Center, y compris des forums, des normes de conception, des exemples de code et des outils de développement.</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">Introduction à ONTAP pour les administrateurs vSphere</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP simplifie les opérations de stockage et de gestion des données et complète distinctement les environnements VMware, que ce soit lors du déploiement sur site ou dans le cloud. Parmi les raisons qui ont poussé des dizaines de milliers de clients à choisir ONTAP comme solution de stockage pour les déploiements vSphere, on compte notamment la protection des données, des innovations en termes d'efficacité du stockage et des performances exceptionnelles dans les architectures VMware basées sur SAN et NAS.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp fournit de nombreux plug-ins, validations et qualifications VMware de différents produits VMware pour aider les clients confrontés aux défis uniques liés à l'administration d'un environnement de virtualisation. NetApp est destiné à la gestion du stockage et des données ce que VMware fait pour la virtualisation, ce qui permet aux clients de se concentrer sur leurs compétences principales plutôt que sur la gestion du stockage physique. Ce partenariat de près de 20 ans entre VMware et NetApp continue d'évoluer et d'apporter de la valeur ajoutée au client à mesure que de nouvelles technologies comme VMware Cloud Foundation et Tanzu émergent, tout en continuant à prendre en charge la base de vSphere.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">Principaux facteurs dont les clients sont :</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">*Stockage unifié*</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">*Efficacité du stockage*</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">*Volumes virtuels et gestion basée sur des stratégies de stockage*</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">*Cloud hybride*</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">Pour plus d'informations sur les solutions NetApp et VMware prises en charge, consultez les ressources suivantes :</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">Matrice d'interopérabilité NetApp</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). Le système IMT définit les composants et les versions qui peuvent être utilisés pour créer des configurations FC/FCoE, iSCSI, NFS et CIFS.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">Guide de compatibilité VMware</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. Le guide de compatibilité VMware répertorie la compatibilité système, E/S, stockage/SAN et sauvegarde avec les produits logiciels et infrastructures VMware</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">Outils NetApp ONTAP pour VMware</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. Les outils ONTAP pour VMware vSphere sont un plug-in vCenter Server unique, notamment les extensions VSC, VASA Provider et Storage Replication adapter (SRA).</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">Lancez-vous avec NetApp et VMware</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware sur NetApp : votre voyage commence ici !</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">Si vous êtes prêt à transformer votre environnement VMware, découvrez nos dernières solutions, nos dernières démonstrations de produits et nos dernières solutions techniques. Si vous êtes prêt à l'étape suivante, faites appel à la communauté d'experts NetApp et VMware pour vous aider à planifier et à mettre en œuvre la modernisation de votre data Center, le cloud hybride ou les initiatives des applications conteneurisées.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">Contactez</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">Vous ne savez pas par où commencer ? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> Membre des experts VMware de NetApp.</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">Format PDF</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">Le contenu présenté sur cette page est également disponible en téléchargement dans <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">lien=<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">Découvrez les solutions NetApp et VMware</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp &amp;amp ; VMware : une synergie optimale</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">Présentation de ONTAP 9.8 : dernières fonctionnalités</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">Utilisation du plug-in SnapCenter pour VMware vSphere</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">Redéfinir les performances de VMware avec NetApp et NVMe</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">Un monde peu performant et économique pour VMware Cloud sur AWS</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">Présentation de VMware Tanzu avec NetApp</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">Virtual Desktop Infrastructure (VDI) : mise à disposition à la demande des postes de travail des employés</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">VMware sur AWS : options d'architecture et de services</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">Programmation avec les API NetApp Cloud Volumes Service afin d'optimiser l'expérience AWS</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes : exécution de K8s sur vSphere et Tanzu</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">Créez votre Data Fabric virtualisé</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">Consultez nos dernières solutions NetApp pour VMware</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">VMware vSphere avec ONTAP : les solutions NetApp</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">Volumes virtuels VMware vSphere avec ONTAP</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">Conception et optimisation de la charge de travail NetApp NVMeoF VMware vSphere ; validation</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">Solution Flash moderne NVMeoF connectée au cloud de NetApp pour VMware &amp;amp ; SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">Accélérez votre transition vers Kubernetes avec VMware Tanzu &amp;amp ; ONTAP</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">Réduisez le coût d'exécution de VMware Cloud sur AWS</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">Découvrez les démonstrations vidéo des dernières solutions VMware</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">Meilleures pratiques pour VMware vSphere et NetApp ONTAP</block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">Exécutez-le sur NVMe-of avec ONTAP pour votre environnement VMware</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">VVvols reprise après incident avec les outils ONTAP et VMware SRM</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">Sauvegarde et restauration VMware pour l'environnement Data Fabric</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">Déployez une infrastructure flexible de cloud hybride et d'applications modernisées pour VMware</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">Vidéos</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">Architecture des datastores VMware sur les systèmes FAS 100 % Flash de NetApp</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">Migration de vos machines virtuelles VMware vers Google Cloud</block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">Déploiement d'un système de stockage persistant dynamique NetApp pour VMware Tanzu, partie 1</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">Déploiement d'un système de stockage persistant dynamique NetApp pour VMware Tanzu, 2e partie</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Déploiement d'un système de stockage persistant dynamique NetApp pour VMware Tanzu, partie 3</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">Blogs</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">VMware Cloud sur AWS : comment Fujitsu économise des millions grâce à CVO</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">Échangez avec les experts NetApp et VMware</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">Rejoignez le forum de discussion sur les solutions VMware</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">Contactez l'équipe NetApp Global Services pour commencer</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Bonnes pratiques de déploiement</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Disposition des SVM et segmentation pour la colocation sécurisée</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Avec ONTAP, le concept de machine virtuelle de stockage (SVM) offre une segmentation stricte dans les environnements mutualisés sécurisés. Les utilisateurs des SVM situés sur un SVM ne peuvent ni accéder aux ressources d'un autre ni les gérer. De cette façon, vous pouvez exploiter la technologie ONTAP en créant des SVM distincts pour différentes unités commerciales qui gèrent leurs propres flux de travail SRM sur le même cluster, pour une efficacité globale supérieure du stockage.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Envisagez de gérer ONTAP avec des comptes SVM-scoped et des LIF de management SVM pour non seulement améliorer les contrôles de sécurité, mais aussi améliorer les performances. Les performances sont supérieures par nature lorsque des connexions SVM-scoped sont utilisées, car SRA n'est pas nécessaire pour traiter toutes les ressources d'un cluster entier, y compris les ressources physiques. Il ne doit plutôt comprendre que les ressources logiques qui sont extraites vers la SVM particulière.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Si vous utilisez uniquement des protocoles NAS (pas d'accès SAN), vous pouvez même exploiter le nouveau mode optimisé NAS en définissant le paramètre suivant (notez que le nom est tel, car SRA et VASA utilisent les mêmes services back-end de l'appliance) :</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Connectez-vous au panneau de commande à<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Et cliquez sur interface de ligne de commande Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Lancer la commande<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Lancer la commande<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Lancer la commande<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Déployez des outils ONTAP et des considérations pour vvols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Si vous prévoyez d'utiliser SRM avec vvols, vous devez gérer le stockage à l'aide d'identifiants cluster-scoped et d'une LIF de cluster management. En effet, le fournisseur VASA doit comprendre l'architecture physique sous-jacente pour satisfaire aux exigences des règles de stockage des VM. Par exemple, si vous disposez d'une règle exigeant un stockage 100 % Flash, le fournisseur VASA doit pouvoir identifier les systèmes 100 % Flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Une autre meilleure pratique de déploiement est de ne jamais stocker votre appliance ONTAP Tools sur un datastore vvols qu'il gère. Cela peut entraîner une situation dans laquelle vous ne pouvez pas mettre le fournisseur VASA sous tension, car vous ne pouvez pas créer le vVol swap pour l'appliance, car l'appliance est hors ligne.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Meilleures pratiques pour la gestion des systèmes ONTAP 9</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">Comme mentionné précédemment, il est possible de gérer des clusters ONTAP avec des identifiants cluster ou SVM évalués et des LIF de gestion. Pour des performances optimales, il est possible que vous souhaitiez utiliser des informations d'identification SVM- scoped chaque fois que vous n'utilisez pas vVols. Cependant, ce faisant, vous devriez être conscient de certaines exigences, et que vous perdez certaines fonctionnalités.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">Le compte SVM vsadmin par défaut ne dispose pas du niveau d'accès requis pour effectuer les tâches des outils ONTAP Il faut donc créer un nouveau compte SVM.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">Si vous utilisez ONTAP 9.8 ou version ultérieure, NetApp vous recommande de créer un compte utilisateur avec contrôle d'accès basé sur les rôles (RBAC) minimum à l'aide du menu utilisateurs de ONTAP System Manager et du fichier JSON disponible sur votre appliance ONTAP Tools à l'adresse<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Utilisez votre mot de passe d'administrateur pour télécharger le fichier JSON. Il peut être utilisé pour les comptes évalués au niveau du SVM ou du cluster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Outils du site de support NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Si vous utilisez ONTAP 9.6 ou une version antérieure, vous devez utiliser l'outil Créateur d'utilisateurs RBAC (RUC) disponible dans le<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Le plug-in de l'interface utilisateur vCenter, VASA Provider et SRA Server étant tous des services entièrement intégrés, vous devez ajouter du stockage à l'adaptateur SRA dans SRM de la même manière que vous ajoutez du stockage dans l'interface utilisateur vCenter pour les outils ONTAP. Sinon, le serveur SRA pourrait ne pas reconnaître les requêtes envoyées depuis SRM via l'adaptateur SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">La vérification du chemin NFS n'est pas effectuée avec les identifiants évalués par SVM. Car l'emplacement physique est logiquement extrait du SVM. Cela ne pose pas de problème, car les systèmes ONTAP modernes ne subissent plus de déclin perceptible des performances lors de l'utilisation de chemins indirects.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Il est possible que les économies d'espace réalisées grâce à l'efficacité du stockage ne soient pas signalées.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Lorsqu'ils sont pris en charge, les miroirs de partage de charge ne peuvent pas être mis à jour.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Il est possible que la connexion EMS ne soit pas effectuée sur des systèmes ONTAP gérés avec des identifiants évalués par SVM.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">Provisionnement traditionnel du stockage bloc vSphere avec ONTAP</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere prend en charge les options de datastore VMFS suivantes avec la prise en charge du protocole SAN ONTAP indiquée.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">Options de datastore VMFS</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">Prise en charge du protocole SAN ONTAP</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">Fibre Channel (FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">oui</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">FCoE (Fibre Channel over Ethernet)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">Extensions iSCSI pour RDMA (iser)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">non</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe over Fabric avec FC (NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">NVMe over Fabric avec RDMA over Converged Ethernet (NVMe/RoCE)</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">Si iser ou NVMe/RoCE VMFS est requis, vérifiez les systèmes de stockage SANtricity.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Avec la transition de l'appliance virtuelle existante, les outils ONTAP apportent une richesse de nouvelles fonctionnalités, de limites plus élevées, et de la prise en charge de nouveaux vvols.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nouvelles fonctionnalités de SRM et des outils ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Dernières versions de vSphere et de site Recovery Manager</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">Avec la sortie de SRM 8.3 et versions ultérieures, ainsi que les versions 9.7.1 et ultérieures des outils ONTAP, vous pouvez désormais protéger des machines virtuelles exécutées sur VMware vSphere 7.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp a partagé un partenariat étroit avec VMware depuis près de deux décennies, et s'efforce de fournir une assistance pour les dernières versions dès que possible. Consultez toujours la matrice d'interopérabilité NetApp (IMT) pour connaître les dernières combinaisons logicielles qualifiées.</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT est disponible<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">Prise en charge de vVvols (et pourquoi SPBM compte, même avec SRM)</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">À partir de la version 8.3, SRM prend désormais en charge la gestion basée sur des règles de stockage (SPBM) de la réplication en exploitant vvols et la réplication basée sur la baie. Pour ce faire, le serveur SRM a été mis à jour afin d'inclure un nouveau service de fournisseur SRM vvols, qui communique avec le service SMS du serveur vCenter pour les tâches liées à VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">L'un des avantages de cette architecture est que SRA n'est plus nécessaire, car tout est géré à l'aide de VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM est un outil puissant dans la boîte à outils vSphere. Il permet de proposer des services de stockage cohérents, prévisibles et cohérents en fonction de la consommation dans les frameworks d'automatisation dans les environnements de cloud privé et hybride. Fondamentalement, grâce à la gestion des règles, vous pouvez définir des classes de service qui répondent aux besoins de votre base client diversifiée. SRM vous permet maintenant d'exposer des fonctionnalités de réplication à vos clients pour des charges de travail stratégiques qui nécessitent une orchestration et une automatisation fiables et standard de la reprise après incident.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">VVols Architecture 2.3 support pour serveurs SRM basés sur des appliances</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Les serveurs SRM basés sur le système d'exploitation de photons sont désormais pris en charge, en plus des plates-formes Windows existantes.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Vous pouvez maintenant installer des cartes SRA quel que soit votre type de serveur SRM préféré.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Prise en charge d'IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 est désormais pris en charge avec les limites suivantes :</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 ou version ultérieure</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">Non pris en charge avec SRM 8.2 (8.1, 8.3 et 8). 4 sont pris en charge)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Matrice d'interopérabilité</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Vérifier le<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> pour les dernières versions qualifiées.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Meilleures performances</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">La performance opérationnelle est une exigence clé pour l'exécution des tâches SRM. Deux ONTAP nouvelles améliorations ont été apportées à SRA et RPO pour respecter les exigences des RTO et RPO modernes.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Prise en charge des opérations de reprotection simultanées.* première introduction dans SRA 9.7.1, cette fonctionnalité vous permet d'exécuter la reprotection sur deux plans de reprise ou plus simultanément, ce qui réduit le temps nécessaire pour reprotéger les datastores après un basculement ou une migration et reste dans vos paramètres RTO et RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*ONTAP Tools 9.8 ajoute un nouveau mode optimisé pour le NAS uniquement.* lorsque vous utilisez des comptes SVM et des connexions aux clusters ONTAP avec uniquement des datastores basés sur NFS, vous pouvez activer le mode optimisé pour NAS uniquement pour des performances optimales dans les environnements pris en charge.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Évolutivité accrue</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">L'outil ONTAP SRA peut désormais prendre en charge jusqu'à 500 groupes de protection (PPG) lorsqu'il est utilisé avec SRM 8.3 et versions ultérieures.</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Réplication synchrone</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Une nouvelle fonctionnalité très attendue et très attendue est la version SnapMirror synchrone (SM-S) avec ONTAP 9.5 et versions ultérieures, qui offre une solution de réplication des données avec un RPO nul et granulaire pour vos applications stratégiques. SM-S requiert ONTAP Tools 9.8 ou version ultérieure.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Prise en charge des API REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configuration du serveur SRA peut désormais être gérée par les API REST. Une interface utilisateur swagger a été ajoutée pour vous aider à créer vos flux de travail d'automatisation. Elle est disponible sur votre appliance ONTAP Tools à l'adresse<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Akash Gupta, NetApp Girish Chanchlani, CommVault</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">Le rapport TR-4320 décrit l'architecture de référence et les bonnes pratiques relatives à l'utilisation d'un système de stockage NetApp E-Series dans un environnement de plateforme de données CommVault V11. CommVault et NetApp ont développé conjointement cette architecture de référence afin de guider les déploiements de CommVault Data Platform V11 avec le stockage NetApp E-Series qui accéléreront le délai d'application pour cette solution.</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta, NetApp Shawn Lieu (Amériques), Stefan Renner (EMEA) et Michael Cade (Performance), Veeam</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash Gupta et Principled technologies, NetApp</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">Le rapport TR-4704 décrit le déploiement de Veritas NetBackup sur un système de stockage NetApp E-Series.</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">Arvind Ramakrishnan, Abhinav Singh, NetApp</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">La certification NVA-1143 décrit comment NetApp HCI peut être conçu et déployé en vue de répondre aux exigences de contrôles de sécurité et de confidentialité du SP 800-53 de l'Institut national des normes et des technologies (NIST) 4, essentielles aux infrastructures de cloud privé et aux déploiements mutualisés.</block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">Échantillons de codage et de sortie d'AsciiDoc</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">Ce document contient quelques exemples de source asciidoc et de sortie obtenue.</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">Niveaux de cap</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[Souligné bleu]*Source AsciiDoc:*</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[Souligné bleu]*HTML généré:*</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">Niveau de cap 1 (titre de la section)</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">Niveau de cap 2 (titre de la section)</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">Niveau de cap 3 (titre de la section)</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">Niveau de cap 4 (titre de la section)</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">Niveau de cap 5 (titre de la section)</block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">Il ne doit y avoir qu'un titre de document (niveau 0) par document et les titres de section ne peuvent pas être ignorés (les sous-titres de section doivent être le niveau de titre suivant sous la section). Pour cette raison, l'échantillon n'est pas affiché dans la sortie pour éliminer les erreurs de construction pendant le traitement.</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">Listes</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">Liste non ordonnée :</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">il s'agit d'une liste non ordonnée</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">il s'agit toujours d'une liste non ordonnée</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">il s'agit d'un sous-élément dans une liste non ordonnée</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">Liste commandée :</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">il s'agit d'une liste ordonnée</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">il s'agit toujours d'une liste ordonnée</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">il s'agit d'un sous-élément dans une liste ordonnée</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">Images</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">Vous pouvez lier des images dans le référentiel ou n'importe où sur le Web. Pour les images dans le référentiel, elles sont placées dans le dossier multimédia. Vous devez donc vous assurer que le ":imagesdir: ./media/" est correctement défini.</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">Image dans le référentiel</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">Image en dehors du référentiel</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">Liens</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">Comme les images, les liens peuvent référencer des documents dans le référentiel ou n'importe où sur le Web. Pour les références internes, il est important de s'assurer que le chemin d'accès à la source du lien est spécifié dans l'instruction "link:".</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">Journal des modifications des solutions NetApp (interne)</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">Journal des modifications des solutions NetApp (externe)</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">Contenu pliable (alias Vingt-dix)</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">Titre</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">Le texte à réduire est ici.</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">Cliquez sur "titre" pour voir le contenu étendu</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">Création d'une table</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">Colonne A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">Colonne B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">Colonne C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">Texte de la colonne A</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">Texte dans la colonne B</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">Texte dans la colonne C</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">Voici un autre exemple où une ligne couvre l'ensemble de la table et où d'autres lignes ont des données réparties sur plusieurs colonnes :</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">Colonne d'en-tête 1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">Colonne d'en-tête 2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">Colonne d'en-tête 3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">Colonne d'en-tête 4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">Il s'agit d'une ligne très longue qui s'étend sur les 4 colonnes de la table. C'est la seule cellule de cette ligne et ne laisse aucune cellule vide.</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">Il s'agit d'une ligne longue qui s'étend sur 3 colonnes de la table en laissant une cellule vide.</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">Cette ligne s'étend sur 2 des colonnes et laisse 2 cellules vides.</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">C'est ça</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">rangée</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">est</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">normale</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">Documentation AsciiDoc</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">Il existe de nombreuses options que vous pouvez spécifier pour modifier la disposition d'une table. Pour plus d'informations, vous pouvez trouver un exemple dans le référentiel (version HTML) que vous souhaitez obtenir et vous rendre sur VScode pour afficher la source ou visiter le <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">Blocs à onglets</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">Premier onglet</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">Le contenu du premier onglet est ici</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">Deuxième onglet</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">Le contenu du second onglet est ici</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">Cliquez sur « second onglet » pour voir le contenu de cette section.</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">Les mentions légales donnent accès aux déclarations de copyright, aux marques, aux brevets, etc.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Mentions légales</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Droits d'auteur</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marques déposées</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, le logo NETAPP et les marques mentionnées sur la page des marques commerciales NetApp sont des marques commerciales de NetApp, Inc. Les autres noms de sociétés et de produits peuvent être des marques commerciales de leurs propriétaires respectifs.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Brevets</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Vous trouverez une liste actuelle des brevets appartenant à NetApp à l'adresse suivante :</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Politique de confidentialité</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Source ouverte</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">Les fichiers de notification fournissent des informations sur les droits d'auteur et les licences de tiers utilisés dans le logiciel NetApp.</block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">L'automatisation des solutions NetApp permet au client d'automatiser le déploiement, la configuration et l'exécution de nombreuses tâches d'infrastructure et d'applications courantes.</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">Commencer à utiliser l'automatisation des solutions NetApp</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">L'automatisation de la solution NetApp offre une simplicité et une reproductibilité pour la plupart des tâches courantes utilisées par les solutions NetApp.</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">Avant d'exécuter toute solution d'automatisation, l'environnement doit être configuré pour le mode d'exécution de l'automatisation. Il existe des options pour exécuter l'automatisation à partir de la ligne de commande ou à l'aide d'un outil tel qu'AWX ou tour.</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">Les sections suivantes présentent les étapes requises pour configurer l'environnement pour chacun des environnements spécifiés.</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="example-title">Configurez le nœud de contrôle Ansible pour les déploiements CLI sur RHEL/CentOS</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Exigences pour le nœud de contrôle Ansible, :</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">Un ordinateur RHEL/CentOS avec les packages suivants installés :</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">Python3</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">IPF3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible (version supérieure à 2.10.0)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">GIT</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">Si vous disposez d'un appareil RHEL/CentOS neuf sans les exigences ci-dessus, suivez les étapes ci-dessous pour configurer cette machine en tant que nœud de contrôle Ansible :</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">Activez le référentiel Ansible pour RHEL-8/RHEL-7</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">Pour RHEL-8 (exécutez la commande ci-dessous en tant que root)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">Pour RHEL-7 (exécutez la commande ci-dessous en tant que root)</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">Créez un fichier .sh</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">Collez le contenu ci-dessous dans le fichier</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">Rendre le fichier exécutable</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">Exécuter le script (en tant que root)</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="example-title">Configurer le nœud de contrôle Ansible pour les déploiements CLI sur Ubuntu/Debian</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">Une machine Ubuntu/Debian avec les paquets suivants installés :</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">Si vous avez une machine Ubuntu/Debian neuve sans les exigences ci-dessus, suivez les étapes ci-dessous pour configurer cette machine en tant que nœud de contrôle Ansible :</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="example-title">Configurer Ansible Tower ou AWX pour les déploiements Tower/AWX</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">Cette section décrit les étapes requises pour configurer les paramètres dans AWX/Ansible Tower qui préparent l'environnement pour l'utilisation des solutions automatisées NetApp.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">Configurer l'inventaire.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Accédez à Ressources → inventaires → Ajouter, puis cliquez sur Ajouter un inventaire.</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">Indiquez le nom et les détails de l'entreprise, puis cliquez sur Save.</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">Dans la page inventaires, cliquez sur les ressources d'inventaire que vous venez de créer.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">S'il existe des variables d'inventaire, collez-les dans le champ variables.</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">Accédez au sous-menu groupes et cliquez sur Ajouter.</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">Indiquez le nom du groupe, copiez les variables du groupe (si nécessaire), puis cliquez sur Enregistrer.</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">Cliquez sur le groupe créé, accédez au sous-menu hôtes et cliquez sur Ajouter un nouvel hôte.</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">Indiquez le nom d'hôte et l'adresse IP de l'hôte, collez les variables hôte (si nécessaire), puis cliquez sur Enregistrer.</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">Créer des types d'informations d'identification. Pour les solutions impliquant ONTAP, Element, VMware ou toute autre connexion de transport basée sur HTTPS, vous devez configurer le type d'informations d'identification pour qu'il corresponde aux entrées de nom d'utilisateur et de mot de passe.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Accédez à Administration → types d'informations d'identification et cliquez sur Ajouter.</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">Indiquez le nom et la description.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">Collez le contenu suivant dans la configuration d'entrée :</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">Collez le contenu suivant dans la configuration de l'injecteur :</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">Configurer les informations d'identification.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Accédez à Ressources → informations d'identification et cliquez sur Ajouter.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">Entrez le nom et les détails de l'organisation.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">Sélectionnez le type d'informations d'identification correct ; si vous souhaitez utiliser la connexion SSH standard, sélectionnez le type machine ou sélectionnez le type d'informations d'identification personnalisé que vous avez créé.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">Entrez les autres détails correspondants et cliquez sur Enregistrer.</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">Configurer le projet.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Accédez à Ressources → projets et cliquez sur Ajouter.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">Sélectionnez Git pour le type d'identification du contrôle source.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">Collez l'URL du contrôle source (ou l'URL du clone git) correspondant à la solution spécifique.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">Si l'URL Git est contrôlée par accès, créez et joignez les informations d'identification correspondantes dans les informations d'identification du contrôle source.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">Cliquez sur Enregistrer.</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">Configurez le modèle de travail.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Accédez à Ressources → modèles → Ajouter, puis cliquez sur Ajouter un modèle de travail.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">Entrez le nom et la description.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">Sélectionnez le type de travail ; Run configure le système en fonction d'un PlayBook et Check effectue une analyse sèche du PlayBook sans configurer le système.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Sélectionnez l'inventaire, le projet et les identifiants correspondant au PlayBook.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">Sélectionnez le PlayBook à exécuter comme partie du modèle de job.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">Généralement, les variables sont collées pendant l'exécution. Par conséquent, pour demander à l'invite de remplir les variables pendant l'exécution, assurez-vous de cocher la case demander au lancement correspondant au champ variable.</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">Indiquez tous les autres détails nécessaires, puis cliquez sur Enregistrer.</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">Lancez le modèle de travail.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">Accédez à Ressources → modèles.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">Cliquez sur le modèle souhaité, puis cliquez sur lancer.</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">Remplissez toutes les variables si vous y êtes invité au lancement, puis cliquez à nouveau sur lancer.</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">Cette page présente la méthode automatisée de déploiement de volumes NetApp sur des fournisseurs cloud (AWS, Azure, GCP) utilisant terraform.</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Cloud volumes Automation via Terraform</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">Cette solution décrit les déploiements automatisés de Cloud volumes sur AWS (CVO pour un nœud unique, CVO pour HA et FSX ONTAP) et Azure (CVO pour un nœud unique, CVO pour ANF) à l'aide de modules Terraform. Le code est disponible à l'adresse<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">Conditions préalables</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform &gt;= 0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Compte Cloud Manager</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">Compte fournisseur cloud – AWS, Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">Machine hôte (tout système d'exploitation pris en charge par Terraform)</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">Documentation du fournisseur</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">La documentation du fournisseur Terraform pour Cloud Manager est disponible à l'adresse suivante : <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">Contrôle de la version du fournisseur</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">Notez que vous pouvez également contrôler la version du fournisseur. Cela est contrôlé par un bloc required_Provider dans votre configuration Terraform.</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">La syntaxe est la suivante :</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">En savoir plus sur le contrôle de version du fournisseur.</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">Exécution de modules spécifiques</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="example-title">AWS</block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">Déploiement de nœud unique CVO</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp CVO (Cloud Volumes ONTAP) à un nœud unique sur AWS (Amazon Web Services).</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Documentation Terraform :<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">Pour exécuter le modèle :</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">Cloner le référentiel.</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">Accédez au dossier souhaité</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">Configurez les identifiants AWS à partir de l'interface de ligne de commandes.</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">ID de clé d'accès AWS [aucun] : clé d'accès</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">Clé d'accès secrète AWS [aucune] : clé secrète</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">Nom de la région par défaut [aucun] : US-West-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">Format de sortie par défaut [aucun] : json</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">Mettre à jour les valeurs de variable dans<block ref="138255b51837a8bb57dce615f0b58218" prefix=" " category="inline-code"></block></block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">Vous pouvez choisir de déployer le connecteur en définissant la valeur de la variable « aws_Connector_Deploy_bool » sur true/false.</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Initialisez le référentiel Terraform pour installer tous les éléments requis et préparer le déploiement.</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">Vérifiez les fichiers de formulaires à l'aide de la commande terraform validate.</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">Effectuez une exécution sèche de la configuration pour obtenir un aperçu de toutes les modifications attendues par le déploiement.</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">Exécuter le déploiement</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">Pour supprimer le déploiement</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph"><block ref="edf21d7ecb364e8210ddd3dfaeca6fbf" prefix="" category="inline-code"></block></block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">Variables Terraform pour l'instance de NetApp AWS Connector pour le déploiement CVO.</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">*Nom*</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">*Type*</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">*Description*</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">*aws_connector_deploy_bool*</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">BOOL</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">(Obligatoire) vérifier le déploiement des connecteurs.</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">*nom_connecteur_aws*</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">Chaîne</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">(Requis) le nom de Cloud Manager Connector.</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">*aws_connector_region*</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">(Obligatoire) région dans laquelle le connecteur Cloud Manager sera créé.</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">*aws_connector_key_name*</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">(Obligatoire) le nom de la paire de clés à utiliser pour l'instance de connecteur.</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">*aws_connector_company*</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">(Obligatoire) le nom de la société de l'utilisateur.</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">*aws_connector_instance_type*</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">(Requis) le type d'instance (par exemple, t3.XLarge). Au moins 4 CPU et 16 Go de mémoire sont nécessaires.</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">*aws_connector_subnet_id*</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">(Requis) ID du sous-réseau de l'instance.</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">*aws_connector_security_group_id*</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">(Obligatoire) l'ID du groupe de sécurité pour l'instance, plusieurs groupes de sécurité peuvent être fournis séparés par ','.</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">*aws_connector_iam_instance_profile_name*</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">(Obligatoire) le nom du profil d'instance pour le connecteur.</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">*aws_connector_account_id*</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">(Facultatif) l'ID de compte NetApp auquel le connecteur sera associé. S'il n'est pas fourni, Cloud Manager utilise le premier compte. Si aucun compte n'existe, Cloud Manager crée un nouveau compte. L'ID de compte est disponible dans l'onglet Account de Cloud Manager à l'adresse<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">*aws_connector_public_ip_bool*</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">(Facultatif) indique s'il faut associer une adresse IP publique à l'instance. S'il n'est pas fourni, l'association sera effectuée en fonction de la configuration du sous-réseau.</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph"><block ref="2642a0976dba96af7529d6e1d27bff5f" prefix="" category="inline-code"></block></block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">Variables Terraform pour une instance Cloud volumes ONTAP unique.</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">*nom_cvo*</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">(Obligatoire) le nom de l'environnement de travail Cloud Volumes ONTAP.</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">*cvo_region*</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">(Obligatoire) la région où l'environnement de travail sera créé.</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">*cvo_subnet_id*</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">(Obligatoire) ID de sous-réseau dans lequel l'environnement de travail sera créé.</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">*cvo_vpc_id*</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">(Facultatif) ID VPC dans lequel l'environnement de travail sera créé. Si cet argument n'est pas fourni, le VPC sera calculé à l'aide de l'ID de sous-réseau fourni.</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">*cvo_svm_password*</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">(Obligatoire) le mot de passe d'administration pour Cloud Volumes ONTAP.</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">*cvo_writing_speed_state*</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">(Facultatif) le réglage de la vitesse d'écriture pour Cloud Volumes ONTAP: ['NORMAL','ÉLEVÉ']. La valeur par défaut est 'NORMALE'.</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">Déploiement de CVO haute disponibilité</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp CVO (Cloud Volumes ONTAP) dans une paire haute disponibilité sur AWS (Amazon Web Services).</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">Mettre à jour les valeurs de variable dans<block ref="d8fbe289f1062e79a6ecf2cb41d4650c" prefix=" " category="inline-code"></block>.</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph"><block ref="c6f18f9568d343bc6accef19de501a79" prefix="" category="inline-code"></block></block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">Variables Terraform pour les instances NetApp CVO dans la paire HA.</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">*cvo_is_ha*</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">(Facultatif) indiquez si l'environnement de travail est une paire HA ou non [true, false]. La valeur par défaut est FALSE.</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">*cvo_node1_subnet_id*</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">(Requis) ID de sous-réseau dans lequel le premier nœud sera créé.</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">*cvo_node2_subnet_id*</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">(Requis) ID de sous-réseau dans lequel le second nœud sera créé.</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">*cvo_failover_mode*</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">(Facultatif) pour HA, le mode de basculement pour la paire HA : ['PrivateIP', 'FloatingIP']. 'PrivateIP' est pour une seule zone de disponibilité et 'FloatingIP' est pour plusieurs zones de disponibilité.</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">*cvo_mediator_subnet_id*</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">(Facultatif) pour HA, l'ID de sous-réseau du médiateur.</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">*cvo_médiateur_key_pair_name*</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">(Facultatif) pour HA, le nom de la paire de clés de l'instance médiateur est utilisé.</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">*cvo_cluster_flottant_ip*</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">(Facultatif) pour la HA FloatingIP, l'adresse IP flottante de gestion du cluster.</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">*cvo_data_floating_ip*</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">(Facultatif) pour la HA FloatingIP, l'adresse IP flottante des données.</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">*cvo_data_floating_ip2*</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">*cvo_svm_flottant_ip*</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">(Facultatif) pour HA FloatingIP, l'adresse IP flottante de gestion du SVM.</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">*cvo_route_table_id*</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">Liste</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">(Facultatif) pour HA FloatingIP, la liste des ID de table de routage qui seront mis à jour avec les adresses IP flottantes.</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">Déploiement FSX</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp ONTAP FSX sur AWS (Amazon Web Services).</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">Format de sortie par défaut [aucun] :</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">Mettre à jour les valeurs de variable dans<block ref="15f7e426a035ec7faf6715523364f143" prefix=" " category="inline-code"></block></block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">Variables Terraform pour l'instance de NetApp AWS Connector.</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph"><block ref="8fa643108c81bb359c39d110fa732b76" prefix="" category="inline-code"></block></block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">Variables Terraform pour l'instance NetApp ONTAP FSX</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">*fsx_name*</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">*fsx_region*</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">*fsx_primary_subnet_id*</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">(Obligatoire) ID de sous-réseau principal dans lequel l'environnement de travail sera créé.</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">*fsx_secondary_subnet_id*</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">(Obligatoire) ID de sous-réseau secondaire où l'environnement de travail sera créé.</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">*fsx_account_id*</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">(Requis) ID de compte NetApp auquel l'instance FSX sera associée. S'il n'est pas fourni, Cloud Manager utilise le premier compte. Si aucun compte n'existe, Cloud Manager crée un nouveau compte. L'ID de compte est disponible dans l'onglet Account de Cloud Manager à l'adresse<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">*fsx_workspace_id*</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">(Requis) ID de l'espace de travail Cloud Manager de l'environnement de travail.</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">*fsx_admin_password*</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">*fsx_débit_capacité*</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">(Facultatif) capacité du débit.</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">*fsx_storage_capacity_size*</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">(Facultatif) taille du volume EBS pour le premier agrégat de données. Pour GB, l'unité peut être : [100 ou 500]. Pour TB, l'unité peut être : [1,2,4,8,16]. La valeur par défaut est « 1 ».</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">*fsx_storage_capacity_size_unit*</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">(Facultatif) ['Go' ou 'To']. La valeur par défaut est 'TB'.</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">*fsx_cloudmanager_aws_identifiants_noms*</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">(Requis) Nom du compte d'informations d'identification AWS.</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="example-title">Azure</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer le volume ANF (Azure NetApp Files) sur Azure.</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Documentation Terraform :<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Connexion à votre interface de ligne de commandes Azure (vous devez installer l'interface de ligne de commandes Azure).</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">Mettre à jour les valeurs de variable dans<block ref="8c39601b8ab8961ff411cd5068a67f11" prefix=" " category="inline-code"></block>.</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">Vous pouvez choisir de déployer le volume ANF à l'aide d'un vnet et d'un sous-réseau existants en définissant la valeur "vnet_create_bool" et "subnet_create_bool" sur FALSE et en fournissant la valeur "subnet_ID_for_anf_vol". Vous pouvez également définir ces valeurs sur vrai et créer un nouveau vnet et un nouveau sous-réseau. Dans ce cas, l'ID de sous-réseau sera automatiquement pris à partir du sous-réseau nouvellement créé.</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">Variables Terraform pour un volume NetApp ANF unique.</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">*az_location*</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">(Obligatoire) indique l'emplacement Azure pris en charge où la ressource existe. La modification de cette option force la création d'une nouvelle ressource.</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">*az_prefix*</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">(Obligatoire) Nom du groupe de ressources dans lequel le volume NetApp doit être créé. La modification de cette option force la création d'une nouvelle ressource.</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">*az_vnet_address_space*</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">(Requis) l'espace d'adresse à utiliser par le vnet nouvellement créé pour le déploiement de volume ANF.</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">*az_subnet_address_prefix*</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">(Obligatoire) le préfixe de l'adresse de sous-réseau à utiliser par le vnet nouvellement créé pour le déploiement de volume ANF.</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">*az_volume_path*</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">(Requis) Un chemin de fichier unique pour le volume. Utilisé lors de la création de cibles de montage. La modification de cette option force la création d'une nouvelle ressource.</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">*az_capacity_pool_size*</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">Entier</block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">(Requis) taille de pool de capacité indiquée en To.</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">*az_vnet_creation_bool*</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">Booléen</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si vous souhaitez créer un nouveau vnet. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un vnet existant.</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">*az_subnet_creation_bool*</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> pour créer un nouveau sous-réseau. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un sous-réseau existant.</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">*az_subnet_id_for_anf_vol*</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">(Obligatoire) mentionnez l'ID de sous-réseau au cas où vous décidiez d'utiliser un sous-réseau existant en le définissant<block ref="1cceaecaa3b91a9f1e23ecb4681ce8af" prefix=" " category="inline-code"></block> à vrai. Si elle est définie sur FALSE, conservez-la à la valeur par défaut.</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">*az_netapp_pool_service_niveau*</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">(Requis) les performances cibles du système de fichiers. Les valeurs valides incluent<block ref="8d5e7e72f12067991186cdf3cb7d5d9d" prefix=" " category="inline-code"></block> ,<block ref="eb6d8ae6f20283755b339c0dc273988b" prefix=" " category="inline-code"></block> , ou<block ref="7057376a419b3334cc7b8b7a9f064abb" prefix=" " category="inline-code"></block>.</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">*az_netapp_vol_service_niveau*</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">*az_netapp_vol_protocol*</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">(Facultatif) le protocole du volume cible exprimé sous forme de liste. Une valeur unique prise en charge inclut<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, ou<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Si l'argument n'est pas défini, il est défini par défaut à<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Alors que vous modifiez cette configuration, la création d'une nouvelle ressource et la perte de données sont alors nécessaires.</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">*az_netapp_vol_security_style*</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">(Facultatif) le style de sécurité du volume, les valeurs acceptées sont<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> ou<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Si non fourni, le volume à protocole unique est créé par défaut à<block ref="6ec1bd1ea6a5d67a63b20c8f6172bddd" prefix=" " category="inline-code"></block> si c'est le cas<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block> ou<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block> volume, si<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>, elle est définie par défaut sur<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>. Dans un volume à double protocole, si ce n'est pas le cas, sa valeur sera<block ref="0984cd69051e659a6125cdff72c4996d" prefix=" " category="inline-code"></block>.</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">*az_netapp_vol_storage_quota*</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">(Requis) quota de stockage maximal autorisé pour un système de fichiers en gigaoctets.</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">Protection des données ANF</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer le volume ANF (Azure NetApp Files) avec Data protection sur Azure.</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">Mettre à jour les valeurs de variable dans<block ref="7faa6da7e229d163db53602f424f1f82" prefix=" " category="inline-code"></block>.</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph"><block ref="7bc40f4d4f846e8c7177d752ac52b775" prefix="" category="inline-code"></block></block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">Variables Terraform pour un volume ANF unique avec protection des données activée.</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">*az_alt_location*</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">(Requis) emplacement Azure dans lequel le volume secondaire sera créé</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">*az_vnet_primary_address_space*</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">(Requis) espace d'adresse à utiliser par le vnet nouvellement créé pour le déploiement de volume primaire ANF.</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">*az_vnet_secondary_address_space*</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">(Requis) l'espace d'adresse à utiliser par le vnet nouvellement créé pour le déploiement de volume secondaire ANF.</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">*az_subnet_primary_address_prefix*</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">(Requis) le préfixe de l'adresse de sous-réseau à utiliser par le vnet nouvellement créé pour le déploiement du volume primaire ANF.</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">*az_subnet_secondary_address_prefix*</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">(Requis) le préfixe de l'adresse de sous-réseau à utiliser par le vnet nouvellement créé pour le déploiement du volume secondaire ANF.</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">*az_volume_path_primary*</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">(Requis) Un chemin de fichier unique pour le volume primaire. Utilisé lors de la création de cibles de montage. La modification de cette option force la création d'une nouvelle ressource.</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">*az_volume_path_secondaire*</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">(Requis) Un chemin de fichier unique pour le volume secondaire. Utilisé lors de la création de cibles de montage. La modification de cette option force la création d'une nouvelle ressource.</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">*az_capacity_pool_size_primary*</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">*az_capacity_pool_size_secondary*</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">*az_vnet_primary_creation_bool*</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si vous souhaitez créer un nouveau vnet pour le volume primaire. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un vnet existant.</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">*az_vnet_secondary_creation_bool*</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> si vous souhaitez créer un nouveau vnet pour le volume secondaire. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un vnet existant.</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">*az_subnet_primary_creation_bool*</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> pour créer un nouveau sous-réseau pour le volume primaire. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un sous-réseau existant.</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">*az_subnet_secondary_creation_bool*</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">(Obligatoire) définissez ce booléen sur<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> pour créer un nouveau sous-réseau pour le volume secondaire. Réglez-le sur<block ref="68934a3e9455fa72420237eb05902327" prefix=" " category="inline-code"></block> pour utiliser un sous-réseau existant.</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">*az_primary_subnet_id_for_anf_vol*</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">(Obligatoire) mentionnez l'ID de sous-réseau au cas où vous décidiez d'utiliser un sous-réseau existant en le définissant<block ref="4480e01b6ddc0f64d89a995dcbd413f6" prefix=" " category="inline-code"></block> à vrai. Si elle est définie sur FALSE, conservez-la à la valeur par défaut.</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">*az_secondary_subnet_id_for_anf_vol*</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">(Obligatoire) mentionnez l'ID de sous-réseau au cas où vous décidiez d'utiliser un sous-réseau existant en le définissant<block ref="963bc6d7f5ebc59003b8ef8f3f92a02c" prefix=" " category="inline-code"></block> à vrai. Si elle est définie sur FALSE, conservez-la à la valeur par défaut.</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">*az_netapp_pool_service_niveau_principal*</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">*az_netapp_pool_service_niveau_secondaire*</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">*az_netapp_vol_service_niveau_principal*</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">*az_netapp_vol_service_niveau_secondaire*</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">*az_netapp_vol_protocol_primary*</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">*az_netapp_vol_protocol_secondary*</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">*az_netapp_vol_storage_quota_primary*</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">*az_netapp_vol_storage_quota_secondary*</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">*az_dp_replication_fréquence*</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">(Obligatoire) fréquence de réplication, les valeurs prises en charge sont<block ref="3602ffca95e52ce3f66ae1c6de108997" prefix=" " category="inline-code"></block>,<block ref="745fd0ea7f576f350a0eed4b8c48a8e2" prefix=" " category="inline-code"></block>,<block ref="bea79186fd7af2da67e59b4b15df5a26" prefix=" " category="inline-code"></block>, les valeurs sont sensibles à la casse.</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">Protocole double ANF</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer le volume ANF (Azure NetApp Files) avec un double protocole activé sur Azure.</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">Mettre à jour les valeurs de variable dans<block ref="b81cd75a858f9c9f13b2c366b4254eea" prefix=" " category="inline-code"></block>.</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">Variables Terraform pour un volume ANF unique avec un double protocole activé.</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">*az_netapp_vol_protocol1*</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">(Requis) le protocole du volume cible exprimé sous forme de liste. Une valeur unique prise en charge inclut<block ref="c6546b53840ec8245dd4d4d70fcdbc26" prefix=" " category="inline-code"></block>,<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>, ou<block ref="de841868c2911da76b8ae2da9fa3166d" prefix=" " category="inline-code"></block>. Si l'argument n'est pas défini, il est défini par défaut à<block ref="5b12ee0369243579651edca43ff65c85" prefix=" " category="inline-code"></block>. Alors que vous modifiez cette configuration, la création d'une nouvelle ressource et la perte de données sont alors nécessaires.</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">*az_netapp_vol_protocol2*</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">*az_smb_server_username*</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">(Obligatoire) Nom d'utilisateur pour créer un objet ActiveDirectory.</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">*az_smb_server_password*</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">(Obligatoire) Mot de passe utilisateur pour créer un objet ActiveDirectory.</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">*az_smb_server_name*</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">(Obligatoire) Nom du serveur pour créer un objet ActiveDirectory.</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">*az_smb_dns_server*</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">(Requis) adresse IP du serveur DNS pour créer un objet ActiveDirectory.</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">Volume ANF à partir de copies Snapshot</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer des volumes ANF (Azure NetApp Files) à partir de Snapshot sur Azure.</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">Mettre à jour les valeurs de variable dans<block ref="ef9d672e94eee49d10d74f858a44d14f" prefix=" " category="inline-code"></block>.</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">Variables Terraform pour un volume ANF unique à l'aide des snapshots.</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">*az_snapshot_id*</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">(Requis) ID Snapshot utilisant le nouveau volume ANF à créer.</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer Cloud volumes ONTAP (Cloud Volumes ONTAP) à un seul nœud sur Azure.</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">Mettez à jour les variables dans<block ref="094639eff38e0172690a0fb13cd97348" prefix=" " category="inline-code"></block>.</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">Variables Terraform pour Cloud Volumes ONTAP à un seul nœud (CVO).</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">*refresh_token*</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">(Requis) le jeton d'actualisation de NetApp Cloud Manager. Ceci peut être généré à partir de netapp Cloud Central.</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">*az_connector_name*</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">*az_connector_location*</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">(Requis) l'emplacement de création du connecteur Cloud Manager.</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">*az_connector_subscription_id*</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">(Obligatoire) ID de l'abonnement Azure.</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">*az_connector_company*</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">*az_connector_resource_group*</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">(Requis) le groupe de ressources dans Azure où les ressources seront créées.</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">*az_connector_subnet_id*</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">(Obligatoire) le nom du sous-réseau de la machine virtuelle.</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">*az_connector_vnet_id*</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">(Obligatoire) le nom du réseau virtuel.</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">*az_connector_network_security_group_name*</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">(Obligatoire) le nom du groupe de sécurité de l'instance.</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">*az_connector_associate_public_ip_address*</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">(Obligatoire) indique s'il faut associer l'adresse IP publique à la machine virtuelle.</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">*az_connector_account_id*</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">(Requis) l'ID de compte NetApp auquel le connecteur sera associé. S'il n'est pas fourni, Cloud Manager utilise le premier compte. Si aucun compte n'existe, Cloud Manager crée un nouveau compte. L'ID de compte est disponible dans l'onglet Account de Cloud Manager à l'adresse<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">*az_connector_admin_password*</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">(Obligatoire) le mot de passe du connecteur.</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">*az_connector_admin_username*</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">(Obligatoire) le nom d'utilisateur du connecteur.</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">*az_cvo_name*</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">*az_cvo_location*</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">(Obligatoire) l'emplacement où l'environnement de travail sera créé.</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">*az_cvo_subnet_id*</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">(Requis) Nom du sous-réseau pour le système Cloud Volumes ONTAP.</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">*az_cvo_vnet_id*</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">*az_cvo_vnet_resource_group*</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">(Requis) le groupe de ressources dans Azure associé au réseau virtuel.</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">*az_cvo_data_encryption_type*</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">(Obligatoire) le type de cryptage à utiliser pour l'environnement de travail : <block ref="71335a48a021ae2aeb7df636ba3d2483" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. La valeur par défaut est<block ref="71335a48a021ae2aeb7df636ba3d2483" prefix=" " category="inline-code"></block>.</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">*az_cvo_storage_type*</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">(Requis) le type de stockage du premier agrégat de données : <block ref="31034b38323b8bba82b33017ce6c13ff" prefix="[" category="inline-code"></block>,<block ref="410e42479a4a7cfdbe16e3e285d05598" prefix=" " category="inline-code"></block>,<block ref="2d641bc6cd6c1342dced281e583a3993" prefix=" " category="inline-code"></block>]. La valeur par défaut est<block ref="31034b38323b8bba82b33017ce6c13ff" prefix=" " category="inline-code"></block></block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">*az_cvo_svm_password*</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">*az_cvo_workspace_id*</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">(Requis) ID de l'espace de travail Cloud Manager dans lequel vous souhaitez déployer Cloud Volumes ONTAP. S'il n'est pas fourni, Cloud Manager utilise le premier espace de travail. Vous trouverez l'ID dans l'onglet espace de travail sur<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">*az_cvo_capacity_tier*</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">(Requis) activation ou non du Tiering des données pour le premier agrégat de données : <block ref="e8016c85ada38bdc5fac616ec1318047" prefix="[" category="inline-code"></block>,<block ref="b50339a10e1de285ac99d4c3990b8693" prefix=" " category="inline-code"></block>]. La valeur par défaut est<block ref="1649cff06611a6025da3dd511a97fb43" prefix=" " category="inline-code"></block>.</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">*az_cvo_writing_speed_state*</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">(Requis) paramètre de vitesse d'écriture pour Cloud Volumes ONTAP : <block ref="1e23852820b9154316c7c06e2b7ba051" prefix="[" category="inline-code"></block> ,<block ref="b89de3b4b81c4facfac906edf29aec8c" prefix=" " category="inline-code"></block>]. La valeur par défaut est<block ref="1e23852820b9154316c7c06e2b7ba051" prefix=" " category="inline-code"></block>. Cet argument n'est pas pertinent pour les paires haute disponibilité.</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">*az_cvo_ontap_version*</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">(Requis) la version ONTAP requise. Ignoré si la valeur 'use_latest_version' est définie sur TRUE. La valeur par défaut est d'utiliser la dernière version.</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">*az_cvo_instance_type*</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">(Obligatoire) le type d'instance à utiliser, qui dépend du type de licence que vous avez choisi : explore :<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard :<block ref="3e47288b0119e2f8cd128c5c1feb02e1" prefix="[" category="inline-code"></block>], Prime :<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block><block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix="," category="inline-code"></block>], BYOL : tous les types d'instances définis pour PayGo. Pour plus d'instances prises en charge, reportez-vous aux notes de version de Cloud Volumes ONTAP. La valeur par défaut est<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">*az_cvo_license_type*</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">(Obligatoire) le type de licence à utiliser. Pour un seul nœud : <block ref="47dfc9e0cae8289642a649a3d4b6f07f" prefix="[" category="inline-code"></block>,<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>,<block ref="fda853806a97d134c59567534d1aabe6" prefix=" " category="inline-code"></block>,<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block>,<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block>]. Pour la haute disponibilité : <block ref="18099bc4697504c468dd18adf279ac68" prefix="[" category="inline-code"></block>,<block ref="87d3f1b34e654923bcf9bc3b1b740e47" prefix=" " category="inline-code"></block>,<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block>,<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block>]. La valeur par défaut est<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Utiliser<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> ou<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Pour la haute disponibilité lors de la sélection, apportez votre propre type de licence basée sur la capacité ou Freemium. Utiliser<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> ou<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Pour la haute disponibilité lors de la sélection, indiquez votre propre type de licence, sur la base du nœud.</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">*az_cvo_nss_account*</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">(Requis) ID de compte du site de support NetApp à utiliser avec ce système Cloud Volumes ONTAP. Si le type de licence est BYOL et qu'un compte NSS n'est pas fourni, Cloud Manager tente d'utiliser le premier compte NSS existant.</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">*az_tenant_id*</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">(Obligatoire) ID de locataire du principal de demande/service enregistré dans Azure.</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">*az_application_id*</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">(Obligatoire) ID de demande du principal de demande/service enregistré dans Azure.</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">*az_application_key*</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">(Requis) la clé de demande du principal de demande/service enregistré dans Azure.</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer CVO (Cloud Volumes ONTAP) HA (haute disponibilité) sur Azure.</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">Mettez à jour les variables dans<block ref="3bdb269db9a3f1a5b57521aa62658bf3" prefix=" " category="inline-code"></block>.</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph"><block ref="a82b90469ebb90af122c361dbb754fd8" prefix="" category="inline-code"></block></block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">Variables Terraform pour la paire HA Cloud Volumes ONTAP (CVO).</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">(Obligatoire) le type d'instance à utiliser, qui dépend du type de licence que vous avez choisi : explore :<block ref="ca3fc7c5e09a3c4fa0f4881f15167411" prefix="[" category="inline-code"></block>], Standard :<block ref="a23549be3ebc980aebe6cb120ab4e310" prefix="[" category="inline-code"></block>], Prime :<block ref="9985a34952917c6a4f0d465c59bb32e6" prefix="[" category="inline-code"></block>,<block ref="7ccab40e6fc8df111c44d0d3a37df667" prefix=" " category="inline-code"></block>], BYOL : tous les types d'instances définis pour PayGo. Pour plus d'instances prises en charge, reportez-vous aux notes de version de Cloud Volumes ONTAP. La valeur par défaut est<block ref="a6f80faf58b4f8e337246cea4f984fc6" prefix=" " category="inline-code"></block> .</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">(Obligatoire) le type de licence à utiliser. Pour un seul nœud : <block ref="3abe68da9038e8e4aabc1b0e2a6530cc" prefix="[" category="inline-code"></block>]. Pour la haute disponibilité : <block ref="86e0c1bceadb9c08ef223996a3e33d86" prefix="[" category="inline-code"></block>]. La valeur par défaut est<block ref="6d7fd627acad65b22bc5bee7e03283c0" prefix=" " category="inline-code"></block>. Utiliser<block ref="f87643778357d753d17f33bd44952668" prefix=" " category="inline-code"></block> ou<block ref="709b724f9fdb1c96f55d9192b5be7a3f" prefix=" " category="inline-code"></block> Pour la haute disponibilité lors de la sélection, apportez votre propre type de licence basée sur la capacité ou Freemium. Utiliser<block ref="371b5a766fa14dc8d36c07dc53ec816c" prefix=" " category="inline-code"></block> ou<block ref="6db401109bfb00cf3ddd45edfbf1ecc0" prefix=" " category="inline-code"></block> Pour la haute disponibilité lors de la sélection, indiquez votre propre type de licence, sur la base du nœud.</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="example-title">GCP</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp CVO (Cloud Volumes ONTAP) à un nœud unique sur GCP (Google Cloud Platform).</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">Enregistrez le fichier JSON de clés d'authentification GCP dans le répertoire.</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">Mettre à jour les valeurs de variable dans<block ref="0635645653586768460c826b4f319a80" prefix=" " category="inline-code"></block></block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">Vous pouvez choisir de déployer le connecteur en définissant la valeur de la variable "gcp_Connector_Deploy_bool" sur true/false.</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">Variables Terraform pour l'instance NetApp GCP Connector pour le déploiement CVO.</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">*gcp_connector_deploy_bool*</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">*nom_connecteur_gcp*</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">*gcp_connector_project_id*</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">(Requis) ID_projet GCP dans lequel le connecteur sera créé.</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">*gcp_connector_zone*</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">(Obligatoire) zone GCP dans laquelle le connecteur sera créé.</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">*gcp_connector_company*</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">*gcp_connector_service_account_email*</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">(Obligatoire) l'e-mail du compte service pour l'instance de connecteur. Ce compte de service permet au connecteur de créer Cloud Volume ONTAP.</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">*gcp_connector_service_account_path*</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">(Requis) le chemin d'accès local du fichier JSON de compte_service pour l'autorisation GCP. Ce compte de service permet de créer le connecteur dans GCP.</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">*gcp_connector_account_id*</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">(Facultatif) l'ID de compte NetApp auquel le connecteur sera associé. S'il n'est pas fourni, Cloud Manager utilise le premier compte. Si aucun compte n'existe, Cloud Manager crée un nouveau compte. L'ID de compte est disponible dans l'onglet Account de Cloud Manager à l'adresse<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">Variables Terraform pour une instance NetApp CVO sur GCP</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">*gcp_nom_cvo*</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">*gcp_cvo_project_id*</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">(Requis) l'ID du projet GCP.</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">*gcp_cvo_zone*</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">(Obligatoire) la zone de la région où l'environnement de travail sera créé.</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">*gcp_cvo_gcp_service_account*</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">(Obligatoire) l'e-mail gcp_service_Account pour activer le Tiering des données inactives vers Google Cloud Storage.</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">*gcp_cvo_svm_password*</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">*gcp_cvo_workspace_id*</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">(Facultatif) l'ID de l'espace de travail Cloud Manager dans lequel vous souhaitez déployer Cloud Volumes ONTAP. S'il n'est pas fourni, Cloud Manager utilise le premier espace de travail. Vous trouverez l'ID dans l'onglet espace de travail sur<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">*gcp_cvo_license_type*</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">(Facultatif) le type de licence à utiliser. Pour le nœud unique : [« Capacity-paygo », « gcp-cot-explorer-paygo », « gcp-lit-standard-paiement à l'utilisation », « gcp-lit-premium-paygo », « gcp-lit-premium-byol »], Pour les systèmes HA : [« ha-Capacity-paygo », « gcp-ha-cot-explorer-paygo », « gcp-ha-cot-standard-paygo », « gcp-ha-cot-premium-paygo », « gcp-ha-cot-premium-byol »]. La valeur par défaut est « Capacity-paygo » pour un seul nœud et « HA-Capacity-paygo » pour HA.</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">*gcp_cvo_capacity_package_name*</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">(Facultatif) le nom du paquet de capacité : ['Essential', 'Professional', 'Freemium']. La valeur par défaut est « essentiel ».</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp CVO (Cloud Volumes ONTAP) dans une paire haute disponibilité sur GCP (Google Cloud Platform).</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">Mettre à jour les valeurs de variable dans<block ref="aca245204ab77411a71da01b8d6ec7cb" prefix=" " category="inline-code"></block>.</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">Variables Terraform pour les instances NetApp CVO dans paire HA sur GCP</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">*gcp_cvo_is_ha*</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">*gcp_cvo_node1_zone*</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">(Facultatif) zone pour le nœud 1.</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">*gcp_cvo_node2_zone*</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">(Facultatif) zone pour le nœud 2.</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">*gcp_cvo_zone_médiateur*</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">(Facultatif) zone pour médiateur.</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">*gcp_cvo_vpc_id*</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">(Facultatif) le nom du VPC.</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">*gcp_cvo_subnet_id*</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">(Facultatif) le nom du sous-réseau pour Cloud Volumes ONTAP. La valeur par défaut est « par défaut ».</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">*gcp_cvo_vpc0_node_and_data_connectivity*</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">(Facultatif) le chemin VPC pour le nic1, requis pour la connectivité des nœuds et des données. Si vous utilisez un VPC partagé, vous devez fournir netwrok_project_ID.</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">*gcp_cvo_vpc1_cluster_connectivity*</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">(Facultatif) le chemin VPC pour le nic2, requis pour la connectivité du cluster.</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">*gcp_cvo_vpc2_ha_connectivity*</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">(Facultatif) le chemin VPC pour le nic3, requis pour la connectivité haute disponibilité.</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">*gcp_cvo_vpc3_data_replication*</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">(Facultatif) le chemin VPC pour le nic4, requis pour la réplication des données.</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">*gcp_cvo_subnet0_node_and_data_connectivity*</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">(Facultatif) chemin de sous-réseau pour nic1, requis pour la connectivité des nœuds et des données. Si vous utilisez un VPC partagé, vous devez fournir netwrok_project_ID.</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">*gcp_cvo_subnet1_cluster_connectivity*</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">(Facultatif) chemin de sous-réseau pour la nic2, requis pour la connectivité du cluster.</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">*gcp_cvo_subnet2_ha_connectivity*</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">(Facultatif) le chemin de sous-réseau pour la nic3 est requis pour la connectivité haute disponibilité.</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">*gcp_cvo_subnet3_data_replication*</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">(Facultatif) chemin de sous-réseau pour nic4, requis pour la réplication des données.</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">*gcp_cvo_gcp_volume_size*</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">(Facultatif) taille du volume GCP pour le premier agrégat de données. Pour GB, l'unité peut être : [100 ou 500]. Pour TB, l'unité peut être : [1,2,4,8]. La valeur par défaut est '1' .</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">*gcp_cvo_gcp_volume_size_unit*</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">Volume CVS</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">Cette section contient plusieurs fichiers de configuration Terraform pour déployer/configurer NetApp CVS (Cloud volumes Services) sur GCP (Google Cloud Platform).</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Documentation Terraform :<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">Mettre à jour les valeurs de variable dans<block ref="eb1510c0f29be1d144dce2bfa2e8caab" prefix=" " category="inline-code"></block>.</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph"><block ref="944ce323a5a1ffb09543fd409911cc88" prefix="" category="inline-code"></block></block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">Variables Terraform pour le volume CVS de NetApp GCP</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">*gcp_nom_cvs*</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">(Requis) le nom du volume NetApp CVS.</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">*gcp_cvs_id_projet*</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">(Requis) ID_projet GCP dans lequel le volume CVS sera créé.</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">*gcp_cvs_gcp_service_account_path*</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">(Requis) le chemin d'accès local du fichier JSON de compte_service pour l'autorisation GCP. Ce compte de service est utilisé pour créer le volume CVS dans GCP.</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">*gcp_cvs_région*</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">(Obligatoire) zone GCP dans laquelle le volume CVS sera créé.</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">*gcp_cvs_réseau*</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">(Requis) le VPC réseau du volume.</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">*gcp_cvs_size*</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">(Requis) la taille du volume est comprise entre 1024 et 102400 inclus (en Gio).</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">*gcp_cvs_volume_path*</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">(Facultatif) le nom du chemin du volume.</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">*gcp_cvs_protocol_types*</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">(Obligatoire) type_protocole du volume. Pour NFS, utilisez NFSv3 ou NFSv4 et SMB, utilisez CIFS ou MB.</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">L'automatisation des solutions NetApp permet au client d'automatiser le déploiement, la configuration et l'exécution de nombreuses tâches d'infrastructure et d'applications courantes.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">Automatisation des solutions NetApp</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">L'automatisation simplifie la consommation des solutions NetApp.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">Cette page fournit des informations détaillées pour la collecte des jetons d'actualisation requis et des clés d'accès/secrètes pour les déploiements CVO et Cloud Manager Connector via NetApp Cloud Manager.</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="section-title">Conditions requises pour l'authentification AWS pour CVO et le connecteur à l'aide de NetApp Cloud Manager</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">Pour configurer les déploiements automatisés de Cloud volumes ONTAP et de connecteurs à l'aide de playbooks Ansible via AWX/Ansible Tower, les informations suivantes sont nécessaires :</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">Acquisition des clés d'accès/secrètes d'AWS</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Pour déployer CVO et le connecteur dans Cloud Manager, nous avons besoin d'AWS Access/Secret Key. Vous pouvez obtenir les clés de la console AWS en lançant IAM--- vos utilisateurs- vos identifiants de sécurité---&gt; Créer une clé d'accès.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">Copiez les clés d'accès et assurez-les qu'elles soient sécurisées pour qu'elles puissent être utilisées dans le déploiement de Connector et CVO.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">Si vous perdez votre clé, vous pouvez créer une autre clé d'accès et supprimer celle que vous avez perdue</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">Actualiser le token</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">Acquisition d'un token d'actualisation sur NetApp Cloud Central</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">Connectez-vous à votre compte Cloud Central à l'aide de vos identifiants de compte à l'adresse<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">Générez un token d'actualisation et enregistrez-le pour les déploiements.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">Acquisition de l'ID client</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">Accédez à la page API pour copier l'ID client sur<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">Cliquez sur « Apprenez comment s'authentifier », dans le coin supérieur droit.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">Dans la fenêtre authentification qui s'affiche, copiez l'ID du client depuis l'accès normal si vous avez besoin d'un nom d'utilisateur/mot de passe pour vous connecter. Les utilisateurs fédérés avec SSO doivent copier l'ID client à partir de l'onglet « Actualiser token ».</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">ID client</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">Acquisition de Key pair auprès d'AWS</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">Dans la console AWS, recherchez « paire de clés » et créez une paire de clés avec « pem ». Souvenez-vous du nom de vous key_pair, nous l'utiliserons pour déployer le connecteur.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">Paire de touches</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">Acquisition de l'ID de compte</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Dans Cloud Manager, cliquez sur compte –&gt; gérer les comptes, puis copiez l'ID de compte à utiliser dans les variables pour AWX.</block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">En proposant des solutions qui répondent aux défis actuels des entreprises, NetApp fournit des solutions ayant les objectifs suivants :</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">Fourniture d'étapes de déploiement et de configuration validées,</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">Fournir des solutions faciles à consommables,</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">Fournir un déploiement de solutions avec des résultats prévisibles est facilement répété et évolutif dans l'ensemble de l'entreprise du client.</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">Pour atteindre ces objectifs, il est primordial de simplifier le déploiement et la configuration de l'infrastructure et/ou des applications fournies par nos solutions via l'automatisation. NetApp s'engage à simplifier la consommation de ses solutions grâce à l'automatisation.</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">Grâce à des outils d'automatisation open source tels que Red Hat Ansible, HashiCorp Terraform ou Microsoft PowerShell, les solutions NetApp permettent d'automatiser le déploiement des applications, le provisionnement cloud, la gestion des configurations et de nombreuses autres tâches IT courantes. Les solutions NetApp tirent parti des artéfacts d'automatisation accessibles au public et de l'automatisation rédigée par NetApp pour simplifier le déploiement global d'une solution.</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">Lorsque des fonctionnalités d'automatisation sont disponibles, la documentation relative à la solution guide l'utilisateur tout au long du processus d'automatisation de la solution ou des étapes de la solution via les outils d'automatisation spécifiques.</block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">Disponibilité des régions pour les datastores NFS supplémentaires sur AWS, Azure et GCP</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">En savoir plus sur la prise en charge par la région mondiale des datastores NFS supplémentaires sur AWS, Azure et Google Cloud Platform (GCP).</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">Disponibilité de la région AWS</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">La disponibilité des datastores NFS supplémentaires sur AWS/VMC est définie par Amazon. Tout d'abord, vous devez déterminer si VMC et FSxN sont disponibles dans une région spécifique. Ensuite, vous devez déterminer si le datastore NFS supplémentaire FSxN est pris en charge dans cette région.</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">Vérifier la disponibilité du VMC <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>.</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">Le guide des tarifs d'Amazon fournit des informations sur les domaines où FSxN (FSX ONTAP) est disponible. Vous trouverez cette information <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">La disponibilité du datastore NFS supplémentaire FSxN pour VMC sera bientôt disponible.</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">Bien que les informations soient encore publiées, le tableau suivant identifie la prise en charge actuelle de VMC, FSxN et FSxN comme datastore NFS supplémentaire.</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">Amériques</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">*Région AWS*</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">*Disponibilité VMC*</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">*Disponibilité ONTAP FSX*</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">*Disponibilité des datastores NFS*</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">EST DES ÉTATS-UNIS (Virginie du Nord)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">États-Unis Est (Ohio)</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">USA Ouest (Californie du Nord)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">US West (Oregon)</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud (USA West)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">Canada (Centre)</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">Amérique du Sud (São Paulo)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">Dernière mise à jour : 2 juin 2022.</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">EMEA</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">Europe (Irlande)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">Europe (Londres)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">Europe (Francfort)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">Europe (Paris)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">Europe (Milan)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">Europe (Stockholm)</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">Asie Pacifique</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">Asie-Pacifique (Sydney)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">Asie-Pacifique (Tokyo)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">Asie-Pacifique (Osaka)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">Asie-Pacifique (Singapour)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">Asie-Pacifique (Séoul)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">Asie-Pacifique (Mumbai)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">Asie-Pacifique (Jakarta)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">Asie-Pacifique (Hong Kong)</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">Dernière mise à jour : 28 septembre 2022.</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Disponibilité de la région Azure</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">La disponibilité des datastores NFS supplémentaires sur Azure/AVS est définie par Microsoft. Tout d'abord, vous devez déterminer si AVS et ANF sont disponibles dans une région spécifique. Ensuite, vous devez déterminer si le datastore NFS supplémentaire ANF est pris en charge dans cette région.</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">Vérifier la disponibilité de AVS et ANF <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>.</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">Vérifier la disponibilité du datastore NFS supplémentaire ANF <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>.</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">Disponibilité d'une région GCP</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">La disponibilité de la région GCP sera disponible lors de l'entrée en fonction du public de GCP.</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">Le multicloud hybride NetApp avec les solutions VMware constituent un ensemble de fonctionnalités stratégiques et technologiques qui démontrent les fonctionnalités du stockage NetApp dans les principaux hyperscalers de cloud public.</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">Multicloud hybride NetApp avec les solutions VMware</block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">Solutions de multicloud hybride NetApp pour Azure/AVS</block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Option supplémentaire de datastore NFS dans Azure</block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">La prise en charge des datastores NFS a été introduite avec ESXi version 3 dans les déploiements sur site, ce qui a permis d'étendre considérablement les fonctionnalités de stockage de vSphere.</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">L'exécution de vSphere sur NFS est une option largement adoptée pour les déploiements de virtualisation sur site, car elle offre de solides performances et une stabilité accrue. Si votre data Center sur site dispose d'un stockage NAS important, il est recommandé de déployer une solution Azure VMware SDDC dans Azure avec les datastores Azure NetApp pour relever les défis de capacité et de performance.</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99 %</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files repose sur le logiciel de gestion des données NetApp ONTAP à haute disponibilité du secteur. Les services Microsoft Azure sont regroupés en trois catégories : fondamentaux, principaux et spécialisés. Azure NetApp Files est dans la catégorie spécialisée et est pris en charge par le matériel déjà déployé dans de nombreuses régions. Grâce à la haute disponibilité intégrée, Azure NetApp Files protège vos données de la plupart des pannes et vous offre un SLA de pointe<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> continuité.</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Avant l'introduction de la fonctionnalité de data stores Azure NetApp Files, l'évolutivité horizontale pour les clients qui prévoient de héberger des charges de travail hautes performances et exigeantes en stockage nécessitait l'extension du système de calcul et du stockage.</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">Gardez à l'esprit les problèmes suivants :</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">Les configurations de cluster non équilibrées ne sont pas recommandées dans un cluster SDDC. Par conséquent, l'extension du stockage implique l'ajout d'hôtes, ce qui signifie plus de coût total de possession.</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">Un seul environnement VSAN est possible. Par conséquent, tout le trafic de stockage est en concurrence directe avec les workloads de production.</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">Il n'est pas possible de fournir plusieurs tiers de performance pour répondre aux exigences, aux performances et aux coûts des applications.</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">Il est facile d'atteindre les limites de capacité de stockage pour le VSAN basé sur les hôtes du cluster.en intégrant les offres de plateforme en tant que service (PaaS) Azure natives comme Azure NetApp Files en tant que datastore, Les clients peuvent faire évoluer séparément leur stockage et ajouter uniquement des nœuds de calcul au cluster SDDC selon leurs besoins. Cette fonctionnalité permet de surmonter les défis évoqués ci-dessus.</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">Azure NetApp Files vous permet également de déployer plusieurs datastores, ce qui contribue à reproduire un modèle de déploiement sur site en plaçant les machines virtuelles dans le datastore approprié et en attribuant le niveau de service requis pour répondre aux exigences de performance des workloads. Grâce à des fonctionnalités uniques de prise en charge multiprotocole, le stockage invité est une option supplémentaire pour les charges de travail de bases de données telles que SQL et Oracle tout en utilisant la fonctionnalité supplémentaire de datastore NFS pour héberger les VMDK restants. Outre cette fonctionnalité native de snapshots, il est possible d'effectuer des sauvegardes rapides et des restaurations granulaires.</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">Contactez les architectes de solutions Azure et NetApp pour planifier et dimensionner le stockage et déterminer le nombre d'hôtes requis. NetApp recommande d'identifier les exigences en matière de performances de stockage avant de finaliser la disposition du datastore pour les déploiements de test, de démonstration de faisabilité et de production.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">Architecture détaillée</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">Sur un plan général, cette architecture explique comment assurer la connectivité dans le cloud hybride et la portabilité des applications dans les environnements sur site et Azure. Il décrit également l'utilisation de Azure NetApp Files en tant que datastore NFS supplémentaire et en tant qu'option de stockage « invité » pour les machines virtuelles invitées hébergées sur la solution Azure VMware.</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="section-title">Dimensionnement</block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">L'aspect le plus important dans le domaine de la migration ou de la reprise d'activité est de déterminer la taille appropriée pour l'environnement cible. Il est très important de comprendre le nombre de nœuds nécessaires pour effectuer un exercice de basculement entre les installations sur site et la solution Azure VMware.</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">Pour le dimensionnement, utilisez les données historiques de l'environnement sur site à l'aide de RVTools (préférés) ou d'autres outils tels que Live Optics ou Azure Migrate. RVTools est un outil idéal pour capturer les vCPU, le vmem et le vDisk ainsi que toutes les informations requises, y compris les machines virtuelles sous tension ou hors tension, afin de caractériser l'environnement cible.</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">Pour exécuter les outils RVTools, procédez comme suit :</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">Téléchargez et installez RVTools.</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">Exécutez RVTools, entrez les informations requises pour vous connecter à votre serveur vCenter sur site, puis appuyez sur Login.</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">Exportez l'inventaire vers une feuille de calcul Excel.</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">Modifiez la feuille de calcul et supprimez les machines virtuelles qui ne sont pas des candidats idéaux dans l'onglet vInfo.cette approche fournit des résultats clairs concernant les exigences de stockage pouvant être utilisées pour dimensionner correctement le cluster Azure VMware SDDC avec le nombre d'hôtes requis.</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">Les machines virtuelles invitées utilisées avec un stockage invité doivent être calculées séparément. Toutefois, Azure NetApp Files peut facilement couvrir la capacité de stockage supplémentaire, ce qui réduit le coût total de possession global.</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Déploiement et configuration d'Azure VMware solution</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">Comme sur site, la planification d'une solution Azure VMware est essentielle pour créer un environnement de production prêt pour créer des machines virtuelles et des migrations.</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">Cette section décrit comment configurer et gérer AVS pour l'utilisation en association avec Azure NetApp Files comme datastore avec un stockage « In-Guest ».</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">Le processus de configuration peut être divisé en trois parties :</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">Enregistrez le fournisseur de ressources et créez un cloud privé.</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">Connectez-vous à une passerelle réseau virtuelle ExpressRoute nouvelle ou existante.</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">Validation de la connectivité réseau et accès au cloud privé Se reporter à ceci <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> Pour une présentation détaillée du processus de provisionnement du SDDC de la solution Azure VMware.</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Configurez Azure NetApp Files avec Azure VMware solution</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">La nouvelle intégration entre Azure NetApp Files vous permet de créer des datastores NFS via les API/l'interface de ligne de commande du fournisseur de ressources Azure VMware solution avec les volumes Azure NetApp Files et de monter les datastores sur les clusters de votre choix dans un cloud privé. Outre l'hébergement des VMDK de la machine virtuelle et des applications, les volumes de fichiers Azure NetApp peuvent également être montés sur les machines virtuelles créées dans l'environnement Azure VMware solution SDDC. Les volumes peuvent être montés sur le client Linux et mappés sur un client Windows, car Azure NetApp Files prend en charge les protocoles SMB (Server message Block) et NFS (Network File System).</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">Pour des performances optimales, déployez la baie Azure NetApp Files dans la même zone de disponibilité que le cloud privé. La colocation dotée de la fonction Express route fastpath offre les meilleures performances, avec une latence réseau minimale.</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Pour joindre un volume Azure NetApp File en tant que datastore VMware d'un cloud privé Azure VMware solution, assurez-vous que les conditions préalables suivantes sont remplies.</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">Utilisez la connexion az et validez que l'abonnement est enregistré dans la fonctionnalité CloudSanExperience de l'espace de noms Microsoft.AVS.</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">S'il n'est pas enregistré, enregistrez-le.</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">L'inscription peut prendre environ 15 minutes.</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">Pour vérifier le statut de l'enregistrement, exécutez la commande suivante.</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">Si l'enregistrement est bloqué dans un état intermédiaire pendant plus de 15 minutes, annulez l'enregistrement et réenregistrez le drapeau.</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">Vérifiez que l'abonnement est enregistré dans la fonctionnalité AnfDatastoreExperience de l'espace de noms Microsoft.AVS.</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">Vérifiez que l'extension vmware est installée.</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">Si l'extension est déjà installée, vérifiez que la version est 3.0.0. Si une version antérieure est installée, mettez à jour l'extension.</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">Si l'extension n'est pas déjà installée, installez-la.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="example-title">Création et montage de volumes Azure NetApp Files</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Connectez-vous au portail Azure et accédez à Azure NetApp Files. Vérifiez l'accès au service Azure NetApp Files et enregistrez le fournisseur de ressources Azure NetApp Files à l'aide du<block ref="37ac6d6acd87f35d4712fb725270d9df" prefix=" " category="inline-code"></block><block ref="d6c188468a5654ff07f3d8da04d06877" prefix=" " category="inline-code"></block> commande. Une fois enregistré, créez un compte NetApp. Se reporter à ceci<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> pour des étapes détaillées.</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">Une fois le compte NetApp créé, configurez des pools de capacité avec le niveau et la taille de service requis. Pour plus d'informations, reportez-vous à ce document<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>.</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="cell">Points à retenir</block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">NFSv3 est pris en charge pour les datastores sur Azure NetApp Files.</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Configurez un sous-réseau délégué pour Azure NetApp Files et spécifiez ce sous-réseau lors de la création de volumes. Pour connaître les étapes détaillées de création d'un sous-réseau délégué, reportez-vous à ce document<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>.</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">Ajoutez un volume NFS pour le datastore à l'aide du serveur lame volumes sous le serveur lame Capacity pools.</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link">Performances de Azure NetApp Files</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Ajoutez le datastore Azure NetApp Files dans le cloud privé</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Pour ajouter un magasin de données Azure NetApp Files à un cloud privé, procédez comme suit :</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">Une fois les fonctionnalités requises enregistrées, reliez un datastore NFS au cluster cloud privé Azure VMware solution en exécutant la commande appropriée.</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Créez un datastore à l'aide d'un volume ANF existant dans le cluster cloud privé Azure VMware solution.</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">C:\Users\niyaz&gt; az vmware datastore list --Resource-group 4497 AVS anprivsval2 --cluster Cluster-1 --private-cloud ANFDataClus [ { « diskPoolVolume »: Null, « resteID »: »/souscriptions/0efa2dfb-917c-4497-b5ba-resourceindes/resuneGroup Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001", « resune2s/resours2s/resourdes/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/s/ { "DiskPoolVolume": Null, "ID": "/souscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/anfavsval2/fournisseurs/Microsoft.AVS/ANFDatalus }/clusters/Cluster-1/resourcein2 4497, « resours2FeveF1Gs Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002" », « Receve2F1F1F1F1F1F1Frcb », « ress/ress », « ReceveF1F1F1F1F1F1F1F1Frcb », « Pros/ress », « ress/ress », « ress/ress », « ress », « ress/ress », « ress », « ress », « ress/s/s/s/s », « resours2F1F1fceve2F1F1F1F1F1F1fceve2F1fc</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">Une fois la connectivité nécessaire en place, les volumes sont montés en tant que datastore.</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">Dimensionnement et optimisation des performances</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files prend en charge trois niveaux de services : standard (16 Mbit/s par téraoctet), Premium (64 Mbit/s par téraoctet) et Ultra (128 Mbit/s par téraoctet). Pour optimiser les performances de la charge de travail de la base de données, il est important de provisionner une taille de volume appropriée. Avec Azure NetApp Files, la performance des volumes et la limite de débit sont déterminées en fonction des facteurs suivants :</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">Niveau de service du pool de capacité auquel le volume appartient</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">Quota attribué au volume</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">La qualité de service (QoS) de type (automatique ou manuelle) du pool de capacité</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Niveaux de service pour Azure NetApp Files</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">Pour plus d'informations, voir<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">Performances</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">Il est important de comprendre qu'avec NFS version 3, il n'existe qu'un seul canal actif pour la connexion entre l'hôte ESXi et une seule cible de stockage. Bien que certaines connexions alternatives soient disponibles pour le basculement, la bande passante d'un seul datastore et le stockage sous-jacent sont limitées à ce qu'une seule connexion peut fournir.</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Pour exploiter davantage de bande passante disponible avec des volumes Azure NetApp Files, un hôte ESXi doit disposer de plusieurs connexions aux cibles de stockage. Pour résoudre ce problème, vous pouvez configurer plusieurs datastores, chaque datastore utilisant des connexions distinctes entre l'hôte ESXi et le système de stockage.</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">Pour une bande passante plus élevée, il est recommandé de créer plusieurs datastores à l'aide de plusieurs volumes ANF, de créer des VMDK et de répartir les volumes logiques sur des VMDK.</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">La solution Azure VMware autorise huit datastores NFS par défaut. Ceci peut être augmenté via une demande d'assistance.</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">Tirez parti de la technologie ER fastpath et de la référence Ultra pour bénéficier d'une bande passante plus élevée et d'une latence plus faible. Plus d'informations</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Grâce aux fonctionnalités réseau de base d'Azure NetApp Files, la connectivité d'Azure VMware est liée à la bande passante du circuit ExpressRoute et à la passerelle ExpressRoute.</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">Points à retenir</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">Augmentation de la taille du datastore</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">La réorganisation des volumes et les modifications dynamiques des niveaux de service sont totalement transparentes pour le SDDC. Dans Azure NetApp Files, ces fonctionnalités permettent d'optimiser sans interruption les performances, la capacité et les coûts. Augmentez la taille des datastores NFS en redimensionnant le volume d'Azure Portal ou à l'aide de l'interface de ligne de commandes. Une fois l'opération terminée, accédez à vCenter, accédez à l'onglet datastore, cliquez avec le bouton droit sur le datastore approprié et sélectionnez « Refresh Capacity information » (Actualiser les informations de capacité). Cette approche peut être utilisée pour augmenter la capacité du datastore et accroître de manière dynamique les performances du datastore sans temps d'indisponibilité. Ce processus est également totalement transparent pour les applications.</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">La modification des volumes et la fonctionnalité de niveau de service dynamique permettent d'optimiser les coûts en dimensionnant les charges de travail prévisibles et ainsi d'éviter le surprovisionnement.</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">Charges de travail</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="example-title">Migration</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">L'un des cas d'utilisation les plus courants est la migration. Utilisez VMware HCX ou vMotion pour déplacer des machines virtuelles sur site. Vous pouvez également utiliser Rivermeadow pour migrer des machines virtuelles vers des datastores Azure NetApp Files.</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="example-title">La protection des données</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">La sauvegarde des machines virtuelles et leur restauration rapide sont parmi les grands avantages des datastores ANF. Utilisez les copies Snapshot pour réaliser des copies rapides de votre machine virtuelle ou de votre datastore sans affecter les performances, puis envoyez-les au stockage Azure pour une protection des données à plus long terme ou vers une région secondaire à l'aide d'une réplication inter-région pour la reprise après incident. Cette approche réduit l'espace de stockage et la bande passante réseau en stockant uniquement les informations modifiées.</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">Vous pouvez utiliser les copies Snapshot de Azure NetApp Files pour une protection générale et utiliser les outils applicatifs pour protéger les données transactionnelles, telles que SQL Server ou Oracle résidant sur les machines virtuelles invitées. Ces copies Snapshot sont différentes des snapshots VMware (cohérence) et conviennent à une protection à long terme.</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">Avec les datastores ANF, l'option Restaurer vers un nouveau volume peut être utilisée pour cloner un volume de datastore entier, et le volume restauré peut être monté comme un autre datastore vers des hôtes au sein d'AVS SDDC. Une fois le datastore monté, les ordinateurs virtuels qui l'utilisent peuvent être enregistrés, reconfigurés et personnalisés comme s'ils étaient individuellement clonés.</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">Cloud Backup pour machines virtuelles</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">Cloud Backup pour machines virtuelles fournit une interface utilisateur graphique de client web vSphere sur vCenter pour protéger les machines virtuelles Azure VMware solution et les datastores Azure NetApp Files via des règles de sauvegarde. Ces règles peuvent définir une planification, une conservation et d'autres fonctionnalités. La fonctionnalité Cloud Backup pour machine virtuelle peut être déployée à l'aide de la commande Exécuter.</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">Vous pouvez installer les règles de configuration et de protection en procédant comme suit :</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">Installez Cloud Backup pour machine virtuelle dans Azure VMware solution cloud privé à l'aide de la commande Exécuter.</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">Ajoutez des identifiants d'abonnement au cloud (client et valeur secrète), puis ajoutez un compte d'abonnement au cloud (compte NetApp et groupe de ressources associés) qui contient les ressources que vous souhaiteriez protéger.</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">Créez une ou plusieurs stratégies de sauvegarde qui gèrent la rétention, la fréquence et d'autres paramètres pour les sauvegardes de groupes de ressources.</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">Créez un conteneur pour ajouter une ou plusieurs ressources qui doivent être protégées par les règles de sauvegarde.</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">En cas de défaillance, restaurez la machine virtuelle complète ou des VMDK individuels spécifiques sur le même site.</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Grâce à la technologie Snapshot de Azure NetApp Files, les sauvegardes et les restaurations sont très rapides.</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Reprise après incident avec Azure NetApp Files, JetStream DR et Azure VMware solution</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">La reprise d'activité dans le cloud est une solution résiliente et économique de protection des workloads contre les pannes sur site et la corruption des données, par exemple, par ransomware. Grâce à la structure VMware VAIO, les charges de travail VMware sur site peuvent être répliquées vers le stockage Azure Blob et récupérées. Vous bénéficiez ainsi d'une perte de données minimale, voire quasi nulle. Jetstream DR peut être utilisé pour restaurer de manière transparente les workloads répliqués depuis les sites vers AVS, et plus particulièrement vers Azure NetApp Files. Il permet une reprise d'activité économique en utilisant peu de ressources sur le site de reprise d'activité et un stockage cloud économique. Jetstream DR automatise la restauration vers les datastores ANF via Azure Blob Storage. Jetstream DR restaure les ordinateurs virtuels ou groupes de serveurs virtuels indépendants dans l'infrastructure de site de restauration en fonction du mappage du réseau et assure une restauration instantanée pour la protection par ransomware.</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">Solution de reprise après incident avec ANF, JetStream et AVS</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>.</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Options de stockage connecté à un réseau invité NetApp pour Azure</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure prend en charge le stockage NetApp connecté par l'invité grâce au service natif Azure NetApp Files (ANF) ou à Cloud Volumes ONTAP (CVO).</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp Files (ANF)</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files apporte des fonctionnalités haute performance de stockage et de gestion des données à Azure afin de faciliter la gestion des workloads et des applications. Migrez vos workloads vers le cloud et exécutez-les sans sacrifier les performances.</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files lève les obstacles pour vous aider à déplacer dans le cloud toutes vos applications basées sur des fichiers. Pour la première fois, vous n'avez pas à modifier l'architecture de vos applications. En outre, vous bénéficiez d'un stockage persistant sans aucune complexité.</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">Comme ce service est proposé via le portail Microsoft Azure, les utilisateurs profitent d'une expérience entièrement gérée dans le cadre de leur contrat Microsoft Enterprise. Le support de premier ordre, régi par Microsoft, vous assure une tranquillité d'esprit totale. Cette solution unique vous permet d'ajouter des workloads multiprotocoles de manière simple et rapide. Vous pouvez créer et déployer des applications basées sur des fichiers à la fois pour Windows et Linux, même pour les environnements hérités.</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="section-title">Azure NetApp Files (ANF) comme stockage connecté invité</block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="example-title">Configurer Azure NetApp Files avec Azure VMware solution (AVS)</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Les partages Azure NetApp Files peuvent être montés à partir des VM créées dans l'environnement Azure VMware solution SDDC. Les volumes peuvent également être montés sur le client Linux et mappés sur le client Windows, car Azure NetApp Files prend en charge les protocoles SMB et NFS. Les volumes Azure NetApp Files peuvent être configurés en cinq étapes simples.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files et Azure VMware solution doivent se trouver dans la même région Azure.</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Pour créer et monter des volumes Azure NetApp Files, procédez comme suit :</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Connectez-vous au portail Azure et accédez à Azure NetApp Files. Vérifiez l'accès au service Azure NetApp Files et enregistrez le fournisseur de ressources Azure NetApp Files à l'aide de la commande _az Provider Register --namespace Microsoft.NetApp –wait_. Une fois l'inscription terminée, créez un compte NetApp.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Partages Azure NetApp Files</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">Pour obtenir des instructions détaillées, reportez-vous à la section <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. Cette page vous guidera tout au long du processus étape par étape.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">Une fois le compte NetApp créé, configurez les pools de capacité avec le niveau et la taille de service requis.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">Pour plus d'informations, voir <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Déléguer un sous-réseau à Azure NetApp Files</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Configurez le sous-réseau délégué pour Azure NetApp Files et spécifiez ce sous-réseau lors de la création des volumes. Pour obtenir des instructions détaillées sur la création d'un sous-réseau délégué, reportez-vous à la section <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Ajoutez un volume SMB en utilisant le serveur lame volumes sous le serveur lame Capacity pools. Assurez-vous que Active Directory Connector est configuré avant de créer le volume SMB.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">Cliquez sur Revue + Créer pour créer le volume SMB.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">Si l'application est SQL Server, activez la disponibilité continue SMB.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">Pour en savoir plus sur les performances des volumes Azure NetApp Files par taille ou quota, reportez-vous à la section <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">Une fois la connectivité en place, le volume peut être monté et utilisé pour les données d'application.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">Pour ce faire, cliquez sur le portail Azure puis sur le serveur lame volumes, puis sélectionnez le volume à monter et accédez aux instructions de montage. Copiez le chemin d'accès et utilisez l'option Map Network Drive pour monter le volume sur la machine virtuelle exécutée sur Azure VMware solution SDDC.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Pour monter des volumes NFS sur des machines virtuelles Linux s'exécutant sur Azure VMware solution SDDC, utilisez ce processus. Adaptation des volumes ou fonctionnalité de niveau de service dynamique pour répondre aux demandes des charges de travail</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">Pour plus d'informations, voir <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">Cloud Volumes ONTAP (CVO)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP, ou CVO, est la solution de gestion des données cloud leader qui repose sur le logiciel de stockage ONTAP de NetApp, disponible de façon native dans Amazon Web Services (AWS), Microsoft Azure et Google Cloud Platform (GCP).</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">Il s'agit d'une version Software-defined de ONTAP qui utilise le stockage cloud natif. Vous pouvez ainsi utiliser le même logiciel de stockage dans le cloud et sur site, limitant ainsi la nécessité de former à nouveau votre personnel IT à des méthodes entièrement nouvelles de gestion des données.</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">Ce logiciel permet au client de déplacer des données de la périphérie, vers le data Center, puis vers le cloud, et inversement, en réunissant votre cloud hybride, le tout géré à l'aide d'une console de gestion centralisée, NetApp Cloud Manager.</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">De par sa conception, CVO fournit des performances extrêmes et des fonctionnalités avancées de gestion de données pour répondre aux applications les plus exigeantes dans le cloud</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="section-title">Cloud Volumes ONTAP (CVO) comme stockage connecté à l'invité</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="example-title">Déploiement du nouveau système Cloud Volumes ONTAP dans Azure</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Les partages et les LUN Cloud Volumes ONTAP peuvent être montés sur les VM créées dans l'environnement Azure VMware solution SDDC. Les volumes peuvent également être montés sur le client Linux et sur le client Windows, car Cloud Volumes ONTAP prend en charge les protocoles iSCSI, SMB et NFS. Les volumes Cloud Volumes ONTAP peuvent être configurés en quelques étapes simples.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">Configuration de la réplication des données entre les systèmes</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">Pour répliquer des volumes depuis un environnement sur site vers le cloud à des fins de reprise d'activité ou de migration, établissez une connectivité réseau à Azure via un VPN site à site ou ExpressRoute. La réplication des données entre les sites et Cloud Volumes ONTAP n'est pas traitée dans ce document. Pour répliquer les données entre les systèmes Cloud Volumes ONTAP et sur site, consultez la section <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Plus outil de dimensionnement Cloud Volumes ONTAP</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">Utiliser <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Pour dimensionner précisément les instances Cloud Volumes ONTAP. Surveillez également les performances sur site et utilisez-les comme entrées dans le dimensionnement Cloud Volumes ONTAP.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">Connectez-vous à NetApp Cloud Central ; l'écran Fabric View s'affiche. Localisez l'onglet Cloud Volumes ONTAP et sélectionnez accéder à Cloud Manager. Une fois connecté, l'écran Canvas s'affiche.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Sur la page d'accueil de Cloud Manager, cliquez sur Add a Working Environment, puis sélectionnez Microsoft Azure comme cloud et le type de configuration du système.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">Lorsque vous créez le premier environnement de travail Cloud Volumes ONTAP, Cloud Manager vous invite à déployer un connecteur.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">Une fois le connecteur créé, mettez à jour les champs Détails et informations d'identification.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">Fournissez les détails de l'environnement à créer, y compris le nom de l'environnement et les identifiants d'administrateur. Ajoutez des balises de groupe de ressources pour l'environnement Azure en tant que paramètre facultatif. Une fois que vous avez terminé, cliquez sur Continuer.</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">Sélectionnez les services d'extension pour le déploiement Cloud Volumes ONTAP, notamment Cloud Data Sense, Cloud Backup et Cloud Insights. Sélectionnez les services, puis cliquez sur Continuer.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Configurez l'emplacement et la connectivité Azure. Sélectionnez la région Azure, le groupe de ressources, le réseau vnet et le sous-réseau à utiliser.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">Sélectionnez l'option de licence : paiement à l'utilisation ou BYOL pour l'utilisation des licences existantes. Dans cet exemple, l'option paiement à l'utilisation est utilisée.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">Sélectionnez l'un des packages préconfigurés disponibles pour les différents types de charges de travail.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Acceptez les deux accords concernant l'activation du support et l'allocation des ressources Azure.pour créer l'instance Cloud Volumes ONTAP, cliquez sur Go.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Une fois Cloud Volumes ONTAP provisionné, il apparaît dans les environnements de travail sur la page Canvas.</block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="example-title">Configurations supplémentaires pour les volumes SMB</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">Une fois l'environnement de travail prêt, assurez-vous que le serveur CIFS est configuré avec les paramètres de configuration DNS et Active Directory appropriés. Cette étape est requise avant de pouvoir créer le volume SMB.</block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">La création du volume SMB est un processus simple. Sélectionnez l'instance CVO pour créer le volume, puis cliquez sur l'option Create Volume. Choisissez la taille appropriée et Cloud Manager choisit l'agrégat contenant ou utilisez un mécanisme d'allocation avancée pour placer sur un agrégat spécifique. Pour cette démonstration, SMB est sélectionné comme protocole.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">Une fois le volume provisionné, celui-ci est disponible sous le volet volumes. Comme un partage CIFS est provisionné, donnez à vos utilisateurs ou groupes l'autorisation d'accéder aux fichiers et dossiers et vérifiez que ces utilisateurs peuvent accéder au partage et créer un fichier. Cette étape n'est pas requise si le volume est répliqué à partir d'un environnement sur site, car les autorisations liées aux fichiers et aux dossiers sont toutes conservées dans le cadre de la réplication SnapMirror.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">Une fois le volume créé, utilisez la commande mount pour vous connecter au partage à partir de la machine virtuelle exécutée sur les hôtes Azure VMware solution SDDC.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">Copiez le chemin suivant et utilisez l'option Map Network Drive pour monter le volume sur la machine virtuelle exécutée sur Azure VMware solution SDDC.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="example-title">Connectez la LUN à un hôte</block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">Pour connecter le LUN à un hôte, procédez comme suit :</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">Sur la page Canevas, double-cliquez sur l'environnement de travail Cloud Volumes ONTAP pour créer et gérer des volumes.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">Cliquez sur Ajouter un volume &gt; Nouveau volume, sélectionnez iSCSI et cliquez sur Créer un groupe d'initiateurs. Cliquez sur Continuer .</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">Une fois le volume provisionné, sélectionnez le volume, puis cliquez sur IQN cible. Pour copier le nom qualifié iSCSI (IQN), cliquez sur Copier. Configurez une connexion iSCSI de l'hôte vers le LUN.</block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Pour en faire de même pour l'hôte résidant sur Azure VMware solution SDDC :</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">RDP vers la machine virtuelle hébergée sur Azure VMware solution SDDC.</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">Ouvrez la boîte de dialogue Propriétés de l'initiateur iSCSI : Gestionnaire de serveur &gt; Tableau de bord &gt; Outils &gt; initiateur iSCSI.</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">Dans l'onglet découverte, cliquez sur Discover Portal ou Add Portal, puis entrez l'adresse IP du port cible iSCSI.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">Dans l'onglet cibles, sélectionnez la cible découverte, puis cliquez sur connexion ou connexion.</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">Sélectionnez Activer le multichemin, puis sélectionnez Restaurer automatiquement cette connexion lorsque l'ordinateur démarre ou Ajouter cette connexion à la liste des cibles favorites. Cliquez sur Avancé.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">*Remarque :* l'hôte Windows doit disposer d'une connexion iSCSI à chaque nœud du cluster. Le DSM natif sélectionne les meilleurs chemins d'accès à utiliser.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">Les LUN présentes sur la machine virtuelle de stockage (SVM) apparaissent sous forme de disques pour l'hôte Windows. Les nouveaux disques ajoutés ne sont pas automatiquement découverts par l'hôte. Déclencher une nouvelle analyse manuelle pour détecter les disques en procédant comme suit :</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">Ouvrez l'utilitaire de gestion de l'ordinateur Windows : Démarrer &gt; Outils d'administration &gt; gestion de l'ordinateur.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">Développez le nœud stockage dans l'arborescence de navigation.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">Cliquez sur gestion des disques.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">Cliquez sur action &gt; Rescan Disks.</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Lorsqu'un nouvel LUN est accédé pour la première fois par l'hôte Windows, il n'a pas de partition ni de système de fichiers. Initialiser la LUN ; et éventuellement formater la LUN avec un système de fichiers en effectuant la procédure suivante :</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Démarrez Windows Disk Management.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">Cliquez avec le bouton droit de la souris sur la LUN, puis sélectionnez le type de disque ou de partition requis.</block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">Suivez les instructions de l'assistant. Dans cet exemple, le lecteur E: Est monté</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Déploiement et configuration de l'environnement de virtualisation sur Azure</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">Comme sur site, la planification d'Azure VMware solution est cruciale pour la réussite d'un environnement prêt à la production à créer des machines virtuelles et à migrer.</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">Cette section décrit comment configurer et gérer Azure VMware solution et l'utiliser en association avec les options disponibles pour connecter le stockage NetApp.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">Le processus de configuration peut être divisé en plusieurs étapes :</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="example-title">Enregistrez le fournisseur de ressources et créez un cloud privé</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Pour utiliser Azure VMware solution, commencez par inscrire le fournisseur de ressources dans l'abonnement identifié :</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Connectez-vous au portail Azure.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Dans le menu du portail Azure, sélectionnez tous les services.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">Dans la boîte de dialogue tous les services, entrez l'abonnement, puis sélectionnez abonnements.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">Pour afficher l'abonnement, sélectionnez-le dans la liste des abonnements.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">Sélectionnez Resource Providers et saisissez Microsoft.AVS dans la recherche.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">Si le fournisseur de ressources n'est pas enregistré, sélectionnez Enregistrer.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">Une fois le fournisseur de ressources enregistré, créez un cloud privé Azure VMware solution à l'aide du portail Azure.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">Sélectionnez Créer une nouvelle ressource.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">Dans la zone de texte Rechercher sur le Marketplace, entrez Azure VMware solution et sélectionnez-la dans les résultats.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Sur la page solution Azure VMware, sélectionnez Create.</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">Dans l'onglet Basics, entrez les valeurs dans les champs et sélectionnez Revue + Créer.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="paragraph">Remarques :</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">Pour un démarrage rapide, rassemblez les informations requises pendant la phase de planification.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">Sélectionnez un groupe de ressources existant ou créez un nouveau groupe de ressources pour le cloud privé. Un groupe de ressources est un conteneur logique dans lequel les ressources Azure sont déployées et gérées.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">Assurez-vous que l'adresse CIDR est unique et qu'elle ne se superpose pas aux autres réseaux Azure Virtual Networks ou sur site. Le CIDR est le réseau de gestion de cloud privé utilisé pour les services de gestion de cluster, tels que vCenter Server et NSX-T Manager. NetApp recommande d'utiliser un espace d'adressage /22. Dans cet exemple, 10.21.0.0/22 est utilisé.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">Le processus de provisionnement prend entre 4 et 5 heures. Une fois le processus terminé, vérifiez que le déploiement a abouti en accédant au cloud privé à partir du portail Azure. L'état « réussi » s'affiche lorsque le déploiement est terminé.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Un cloud privé pour solution Azure VMware nécessite un réseau virtuel Azure. Étant donné que la solution Azure VMware ne prend pas en charge vCenter sur site, des étapes supplémentaires sont requises pour l'intégration avec un environnement existant sur site. Il est également nécessaire de configurer un circuit ExpressRoute et une passerelle réseau virtuelle. En attendant la fin du provisionnement du cluster, créez un nouveau réseau virtuel ou utilisez un réseau existant pour vous connecter à la solution Azure VMware.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="example-title">Connectez-vous à une passerelle réseau virtuelle ExpressRoute nouvelle ou existante</block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">Pour créer un nouveau réseau virtuel Azure (vNet), sélectionnez l'onglet Azure vNet Connect. Vous pouvez également en créer un manuellement à partir du portail Azure à l'aide de l'assistant de création de réseau virtuel :</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Accédez à Azure VMware solution cloud privé et à Access Connectivity sous l'option Manage.</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Sélectionnez Azure VNet Connect.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">Pour créer un nouveau vnet, sélectionnez l'option Créer nouveau.</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">Cette fonctionnalité permet de connecter un vnet au cloud privé Azure VMware solution. Il permet la communication entre les charges de travail sur ce réseau virtuel en créant automatiquement les composants nécessaires (par exemple, sauter le pas, les services partagés tels qu'Azure NetApp Files et Cloud Volume ONTAP) vers le cloud privé créé dans Azure VMware solution over ExpressRoute.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">*Remarque :* l'espace d'adressage VNet ne doit pas se chevaucher avec le CIDR sur le Cloud privé.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">Fournissez ou mettez à jour les informations relatives au nouveau VNet et sélectionnez OK.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">Le vnet avec la plage d'adresses et le sous-réseau de passerelle fournis est créé dans le groupe d'abonnement et de ressources désigné.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Configurez le réseau pour votre cloud privé VMware dans Azure</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">Si vous créez un VNet manuellement, créez une passerelle réseau virtuelle avec le SKU approprié et ExpressRoute comme type de passerelle. Une fois le déploiement terminé, connectez la connexion ExpressRoute à la passerelle de réseau virtuel contenant le cloud privé Azure VMware solution à l'aide de la clé d'autorisation. Pour plus d'informations, voir <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="example-title">Validation de la connexion réseau et de l'accès au cloud privé Azure VMware solution</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware solution ne vous permet pas de gérer un cloud privé avec VMware vCenter sur site. Un hôte saut est alors nécessaire pour la connexion à l'instance Azure VMware solution vCenter. Créez un hôte de démarrage dans le groupe de ressources désigné et connectez-vous à Azure VMware solution vCenter. Cet hôte de saut doit être une machine virtuelle Windows sur le même réseau virtuel créé pour la connectivité et doit fournir un accès à vCenter et à NSX Manager.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">Une fois la machine virtuelle provisionnée, utilisez l'option Connect pour accéder à RDP.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">Connectez-vous à vCenter à partir de cette nouvelle machine virtuelle hôte de démarrage en utilisant l'utilisateur d'administration du cloud . Pour accéder aux identifiants, accédez au portail Azure et recherchez Identity (sous l'option Manage (gérer dans le cloud privé). Les URL et les informations d'identification de l'utilisateur pour le cloud privé vCenter et NSX-T Manager peuvent être copiés à partir d'ici.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Dans la machine virtuelle Windows, ouvrez un navigateur et accédez à l'URL du client Web vCenter <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> et utilisez le nom d'utilisateur admin comme *cloudadmin@vsphere.locumbip* et collez le mot de passe copié. De même, NSX-T Manager est également accessible à l'aide de l'URL du client Web <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> utilisez le nom d'utilisateur admin et collez le mot de passe copié pour créer de nouveaux segments ou modifier les passerelles de niveau existantes.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">Les URL des clients Web sont différentes pour chaque SDDC provisionné.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">Concevez des environnements sur site vers la solution Azure VMware</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">Le SDDC Azure VMware solution est désormais déployé et configuré. Tirez parti d'ExpressRoute Global Reach pour relier l'environnement sur site au cloud privé Azure VMware solution. Pour plus d'informations, voir <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">Reprise après incident avec ANF et JetStream</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">La reprise d'activité dans le cloud est une solution résiliente et économique de protection des workloads contre les pannes sur site et la corruption des données, par exemple, par ransomware. Grâce à la structure VMware VAIO, les charges de travail VMware sur site peuvent être répliquées vers le stockage Azure Blob et récupérées. Vous bénéficiez ainsi d'une perte de données minimale, voire quasi nulle.</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">Jetstream DR peut être utilisé pour restaurer de manière transparente les workloads répliqués depuis les sites vers AVS, et plus particulièrement vers Azure NetApp Files. Il permet une reprise d'activité économique en utilisant peu de ressources sur le site de reprise d'activité et un stockage cloud économique. Jetstream DR automatise la restauration vers les datastores ANF via Azure Blob Storage. Jetstream DR restaure les ordinateurs virtuels ou groupes de serveurs virtuels indépendants dans l'infrastructure de site de restauration en fonction du mappage du réseau et assure une restauration instantanée pour la protection par ransomware.</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">Ce document présente les principes JetStream DR des opérations et de ses principaux composants.</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">Présentation du déploiement de la solution</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">Installez le logiciel JetStream DR dans le data Center sur site.</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">Téléchargez le pack logiciel JetStream DR depuis Azure Marketplace (ZIP) et déployez JetStream DR MSA (OVA) dans le cluster désigné.</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">Configurez le cluster à l'aide du package filtre d'E/S (installez JetStream VIB).</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">Provisionnez Azure Blob (Azure Storage Account) dans la même région que le cluster AVS pour la reprise après incident.</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">Déployer des appliances DRVA et attribuer des volumes de journaux de réplication (VMDK à partir d'un datastore existant ou d'un stockage iSCSI partagé).</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">Créez des domaines protégés (groupes de machines virtuelles associées) et attribuez des DRVAs et Azure Blob Storage/ANF.</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">Démarrer la protection.</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">Installez le logiciel JetStream DR dans le cloud privé Azure VMware solution.</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">Utilisez la commande Exécuter pour installer et configurer JetStream DR.</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">Ajoutez le même conteneur Azure Blob et découvrez les domaines à l'aide de l'option Scan Domains.</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">Déployer les appareils DRVA requis.</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">Créez des volumes du journal de réplication à l'aide des datastores VSAN ou ANF disponibles.</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">Importez des domaines protégés et configurez RocVA (Recovery va) pour utiliser le datastore ANF dans le cadre du placement de VM.</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">Sélectionnez l'option de basculement appropriée et démarrez la réhydratation continue pour les domaines ou les machines virtuelles RTO proches de zéro.</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">En cas d'incident, déclenchez le basculement vers les datastores Azure NetApp Files sur le site AVS dédié à la reprise après incident.</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure Marketplace</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">Appelez le rétablissement vers le site protégé après la récupération du site protégé.avant de commencer, assurez-vous que les conditions préalables sont remplies comme indiqué dans le présent document<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> De plus, exécutez l'outil de test de bande passante (BWT) fourni par JetStream Software pour évaluer les performances potentielles du stockage Azure Blob et de sa bande passante de réplication lorsqu'il est utilisé avec le logiciel JetStream DR. Une fois les conditions requises, y compris la connectivité, mises en place, configurez et abonnez-vous à JetStream DR pour AVS à partir du<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>. Une fois le pack logiciel téléchargé, procédez au processus d'installation décrit ci-dessus.</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">Lors de la planification et du démarrage de la protection pour un grand nombre de machines virtuelles (par exemple, 100+), utilisez l'outil de planification des capacités (CPT) du kit d'outils JetStream DR Automation. Fournissez une liste des machines virtuelles à protéger avec leurs préférences RTO et de groupes de récupération, puis exécutez CPT.</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT effectue les fonctions suivantes :</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">Combinaison des machines virtuelles dans des domaines de protection selon leur objectif de durée de restauration.</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">Définir le nombre optimal de DRVAS et leurs ressources.</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">Estimation de la bande passante de réplication requise.</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">L'identification des caractéristiques du volume du journal de réplication (capacité, bande passante, etc.)</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">Estimation de la capacité de stockage objet requise, etc.</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">Le nombre et le contenu des domaines prescrits dépendent de diverses caractéristiques des VM, telles que les IOPS moyennes, la capacité totale, la priorité (qui définit l'ordre de basculement), RTO et autres.</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">Installer JetStream DR dans le data Center sur site</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Le logiciel Jetstream DR est constitué de trois composants principaux : le serveur virtuel Jetstream DR Management Server (MSA), le dispositif virtuel DR (DRVA) et les composants hôtes (packages de filtres d'E/S). MSA est utilisé pour installer et configurer des composants hôtes sur le cluster de calcul, puis pour administrer le logiciel JetStream DR. La liste suivante fournit une description générale du processus d'installation :</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">Comment installer JetStream DR sur site</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">Vérifier les prérequis.</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">Exécutez l'outil de planification de la capacité pour obtenir des recommandations en matière de ressources et de configuration (facultatif, mais recommandé pour les essais de validation).</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">Déployez JetStream DR MSA sur un hôte vSphere du cluster désigné.</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">Lancez le MSA à l'aide de son nom DNS dans un navigateur.</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">Enregistrez le serveur vCenter avec MSA.pour effectuer l'installation, procédez comme suit :</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">Après le déploiement de JetStream DR MSA et l'enregistrement du serveur vCenter, accédez au plug-in JetStream DR à l'aide du client Web vSphere. Pour ce faire, accédez à Datacenter &gt; configurer &gt; JetStream DR.</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">Dans l'interface JetStream DR, sélectionnez le cluster approprié.</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">Configurez le cluster avec le package de filtre d'E/S.</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">Ajoutez un stockage Azure Blob Storage situé sur le site de reprise.</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">Déployez une appliance DR virtuelle (DRVA) depuis l'onglet Appliances.</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">Les DRVAS peuvent être créés automatiquement par CPT, mais pour les tests POC, nous vous recommandons de configurer et d'exécuter manuellement le cycle de reprise après incident (démarrer la protection &gt; basculement &gt; retour arrière).</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">JetStream DRVA est une appliance virtuelle qui facilite les principales fonctions du processus de réplication des données. Un cluster protégé doit contenir au moins un DRVA et, en général, un DRVA est configuré par hôte. Chaque DRVA peut gérer plusieurs domaines protégés.</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">Dans cet exemple, quatre DRVA ont été créés pour 80 machines virtuelles.</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">Créez des volumes de journal de réplication pour chaque DRVA à l'aide de VMDK provenant des datastores disponibles ou des pools de stockage iSCSI partagés indépendants.</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">À partir de l'onglet domaines protégés, créez le nombre requis de domaines protégés à l'aide des informations concernant le site Azure Blob Storage, l'instance DRVA et le journal de réplication. Un domaine protégé définit un ordinateur virtuel ou un ensemble de serveurs virtuels dans le cluster qui sont protégés ensemble et se voit attribuer un ordre de priorité pour les opérations de basculement/retour arrière.</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">Sélectionnez les machines virtuelles que vous souhaitez protéger et démarrez la protection des machines virtuelles du domaine protégé. La réplication des données commence alors dans le magasin d'objets blob désigné.</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">Vérifier que le même mode de protection est utilisé pour toutes les VM d'un domaine protégé.</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">Le mode Write- Back (VMDK) peut offrir de meilleures performances.</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">Vérifier que les volumes des journaux de réplication sont placés sur un stockage haute performance.</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">Les guides d'exécution de basculement peuvent être configurés pour regrouper les VM (appelés groupes de récupération), définir l'ordre de démarrage et modifier les paramètres CPU/mémoire avec les configurations IP.</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">Installez JetStream DR pour AVS dans un cloud privé Azure VMware solution à l'aide de la commande Exécuter</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">Il est recommandé de créer à l'avance un cluster Pilot-light à trois nœuds sur le site de récupération (AVS). L'infrastructure du site de reprise peut ainsi être préconfigurée, incluant les éléments suivants :</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">Segments de réseau de destination, pare-feu, services comme DHCP et DNS, etc.</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">Installation de JetStream DR pour AVS</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">La configuration des volumes ANF en tant que datastores, et moreJetStream DR prend en charge le mode RTO quasi-nul pour les domaines stratégiques. Pour ces domaines, le stockage de destination doit être préinstallé. ANF est un type de stockage recommandé dans ce cas.</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">La configuration réseau comprenant la création de segments doit être configurée sur le cluster AVS afin de répondre aux exigences sur site.</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">Selon les exigences des niveaux de service et de l'objectif RTO, il est possible d'utiliser un mode de basculement continu ou standard. Pour un RTO proche de zéro, la réhydratation continue doit être mise sur le site de reprise.</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">Comment installer JetStream DR pour AVS dans un cloud privé</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">Pour installer JetStream DR pour AVS sur un cloud privé Azure VMware solution, procédez comme suit :</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">Depuis le portail Azure, accédez à la solution Azure VMware, sélectionnez le cloud privé et sélectionnez Exécuter la commande &gt; packages &gt; JSDR.Configuration.</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">L'utilisateur CloudAdmin par défaut dans Azure VMware solution ne dispose pas des privilèges suffisants pour installer JetStream DR pour AVS. Azure VMware solution permet une installation simplifiée et automatisée de JetStream DR en appelant la commande Azure VMware solution Run pour JetStream DR.</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">La capture d'écran suivante montre l'installation à l'aide d'une adresse IP DHCP.</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">Une fois l'installation de JetStream DR pour AVS terminée, actualisez le navigateur. Pour accéder à l'interface de reprise après incident JetStream, allez dans SDDC Datacenter &gt; configurer &gt; JetStream DR.</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">À partir de l'interface JetStream DR, ajoutez le compte Azure Blob Storage utilisé pour protéger le cluster sur site en tant que site de stockage, puis exécutez l'option Scan Domains.</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">Une fois les domaines protégés importés, déployez les appareils DRVA. Dans cet exemple, la réhydratation continue est lancée manuellement à partir du site de restauration à l'aide de l'interface utilisateur JetStream DR.</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">Ces étapes peuvent également être automatisées à l'aide de plans créés par CPT.</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">Importez les domaines protégés et configurez le va de restauration de manière à utiliser le datastore ANF pour le positionnement des VM.</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">Assurez-vous que DHCP est activé sur le segment sélectionné et qu'un nombre suffisant d'adresses IP est disponible. Des adresses IP dynamiques sont utilisées temporairement pendant la restauration des domaines. Chaque machine virtuelle de restauration (y compris la réhydratation continue) requiert une adresse IP dynamique individuelle. Une fois la récupération terminée, le IP est libéré et peut être réutilisé.</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">Sélectionnez l'option de basculement appropriée (basculement continu ou basculement). Dans cet exemple, la réhydratation continue (basculement continu) est sélectionnée.</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">Exécution du basculement/retour arrière</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">Comment effectuer un basculement/retour arrière</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">Après un incident se produit dans le cluster protégé de l'environnement sur site (défaillance partielle ou complète), déclencher le basculement.</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT peut être utilisé pour exécuter le plan de basculement pour restaurer les machines virtuelles à partir d'Azure Blob Storage vers le site de restauration du cluster AVS.</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">Après le basculement (pour la réhydratation en continu ou standard) lorsque les machines virtuelles protégées ont été lancées dans AVS, la protection reprend automatiquement et la reprise après incident JetStream continue de répliquer leurs données dans les conteneurs appropriés/originaux dans Azure Blob Storage.</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">La barre des tâches affiche la progression des activités de basculement.</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">Une fois la tâche terminée, accédez aux machines virtuelles récupérées et l'entreprise continue d'être opérationnelle normalement.</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">Une fois que le site primaire est à nouveau opérationnel, le retour arrière peut être effectué. La protection des machines virtuelles est reprise et la cohérence des données doit être vérifiée.</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">Restaurer l'environnement sur site. Selon le type d'incident, il peut être nécessaire de restaurer et/ou de vérifier la configuration du cluster protégé. Si nécessaire, il peut être nécessaire de réinstaller le logiciel JetStream DR.</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">Remarque : le<block ref="cad8a6b900ca13dfc8b04dee1f744111" prefix=" " category="inline-code"></block> Le script fourni dans le kit d'automatisation peut être utilisé pour nettoyer le site protégé d'origine de toutes les machines virtuelles obsolètes, des informations de domaine, etc.</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">Accédez à l'environnement sur site restauré, accédez à l'interface utilisateur Jetstream DR et sélectionnez le domaine protégé approprié. Une fois que le site protégé est prêt à être restauré, sélectionnez l'option de retour arrière dans l'interface utilisateur.</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">Le plan de restauration généré par CPT peut également être utilisé pour initier le retour des VM et de leurs données du magasin d'objets vers l'environnement VMware d'origine.</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">Spécifier le délai maximal après la mise en pause des VM dans le site de reprise et leur redémarrage sur le site protégé. Cette durée comprend l'exécution de la réplication après l'arrêt des machines virtuelles de basculement, la propreté du site de restauration et la recréation des machines virtuelles sur le site protégé. La valeur recommandée par NetApp est de 10 minutes.</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">Exécuter le processus de retour arrière, puis confirmer la reprise de la protection des machines virtuelles et de la cohérence des données.</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Récupération de Rantomeware</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">Récupérer des données suite à un ransomware peut être une tâche extrêmement fastidieuse. En particulier, il peut être difficile pour les services IT de déterminer le point de retour sûr et, une fois déterminé, de garantir la protection des charges de travail récupérées contre les attaques se reproduisant (contre les programmes malveillants en veille ou à l'aide d'applications vulnérables).</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Jetstream DR pour AVS avec les datastores Azure NetApp Files peut résoudre ces problèmes en permettant aux entreprises de récupérer les données à partir de points disponibles dans le temps, de sorte que les charges de travail soient récupérées sur un réseau fonctionnel et isolé si nécessaire. La récupération permet aux applications de fonctionner et de communiquer entre elles sans les exposer au trafic nord- sud, offrant ainsi aux équipes de sécurité un endroit sûr pour effectuer des analyses et autres corrections nécessaires.</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">Disponibilité de région : datastore NFS supplémentaire pour ANF</block>
  <block id="668f202e4850de68f941501493126dea" category="doc">Tr-4940 : migrer des charges de travail vers un datastore Azure NetApp Files à l'aide de VMware HCX - Guide de démarrage rapide</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">Auteur(s) : Ingénierie de solutions NetApp</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">Présentation : migration de machines virtuelles avec VMware HCX, datastores Azure NetApp Files et solution Azure VMware</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">L'une des utilisations les plus courantes pour la solution Azure VMware et le datastore Azure NetApp Files est la migration des charges de travail VMware. VMware HCX est une option privilégiée qui fournit plusieurs mécanismes de migration pour déplacer des machines virtuelles sur site et leurs données vers les datastores Azure NetApp Files.</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX est principalement une plateforme de migration conçue pour simplifier la migration des applications, le rééquilibrage des charges de travail et même la continuité de l'activité dans les clouds. Il est inclus dans le cloud privé Azure VMware solution et offre de nombreuses façons de migrer les workloads et peut être utilisé pour les opérations de reprise d'activité.</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">Ce document fournit des instructions détaillées pour le provisionnement du datastore Azure NetApp Files, puis le téléchargement, le déploiement et la configuration de VMware HCX, notamment tous ses composants principaux sur site et côté solution VMware Azure, notamment l'interconnexion, l'extension réseau et l'optimisation WAN pour activer divers mécanismes de migration de VM.</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX fonctionne avec n'importe quel type de datastore lorsque la migration se trouve au niveau des VM. Ce document s'applique donc aux clients NetApp et aux clients non NetApp qui prévoient de déployer Azure NetApp Files avec Azure VMware, pour un déploiement cloud VMware rentable.</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">Étapes générales</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">Cette liste fournit les étapes générales nécessaires pour installer et configurer HCX Cloud Manager côté cloud Azure et installer HCX Connector sur site :</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">Installez HCX via le portail Azure.</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">Téléchargez et déployez le programme d'installation HCX Connector Open Virtualization Appliance (OVA) dans VMware vCenter Server sur site.</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">Activez HCX à l'aide de la clé de licence.</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">Couplez le connecteur VMware HCX sur site avec Azure VMware solution HCX Cloud Manager.</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">Configurez le profil réseau, le profil de calcul et le maillage de service.</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(Facultatif) effectuez l'extension réseau pour éviter toute nouvelle IP pendant les migrations.</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">Validez l'état du système et assurez-vous que la migration est possible.</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">Migrer les workloads de VM.</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">Avant de commencer, assurez-vous que les conditions préalables suivantes sont remplies. Pour plus d'informations, reportez-vous à ce document<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>. Une fois les prérequis, y compris la connectivité, mis en place, configurez et activez HCX en générant la clé de licence à partir du portail de solutions Azure VMware. Une fois le programme d'installation OVA téléchargé, procédez au processus d'installation comme décrit ci-dessous.</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCX Advanced est l'option par défaut et VMware HCX Enterprise Edition est également disponible via un ticket d'assistance et pris en charge sans frais supplémentaires.</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">Lien NetApp</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Lien Microsoft</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">Utilisez un SDDC (Software-Defined Data Center) ou créez un cloud privé avec la solution Azure VMware<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> ou ceci<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>.</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">Configurez une connexion VPN site à site ou une connexion à portée globale express</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">La migration des VM et des données associées depuis le data Center sur site compatible VMware vSphere nécessite une connectivité réseau du data Center vers l'environnement SDDC. Avant de migrer des workloads,<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> entre l'environnement sur site et le cloud privé respectif.</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">Le chemin du réseau depuis l'environnement VMware vCenter Server sur site vers le cloud privé Azure VMware solution doit prendre en charge la migration des machines virtuelles à l'aide de vMotion.</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">règles et ports de pare-feu</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">Assurez-vous que le nécessaire<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sont autorisées pour le trafic vMotion entre vCenter Server sur site et SDDC vCenter. Dans le cloud privé, le routage sur le réseau vMotion est configuré par défaut.</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Le volume NFS Azure NetApp Files doit être monté en tant que datastore dans Azure VMware solution. Suivez les étapes décrites dans ce document<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Connexion de datastores Azure NetApp Files aux hôtes Azure VMware Solutions</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">Architecture de haut niveau</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">À des fins de test, l'environnement de laboratoire sur site utilisé pour cette validation a été connecté par le biais d'un VPN site à site, permettant une connectivité sur site à la solution Azure VMware.</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">Cette image illustre l'architecture de haut niveau utilisée dans cette solution.</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">Déploiement de la solution</block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">Suivez les étapes du déploiement de cette solution :</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">Étape 1 : installez HCX via Azure Portal à l'aide de l'option Add-ons</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">Pour effectuer l'installation, procédez comme suit :</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Connectez-vous au portail Azure et accédez au cloud privé Azure VMware solution.</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">Sélectionnez le cloud privé approprié et accédez à des modules complémentaires. Pour ce faire, accédez à *Manage &gt; Add-ons*.</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">Dans la section mobilité de la charge de travail HCX, cliquez sur *Get Started*.</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">Capture d'écran de la section mobilité de la charge de travail HCX.</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">Sélectionnez l'option *J'accepte les termes et conditions* et cliquez sur *Activer et déployer*.</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">Le déploiement par défaut est HCX Advanced. Ouvrez une demande d'assistance pour activer l'édition Enterprise.</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">Le déploiement prend environ 25 à 30 minutes.</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">Capture d'écran de la fin de la section mobilité de la charge de travail HCX.</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">Étape 2 : déployer le fichier OVA du programme d'installation dans le serveur vCenter sur site</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">Pour que le connecteur sur site puisse se connecter à HCX Manager dans Azure VMware solution, assurez-vous que les ports pare-feu appropriés sont ouverts dans l'environnement sur site.</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">Pour télécharger et installer HCX Connector dans le serveur vCenter sur site, procédez comme suit :</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">Depuis le portail Azure, accédez à la solution VMware Azure, sélectionnez le cloud privé, puis sélectionnez *Manage &gt; Add-ons &gt; migration* à l'aide de HCX et copiez le portail HCX Cloud Manager pour télécharger le fichier OVA.</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">Utilisez les informations d'identification par défaut de l'utilisateur CloudAdmin pour accéder au portail HCX.</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">Capture d'écran du portail Azure pour télécharger le fichier OVA HCX.</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">Une fois que vous avez accédé au portail HCX avec mailto:cloudadmin@vsphere.lockubl[cloudadmin@vsphere.lockubl^] à l'aide de la commande jumpost, accédez à *Administration &gt; mises à jour du système* et cliquez sur *demander un lien de téléchargement*.</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">Téléchargez ou copiez le lien vers le fichier OVA et collez-le dans un navigateur pour lancer le processus de téléchargement du fichier OVA VMware HCX Connector à déployer sur le serveur vCenter sur site.</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">Erreur : capture d'écran du lien de téléchargement OVA.</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">Une fois le fichier OVA téléchargé, déployez-le dans l'environnement VMware vSphere sur site à l'aide de l'option *Deploy OVF Template*.</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">Erreur : capture d'écran pour sélectionner le modèle OVA correct.</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">Entrez toutes les informations requises pour le déploiement OVA, cliquez sur *Next*, puis sur *Finish* pour déployer le connecteur OVA VMware HCX.</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">Mettez l'appliance virtuelle sous tension manuellement.</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">Guide de l'utilisateur VMware HCX</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">Pour des instructions détaillées, reportez-vous à la<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">Étape 3 : activez le connecteur HCX avec la clé de licence</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">Après avoir déployé le connecteur OVA VMware HCX sur site et démarré l'appliance, procédez comme suit pour activer le connecteur HCX. Générez la clé de licence à partir du portail Azure VMware solution et activez-la dans VMware HCX Manager.</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">Depuis le portail Azure, accédez à la solution VMware Azure, sélectionnez le cloud privé et sélectionnez *gérer &gt; modules complémentaires &gt; migration à l'aide de HCX*.</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">Sous *connexion avec sur site à l'aide des clés HCX*, cliquez *Ajouter* et copiez la clé d'activation.</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">Capture d'écran pour l'ajout de clés HCX.</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">Une clé distincte est requise pour chaque connecteur HCX sur site déployé.</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">Connectez-vous au gestionnaire VMware HCX sur site à l'adresse<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> utilisation des informations d'identification administrateur.</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">Utiliser le mot de passe défini lors du déploiement de l'OVA.</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">Dans la licence, entrez la clé copiée à partir de l'étape 3 et cliquez sur *Activer*.</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">Le connecteur HCX sur site doit disposer d'un accès Internet.</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">Sous *Datacenter Location*, indiquez l'emplacement le plus proche pour l'installation sur site de VMware HCX Manager. Cliquez sur *Continuer*.</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">Sous *Nom du système*, mettez à jour le nom et cliquez sur *Continuer*.</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">Cliquez sur *Oui, Continuer*.</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">Sous *Connect Your vCenter*, indiquez le nom de domaine complet (FQDN) ou l'adresse IP de vCenter Server et les informations d'identification appropriées, puis cliquez sur *Continuer*.</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">Utilisez le FQDN pour éviter les problèmes de connectivité ultérieurement.</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">Sous *configurer SSO/PSC*, indiquez le FQDN ou l'adresse IP du contrôleur Platform Services Controller et cliquez sur *Continuer*.</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">Entrez le FQDN ou l'adresse IP de VMware vCenter Server.</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">Vérifiez que les informations saisies sont correctes et cliquez sur *redémarrer*.</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">Après le redémarrage des services, vCenter Server s'affiche en vert sur la page qui s'affiche. VCenter Server et SSO doivent avoir les paramètres de configuration appropriés, qui doivent être identiques à la page précédente.</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">Ce processus dure environ 10 à 20 minutes et le plug-in doit être ajouté à vCenter Server.</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">Capture d'écran montrant le processus terminé.</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">Étape 4 : connecteur VMware HCX sur site avec Azure VMware solution HCX Cloud Manager</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">Une fois que HCX Connector est installé à la fois sur site et dans Azure VMware solution, configurez le connecteur VMware HCX sur site pour le cloud privé Azure VMware solution en ajoutant le couplage. Pour configurer le couplage du site, procédez comme suit :</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">Pour créer une paire de sites entre l'environnement vCenter sur site et Azure VMware solution SDDC, connectez-vous au serveur vCenter sur site et accédez au nouveau plug-in client Web HCX vSphere.</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">Capture d'écran du plug-in client Web HCX vSphere.</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">Sous Infrastructure, cliquez sur *Ajouter un couplage de site*.</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">Entrez l'URL ou l'adresse IP d'Azure VMware solution HCX Cloud Manager et les identifiants du rôle CloudAdmin pour accéder au cloud privé.</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">Capture d'écran URL ou adresse IP et informations d'identification pour le rôle CloudAdmin.</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">Cliquez sur *connexion*.</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">Le connecteur VMware HCX doit pouvoir acheminer vers l'IP HCX Cloud Manager via le port 443.</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">Une fois le couplage créé, le couplage de site nouvellement configuré est disponible sur le tableau de bord HCX.</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">Capture d'écran du processus terminé sur le tableau de bord HCX.</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">Étape 5 : configurer le profil réseau, le profil de calcul et le maillage de service</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">Le dispositif d'interconnexion VMware HCX offre des fonctionnalités de réplication et de migration basée sur vMotion via Internet et des connexions privées vers le site cible. L'interconnexion offre le cryptage, l'ingénierie du trafic et la mobilité des machines virtuelles. Pour créer une appliance de service d'interconnexion, procédez comme suit :</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">Sous Infrastructure, sélectionnez *Interconnexion &gt; maillage de service multisite &gt; profils de calcul &gt; Créer un profil de calcul*.</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">Les profils de calcul définissent les paramètres de déploiement, y compris les appliances déployées et la partie du data Center VMware accessible au service HCX.</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">Capture d'écran de la page vSphere client Interconnect</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">Une fois le profil de calcul créé, créez les profils réseau en sélectionnant *maillage de service multisite &gt; profils réseau &gt; Créer profil réseau*.</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">Le profil réseau définit une plage d'adresses IP et de réseaux utilisés par HCX pour ses appliances virtuelles.</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">Cette étape nécessite au moins deux adresses IP. Ces adresses IP sont attribuées depuis le réseau de gestion aux dispositifs d'interconnexion.</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">Capture d'écran indiquant l'ajout d'adresses IP à la page vSphere client Interconnect.</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">A ce stade, les profils de calcul et de réseau ont été créés avec succès.</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">Créez le maillage de service en sélectionnant l'onglet *maillage de service* dans l'option *Interconnexion* et sélectionnez les sites SDDC sur site et Azure.</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">Le maillage de service spécifie une paire de profils réseau et de calcul locale et distante.</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">Dans le cadre de ce processus, les appliances HCX sont déployées et configurées automatiquement sur les sites source et cible afin de créer une structure de transport sécurisée.</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">Capture d'écran de l'onglet maillage de service sur la page vSphere client Interconnect.</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">Il s'agit de la dernière étape de la configuration. Le déploiement devrait s'effectuer en 30 minutes environ. Une fois le maillage de service configuré, l'environnement est prêt avec les tunnels IPsec créés pour migrer les VM de charge de travail.</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">Capture d'écran du processus terminé sur la page vSphere client Interconnect.</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">Étape 6 : migrer les workloads</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">Les charges de travail peuvent être migrées dans un sens bidirectionnel entre les SDDC sur site et Azure à l'aide de différentes technologies de migration VMware HCX. Les machines virtuelles peuvent être déplacées vers et depuis des entités activées par VMware HCX à l'aide de plusieurs technologies de migration telles que la migration en bloc HCX, HCX vMotion, la migration à froid HCX, l'option vMotion par réplication assistée par HCX (disponible avec l'édition Enterprise de HCX) et la migration assistée par système d'exploitation HCX (disponible avec l'édition Enterprise de HCX).</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">Types de migration VMware HCX</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">Pour en savoir plus sur les différents mécanismes de migration HCX, voir<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>.</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">*Migration groupée*</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">Cette section détaille le mécanisme de migration en bloc. Lors d'une migration en bloc, la fonctionnalité de migration en bloc de HCX utilise la réplication vSphere pour migrer des fichiers de disque tout en recréant la machine virtuelle sur l'instance vSphere HCX de destination.</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">Pour démarrer une migration de serveurs virtuels en bloc, procédez comme suit :</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">Accédez à l'onglet *migration* sous *Services &gt; migration*.</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">Capture d'écran de la section migration du client vSphere.</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">Sous *Remote site Connection*, sélectionnez la connexion du site distant et sélectionnez la source et la destination. Dans cet exemple, le terminal Microsoft Azure VMware solution SDDC HCX est la destination.</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">Cliquez sur *Sélectionner les VM pour migration*. Fournit une liste de toutes les machines virtuelles sur site. Sélectionnez les machines virtuelles en fonction de l'expression correspondance:valeur et cliquez sur *Ajouter*.</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">Dans la section *transfert et placement*, mettez à jour les champs obligatoires (*Cluster*, *Storage*, *destination* et *Network*), y compris le profil de migration, puis cliquez sur *Validate*.</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">Capture d'écran de la section transfert et placement du client vSphere.</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">Une fois les vérifications de validation terminées, cliquez sur *Go* pour lancer la migration.</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">Capture d'écran de l'initiation de la migration.</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">Au cours de cette migration, un disque réservé est créé dans le datastore Azure NetApp Files spécifié dans le vCenter cible afin de permettre la réplication des données du disque de la machine virtuelle source vers les disques de l'espace réservé. Le mode HBR est déclenché pour une synchronisation complète vers la cible. Une fois la ligne de base terminée, une synchronisation incrémentielle est effectuée en fonction du cycle de l'objectif de point de récupération (RPO). Une fois la synchronisation complète/incrémentielle terminée, le basculement est déclenché automatiquement, sauf si un planning spécifique est défini.</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">Une fois la migration terminée, validez la même opération en accédant au SDDC vCenter de destination.</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">Pour plus d'informations sur les différentes options de migration et sur la façon de migrer des workloads du site vers la solution VMware Azure via HCX, consultez<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="73e6478a04a38e6c1af3fd112abd351f" category="paragraph">Pour en savoir plus sur ce processus, n'hésitez pas à suivre la vidéo de présentation détaillée :</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">Voici une capture d'écran de l'option HCX vMotion.</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">Assurez-vous que suffisamment de bande passante est disponible pour gérer la migration.</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">L'espace du datastore ANF cible doit être suffisant pour gérer la migration.</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">Que vous ciblez les clouds ou les clouds hybrides et les données qui résident sur un système de stockage de tout type ou fournisseur sur site, Azure NetApp Files et HCX offrent d'excellentes options pour déployer et migrer les charges de travail applicatives tout en réduisant le coût total de possession en rendant les données requises de manière transparente dans la couche applicative. Quelle que soit l'utilisation, optez pour Azure VMware solution et Azure NetApp Files afin de bénéficier rapidement des avantages du cloud, d'une infrastructure cohérente et des opérations sur site et dans plusieurs clouds, de la portabilité bidirectionnelle des charges de travail, et de la capacité et des performances élevées. Il s'agit du même processus et procédures que celui utilisé pour connecter le stockage et migrer les machines virtuelles à l'aide de VMware vSphere Replication, VMware vMotion ou même de la copie de fichiers réseau (NFC).</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">Messages clés</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">Les points clés de ce document sont les suivants :</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">Vous pouvez désormais utiliser Azure NetApp Files comme datastore dans Azure VMware solution SDDC.</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">Vous pouvez migrer facilement les données depuis un environnement sur site vers un datastore Azure NetApp Files.</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">Vous pouvez aisément étendre et réduire le datastore Azure NetApp Files afin de répondre aux exigences en termes de capacités et de performances lors de l'activité de migration.</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">Pour en savoir plus sur les informations fournies dans ce document, visitez nos sites web :</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Documentation sur la solution Azure VMware</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Documentation Azure NetApp Files</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Fonctionnalités NetApp pour Azure AVS</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">Découvrez plus en détail les fonctionnalités que NetApp propose à Azure VMware solution (AVS) : de NetApp en tant que dispositif de stockage connecté à l'invité ou un datastore NFS supplémentaire pour migrer les workflows, étendre/bursting au cloud, sauvegarde/restauration et reprise après incident.</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">Passez directement à la section du contenu souhaité en sélectionnant l'une des options suivantes :</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="inline-link-macro">Configuration d'AVS dans Azure</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="inline-link-macro">Options de stockage NetApp pour AVS</block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">Solutions clouds NetApp/VMware</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">Comme sur site, il est essentiel de planifier un environnement de virtualisation basé sur le cloud pour créer des machines virtuelles et migrer vers un environnement prêt pour la production.</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">Le stockage In-guest est la seule méthode prise en charge de connexion de Cloud Volumes ONTAP à Azure VMware solution.</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="list-text">Validation de la connectivité réseau et accès au cloud privé</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">Étapes de configuration de AVS</block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">Afficher les détails <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>.</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">Le stockage NetApp peut être utilisé de plusieurs façons (soit en tant que point de connexion, soit en tant que datastore NFS supplémentaire) dans Azure AVS.</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">Options de stockage NetApp prises en charge</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">Visitez le site <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure prend en charge le stockage NetApp dans les configurations suivantes :</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">Option de stockage avec connexion invité pour AVS</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">Options supplémentaires de datastore NFS pour AVS</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">Afficher les détails <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>. Afficher les détails <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>.</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">Cas d'utilisation de la solution</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">Avec les solutions cloud de NetApp et VMware, le déploiement dans Azure AVS est très simple. Des cas se sont définis pour chaque domaine cloud défini par VMware :</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">Protection (inclut la reprise après incident et la sauvegarde/restauration)</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">Extension</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="list-text">Migrer</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Découvrez les solutions NetApp pour Azure AVS</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Solutions NetApp pour Azure VMware solution (AVS)</block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">En savoir plus sur les solutions NetApp pour Azure.</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware définit les workloads cloud en trois catégories :</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">Protection (y compris la reprise après incident et la sauvegarde/restauration)</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">Parcourez les solutions disponibles dans les sections suivantes.</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">Protéger</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">Reprise après incident avec ANF et JetStream (datastore NFS supplémentaire)</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">Reprise après incident avec ANF et CVO (stockage connecté à l'invité)</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">Migrez les charges de travail vers le datastore Azure NetApp Files avec VMware HCX</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">DISPONIBLE PROCHAINEMENT !</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">Présentation des solutions de datastores ANF</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">Chaque organisation réussie est sur le chemin de la transformation et de la modernisation. Dans le cadre de ce processus, les entreprises utilisent généralement leurs investissements VMware existants tout en tirant parti des avantages du cloud et en explorant comment rendre les processus de migration, de rafale, d'extension et de reprise sur incident aussi transparents que possible. Les clients qui migrent vers le cloud doivent évaluer les difficultés liées à la flexibilité et aux bursting, à la sortie du data Center, à la consolidation des data centers, aux scénarios de fin de vie, aux fusions, aux acquisitions, etc. L'approche adoptée par chaque organisation peut varier en fonction de leurs priorités commerciales respectives. Lors du choix des opérations basées sur le cloud, il est essentiel de choisir un modèle économique aux performances appropriées et à un obstacle minimal. Si vous choisissez la plateforme appropriée, l'orchestration du stockage et des workflows est particulièrement importante pour exploiter toute la puissance du déploiement cloud et de l'élasticité.</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Bien que la solution Azure VMware offre des fonctionnalités hybrides uniques à un client, les options de stockage natives limitées n'ont pas de utilité pour les entreprises qui utilisent de lourdes charges de travail. Le stockage étant directement lié aux hôtes, la seule façon de faire évoluer le stockage consiste à ajouter d'autres hôtes, ce qui permet d'augmenter les coûts de 35 à 40 % ou plus pour les charges de travail consommatrices de stockage. Ces charges de travail ont besoin d'un système de stockage supplémentaire, sans puissance supplémentaire, mais cela implique de payer pour des hôtes supplémentaires.</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">Examinons le scénario suivant : un client nécessite six hôtes pour la puissance (CPU virtuel/vmem), mais il a également des exigences importantes en matière de stockage. En fonction de leur évaluation, ils nécessitent 12 hôtes pour répondre aux besoins en stockage. Cela augmente le coût total de possession global car ils doivent acheter toute cette puissance supplémentaire lorsque c'est la capacité de stockage requise. Cette fonctionnalité est applicable à toutes les utilisations, y compris la migration, la reprise sur incident, l'bursting, le développement/test, et ainsi de suite.</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">La reprise après incident est un autre scénario commun à la solution Azure VMware. La plupart des entreprises ne disposent pas d'une stratégie de reprise après incident trop fiable ou peinent à justifier l'exécution d'un data Center fantôme pour la reprise après incident. Les administrateurs peuvent explorer les options de reprise après incident sans encombrement avec un cluster à lampe témoin ou un cluster à la demande. La capacité de stockage peut ensuite évoluer sans ajouter d'hôtes supplémentaires, ce qui représente une option intéressante.</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">Pour résumer, les cas d'utilisation peuvent être classés de deux façons :</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">Évolutivité de la capacité de stockage avec les datastores ANF</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">Utilisation des datastores ANF en tant que cible de reprise après incident pour un workflow de restauration optimisé en termes de coût depuis des sites ou des régions Azure entre les data centers Software-defined (SDDC).ce guide fournit des informations sur l'utilisation de Azure NetApp Files pour fournir un stockage optimisé aux datastores (actuellement dans une présentation publique) Avec les meilleures fonctionnalités de protection des données et de reprise après incident dans une solution Azure VMware, vous pouvez décharger la capacité de stockage du stockage VSAN.</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">Options VMware Cloud dans Azure</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Solution Azure VMware</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Azure VMware solution (AVS) est un service de cloud hybride qui permet de bénéficier pleinement des SDDC VMware d'un cloud public Microsoft Azure. AVS est une solution première entièrement gérée et prise en charge par Microsoft, puis vérifiée par VMware qui utilise l'infrastructure Azure. Par conséquent, les clients bénéficient de VMware ESXi pour la virtualisation du calcul, de VSAN pour le stockage hyper-convergé et de NSX pour la mise en réseau et la sécurité, tout en exploitant la présence mondiale de Microsoft Azure, des sites de data Center leaders de pointe et de notre écosystème de services et solutions Azure natifs. La combinaison d'Azure VMware solution SDDC et d'Azure NetApp Files offre les meilleures performances et une latence réseau minimale.</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">Quel que soit le cloud utilisé lorsqu'un SDDC VMware est déployé, le cluster initial inclut les composants suivants :</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">Hôtes VMware ESXi pour la virtualisation du calcul avec une appliance vCenter Server à gérer.</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">Stockage hyper-convergé VMware VSAN incluant les ressources de stockage physique de chaque hôte ESXi.</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">VMware NSX pour la mise en réseau virtuelle et la sécurité avec un cluster NSX Manager à des fins de gestion.</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">Qu'il s'agisse d'un cloud ou d'un cloud hybride, Azure NetApp Files constitue une excellente option pour déployer et gérer les workloads applicatifs et les services de fichiers tout en réduisant le coût total de possession, en rendant les exigences de données transparentes pour la couche applicative. Quelle que soit l'utilisation, optez pour Azure VMware solution et Azure NetApp Files pour bénéficier rapidement des avantages du cloud, d'une infrastructure cohérente et des opérations en local et dans plusieurs clouds, de la portabilité bidirectionnelle des charges de travail, ainsi que de la capacité et des performances élevées. Il s'agit du même processus que celui utilisé pour connecter le stockage. N'oubliez pas que la position des données a changé avec de nouveaux noms. Les outils et les processus restent les mêmes, et Azure NetApp Files contribue à optimiser le déploiement global.</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">Vous pouvez désormais utiliser Azure NetApp Files comme datastore sur AVS SDDC.</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">Améliorez les temps de réponse des applications et offrez une plus grande disponibilité pour accéder aux données des workloads à tout moment où qu'elles soient.</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">Simplifiez la complexité globale du stockage VSAN grâce à des fonctionnalités de redimensionnement simple et instantané.</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">Performances garanties pour les charges de travail stratégiques grâce aux fonctionnalités de remaniement dynamique.</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Si Azure VMware solution Cloud est la destination incontournable, Azure NetApp Files est la solution de stockage idéale pour optimiser le déploiement.</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Connexion des datastores Azure NetApp Files aux hôtes de solution Azure VMware (aperçu)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">La reprise d'activité dans le cloud est une solution résiliente et économique qui protège les charges de travail contre les pannes sur site et la corruption des données, comme les attaques par ransomware. NetApp SnapMirror permet de répliquer les charges de travail VMware sur site utilisant un stockage connecté à l'invité vers NetApp Cloud Volumes ONTAP exécuté dans Azure.</block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">Reprise après incident avec CVO et AVS (stockage connecté à l'invité)</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">Auteurs : Ravi BCB et Niyaz Mohamed, NetApp</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">La reprise d'activité dans le cloud est une solution résiliente et économique qui protège les charges de travail contre les pannes sur site et la corruption des données, comme les attaques par ransomware. NetApp SnapMirror permet de répliquer les charges de travail VMware sur site utilisant un stockage connecté à l'invité vers NetApp Cloud Volumes ONTAP exécuté dans Azure. Il s'agit aussi des données applicatives, mais qu'en est-il des machines virtuelles elles-mêmes ? La reprise sur incident doit couvrir tous les composants dépendants, notamment les machines virtuelles, les VMDK ou les données d'application. Pour ce faire, SnapMirror et Jetstream peuvent être utilisés pour restaurer de manière transparente les charges de travail répliquées sur site vers Cloud Volumes ONTAP tout en utilisant le stockage VSAN pour les VMDK de VM.</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">Ce document présente une approche détaillée de la configuration et des performances de la reprise après incident à l'aide de NetApp SnapMirror, JetStream et d'Azure VMware solution (AVS).</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">Hypothèses</block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">Ce document est axé sur le stockage invité pour les données d'applications (également appelé « invité connecté »), et nous supposons que l'environnement sur site utilise SnapCenter pour assurer des sauvegardes cohérentes au niveau des applications.</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">Ce document s'applique à toute solution de sauvegarde et de restauration tierce. En fonction de la solution utilisée dans l'environnement, suivez les bonnes pratiques pour créer des stratégies de sauvegarde conformes aux SLA de l'entreprise.</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">Pour la connectivité entre l'environnement sur site et le réseau virtuel Azure, utilisez la voie express à portée globale ou un WAN virtuel avec une passerelle VPN. Les segments doivent être créés en fonction de la conception VLAN sur site.</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">Plusieurs options de connexion des data centers sur site à Azure restent disponibles. Ainsi, nous ne pouvons pas présenter un workflow spécifique dans ce document. Pour en savoir plus sur la méthode de connectivité, consultez la documentation Azure.</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">Déploiement de la solution de reprise d'activité</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">Présentation du déploiement de la solution</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">Assurez-vous que les données applicatives sont sauvegardées à l'aide de SnapCenter avec les exigences de RPO requises.</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">Provisionnez Cloud Volumes ONTAP avec la taille d'instance appropriée à l'aide de Cloud Manager dans l'abonnement et le réseau virtuel appropriés.</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">Configurer SnapMirror pour les volumes applicatifs concernés.</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">Mettez à jour les règles de sauvegarde dans SnapCenter pour déclencher des mises à jour SnapMirror après les tâches planifiées.</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">Installez le logiciel JetStream DR dans le data Center sur site et commencez à protéger les machines virtuelles.</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">En cas d'incident, interrompre la relation SnapMirror avec Cloud Manager et déclencher le basculement des machines virtuelles vers des datastores Azure NetApp Files ou VSAN sur le site AVS dédié.</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">Reconnectez les LUN ISCSI et les montages NFS pour les machines virtuelles d'applications.</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">Annulez le rétablissement du site protégé après la restauration du site primaire.</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">Détails du déploiement</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">Configurez CVO pour Azure et répliquez les volumes dans CVO</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">Lien</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">La première étape consiste à configurer Cloud Volumes ONTAP sur Azure <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>) Et répliquez les volumes souhaités dans Cloud Volumes ONTAP avec les fréquences et les instantanés souhaités.</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">Configurez l'accès aux données des hôtes AVS et CVO</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">Deux facteurs importants à prendre en compte lors du déploiement d'un SDDC sont la taille du cluster SDDC dans la solution Azure VMware et le délai de conservation d'un SDDC. Ces deux considérations clés à prendre en compte dans une solution de reprise sur incident permettent de réduire les coûts d'exploitation globaux. Le SDDC peut héberger jusqu'à trois hôtes, tout comme un cluster multi-hôtes dans un déploiement à grande échelle.</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">La décision de déployer un cluster AVS se base principalement sur les exigences en matière de RPO/RTO. Avec la solution Azure VMware, le SDDC peut être provisionné dans le temps en préparation des tests ou d'un incident. Un SDDC déployé juste à temps fait gagner des coûts d'hôtes ESXi lorsque vous ne traitez pas d'incident. Néanmoins, ce type de déploiement affecte le RTO de quelques heures lors du provisionnement du SDDC.</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">L'option la plus courante consiste à faire fonctionner le SDDC en mode de fonctionnement toujours actif avec un voyant allumé. Cette option réduit l'empreinte de trois hôtes disponibles en continu et accélère les opérations de reprise en fournissant une base en cours d'exécution pour les activités de simulation et les vérifications de conformité, ce qui évite le risque de dérive opérationnelle entre les sites de production et de reprise. Le cluster de lampe témoin peut être rapidement étendu au niveau souhaité si nécessaire pour gérer un événement de reprise après incident réel.</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">Pour configurer AVS (qu'il s'agit de IT à la demande ou en mode témoin lumineux), voir<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>. Avant cela, vérifiez que les machines virtuelles invitées résidant sur les hôtes AVS peuvent consommer des données depuis Cloud Volumes ONTAP une fois la connectivité établie.</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Une fois que Cloud Volumes ONTAP et AVS ont été correctement configurés, commencez par configurer Jetstream pour automatiser la restauration des charges de travail sur site vers AVS (machines virtuelles avec VMDK des applications et machines virtuelles avec stockage « Guest ») à l'aide du mécanisme VAIO et en exploitant SnapMirror pour les copies de volumes d'applications vers Cloud Volumes ONTAP.</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">Installer JetStream DR dans le data Center sur site</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Le logiciel Jetstream DR est constitué de trois composants principaux : le serveur virtuel JetStream DR Management Server (MSA), le dispositif virtuel DR (DRVA) et les composants hôtes (packages de filtres E/S). MSA est utilisé pour installer et configurer des composants hôtes sur le cluster de calcul, puis pour administrer le logiciel JetStream DR. La procédure d'installation est la suivante :</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">Vérifiez les prérequis.</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">Exécutez l'outil de planification de la capacité pour obtenir des recommandations en matière de ressources et de configuration.</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">Déployez JetStream DR MSA sur chaque hôte vSphere du cluster désigné.</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">Enregistrez le serveur vCenter avec MSA.</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">Après le déploiement de JetStream DR MSA et l'enregistrement du serveur vCenter, accédez au plug-in JetStream DR avec le client Web vSphere. Pour ce faire, accédez à Datacenter &gt; configurer &gt; JetStream DR.</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">À partir de l'interface JetStream DR, effectuez les tâches suivantes :</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">Ajoutez le stockage Azure Blob situé sur le site de reprise.</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">Déployez le nombre requis d'appliances virtuelles de reprise sur incident (DR) dans l'onglet appliances.</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">Utiliser l'outil de planification de la capacité pour estimer le nombre d'ACR requis.</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">Créez des volumes de journal de réplication pour chaque DRVA à l'aide du VMDK provenant des datastores disponibles ou du pool de stockage iSCSI partagé indépendant.</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">À partir de l'onglet domaines protégés, créez le nombre requis de domaines protégés à l'aide des informations concernant le site Azure Blob Storage, l'instance DRVA et le journal de réplication. Un domaine protégé définit un ordinateur virtuel ou un ensemble de VM d'applications spécifiques au sein du cluster, qui sont protégés ensemble et ont un ordre de priorité pour les opérations de basculement/retour arrière.</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">Sélectionnez les VM à protéger et regroupez-les dans des groupes d'applications en fonction de la dépendance. Les définitions d'application vous permettent de regrouper des jeux de machines virtuelles en groupes logiques contenant leurs ordres de démarrage, leurs retards de démarrage et les validations d'applications en option qui peuvent être exécutées à la reprise.</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">Assurez-vous que le même mode de protection est utilisé pour toutes les machines virtuelles d'un domaine protégé.</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">Le mode Write-Back (VMDK) offre de meilleures performances.</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">Assurez-vous que les volumes des journaux de réplication sont placés sur un stockage haute performance.</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">Une fois que vous avez terminé, cliquez sur Démarrer la protection du domaine protégé. La réplication des données démarre pour les machines virtuelles sélectionnées vers le magasin de objets blob désigné.</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">Une fois la réplication terminée, l'état de protection de la VM est marqué comme récupérable.</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">Les runbooks de basculement peuvent être configurés pour regrouper les VM (appelé groupe de reprise), définir l'ordre de démarrage et modifier les paramètres CPU/mémoire avec les configurations IP.</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">Cliquez sur Paramètres, puis sur le lien Runbook Configure pour configurer le groupe Runbook.</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">Cliquez sur le bouton Créer un groupe pour commencer à créer un nouveau groupe de runbook.</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">Si nécessaire, dans la partie inférieure de l'écran, appliquez des pré-scripts personnalisés et des post-scripts pour s'exécuter automatiquement avant et après l'opération du groupe Runbook. Assurez-vous que les scripts Runbook résident sur le serveur de gestion.</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">Modifiez les paramètres de la machine virtuelle selon vos besoins. Spécifier les paramètres de restauration des VM, y compris la séquence de démarrage, le délai de démarrage (spécifié en secondes), le nombre de CPU et la quantité de mémoire à allouer. Modifier la séquence de démarrage des machines virtuelles en cliquant sur les flèches vers le haut ou vers le bas. Des options sont également fournies pour conserver MAC.</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">Les adresses IP statiques peuvent être configurées manuellement pour les machines virtuelles individuelles du groupe. Cliquez sur le lien vue NIC d'une machine virtuelle pour configurer manuellement ses paramètres d'adresse IP.</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">Cliquez sur le bouton configurer pour enregistrer les paramètres NIC pour les machines virtuelles respectives.</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">L'état des runbooks de basculement et de retour arrière est désormais répertorié comme configuré. Les groupes de runbooks de basculement et de retour arrière sont créés par paires en utilisant le même groupe initial de machines virtuelles et de paramètres. Si nécessaire, les paramètres d'un groupe de runbook peuvent être personnalisés individuellement en cliquant sur son lien Détails respectifs et en effectuant des modifications.</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">Installer JetStream DR pour AVS dans le cloud privé</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">Il est recommandé de créer à l'avance un cluster Pilot-light à trois nœuds sur le site de récupération (AVS). L'infrastructure du site de reprise peut ainsi être préconfigurée, notamment :</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">Segments de réseau de destination, pare-feu, services comme DHCP et DNS, etc</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">Configuration des volumes ANF comme datastore et plus encore</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR prend en charge un mode RTO proche de zéro pour les domaines stratégiques. Pour ces domaines, le stockage de destination doit être préinstallé. ANF est un type de stockage recommandé dans ce cas.</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">Selon les exigences des contrats de niveau de service et de durée de restauration, vous pouvez utiliser un mode de basculement continu ou standard. Pour un RTO proche de zéro, vous devez commencer la réhydratation continue sur le site de restauration.</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Pour installer JetStream DR pour AVS sur un cloud privé Azure VMware solution, utilisez la commande Exécuter. Depuis le portail Azure, accédez à la solution VMware Azure, sélectionnez le cloud privé et sélectionnez Exécuter la commande &gt; packages &gt; JSDR.Configuration.</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">L'utilisateur CloudAdmin par défaut de la solution Azure VMware ne dispose pas des privilèges suffisants pour installer JetStream DR pour AVS. La solution Azure VMware permet une installation simplifiée et automatisée de JetStream DR en appelant la commande Azure VMware solution Run pour JetStream DR.</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">Ajoutez le compte Azure Blob Storage qui a été utilisé pour protéger le cluster sur site en tant que site de stockage, puis exécutez l'option Scan Domains.</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">Dans la boîte de dialogue qui s'affiche, sélectionnez le domaine protégé à importer, puis cliquez sur son lien Importer.</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">Le domaine est importé pour la récupération. Accédez à l'onglet domaines protégés et vérifiez que le domaine prévu a été sélectionné ou choisissez le domaine souhaité dans le menu Sélectionner un domaine protégé. La liste des VM récupérables du domaine protégé s'affiche.</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">Une fois les domaines protégés importés, déployez les appareils DRVA.</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">Ces étapes peuvent également être automatisées à l'aide de plans créés par CPT.</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">Importez les domaines protégés et configurez le va de restauration de manière à utiliser un datastore ANF pour le positionnement des VM.</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">Assurez-vous que DHCP est activé sur le segment sélectionné et qu'un nombre suffisant d'adresses IP est disponible. Des adresses IP dynamiques sont utilisées temporairement pendant la restauration des domaines. Chaque machine virtuelle de restauration (y compris la réhydratation continue) requiert une adresse IP dynamique individuelle. Une fois la récupération terminée, le IP est libéré et peut être réutilisé.</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">Bien que les modes de basculement et de basculement continu diffèrent lorsque la configuration est effectuée, les deux modes de basculement sont configurés à l'aide des mêmes étapes. Les étapes de basculement sont configurées et effectuées ensemble en cas d'incident. Le basculement continu peut être configuré à tout moment, puis s'exécuter en arrière-plan pendant le fonctionnement normal du système. Après un incident, un basculement continu est effectué pour transférer immédiatement la propriété des machines virtuelles protégées vers le site de reprise (RTO quasi nul).</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">Le processus de basculement continu démarre et sa progression peut être surveillée dans l'interface utilisateur. Un clic sur l'icône bleue dans la section Etape actuelle permet d'afficher une fenêtre contextuelle affichant les détails de l'étape en cours du processus de basculement.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">Basculement et rétablissement</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">Après un incident se produit dans le cluster protégé de l'environnement sur site (défaillance partielle ou complète), vous pouvez déclencher le basculement pour les machines virtuelles à l'aide de Jetstream après avoir déclenché la relation SnapMirror pour les volumes d'application respectifs.</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">Cette étape peut facilement être automatisée afin de faciliter le processus de reprise.</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">Accédez à l'interface utilisateur Jetstream sur AVS SDDC (côté destination) et activez l'option de basculement pour terminer le basculement. La barre des tâches affiche la progression des activités de basculement.</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">Dans la boîte de dialogue qui s'affiche lors de la fin du basculement, la tâche de basculement peut être spécifiée comme planifié ou supposée être forcée.</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">Le basculement forcé suppose que le site principal n'est plus accessible et que la propriété du domaine protégé devrait être directement assumée par le site de reprise.</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">Une fois le basculement continu terminé, un message confirmant la fin de la tâche s'affiche. Une fois la tâche terminée, accédez aux VM récupérées pour configurer les sessions ISCSI ou NFS.</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">Le mode de basculement passe en mode d'exécution en basculement et l'état de la VM peut être récupérable. Toutes les machines virtuelles du domaine protégé sont à présent exécutées sur le site de reprise, dans l'état spécifié par les paramètres de runbook de basculement.</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">Pour vérifier la configuration et l'infrastructure de basculement, JetStream DR peut être utilisé en mode test (option Test Failover) afin d'observer la récupération des machines virtuelles et de leurs données à partir du magasin d'objets dans un environnement de restauration de test. Lorsqu'une procédure de basculement est exécutée en mode test, son fonctionnement ressemble à un processus de basculement réel.</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">Une fois les machines virtuelles restaurées, utilisez la reprise après incident du stockage pour le stockage invité. Pour démontrer ce processus, SQL Server est utilisé dans cet exemple.</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">Connectez-vous à la machine virtuelle SnapCenter récupérée sur AVS SDDC et activez le mode DR.</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">Accédez à l'interface utilisateur SnapCenter à l'aide du navigateur.</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">Dans la page Paramètres, accédez à Paramètres &gt; Paramètres globaux &gt; reprise après incident.</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">Sélectionnez Activer la reprise après incident.</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">Cliquez sur appliquer.</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">Vérifiez si la tâche DR est activée en cliquant sur Monitor &gt; Jobs.</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">NetApp SnapCenter 4.6 ou version ultérieure doit être utilisé pour la reprise après incident du stockage. Pour les versions précédentes, des snapshots cohérents avec les applications (répliqués à l'aide de SnapMirror) doivent être utilisés. Il convient également d'exécuter une restauration manuelle si les sauvegardes précédentes doivent être restaurées sur le site de reprise après incident.</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">S'assurer que la relation SnapMirror est rompue.</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Reliez le LUN de Cloud Volumes ONTAP à la machine virtuelle hôte SQL récupérée à l'aide des mêmes lettres de disque.</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">Ouvrez l'initiateur iSCSI, effacez la session précédente déconnectée et ajoutez la nouvelle cible avec les chemins d'accès multiples pour les volumes Cloud Volumes ONTAP répliqués.</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">Assurez-vous que tous les disques sont connectés à l'aide des mêmes lettres que celles utilisées avant la reprise sur incident.</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">Redémarrez le service serveur MSSQL.</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">Assurez-vous que les ressources SQL sont de nouveau en ligne.</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">Dans le cas d'un système NFS, reliez les volumes à l'aide de la commande mount et mettez à jour le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> entrées.</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">À ce stade, le fonctionnement de l'entreprise peut se faire et son activité se poursuit normalement.</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">Sur la fin NSX-T, il est possible de créer une passerelle de niveau 1 dédiée distincte pour simuler des scénarios de basculement. Cela permet de s'assurer que toutes les charges de travail peuvent communiquer les unes avec les autres, mais qu'aucun trafic ne peut être acheminé depuis et vers l'environnement, de manière à ce que les tâches de triage, de confinement ou de durcissement puissent être effectuées sans risque de contamination croisée. Cette opération est hors du champ d'application de ce document, mais elle peut être facilement réalisée pour simuler l'isolement.</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">Une fois que le site primaire est de nouveau opérationnel, vous pouvez effectuer le rétablissement. La protection de machine virtuelle est reprise par Jetstream et la relation SnapMirror doit être inversée.</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">Restaurer l'environnement sur site. Selon le type d'incident, il peut être nécessaire de restaurer et/ou de vérifier la configuration du cluster protégé. Si nécessaire, il peut être nécessaire de réinstaller le logiciel JetStream DR.</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">Le plan de restauration généré par CPT peut également être utilisé pour initier le retour des VM et de leurs données du magasin d'objets vers l'environnement VMware d'origine.</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">Préciser le délai maximal après la mise en pause des VM dans le site de reprise, puis leur redémarrage sur le site protégé. Le temps nécessaire à l'exécution de ce processus comprend l'achèvement de la réplication après l'arrêt des VM de basculement, le temps nécessaire pour nettoyer le site de reprise et le temps nécessaire pour recréer les VM sur le site protégé. NetApp recommande 10 minutes.</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">Suivre le processus de retour arrière, puis confirmer la reprise de la protection des machines virtuelles et la cohérence des données.</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">Une fois les machines virtuelles restaurées, déconnectez le stockage secondaire de l'hôte et connectez-vous au stockage primaire.</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">Vérifiez que les ressources SQL sont de nouveau en ligne.</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">Pour revenir au stockage primaire, veillez à ce que la direction de la relation reste la même qu'avant le basculement en effectuant une opération de resynchronisation inverse.</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">Pour conserver les rôles de stockage primaire et secondaire après l'opération de resynchronisation inverse, effectuez à nouveau l'opération de resynchronisation inverse.</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">Ce processus s'applique à d'autres applications telles qu'Oracle, des versions similaires des bases de données et à toutes les autres applications qui utilisent un système de stockage connecté par l'invité.</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">Comme toujours, testez les étapes de récupération des charges de travail critiques avant de les porter en production.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">Avantages de cette solution</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">Utilise la réplication efficace et résiliente de SnapMirror.</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">Restauration des points disponibles à temps avec la conservation des snapshots de ONTAP.</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">Une automatisation complète est disponible pour toutes les étapes nécessaires à la restauration de centaines de milliers de machines virtuelles, depuis les étapes de validation du stockage, du calcul, du réseau et des applications.</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter utilise des mécanismes de clonage qui ne modifient pas le volume répliqué.</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">Cela permet d'éviter le risque de corruption des données pour les volumes et les snapshots.</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">Evite les interruptions de réplication pendant les workflows de test de reprise après incident</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">Optimise les données de reprise après incident pour les flux de travail autres que la reprise après incident, comme le développement/test, les tests de sécurité, les tests de correctifs et de mise à niveau, et les tests de résolution des problèmes.</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">L'optimisation du processeur et de la RAM permet de réduire les coûts liés au cloud en permettant la restauration sur des clusters de calcul plus petits.</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">Fournisseurs de cloud public : options de stockage NetApp</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">Découvrez les options de NetApp en tant que stockage dans les trois principaux hyperscalers.</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS prend en charge le stockage NetApp dans les configurations suivantes :</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="list-text">FSX ONTAP en tant que stockage invité connecté</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP en tant que datastore NFS supplémentaire</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">Options de stockage à connexion invité pour VMC</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">Options supplémentaires des datastores NFS pour VMC</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">Afficher les détails <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>. Afficher les détails <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>.</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure/AVS</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">Afficher les détails <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>. Afficher les détails <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud prend en charge le stockage NetApp dans les configurations suivantes :</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="list-text">Cloud Volumes Service (CVS) comme stockage connecté invité</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">Options de stockage de connexion invité pour GCVE</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">Afficher les détails <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>.</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">Présentation du multicloud hybride NetApp avec VMware</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">La plupart des départements IT adoptent une approche axée sur le cloud hybride. Ces entreprises sont en phase de transformation. Les clients évaluent leur environnement IT actuel, puis migrent leurs charges de travail vers le cloud à partir de l'évaluation et de l'exercice de découverte.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">Les clients qui migrent vers le cloud peuvent inclure l'élasticité et les pics d'utilisation, la sortie du data Center, la consolidation du data Center, des scénarios de fin de vie, des fusions, des acquisitions, etc. La raison de cette migration peut varier en fonction de chaque entreprise et de leurs priorités business. Lors de la migration vers le cloud hybride, il est primordial de choisir le bon stockage dans le cloud pour bénéficier de la puissance du déploiement et de l'élasticité du cloud.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">Options clouds VMware dans le cloud public</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">avs</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware solution est un service de cloud hybride qui permet d'assurer un fonctionnement optimal des SDDC VMware dans le cloud public Microsoft Azure. Azure VMware solution est une solution première entièrement gérée et prise en charge par Microsoft, vérifiée par VMware exploitant l'infrastructure Azure. Cela signifie qu'lors du déploiement de la solution Azure VMware, les clients bénéficient de VMware ESXi pour la virtualisation du calcul, de VSAN pour le stockage hyper-convergé, Enfin, NSX pour la mise en réseau et la sécurité, tout en exploitant la présence mondiale de Microsoft Azure, d'installations de data Center de premier plan et à proximité de notre riche écosystème de services et de solutions Azure natifs.</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="section-title">VMware Cloud sur AWS</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">vmc</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud sur AWS permet au logiciel SDDC de VMware d'entreprise d'accéder au cloud AWS grâce à un accès optimisé aux services AWS natifs. Optimisée par VMware Cloud Foundation, VMware Cloud sur AWS intègre les produits de virtualisation du réseau, du stockage et de calcul de VMware (VMware vSphere, VMware VSAN et VMware NSX), ainsi que la solution de gestion de VMware vCenter Server, optimisée pour s'exécuter sur une infrastructure AWS dédiée, flexible et sans système d'exploitation.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Moteur VMware Google Cloud</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine est une offre d'infrastructure en tant que service (IaaS) basée sur l'infrastructure évolutive haute performance de Google Cloud et sur la pile VMware Cloud Foundation : VMware vSphere, vCenter, VSAN et NSX-T. Ce service permet une migration rapide vers le cloud, et ceci de migrer ou d'étendre les charges de travail VMware existantes d'un environnement sur site à Google Cloud Platform sans le coût, les efforts ou le risque de modifier l'architecture des applications ou d'exploiter de nouveau les opérations. Il s'agit d'un service vendu et pris en charge par Google, en étroite collaboration avec VMware.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">Un cloud privé SDDC et la colocation NetApp Cloud volumes offrent les meilleures performances avec une latence réseau minimale.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">Le saviez-vous ?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">Quel que soit le cloud utilisé lorsqu'un SDDC VMware est déployé, le cluster initial inclut les produits suivants :</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">Hôtes VMware ESXi pour la virtualisation du calcul avec une appliance vCenter Server à gérer</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">Stockage hyper-convergé VMware VSAN incluant les ressources de stockage physique de chaque hôte ESXi</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">VMware NSX pour la mise en réseau virtuelle et la sécurité avec un cluster NSX Manager à des fins de gestion</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">Configuration de stockage sous-jacente</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">Pour les clients qui prévoient d'héberger des charges de travail exigeantes en stockage et de faire évoluer horizontalement sur n'importe quelle solution VMware hébergée dans le cloud, l'infrastructure hyperconvergée par défaut impose que l'extension soit sur les ressources de calcul et de stockage.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">En s'intégrant avec NetApp Cloud volumes, comme Azure NetApp Files, Amazon FSX pour NetApp ONTAP, Cloud Volumes ONTAP (disponible dans les trois principaux hyperscalers) et Cloud Volumes Service pour Google Cloud, les clients peuvent désormais faire évoluer leur stockage séparément Il suffit d'ajouter des nœuds de calcul au cluster SDDC selon les besoins.</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware ne recommande pas de configurations de cluster non équilibrées. L'extension du stockage entraîne donc un ajout d'hôtes, ce qui implique un coût total de possession plus élevé.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">Un seul environnement VSAN est possible. Par conséquent, tout le trafic de stockage sera directement en concurrence avec les workloads de production.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">Il n'est pas possible de fournir plusieurs tiers de performance pour répondre aux exigences des applications, aux performances et aux coûts.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">Il est très facile d'atteindre les limites de capacité de stockage de VSAN basées sur le cluster hôtes. Utilisez NetApp Cloud volumes pour faire évoluer le stockage soit pour héberger des datasets actifs, soit pour hiérarchiser les données inactives dans un stockage persistant.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSX pour NetApp ONTAP, Cloud Volumes ONTAP (disponible dans les trois principaux hyperscalers) et Cloud Volumes Service pour Google Cloud peuvent être associés à des VM invités. Cette architecture de stockage hybride est composée d'un datastore VSAN qui contient le système d'exploitation invité et les données binaires des applications. Les données d'application sont reliées à la machine virtuelle via un initiateur iSCSI basé sur l'invité ou des montages NFS/SMB qui communiquent directement avec Amazon FSX pour NetApp ONTAP, Cloud Volume ONTAP, Azure NetApp Files et Cloud Volumes Service pour Google Cloud respectivement. Cette configuration vous permet de relever facilement les défis en matière de capacité de stockage. Comme avec VSAN, l'espace libre disponible dépend de l'espace Slack et des règles de stockage utilisées.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">Considérons un cluster SDDC à trois nœuds sous VMware Cloud sur AWS :</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">La capacité brute totale d'un SDDC à trois nœuds = 31 To (environ 10 To pour chaque nœud).</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">L'espace Slack à conserver avant d'ajouter des hôtes supplémentaires = 25 % = (.25 x 31,1 To) = 7,7 To.</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">La capacité brute utilisable après la perte d'espace Slack = 23.4 To</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">L'espace disponible effectif dépend de la stratégie de stockage appliquée.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Par exemple :</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = espace libre effectif = 23,4 To (capacité brute utilisable/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = espace libre effectif = 11,7 To (capacité brute utilisable/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = espace libre effectif = 17,5 To (capacité brute utilisable/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">Ainsi, l'utilisation de NetApp Cloud volumes en tant que stockage connecté à l'invité permettrait d'étendre le stockage et d'optimiser le TCO tout en répondant aux exigences de performances et de protection des données.</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">Le stockage invité était la seule option disponible au moment de l'écriture de ce document. Une documentation supplémentaire sera disponible lors de la prise en charge des datastores NFS <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>.</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">Dans les modèles de stockage hybride, placez des workloads de Tier 1 ou hautement prioritaires sur le datastore VSAN pour répondre aux exigences de latence spécifiques, car ils font partie de l'hôte lui-même et à proximité. Utilisation de mécanismes In-Guest pour les machines virtuelles de charges de travail pour lesquelles les latences transactionnelles sont acceptables</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">Utilisez la technologie NetApp SnapMirror® pour répliquer les données des workloads depuis le système ONTAP sur site vers Cloud Volumes ONTAP ou Amazon FSX pour NetApp ONTAP afin de faciliter la migration à l'aide de mécanismes de niveau bloc. Cela ne s'applique pas aux services Azure NetApp Files et Cloud volumes. Pour la migration des données vers Azure NetApp Files ou Cloud volumes Services, utilisez NetApp XCP, Cloud Sync, rysnc ou robocopy, selon le protocole de fichiers utilisé.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">Les tests montrent une latence supplémentaire de 2 à 4 ms lors de l'accès au stockage à partir des data centers SDDC respectifs. Tenez compte de cette latence supplémentaire dans les exigences des applications lors du mappage du stockage.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">Pour le montage du stockage connecté à l'invité pendant le basculement test et le basculement réel, assurez-vous que les initiateurs iSCSI sont reconfigurés, que le DNS est mis à jour pour les partages SMB et que les points de montage NFS sont mis à jour dans fstab.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">Assurez-vous que les paramètres du registre d'expiration des disques (MPIO), de pare-feu et de chemins d'accès E/S multiples (Multipath I/O) intégré à l'invité sont correctement configurés à l'intérieur de la machine virtuelle.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">Ceci s'applique uniquement au stockage connecté à l'invité.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">Avantages du stockage cloud NetApp</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">Le stockage cloud NetApp offre plusieurs avantages :</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">Améliore la densité de calcul à stockage en faisant évoluer le stockage indépendamment de la puissance de calcul.</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">Permet de réduire le nombre d'hôtes, ce qui réduit le coût total de possession global.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">La défaillance du nœud de calcul n'a aucune incidence sur les performances du stockage.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">La réorganisation des volumes et la fonctionnalité de niveau de service dynamique d'Azure NetApp Files permettent d'optimiser les coûts par le dimensionnement des charges de travail prévisibles, tout en empêchant le surprovisionnement.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">L'efficacité du stockage, le Tiering cloud et les fonctionnalités de modification du type d'instance de Cloud Volumes ONTAP offrent des moyens optimaux d'ajouter et de faire évoluer le stockage.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">Les capacités de surprovisionnement ne sont ajoutées qu'en cas de besoin.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">Des copies et des clones efficaces Snapshot vous permettent de créer rapidement des copies sans affecter les performances.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Aide à contrer les attaques par ransomware grâce à la restauration rapide à partir de copies Snapshot.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">Assure une reprise après incident régionale et un niveau de bloc de sauvegarde intégré efficaces par transfert de blocs entre les régions pour un meilleur RPO et RTO.</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">La technologie SnapMirror ou d'autres mécanismes pertinents de migration des données sont activés. De nombreuses options de connectivité sont disponibles, sur site comme dans tout cloud hyperscale. Utilisez le parcours approprié et collaborez avec les équipes de mise en réseau concernées.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">Faites appel aux architectes de solutions NetApp et aux architectes de cloud hyperscale pour planifier et dimensionner le stockage et le nombre d'hôtes requis. NetApp recommande d'identifier les exigences en matière de performances de stockage avant d'utiliser le dimensionnement Cloud Volumes ONTAP pour finaliser le type d'instance de stockage ou le niveau de service approprié avec le débit adéquat.</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">Sur un plan général, cette architecture (illustrée dans la figure ci-dessous) explique comment bénéficier d'une connectivité multicloud hybride et de la portabilité des applications entre plusieurs fournisseurs de cloud utilisant NetApp Cloud Volumes ONTAP, Cloud Volumes Service pour Google Cloud et Azure NetApp Files comme option de stockage invité supplémentaire.</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">Architecture du cloud hybride d'entreprise</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">Solutions de multicloud hybride NetApp pour GCP/GCVE</block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Fonctionnalités NetApp pour Google Cloud Platform GCVE</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">En savoir plus sur les fonctionnalités que NetApp propose à Google Cloud Platform (GCP) Google Cloud Virtualization Engine (GCVE) - de NetApp en tant que périphérique de stockage connecté à l'invité ou un datastore NFS supplémentaire pour la migration des workflows, l'extension/la bursting dans le cloud, la sauvegarde/restauration et la reprise après incident.</block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="inline-link-macro">Configuration de GCVE dans GCP</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="inline-link-macro">Options de stockage NetApp pour GCVE</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">Cette section décrit comment configurer et gérer GCVE et l'utiliser en association avec les options disponibles pour la connexion du stockage NetApp.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">Le stockage « en invité » est la seule méthode prise en charge pour connecter Cloud Volumes ONTAP et Cloud volumes Services à GCVE.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="list-text">Déployer et configurer GCVE</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="list-text">Activez l'accès privé à GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">Étapes de configuration pour GCVE</block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">Afficher les détails <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>.</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">Le stockage NetApp peut être utilisé de plusieurs façons - soit en tant que connexion soit en tant que datastore NFS supplémentaire - dans GCP GCVE.</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">Afficher les détails <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>.</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">Découvrez les solutions NetApp pour Google Cloud GCVE</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Solutions NetApp pour Google Cloud Virtualization Engine (GCVE)</block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">En savoir plus sur les solutions NetApp pour GCP.</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="inline-link-macro">Reprise après incident des applications avec SnapCenter, Cloud Volumes ONTAP et Veeam Replication</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">Disponibilité de région – datastore NFS supplémentaire pour Google Cloud Platform (GCP)</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">La disponibilité de datastores NFS supplémentaires dans GCP/GCVE est définie par Google. Tout d'abord, vous devez déterminer si GCVE et CVS sont disponibles dans une région spécifique. Ensuite, vous devez déterminer si le datastore NFS supplémentaire CVS est pris en charge dans cette région.</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">Vérifier la disponibilité de GCVE et CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">Vérifier la disponibilité du datastore NFS supplémentaire CVS <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">Options NetApp supplémentaires de datastores NFS pour GCP</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Déploiement et configuration de l'environnement de virtualisation sur Google Cloud Platform (GCP)</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">Comme pour les environnements sur site, la planification de Google Cloud VMware Engine (GCVE) est essentielle pour la réussite de l'environnement de production pour la création de VM et la migration.</block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">Déployer et configurer GCVE</block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">Pour configurer un environnement GCVE dans GCP, connectez-vous à la console GCP et accédez au portail VMware Engine.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">Cliquez sur le bouton "Nouveau Cloud privé" et entrez la configuration souhaitée pour le Cloud privé GCVE. Sur « Location », veillez à déployer le Cloud privé dans la même région/zone où CVS/CVO est déployé, afin d'assurer les meilleures performances et la plus faible latence.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">Conditions préalables :</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">Configurer le rôle IAM d'administration des services VMware Engine</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">Activez l'accès à l'API VMware Engine et le quota de nœuds</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">Assurez-vous que la plage CIDR ne se chevauchent pas avec vos sous-réseaux locaux ou dans le cloud. La gamme CIDR doit être /27 ou supérieure.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">Remarque : la création d'un cloud privé peut prendre entre 30 minutes et 2 heures.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">Une fois le cloud privé provisionné, configurez l'accès privé au cloud privé pour obtenir un débit élevé et une connexion à faible latence du chemin d'accès aux données.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">Documentation GCP</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">Cela permet de s'assurer que le réseau VPC dans lequel des instances Cloud Volumes ONTAP sont en cours d'exécution peut communiquer avec le Cloud privé GCVE. Pour ce faire, suivez le <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. Pour le service de volume cloud, établissez une connexion entre VMware Engine et Cloud Volumes Service en effectuant un peering unique entre les projets hôtes du locataire. Pour obtenir des instructions détaillées, suivez cette procédure <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">Connectez-vous à vcenter à l'aide de l'utilisateur CloudOwner@gve.llocabmabl. Pour accéder aux identifiants, rendez-vous sur le portail VMware Engine, accédez à Ressources et sélectionnez le cloud privé approprié. Dans la section informations de base, cliquez sur le lien View pour accéder aux informations de connexion vCenter (vCenter Server, HCX Manager) ou aux informations de connexion NSX-T (NSX Manager).</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Dans une machine virtuelle Windows, ouvrez un navigateur et accédez à l'URL du client Web vCenter <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> Et utilisez le nom d'utilisateur admin tel que CloudOwner@gve.locusmabl et collez le mot de passe copié. De même, NSX-T Manager est également accessible à l'aide de l'URL du client Web <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> utilisez le nom d'utilisateur admin et collez le mot de passe copié pour créer de nouveaux segments ou modifier les passerelles de niveau existantes.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">Pour la connexion à partir d'un réseau sur site vers un cloud privé VMware Engine, utilisez un VPN cloud ou une interconnexion de cloud pour assurer la connectivité appropriée et assurez-vous que les ports requis sont ouverts. Pour obtenir des instructions détaillées, suivez cette procédure <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="doc">Options de stockage NetApp pour GCP</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCP prend en charge le stockage NetApp connecté par l'invité avec Cloud Volumes ONTAP (CVO) ou Cloud Volumes Service (CVS).</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="example-title">Déploiement de Cloud Volumes ONTAP dans Google Cloud (faites vous-même)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Les partages Cloud Volumes ONTAP et les LUN peuvent être montés à partir de machines virtuelles créées dans l'environnement de Cloud privé GCVE. Les volumes peuvent également être montés sur le client Linux, ainsi que sur les clients Windows et LES LUN, accessibles sur les clients Linux ou Windows en tant que périphériques de bloc lorsqu'ils sont montés sur iSCSI, car Cloud Volumes ONTAP prend en charge les protocoles iSCSI, SMB et NFS. Les volumes Cloud Volumes ONTAP peuvent être configurés en quelques étapes simples.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">Pour répliquer des volumes depuis un environnement sur site vers le cloud à des fins de reprise d'activité ou de migration, établissez une connectivité réseau vers Google Cloud en utilisant un VPN site à site ou une interconnexion cloud. La réplication des données entre les sites et Cloud Volumes ONTAP n'est pas traitée dans ce document. Pour répliquer les données entre les systèmes Cloud Volumes ONTAP et sur site, consultez la section <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Dans l'onglet Canvas de Cloud Manager, cliquez sur Ajouter un environnement de travail, puis sélectionnez Google Cloud Platform comme cloud et le type de configuration du système. Cliquez ensuite sur Suivant.</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">Fournissez les détails de l'environnement à créer, y compris le nom de l'environnement et les identifiants d'administrateur. Une fois que vous avez terminé, cliquez sur Continuer.</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">Sélectionnez ou désélectionnez les services complémentaires pour le déploiement Cloud Volumes ONTAP, y compris Data Sense &amp; Compliance ou Backup to Cloud. Cliquez ensuite sur Continuer.</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">CONSEIL : un message contextuel de vérification s'affiche lors de la désactivation des services complémentaires. Des services d'extension peuvent être ajoutés/supprimés après le déploiement de Cloud volumes ONTAP. Pour éviter les coûts, il est possible de les désélectionner à la fois si nécessaire.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">Sélectionnez un emplacement, choisissez une politique de pare-feu et cochez la case pour confirmer la connectivité réseau au stockage Google Cloud.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">Sélectionnez l'option de licence : paiement à l'utilisation ou BYOL pour l'utilisation des licences existantes. Dans cet exemple, l'option Freemium est utilisée. Cliquez ensuite sur Continuer.</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">Sélectionnez un des packages préconfigurés disponibles en fonction du type de charge de travail qui sera déployé sur les machines virtuelles exécutées sur VMware Cloud sur AWS SDDC.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">CONSEIL : passez votre souris sur les mosaïques pour plus de détails ou personnalisez les composants CVO et la version de ONTAP en cliquant sur Modifier la configuration.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">Sur la page révision et approbation, vérifiez et confirmez les sélections.pour créer l'instance Cloud Volumes ONTAP, cliquez sur Go.</block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">CONSEIL : cliquez sur l'icône Menu (º), sélectionnez Avancé pour afficher plus d'options et sélectionnez Configuration CIFS.</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">La création du volume SMB est un processus simple. Dans Canvas, double-cliquez sur l'environnement de travail Cloud Volumes ONTAP pour créer et gérer des volumes, puis cliquez sur l'option Créer un volume. Choisissez la taille appropriée et Cloud Manager choisit l'agrégat contenant ou utilisez un mécanisme d'allocation avancée pour placer sur un agrégat spécifique. Pour cette démonstration, CIFS/SMB est sélectionné comme protocole.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">CONSEIL : cliquez sur le menu du volume (º) pour afficher ses options.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">Une fois le volume créé, utilisez la commande mount pour afficher les instructions de connexion du volume, puis connectez-vous au partage des machines virtuelles sur Google Cloud VMware Engine.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">Copiez le chemin suivant et utilisez l'option Map Network Drive pour monter le volume sur la machine virtuelle exécutée sur Google Cloud VMware Engine.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">Une fois mappé, il est facilement accessible et les autorisations NTFS peuvent être définies en conséquence.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="example-title">Connectez le LUN de Cloud Volumes ONTAP à un hôte</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Pour connecter le LUN Cloud Volumes ONTAP à un hôte, procédez comme suit :</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">Une fois le volume provisionné, sélectionnez le menu volume (º), puis cliquez sur IQN cible. Pour copier le nom qualifié iSCSI (IQN), cliquez sur Copier. Configurez une connexion iSCSI de l'hôte vers le LUN.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Pour procéder de la même manière pour l'hôte résidant sur Google Cloud VMware Engine :</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">RDP sur la machine virtuelle hébergée sur Google Cloud VMware Engine.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">L'hôte Windows doit disposer d'une connexion iSCSI à chaque nœud du cluster. Le DSM natif sélectionne les meilleurs chemins d'accès à utiliser.</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">Suivez les instructions de l'assistant. Dans cet exemple, le lecteur F: Est monté.</block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Sur les clients Linux, assurez-vous que le démon iSCSI est en cours d'exécution. Une fois les LUN provisionnées, consultez ici les conseils détaillés sur la configuration iSCSI avec Ubuntu. Pour vérifier, exécutez lsblk cmd à partir du shell.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="example-title">Montez un volume NFS Cloud Volumes ONTAP sur un client Linux</block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Pour monter le système de fichiers Cloud Volumes ONTAP (DIY) depuis des VM dans Google Cloud VMware Engine, effectuez la procédure suivante :</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">Procédez au provisionnement du volume en suivant les étapes ci-dessous</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">Dans l'onglet Volumes , cliquez sur Créer un nouveau volume .</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">Sur la page Créer un nouveau volume, sélectionnez un type de volume :</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">Dans l'onglet volumes, placez le curseur de la souris sur le volume, sélectionnez l'icône de menu (º), puis cliquez sur commande de montage.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">Cliquez sur Copier .</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">Connectez-vous à l'instance Linux désignée.</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">Ouvrez un terminal sur l'instance à l'aide du shell sécurisé (SSH) et connectez-vous avec les informations d'identification appropriées.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">Créer un répertoire pour le point de montage du volume avec la commande suivante.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">Montez le volume NFS Cloud Volumes ONTAP dans le répertoire créé à l'étape précédente.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">Cloud Volumes Service (CVS)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">Cloud volumes Services (CVS) est un portefeuille complet de services de données pour proposer des solutions cloud avancées. Cloud volumes Services prend en charge plusieurs protocoles d'accès aux fichiers pour les principaux fournisseurs de cloud (prise en charge NFS et SMB).</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">Les autres avantages et fonctionnalités sont les suivants : protection et restauration des données avec Snapshot, fonctionnalités spéciales de réplication, de synchronisation et de migration des données sur site ou dans le cloud, et haute performance prévisible au niveau d'un système de stockage Flash dédié.</block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="example-title">Configurez Cloud Volumes Service avec VMware Engine</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Les partages Cloud Volumes Service peuvent être montés sur les machines virtuelles qui sont créées dans l'environnement VMware Engine. Les volumes peuvent également être montés sur le client Linux et mappés sur le client Windows, car Cloud Volumes Service prend en charge les protocoles SMB et NFS. Les volumes Cloud Volumes Service peuvent être configurés en étapes simples.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud volumes Service et le cloud privé Google Cloud VMware Engine doivent se trouver dans la même région.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">guide</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Pour acheter, activer et configurer NetApp Cloud Volumes Service pour Google Cloud depuis Google Cloud Marketplace, suivez cette section <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="example-title">Créez un volume NFS CVS dans le Cloud privé GCVE</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">Pour créer et monter des volumes NFS, procédez comme suit :</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Accédez à Cloud volumes à partir des solutions partenaires dans la console Google Cloud.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Dans la console Cloud volumes, accédez à la page volumes et cliquez sur Créer.</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">Sur la page Créer un système de fichiers, spécifiez le nom du volume et les libellés de facturation requis pour les mécanismes de refacturation.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">Sélectionnez le service approprié. Pour GCVE, choisissez CVS-Performance et le niveau de service souhaité pour une latence améliorée et des performances supérieures en fonction des exigences des charges de travail applicatives.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">Spécifier la région Google Cloud pour le chemin de volume et de volume (le chemin du volume doit être unique sur l'ensemble des volumes cloud du projet)</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">Sélectionnez le niveau de performances du volume.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">Spécifiez la taille du volume et le type de protocole. Lors de ce test, NFSv3 est utilisé.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">Au cours de cette étape, sélectionnez le réseau VPC à partir duquel le volume sera accessible. Assurez-vous que le peering VPC est en place.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">CONSEIL : si le peering VPC n'a pas été effectué, un bouton contextuel s'affiche pour vous guider à travers les commandes de peering. Ouvrez une session Cloud Shell et exécutez les commandes appropriées pour peer-to-peer votre VPC avec le producteur Cloud Volumes Service. Au cas où vous décidiez de préparer le peering de VPC au préalable, reportez-vous à ces instructions.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">Gérez les règles de stratégie d'exportation en ajoutant les règles appropriées et cochez la case correspondant à la version NFS correspondante.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">Remarque : l'accès aux volumes NFS n'est possible que si une export policy est ajoutée.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Cliquez sur Enregistrer pour créer le volume.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="example-title">Montage des exportations NFS vers les machines virtuelles s'exécutant sur VMware Engine</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">Avant de préparer le montage du volume NFS, assurez-vous que l'état de peering de la connexion privée est défini sur actif. Une fois l'état actif, utilisez la commande mount.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">Pour monter un volume NFS, procédez comme suit :</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">Dans Cloud Console, accédez à Cloud volumes &gt; volumes.</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">Accédez à la page volumes</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">Cliquez sur le volume NFS pour lequel vous souhaitez monter les exports NFS.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">Faites défiler vers la droite, sous Afficher plus, cliquez sur instructions de montage.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">Pour effectuer le processus de montage à partir du système d'exploitation invité de la machine virtuelle VMware, procédez comme suit :</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">Utilisez le client SSH et SSH sur la machine virtuelle.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">Installez le client nfs sur l'instance.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Sur l'instance Red Hat Enterprise Linux ou SUSE Linux :</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Sur une instance Ubuntu ou Debian :</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">Créer un nouveau répertoire sur l'instance, tel que "/CVnimSNFSol01" :</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">Montez le volume à l'aide de la commande appropriée. L'exemple de commande de l'exercice pratique est ci-dessous :</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="example-title">Création et montage du partage SMB sur des machines virtuelles exécutées sur VMware Engine</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">Pour les volumes SMB, assurez-vous que les connexions Active Directory sont configurées avant de créer le volume SMB.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">Une fois la connexion AD en place, créez le volume avec le niveau de service souhaité. Les étapes sont telles que la création du volume NFS, sauf la sélection du protocole approprié.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">Sélectionnez le service approprié. Pour GCVE, choisissez CVS-Performance et le niveau de service souhaité pour une latence améliorée et des performances supérieures en fonction des exigences des charges de travail.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">Spécifiez la taille du volume et le type de protocole. SMB est utilisé lors de ce test.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">instructions</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">CONSEIL : si le peering VPC n'a pas été effectué, un bouton contextuel s'affiche pour vous guider à travers les commandes de peering. Ouvrez une session Cloud Shell et exécutez les commandes appropriées pour peer-to-peer votre VPC avec le producteur Cloud Volumes Service. Au cas où vous décidiez de préparer le peering de VPC au préalable, reportez-vous à ces <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">Pour monter le volume SMB, procédez comme suit :</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">Cliquez sur le volume SMB pour lequel vous souhaitez mapper un partage SMB.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">Pour effectuer le processus de montage à partir du système d'exploitation invité Windows de la machine virtuelle VMware, procédez comme suit :</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">Cliquez sur le bouton Démarrer, puis sur ordinateur.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">Cliquez sur carte lecteur réseau.</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">Dans la liste lecteur, cliquez sur n'importe quelle lettre de lecteur disponible.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">Dans la zone dossier, saisissez :</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">Pour vous connecter chaque fois que vous vous connectez à votre ordinateur, cochez la case reconnecter à la connexion.</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">Cliquez sur Terminer.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">La reprise d'activité dans le cloud est une solution résiliente et économique qui protège les charges de travail contre les pannes sur site et la corruption des données, comme les attaques par ransomware. NetApp SnapMirror permet de répliquer les charges de travail VMware sur site utilisant un stockage connecté à l'invité vers NetApp Cloud Volumes ONTAP exécuté dans Google Cloud.</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">Auteurs : Suresh Thoppay, NetApp</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">La reprise d'activité dans le cloud est une solution résiliente et économique qui protège les charges de travail contre les pannes sur site et la corruption des données, comme les attaques par ransomware. NetApp SnapMirror permet de répliquer les charges de travail VMware sur site utilisant un stockage connecté à l'invité vers NetApp Cloud Volumes ONTAP exécuté dans Google Cloud. Il s'agit aussi des données applicatives, mais qu'en est-il des machines virtuelles elles-mêmes ? La reprise sur incident doit couvrir tous les composants dépendants, notamment les machines virtuelles, les VMDK ou les données d'application. Pour ce faire, SnapMirror et Veeam peuvent être utilisés pour restaurer de manière transparente les workloads répliqués depuis des sites sur Cloud Volumes ONTAP et en utilisant le stockage VSAN pour les VMDK de VM.</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">Ce document propose une approche détaillée de la configuration et de l'exécution d'une reprise d'activité à l'aide de NetApp SnapMirror, Veeam et Google Cloud VMware Engine (GCVE).</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">Pour la connectivité entre l'environnement sur site et le réseau Google Cloud, utilisez les options de connectivité telles que une interconnexion dédiée ou un VPN cloud. Les segments doivent être créés en fonction de la conception VLAN sur site.</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">Plusieurs options de connexion des data centers sur site à Google Cloud sont possibles, ce qui évite de présenter un workflow spécifique dans ce document. Consultez la documentation Google Cloud pour connaître la méthode de connectivité appropriée, du site vers Google.</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Installez le logiciel Veeam et commencez à répliquer des machines virtuelles sur l'instance Google Cloud VMware Engine.</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">En cas d'incident, interrompre la relation SnapMirror avec Cloud Manager et déclencher le basculement des machines virtuelles avec Veeam.</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">Permet de mettre les applications en ligne.</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Configurez CVO pour Google Cloud et répliquez les volumes dans CVO</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">cvo</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">La première étape consiste à configurer Cloud Volumes ONTAP sur Google Cloud <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>) Et répliquez les volumes souhaités dans Cloud Volumes ONTAP avec les fréquences et les instantanés souhaités.</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">Configurez la réplication avec SnapCenter</block>
  <block id="8064e6b40ef12da2c44763dcfe735ae8" category="paragraph">Pour obtenir des exemples d'instructions détaillées sur la configuration de SnapCenter et la réplication des données, reportez-vous à<block ref="68793c30d3c5e8a024de6c79bc478fe1" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">Configurez l'accès aux données des hôtes GCVE et CVO</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">Deux facteurs importants à prendre en compte lors du déploiement du SDDC sont la taille du cluster SDDC dans la solution GCVE et le temps de maintenance du SDDC. Ces deux considérations clés à prendre en compte dans une solution de reprise sur incident permettent de réduire les coûts d'exploitation globaux. Le SDDC peut héberger jusqu'à trois hôtes, tout comme un cluster multi-hôtes dans un déploiement à grande échelle.</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">Cloud Volumes ONTAP peut être déployé sur n'importe quel VPC et GCVE doit disposer d'une connexion privée à ce VPC pour que la VM se connecte aux LUN iSCSI.</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">Pour configurer GCVE SDDC, voir<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>. Avant cela, vérifiez que les VM invités résidant sur les hôtes GCVE peuvent consommer des données de Cloud Volumes ONTAP une fois la connectivité établie.</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Une fois que Cloud Volumes ONTAP et GCVE ont été correctement configurés, commencez à configurer Veeam pour automatiser la restauration des workloads sur site vers GCVE (machines virtuelles avec VMDK d'application et VM avec stockage « Guest ») en utilisant la fonctionnalité de réplication Veeam et en utilisant SnapMirror pour les copies de volumes d'application vers Cloud Volumes ONTAP.</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Installer les composants Veeam</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">Se référer à la documentation Veeam pour la procédure d'installation</block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">Configuration de la réplication de machine virtuelle avec Veeam</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">Configuration de la tâche de réplication de VM vSphere</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">VCenter sur site et GCVE vCenter doit être enregistré auprès de Veeam.<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> À l'étape traitement invité de l'assistant, sélectionnez Désactiver le traitement de l'application, car nous utilisons SnapCenter pour la sauvegarde et la restauration intégrant la cohérence applicative.</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Le basculement de la machine virtuelle Microsoft SQL Server</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">Veeam Replication permet de modifier les adresses IP des VM sur le site de reprise après incident.</block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">Configurations prises en charge pour l'environnement multicloud hybride NetApp avec VMware</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">Comprendre les combinaisons de la prise en charge du stockage NetApp dans les principaux hyperscalers.</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">*Invité connecté*</block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">*Datastore NFS supplémentaire*</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">*AWS*</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">ONTAP CVO FSX<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">ONTAP FSX<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">*Azure*</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">ANF CVO<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">*GCP*</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVS DE CVO<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">Synthèse et conclusion : pourquoi NetApp offre un multicloud hybride avec VMware</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">NetApp Cloud volumes et les solutions VMware pour les principaux hyperscalers offrent un grand potentiel aux entreprises qui cherchent à exploiter le cloud hybride. Le reste de cette section présente des cas d'utilisation permettant l'intégration de NetApp Cloud volumes offre de véritables fonctionnalités multicloud hybrides.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">Cas d'utilisation n° 1 : optimisation du stockage</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">Lors d'un exercice de dimensionnement à l'aide des outils RVTools, il est toujours évident que l'évolutivité de la puissance (vCPU/vmem) est parallèle au stockage. Elles sont souvent nombreuses à se retrouver dans une situation où l'espace de stockage nécessaire permet de définir la taille du cluster bien au-delà de ce qui est nécessaire en puissance.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">L'intégration de NetApp Cloud volumes permet aux entreprises de réaliser une solution cloud vSphere selon une approche de migration simple, sans changement de plateforme, ni modification de l'architecture. De plus, cette optimisation vous permet de faire évoluer l'empreinte du stockage tout en réduisant le nombre d'hôtes à un volume minimal dans vSphere, sans modification de la hiérarchie de stockage, de la sécurité ou des fichiers disponibles. Vous pouvez ainsi optimiser le déploiement et réduire le coût total de possession de 35 à 45 %. Cette intégration vous permet également de faire évoluer le stockage depuis le stockage chaud jusqu'au niveau de production en quelques secondes.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">Cas d'utilisation n°2 : migration vers le cloud</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">Les entreprises subissent une pression considérable pour migrer les applications depuis les data centers sur site vers le cloud public pour de nombreuses raisons : une expiration de bail imminente, une directive financière pour passer des dépenses d'investissement aux dépenses d'exploitation (OpEx) ou simplement un mandat descendante pour déplacer l'ensemble du cloud.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">Lorsque la vitesse est essentielle, seule une approche de migration rationalisée est possible, car le changement de plateforme et le remaniement d'applications pour l'adapter à la plateforme IaaS spécifique au cloud sont lents et onéreux, et prennent souvent des mois. En associant NetApp Cloud volumes à la réplication SnapMirror économe en bande passante pour les systèmes de stockage connectés à l'invité (dont RDM avec des copies Snapshot cohérentes au niveau des applications et HCX, par exemple, pour la migration vers le cloud Azure Migrate) ou produits tiers pour la réplication des machines virtuelles), cette transition est encore plus simple que s'appuyant sur des mécanismes de filtres d'E/S chronophages.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">Cas d'utilisation n°3 : extension du data Center</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">Lorsqu'un data Center atteint ses limites de capacité en raison de pics de demande saisonniers ou simplement d'une croissance organique soutenue, il est facile de migrer vers le cloud VMware avec NetApp Cloud volumes. En exploitant NetApp Cloud volumes, vous pouvez créer, répliquer et étendre votre stockage très facilement en assurant une haute disponibilité sur les zones de disponibilité et des fonctionnalités d'évolutivité dynamique. En exploitant NetApp Cloud volumes, vous pouvez minimiser la capacité des clusters hôtes en surpassant la nécessité de clusters étendus.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">Cas d'utilisation n°4 : reprise après incident dans le cloud</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">Dans une approche classique, en cas d'incident, les machines virtuelles répliquées dans le cloud nécessitent une conversion vers la propre plateforme d'hyperviseur du cloud avant qu'elles ne puissent être restaurées, pas une tâche à traiter en cas de crise.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">L'utilisation de NetApp Cloud volumes pour le stockage connecté à l'invité via la réplication SnapCenter et SnapMirror depuis des systèmes sur site ainsi que des solutions de virtualisation de cloud public améliore la reprise d'activité. De cette manière, les réplicas de VM peuvent être récupérés sur une infrastructure VMware SDDC entièrement cohérente, ainsi que sur des outils de restauration spécifiques au cloud (par exemple Azure site Recovery) ou des outils tiers équivalents tels que Veeam. Ainsi, vous pouvez réaliser rapidement des tests de reprise après incident et des opérations de reprise après incident en cas d'attaque par ransomware. Cela vous permet également d'évoluer vers une production complète à des fins de test ou lors d'un incident en ajoutant des hôtes à la demande.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">Cas d'utilisation n°5 : modernisation des applications</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">Une fois que les applications sont dans le cloud public, les entreprises voudront exploiter des centaines de services cloud puissants pour les moderniser et les étendre. Avec NetApp Cloud volumes, la modernisation est un processus simple, car les données applicatives ne sont pas verrouillées dans VSAN et permet la mobilité des données pour un large éventail d'utilisations, y compris Kubernetes.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">Que vous cibliez un cloud hybride ou 100 % cloud, NetApp Cloud volumes offre une excellente option pour déployer et gérer les charges de travail applicatives avec les services de fichiers et les protocoles de bloc, tout en réduisant le coût total de possession grâce à une intégration transparente des données à la couche applicative.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">Quelles que soient les utilisations, vous pouvez choisir votre cloud/hyperscaler favori et NetApp Cloud volumes pour bénéficier rapidement des avantages du cloud, d'une infrastructure cohérente et des opérations entre plusieurs clouds et sur site, de la portabilité bidirectionnelle des workloads, et de la capacité et des performances élevées.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">Il s'agit du même processus et procédures que ceux utilisés pour connecter le stockage. N'oubliez pas que la position des données a changé de nom. Les outils et les processus restent identiques, et NetApp Cloud volumes contribue à optimiser le déploiement global.</block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">Cas d'utilisation de l'environnement multicloud hybride NetApp avec VMware</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">Présentation des cas d'utilisation importants pour les ÉQUIPES IT lors de la planification de déploiements de cloud hybride ou premier cloud.</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">Cas d'utilisation populaires</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">Cas d'utilisation :</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">Reprise sur incident,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">Hébergement de charges de travail pendant la maintenance du data Center, * rafale rapide dans laquelle des ressources supplémentaires sont requises au-delà de ce qui est provisionné dans le data Center local,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">L'extension de site VMware,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">Migration rapide vers le cloud,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">Développement/test et</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">La modernisation des applications en tirant parti de technologies complémentaires du cloud.</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">Dans cette documentation, les références aux charges de travail cloud seront détaillées dans les cas d'utilisation de VMware. Ces utilisations sont les suivantes :</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">Inside ® le parcours DE L'IT</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">La plupart des entreprises sont en voie de transformation et de modernisation. Dans le cadre de ce processus, les entreprises tentent d'utiliser leurs investissements VMware existants, tout en tirant parti des avantages du cloud et en explorant les façons de rendre le processus de migration aussi transparent que possible. Cette approche facilite grandement la tâche de modernisation, car les données sont déjà dans le cloud.</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">La réponse la plus simple à ce scénario est d'utiliser des offres VMware pour chaque hyperscaler. Comme NetApp® Cloud volumes, VMware offre un moyen de déplacer ou d'étendre les environnements VMware sur site vers n'importe quel cloud. Vous pouvez ainsi conserver vos ressources, compétences et outils sur site existants tout en exécutant les charges de travail de façon native dans le cloud. Les risques sont réduits, car aucun service n'est disponible ni modifié IP. De plus, l'équipe INFORMATIQUE est en mesure de gérer ses pratiques sur site à l'aide des compétences et des outils existants. Cela permet d'accélérer les migrations vers le cloud et de faciliter la transition vers une architecture multicloud hybride.</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">Comprendre l'importance d'autres options de stockage NFS</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">Même si VMware quel que soit le cloud offre des fonctionnalités hybrides uniques à chaque client, les options de stockage NFS supplémentaires limitées ne sont pas utiles pour les entreprises qui traite de charges de travail très exigeantes en termes de stockage. Comme le stockage est directement lié aux hôtes, le seul moyen de faire évoluer le stockage consiste à ajouter d'autres hôtes, ce qui représente une augmentation des coûts de 35 à 40 % ou plus pour les charges de travail consommatrices de stockage. Ces charges de travail ont simplement besoin d'espace de stockage supplémentaire et ne sont pas de puissance supplémentaire. Mais cela signifie que les hôtes supplémentaires sont payants.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">Examinons ce scénario :</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">Un client ne requiert que cinq hôtes pour le processeur et la mémoire, mais ses besoins en stockage sont nombreux et doit disposer de 12 hôtes pour répondre aux besoins en stockage. En fin de compte, il est indispensable de faire évoluer l'infrastructure financière en achetant de la puissance supplémentaire si nécessaire.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">Lorsque vous planifiez l'adoption et les migrations du Cloud, il est toujours important d'évaluer la meilleure approche et de prendre le chemin le plus simple qui réduit les investissements totaux. L'approche la plus courante et la plus simple pour toute migration d'applications est le réhébergement (aussi appelé lift and shift) où il n'existe pas de machine virtuelle (VM) ou de conversion des données. L'utilisation de NetApp Cloud volumes avec le Software-Defined Data Center VMware (SDDC), tout en complétant VSAN, offre une option facile à déplacer.</block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">Configuration de l'environnement de virtualisation dans le fournisseur cloud</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">Vous trouverez plus d'informations sur la configuration de l'environnement de virtualisation dans chacun des hyperscalers pris en charge.</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">Cette section décrit comment configurer et gérer VMware Cloud sur AWS SDDC et l'utiliser en association avec les options de connexion de stockage NetApp disponibles.</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">Le stockage invité est la seule méthode prise en charge pour connecter Cloud Volumes ONTAP à AWS VMC.</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">Déploiement et configuration de VMware Cloud pour AWS</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="list-text">Connectez le cloud VMware à FSX ONTAP</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">Étapes de configuration pour VMC</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">Afficher les détails <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>.</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">Afficher les détails <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>.</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">Afficher les détails <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>.</block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS est un protocole de système de fichiers distribué qui est une norme IETF ouverte définie dans la norme RFC (Request for Comments) qui permet à quiconque d'implémenter le protocole.</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">Précédent : notions de base sur les protocoles NAS_overview.</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">Les volumes de Cloud Volumes Service sont partagés avec les clients NFS en exportant un chemin accessible à un client ou à un ensemble de clients. Les autorisations de monter ces exportations sont définies par des règles et des règles d'exportation, qui peuvent être configurées par les administrateurs Cloud Volumes Service.</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">L'implémentation NFS de NetApp est considérée comme une norme Gold pour le protocole et elle est utilisée dans d'innombrables environnements NAS d'entreprise. Les sections suivantes présentent le protocole NFS ainsi que les fonctionnalités de sécurité spécifiques disponibles dans Cloud Volumes Service et leur mise en œuvre.</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">Utilisateurs et groupes UNIX locaux par défaut</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service contient plusieurs utilisateurs et groupes UNIX par défaut pour diverses fonctionnalités de base. Ces utilisateurs et ces groupes ne peuvent actuellement pas être modifiés ou supprimés. Actuellement, les nouveaux utilisateurs et groupes locaux ne peuvent pas être ajoutés à Cloud Volumes Service. Les utilisateurs et groupes UNIX hors des utilisateurs et des groupes par défaut doivent être fournis par un service de noms LDAP externe.</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">Le tableau suivant indique les utilisateurs et groupes par défaut et leurs ID numériques correspondants. NetApp recommande de ne pas créer de nouveaux utilisateurs ou groupes dans LDAP ou sur les clients locaux qui utilisent à nouveau ces ID numériques.</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">Utilisateurs par défaut : ID numériques</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">Groupes par défaut : ID numériques</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">racine : 0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser:65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">personne:65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">démon:1</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">Lors de l'utilisation de NFSv4.1, l'utilisateur root peut s'afficher comme personne lors de l'exécution des commandes de liste de répertoires sur les clients NFS. Ceci est dû à la configuration du mappage de domaine d'ID du client. Voir la section appelée <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> pour plus de détails sur ce problème et sur la façon de le résoudre.</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">L'utilisateur root</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">Sous Linux, le compte racine a accès à toutes les commandes, fichiers et dossiers d'un système de fichiers Linux. En raison de la puissance de ce compte, les bonnes pratiques en matière de sécurité exigent souvent que l'utilisateur root soit désactivé ou restreint d'une façon ou d'une autre. Dans les exportations NFS, la puissance dont dispose un utilisateur root sur les fichiers et les dossiers peut être contrôlée dans Cloud Volumes Service au moyen de règles et de stratégies d'exportation et d'un concept appelé « squash racine ».</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">commandes setuid/setgid (le bit collant)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">Le scaling racine garantit que l'utilisateur root accédant à un montage NFS est écrasé à l'utilisateur numérique anonyme 65534 (voir la section «<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>”) et n'est actuellement disponible que lors de l'utilisation de CVS-Performance en sélectionnant Désactivé pour l'accès racine lors de la création de règles d'export. Si l'utilisateur root est écrasé par l'utilisateur anonyme, il n'a plus accès à exécuter CHown ou<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> Sur les fichiers ou dossiers du montage NFS, et les fichiers ou dossiers créés par l'utilisateur root affichent l'UID d'anon comme propriétaire/groupe. En outre, les ACL NFSv4 ne peuvent pas être modifiés par l'utilisateur root. Cependant, l'utilisateur root a toujours accès aux fichiers chmod et supprimés pour lesquels il n'a pas d'autorisations explicites. Si vous souhaitez limiter l'accès aux autorisations de fichier et de dossier d'un utilisateur root, envisagez d'utiliser un volume avec des listes de contrôle d'accès NTFS, créant un utilisateur Windows nommé<block ref="63a9f0ea7bb98050796b649e85481845" prefix=" " category="inline-code"></block>, et application des autorisations souhaitées aux fichiers ou dossiers.</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">L'utilisateur anonyme</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">L'ID utilisateur anonyme (anon) spécifie un ID utilisateur UNIX ou un nom d'utilisateur qui est mappé aux requêtes client qui arrivent sans identifiants NFS valides. Cela peut inclure l'utilisateur racine lorsque le squaing racine est utilisé. L'utilisateur d'anon dans Cloud Volumes Service est 65534.</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">Cet UID est normalement associé au nom d'utilisateur<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> ou<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> Dans les environnements Linux. Cloud Volumes Service utilise également 65534 comme pcuser UNIX local (voir la section «<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>”), qui est également l'utilisateur de secours par défaut pour les mappages de noms Windows à UNIX lorsqu'aucun utilisateur UNIX correspondant valide n'est trouvé dans LDAP.</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">En raison des différences entre les noms d'utilisateur Linux et Cloud Volumes Service pour UID 65534, la chaîne de nom des utilisateurs mappés sur 65534 risque de ne pas correspondre lors de l'utilisation de NFSv4.1. Vous pouvez donc voir<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> en tant qu'utilisateur sur certains fichiers et dossiers. Voir la section «<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>” pour plus d'informations sur ce problème et sur la façon de le résoudre.</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">Contrôle d'accès/exportations</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">L'accès initial aux exportations/partages pour les montages NFS est contrôlé par le biais de règles d'export policy basées sur les hôtes, figurant dans une export policy. Une adresse IP hôte, un nom d'hôte, un sous-réseau, un groupe réseau ou un domaine sont définis pour permettre l'accès au montage du partage NFS et le niveau d'accès autorisé à l'hôte. Les options de configuration des règles d'export-policy dépendent du niveau Cloud Volumes Service.</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">Pour CVS-SW, les options suivantes sont disponibles pour la configuration des export-policy :</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">*Correspondance client.* liste d'adresses IP séparées par des virgules, liste de noms d'hôte séparés par des virgules, sous-réseaux, groupes réseau, noms de domaine.</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">*Règles d'accès RO/RW.* sélectionnez lecture/écriture ou lecture seule pour contrôler le niveau d'accès à l'exportation.CVS-Performance fournit les options suivantes :</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">*Règles d'accès RO/RW.* sélectionnez lecture/écriture ou lecture seulement pour contrôler le niveau d'accès à l'exportation.</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">*Accès racine (activé/désactivé).* configure le squash racine (voir la section «<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>« pour plus de détails).</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">*Type de protocole.* cette option limite l'accès au montage NFS à une version de protocole spécifique. Lorsque vous spécifiez à la fois NFS v3 et NFS v4.1 pour le volume, laissez les deux vides ou cochez les deux cases.</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">*Niveau de sécurité Kerberos (lorsque l'option Activer Kerberos est sélectionnée).* fournit les options de krb5, krb5i et/ou krb5p pour l'accès en lecture seule ou en lecture/écriture.</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">Changer la propriété (chown) et le groupe de changement (chgrp)</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">NFS sur Cloud Volumes Service ne permet à l'utilisateur root d'exécuter chown/chgrp que sur des fichiers et des dossiers. Les autres utilisateurs voient un<block ref="7627e13d3e1910d7f604aa77914613da" prefix=" " category="inline-code"></block> erreur : même sur les fichiers qu'ils possèdent. Si vous utilisez du squash racine (comme décrit dans la section «<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>”), la racine est écrasée à un utilisateur non root et ne peut pas accéder à chown et chgrp. Il n'existe actuellement aucune solution de contournement dans Cloud Volumes Service pour permettre aux chown et aux chgrp de non-root utilisateurs. Si des modifications de propriété sont requises, envisagez d'utiliser des volumes à double protocole et définissez le style de sécurité sur NTFS pour contrôler les autorisations du côté Windows.</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">Gestion des autorisations</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service prend en charge les deux bits de mode (par exemple 644, 777, etc. Pour rwx) et les ACL NFSv4.1 pour contrôler les autorisations sur les clients NFS pour les volumes qui utilisent le style de sécurité UNIX. La gestion des autorisations standard est utilisée pour ces clients (tels que chmod, chown ou nfs4_setfacl) et avec n'importe quel client Linux qui les prend en charge.</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">En outre, lorsque des volumes à double protocole sont définis sur NTFS, les clients NFS peuvent tirer parti du mappage de noms Cloud Volumes Service aux utilisateurs Windows, qui sont ensuite utilisés pour résoudre les autorisations NTFS. Pour ce faire, une connexion LDAP à Cloud Volumes Service doit fournir des traductions d'ID numérique vers nom d'utilisateur car Cloud Volumes Service nécessite un nom d'utilisateur UNIX valide pour être correctement mappé à un nom d'utilisateur Windows.</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">Fournissant des listes de contrôle d'accès granulaires pour NFSv3</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">Les autorisations bits du mode couvrent uniquement le propriétaire, le groupe et tous les autres éléments de la sémantique, ce qui signifie qu'aucun contrôle granulaire des accès utilisateur n'est mis en place pour les données NFSv3 de base. Cloud Volumes Service ne prend pas en charge les listes de contrôle d'accès POSIX, ni les attributs étendus (tels que chattr). Les listes de contrôle d'accès granulaires ne sont donc possibles que dans les scénarios suivants avec NFSv3 :</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">Volumes de style de sécurité NTFS (serveur CIFS requis) avec des mappages utilisateur UNIX vers Windows valides.</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">NFS v4.1 a été appliqué à l'aide d'un client admin montage NFSv4.1 pour appliquer les ACL.</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">« LDAP »</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">Ces deux méthodes nécessitent une connexion LDAP pour la gestion des identités UNIX et des informations utilisateur et groupe UNIX valides (voir la section <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>) Et ne sont disponibles qu'avec des instances CVS-Performance. Pour utiliser des volumes de style de sécurité NTFS avec le protocole NFS, vous devez utiliser le protocole double (SMB et NFS v3) ou le double protocole (SMB et NFS v4.1), même si aucune connexion SMB n'est établie. Pour utiliser les listes de contrôle d'accès NFSv4.1 avec montages NFSv3, vous devez sélectionner<block ref="3e8ec25076adc34554202fd2df86b9b4" prefix=" " category="inline-code"></block> comme type de protocole.</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">Nfs4_acl - listes de contrôle d'accès NFSv4</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">Les bits standard en mode UNIX ne fournissent pas le même niveau de granularité dans les autorisations que les ACL NTFS ou NFSv4.x fournissent. Le tableau suivant compare la granularité des autorisations entre les bits en mode NFS v3 et les ACL NFSv4.1. Pour plus d'informations sur les listes de contrôle d'accès NFSv4.1, voir<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>.</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">Bits de mode NFSv3</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">Listes de contrôle d'accès NFSv4.1</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">Définir l'ID utilisateur lors de l'exécution</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">Définir l'ID du groupe lors de l'exécution</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">Enregistrer le texte échangé (non défini dans POSIX)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">Autorisation de lecture du propriétaire</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">Autorisation d'écriture pour le propriétaire</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">Exécutez l'autorisation de propriétaire sur un fichier ou recherchez (recherchez) l'autorisation de propriétaire dans le répertoire</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">Autorisation de lecture pour le groupe</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">Autorisation d'écriture pour le groupe</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">Exécutez l'autorisation de groupe sur un fichier ou recherchez (recherchez) l'autorisation de groupe dans le répertoire</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">Autorisation de lecture pour les autres utilisateurs</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">Autorisation d'écriture pour les autres</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">Exécutez l'autorisation pour les autres utilisateurs d'un fichier ou recherchez (recherchez) l'autorisation pour d'autres personnes dans le répertoire</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">Types d'entrée de contrôle d'accès (ACE) (Allow/Deny/Audit) * indicateurs d'héritage * Directory-Hériter * fichier-Hériter * no-Propagate-Hériter * hériter-only</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">Autorisations * lecture-données (fichiers) / répertoire-liste (répertoires) * écriture-données (fichiers) / création-fichier (répertoires) * ajout-données (fichiers) / création-sous-répertoire (répertoires) * exécution (fichiers) / changement-répertoire (répertoires) * suppression * suppression-enfant * lecture-attributs * écriture-attributs * liste de contrôle d'accès * lecture-écriture * liste de contrôle d'accès *</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">Enfin, l'appartenance au groupe NFS (dans NFSv3 et NFSV4.x) est limitée à un maximum par défaut de 16 pour AUTH_SYS selon les limites de paquets RPC. NFS Kerberos fournit jusqu'à 32 groupes et les ACL NFSv4 suppriment la limite par le biais de listes de contrôle d'accès granulaires des utilisateurs et des groupes (jusqu'à 1024 entrées par ACE).</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">Création et gestion des volumes NFS</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">En outre, Cloud Volumes Service offre une prise en charge étendue des groupes pour étendre le nombre maximal de groupes pris en charge jusqu'à 32. Pour ce faire, une connexion LDAP à un serveur LDAP qui contient des identités d'utilisateur et de groupe UNIX valides est nécessaire. Pour plus d'informations sur cette configuration, reportez-vous à la section<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> Dans la documentation Google.</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">ID d'utilisateur et de groupe NFSv3</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">Les ID utilisateur et groupe NFSv3 sont répartis sur le fil sous forme d'ID numériques plutôt que de noms. Cloud Volumes Service ne résout pas le nom d'utilisateur de ces ID numériques avec NFSv3, avec des volumes de style de sécurité UNIX utilisant des bits de mode uniquement. Lorsque des listes de contrôle d'accès NFSv4.1 sont présentes, une recherche d'ID numérique et/ou une recherche de chaîne de nom est nécessaire pour résoudre correctement la liste de contrôle d'accès, même en cas d'utilisation de NFS v3. Avec les volumes de style de sécurité NTFS, Cloud Volumes Service doit résoudre un ID numérique à un utilisateur UNIX valide, puis le mapper à un utilisateur Windows valide pour négocier les droits d'accès.</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">Limitations de sécurité des ID d'utilisateur et de groupe NFSv3</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">Avec NFSv3, le client et le serveur n'ont jamais à confirmer que l'utilisateur qui tente de lire ou d'écrire avec un ID numérique est un utilisateur valide ; il est simplement implicitement approuvé. Cela ouvre le système de fichiers jusqu'à des failles potentielles simplement en usurper n'importe quel ID numérique. Pour éviter les trous de sécurité de ce type, il existe quelques options pour Cloud Volumes Service.</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">L'implémentation de Kerberos pour NFS oblige les utilisateurs à s'authentifier avec un nom d'utilisateur et un mot de passe ou un fichier keytab afin d'obtenir un ticket Kerberos pour autoriser l'accès à un montage. Kerberos est disponible avec des instances CVS-Performance et uniquement avec NFSv4.1.</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">En limitant la liste des hôtes des règles d'export policy, les clients NFSv3 disposent d'un accès au volume Cloud Volumes Service.</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">L'utilisation de volumes à double protocole et l'application de listes de contrôle d'accès NTFS au volume oblige les clients NFSv3 à résoudre des ID numériques à des noms d'utilisateur UNIX valides afin de s'authentifier correctement pour accéder aux montages. Pour cela, il est nécessaire d'activer LDAP et de configurer les identités d'utilisateur et de groupe UNIX.</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">L'affaissement de l'utilisateur root limite les dommages qu'un utilisateur root peut faire sur un montage NFS, mais ne élimine pas complètement les risques. Pour plus d'informations, reportez-vous à la section «<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>. »</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">En fin de compte, la sécurité NFS est limitée à la version de protocole que vous utilisez. NFS v3, bien que plus performant que NFSv4.1, n'offre pas le même niveau de sécurité.</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1 offre une sécurité et une fiabilité supérieures par rapport à NFS v3, pour les raisons suivantes :</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">Verrouillage intégré grâce à un mécanisme de location</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">Sessions avec état</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">Toutes les fonctionnalités NFS sur un seul port (2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">TCP uniquement</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">Mappage du domaine d'ID</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Intégration Kerberos (NFSv3 peut utiliser Kerberos, mais uniquement pour NFS, pas pour les protocoles auxiliaires tels que NLM)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">Dépendances NFSv4.1</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">En raison des fonctions de sécurité ajoutées dans NFSv4.1, certaines dépendances externes étaient impliquées dans l'utilisation de NFSv3 (semblable au mode d'utilisation requis par SMB, comme Active Directory).</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service prend en charge les listes de contrôle d'accès NFSv4.x, qui offrent des avantages distincts par rapport aux autorisations de style POSIX standard, notamment :</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">Contrôle granulaire de l'accès des utilisateurs aux fichiers et aux répertoires</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">Sécurité NFS renforcée</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">Interopérabilité améliorée avec CIFS/SMB</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">Suppression de la limitation NFS de 16 groupes par utilisateur avec sécurité AUTH_SYS</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">Les ACL contournent le besoin en résolution d'ID de groupe (GID), qui supprime efficacement les ACL limitésNFS sont contrôlées par les clients NFS, et non par Cloud Volumes Service. Pour utiliser les listes de contrôle d’accès NFS NFSv4.1, assurez-vous que la version logicielle de votre client les prend en charge et que les utilitaires NFS appropriés sont installés.</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">Compatibilité entre les listes de contrôle d'accès NFSv4.1 et les clients SMB</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">Les ACL NFSv4 ne sont pas plus les ACL de niveau fichier (ACL NTFS) de Windows, mais possèdent une fonctionnalité similaire. Cependant, dans les environnements NAS multiprotocoles, si vous disposez de listes de contrôle d'accès NFSv4.1 et que vous utilisez un accès double protocole (NFS et SMB sur les mêmes datasets), les clients qui utilisent SMB2.0 et versions ultérieures ne pourront pas afficher ni gérer les listes de contrôle d'accès à partir des onglets de sécurité Windows.</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">Fonctionnement des listes de contrôle d'accès NFSv4.1</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">Pour référence, les termes suivants sont définis :</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">*Liste de contrôle d'accès (ACL).* liste des entrées d'autorisations.</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">*Entrée de contrôle d'accès (ACE).* Entrée d'autorisation dans la liste.</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">Lorsqu'un client définit une liste de contrôle d'accès NFSv4.1 sur un fichier lors d'une opération SETATTR, Cloud Volumes Service définit cette liste de contrôle d'accès sur l'objet en remplaçant toute liste de contrôle d'accès existante. S'il n'y a pas de liste de contrôle d'accès sur un fichier, les autorisations de mode sur ce fichier sont calculées à partir DE OWNER@, GROUP@ et EVERYONE@. S'il existe des SUID/SGID/bits COLLANTS sur le fichier, ils ne sont pas affectés.</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">Lorsqu'un client obtient une liste de contrôle d'accès NFS (ACL) NFSv4.1 sur un fichier au cours d'une opération GETATTR, Cloud Volumes Service lit la liste de contrôle d'accès NFS (ACL) associée à l'objet, construit une liste d'ACE et renvoie la liste au client. Si le fichier possède une liste de contrôle d’accès NT ou des bits de mode, une liste de contrôle d’accès est construite à partir de bits de mode et renvoyée au client.</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">L'accès est refusé si une ACE DE REFUS est présente dans la liste de contrôle d'accès ; l'accès est accordé si une ACE D'AUTORISATION existe. Toutefois, l'accès est également refusé si aucun des ACE n'est présent dans l'ACL.</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">Un descripteur de sécurité se compose d'une liste de contrôle d'accès (SACL) et d'une liste de contrôle d'accès discrétionnaire (DACL). Lorsque NFSv4.1 interagit avec CIFS/SMB, le DACL est mappé à NFSv4 et CIFS. La DACL se compose des ACCE AUTORISER et REFUSER.</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">Si un niveau de base<block ref="417e248f80c35ca0d471575a5fb951f5" prefix=" " category="inline-code"></block> Est exécuté sur un fichier ou un dossier avec les ACL NFSv4.1 définies, les listes de contrôle d'accès utilisateur et groupe existantes sont conservées, mais le PROPRIÉTAIRE par défaut@, GROUPE@, EVERYONE@ ACL sont modifiés.</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">indicateurs d'héritage</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">Un client utilisant des listes de contrôle d’accès NFSv4.1 peut définir et afficher des listes de contrôle d’accès pour les fichiers et les répertoires du système. Lorsqu'un nouveau fichier ou sous-répertoire est créé dans un répertoire comportant une liste de contrôle d'accès, cet objet hérite de tous les ACE de la liste de contrôle d'accès qui ont été marqués avec le nom approprié<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>.</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">Si un fichier ou un répertoire possède une liste de contrôle d'accès NFSv4.1, cette liste de contrôle d'accès est utilisée pour contrôler l'accès, quel que soit le protocole utilisé pour accéder au fichier ou au répertoire.</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">Les fichiers et les répertoires héritent des ACE des listes de contrôle d'accès NFSv4 sur les répertoires parents (éventuellement avec les modifications appropriées) tant que les ACE ont été balisés avec les indicateurs d'héritage corrects.</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">Lorsqu'un fichier ou un répertoire est créé à la suite d'une requête NFSv4, la liste de contrôle d'accès du fichier ou répertoire résultant dépend du fait que la demande de création de fichier inclut une liste de contrôle d'accès ou uniquement les autorisations d'accès aux fichiers UNIX standard. La liste de contrôle d’accès dépend également de la présence ou non d’une liste de contrôle d’accès dans le répertoire parent.</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">Si la requête inclut une liste de contrôle d’accès, cette liste de contrôle d’accès est utilisée.</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">Si la requête inclut uniquement les autorisations d'accès aux fichiers UNIX standard et que le répertoire parent ne dispose pas d'ACL, le mode fichier client est utilisé pour définir les autorisations d'accès aux fichiers UNIX standard.</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">Si la requête inclut uniquement les autorisations d'accès aux fichiers UNIX standard et que le répertoire parent dispose d'une liste de contrôle d'accès non héritable, une liste de contrôle d'accès par défaut basée sur les bits de mode transmis à la requête est définie sur le nouvel objet.</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">Si la demande comprend uniquement des autorisations d'accès aux fichiers UNIX standard mais que le répertoire parent possède une ACL, les ACE de l'ACL du répertoire parent sont hérités par le nouveau fichier ou répertoire tant que les ACE ont été balisés avec les indicateurs d'héritage appropriés.</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">Autorisations ACE</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">COMMENT : utiliser NFSv4 ACL</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">Les autorisations de listes de contrôle d'accès NFSv4.1 utilisent une série de valeurs de lettres majuscules et minuscules (par exemple<block ref="a0331a73af55fd5fda99201f776e847c" prefix=" " category="inline-code"></block>) pour contrôler l'accès. Pour plus d'informations sur ces valeurs de lettre, reportez-vous à la section<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>.</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">Comportement ACL NFSv4.1 avec umask et héritage ACL</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">Les ACL NFSv4 permettent d'offrir l'héritage ACL</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">Indicateur d'héritage ACL</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>. L'héritage ACL signifie que les fichiers ou les dossiers créés sous des objets avec des listes de contrôle d'accès NFSv4.1 peuvent hériter des listes de contrôle d'accès basées sur la configuration du<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>.</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">Umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> permet de contrôler le niveau d'autorisation auquel les fichiers et dossiers sont créés dans un répertoire sans interaction avec l'administrateur. Par défaut, Cloud Volumes Service permet à umask de remplacer les listes de contrôle d'accès héritées, ce qui est le comportement attendu selon<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>.</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">Formatage ACL</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">Les ACL NFSv4.1 ont un formatage spécifique. L'exemple suivant est un ensemble ACE sur un fichier :</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">L'exemple précédent suit les directives de format ACL de :</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">Un type de<block ref="7fc56270e7a70fa81a5935b72eacbe29" prefix=" " category="inline-code"></block> signifie « autoriser ». Les indicateurs hériter ne sont pas définis dans ce cas, car le principal n'est pas un groupe et n'inclut pas l'héritage. De plus, comme l'ACE n'est pas une entrée D'AUDIT, il n'est pas nécessaire de définir les indicateurs d'audit. Pour plus d'informations sur les listes de contrôle d'accès NFSv4.1, voir<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>.</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">Si la liste de contrôle d’accès NFSv4.1 n’est pas définie correctement (ou si une chaîne de nom ne peut pas être résolue par le client et le serveur), la liste de contrôle d’accès peut ne pas se comporter comme prévu, ou si la modification de la liste de contrôle d’accès échoue à s’appliquer et générer une erreur.</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">Les exemples d'erreurs sont les suivants :</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">REFUS explicite</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">Les autorisations NFSv4.1 peuvent inclure des attributs DE REFUS explicites pour LE PROPRIÉTAIRE, LE GROUPE et TOUT LE MONDE. En effet, les listes de contrôle d’accès NFSv4.1 étant des listes de contrôle d’accès par défaut, ce qui signifie que si une liste de contrôle d’accès n’est pas explicitement accordée par une ACE, elle est alors refusée. Les attributs DE REFUS explicite remplacent les ACE D'ACCÈS, explicites ou non.</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">LES ACE DE REFUS sont définis avec une balise d'attribut de<block ref="f623e75af30e62bbd73d6df5b50bb7b5" prefix=" " category="inline-code"></block>.</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">Dans l'exemple ci-dessous, GROUP@ est autorisé à toutes les autorisations de lecture et d'exécution, mais a refusé tout accès en écriture.</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">DANS la mesure du possible, LES ACE DE REFUS doivent être évités parce qu'ils peuvent être confus et compliqués ; AUTORISER les listes de contrôle d'accès qui ne sont pas explicitement définies sont refusées implicitement. Lorsque LES ACE DE REFUS sont définis, les utilisateurs peuvent se voir refuser l'accès lorsqu'ils s'attendent à bénéficier de l'accès.</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">L'ensemble précédent d'ACE est équivalent à 755 bits de mode, ce qui signifie :</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">Le propriétaire a tous les droits.</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">Les groupes ont lecture seule.</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">D'autres ont lecture seule.</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">Cependant, même si les autorisations sont ajustées à l'équivalent 775, l'accès peut être refusé en raison du REFUS explicite défini sur TOUT LE MONDE.</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">Dépendances de mappage de domaine ID NFSv4.1</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1 s'appuie sur la logique de mappage de domaine d'ID en tant que couche de sécurité pour garantir qu'un utilisateur qui tente d'accéder à un montage NFSv4.1 est en effet celui qu'il prétend être. Dans ce cas, le nom d'utilisateur et le nom de groupe provenant du client NFSv4.1 ajoute une chaîne de nom et l'envoie à l'instance Cloud Volumes Service. Si cette combinaison nom d'utilisateur/groupe et chaîne ID ne correspond pas, alors l'utilisateur et/ou le groupe est écrasé par défaut, aucun utilisateur spécifié dans le<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block> fichier sur le client.</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">Cette chaîne d'ID est une exigence pour le respect correct des autorisations, en particulier lorsque des ACL NFSv4.1 et/ou Kerberos sont utilisés. Par conséquent, des dépendances au niveau du serveur de service de noms, telles que les serveurs LDAP, sont nécessaires pour assurer la cohérence entre les clients et Cloud Volumes Service afin de permettre une résolution appropriée de l'identité des noms d'utilisateur et de groupe.</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service utilise une valeur de nom de domaine d'ID par défaut statique de<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block>. Les clients NFS utilisent par défaut le nom de domaine DNS pour ses paramètres de nom de domaine ID, mais vous pouvez régler manuellement le nom de domaine ID dans<block ref="f606fb2da2ae329157d791c6955a0337" prefix=" " category="inline-code"></block>.</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Si le protocole LDAP est activé dans Cloud Volumes Service, Cloud Volumes Service automatise le domaine d'ID NFS pour modifier ce qui est configuré pour le domaine de recherche dans DNS et les clients n'ont pas besoin d'être modifiés à moins qu'ils n'utilisent des noms de recherche de domaine DNS différents.</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Lorsque Cloud Volumes Service peut résoudre un nom d'utilisateur ou un nom de groupe dans les fichiers locaux ou LDAP, la chaîne de domaine est utilisée et les ID de domaine ne sont pas identiques. Si Cloud Volumes Service ne parvient pas à trouver un nom d'utilisateur ou un nom de groupe dans les fichiers locaux ou LDAP, la valeur d'ID numérique est utilisée et le client NFS résout correctement le nom (ceci est similaire au comportement NFSv3).</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">Sans modifier le domaine d'ID NFSv4.1 du client pour correspondre à l'utilisation du volume Cloud Volumes Service, le comportement suivant s'affiche :</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">Les utilisateurs et groupes UNIX avec des entrées locales dans Cloud Volumes Service (comme root, comme défini dans les utilisateurs et groupes UNIX locaux) sont écrasés sur la valeur personne.</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">Les utilisateurs et groupes UNIX dont les entrées sont dans LDAP (si Cloud Volumes Service est configuré pour utiliser LDAP) ne s'acclaent à personne si les domaines DNS sont différents entre les clients NFS et Cloud Volumes Service.</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">Les utilisateurs et groupes UNIX sans entrées locales ou LDAP utilisent la valeur d'ID numérique et résolvez le nom spécifié sur le client NFS. Si aucun nom n'existe sur le client, seul l'ID numérique est affiché.</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">Voici les résultats du scénario précédent :</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">Lorsque les domaines d'ID client et serveur correspondent, voici l'apparence de la même liste de fichiers :</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">Pour plus d'informations sur ce problème et sur la façon de le résoudre, reportez-vous à la section «<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>. »</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Les dépendances Kerberos</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">Si vous prévoyez d'utiliser Kerberos avec NFS, vous devez disposer des éléments suivants en Cloud Volumes Service :</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Domaine Active Directory pour les services du centre de distribution Kerberos (KDC)</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">Domaine Active Directory avec des attributs utilisateur et groupe renseignés avec des informations UNIX pour la fonctionnalité LDAP (le protocole Kerberos NFS dans Cloud Volumes Service requiert un mappage utilisateur SPN vers UNIX pour assurer le bon fonctionnement du système).</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">LDAP activée sur l'instance Cloud Volumes Service</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">Domaine Active Directory pour les services DNS</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1 et personne utilisateur/groupe</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">L'un des problèmes les plus courants rencontrés avec une configuration NFSv4.1 est lorsqu'un fichier ou un dossier est affiché dans une liste à l'aide de<block ref="44ba5ca65651b4f36f1927576dd35436" prefix=" " category="inline-code"></block> appartenant au<block ref="aa22bf558e0fe9237af37223aa4eecbb" prefix=" " category="inline-code"></block> combinaison de<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>.</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">Et l'ID numérique est<block ref="ac627ab1ccbdb62ec96e702f07f6425b" prefix=" " category="inline-code"></block>.</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">Dans certains cas, le fichier peut indiquer le propriétaire correct, mais<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> en tant que groupe.</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">Qui n'est personne?</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">Le<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> L'utilisateur dans NFSv4.1 est différent de<block ref="3ff01acd436943ffc00e90a99dd4f83e" prefix=" " category="inline-code"></block> utilisateur. Vous pouvez afficher la manière dont un client NFS voit chaque utilisateur en exécutant le<block ref="b80bb7740288fda1f201890375a60c8f" prefix=" " category="inline-code"></block> commande :</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">Avec NFSv4.1, le<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> l'utilisateur est l'utilisateur par défaut défini par le<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> et peut être défini comme n'importe quel utilisateur que vous voulez utiliser.</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">Pourquoi cela se produit-il ?</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">Étant donné que la sécurité par mappage de chaînes de noms est un principe clé des opérations NFSv4.1, le comportement par défaut lorsqu'une chaîne de noms ne correspond pas correctement est de court-courser cet utilisateur à un utilisateur qui n'aura normalement pas accès aux fichiers et dossiers appartenant aux utilisateurs et aux groupes.</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">Lorsque vous voyez<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Pour l'utilisateur et/ou le groupe dans les listes de fichiers, cela signifie généralement que quelque chose dans NFSv4.1 est mal configuré. La sensibilité de la casse peut être ici en jeu.</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">Par exemple, si utilisateur1@CVSDEMO.LOmabL (uid 1234, gid 1234) accède à une exportation, alors Cloud Volumes Service doit pouvoir trouver utilisateur1@CVSDEMO.LOMOL (uid 1234, gid 1234). Si l'utilisateur dans Cloud Volumes Service est USER1@CVSDEMO.LOmabmacop, il ne correspond pas (majuscules UTILISATEUR1 contre minuscules utilisateur1). Dans de nombreux cas, vous pouvez voir ce qui suit dans le fichier de messages sur le client :</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">Le client et le serveur doivent tous deux convenir qu'un utilisateur est effectivement celui qu'il prétend être. Vous devez donc vérifier les éléments suivants pour vous assurer que l'utilisateur que le client voit dispose des mêmes informations que l'utilisateur que celui que Cloud Volumes Service voit.</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">*Domaine ID NFSv4.x.* client :<block ref="83c686a28c61cd8fdbac9a1804f10e47" prefix=" " category="inline-code"></block> Fichier ; utilisations de Cloud Volumes Service<block ref="22a3233341e094b6c2067cb2972e530a" prefix=" " category="inline-code"></block> et ne peut pas être modifié manuellement. En cas d'utilisation de LDAP avec NFSv4.1, Cloud Volumes Service modifie le domaine d'ID en fonction de ce que le domaine de recherche DNS utilise, ce qui est le même que le domaine AD.</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">*Nom d'utilisateur et ID numériques.* Ceci détermine l'endroit où le client recherche des noms d'utilisateur et utilise la configuration du commutateur de service de nom—client:<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Et/ou fichiers de passwd et de groupe locaux ; Cloud Volumes Service n'autorise pas les modifications à ceci mais ajoute automatiquement LDAP à la configuration lorsqu'elle est activée.</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">*Nom de groupe et ID numériques.* cette option détermine où le client recherche des noms de groupe et utilise la configuration du commutateur de service de nom—client :<block ref="ea2e5642148891c2d0cae7bf555be98a" prefix=" " category="inline-code"></block> Et/ou fichiers de passwd et de groupe locaux ; Cloud Volumes Service n'autorise pas les modifications à ceci mais ajoute automatiquement LDAP à la configuration lorsqu'elle est activée.</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">Dans presque tous les cas, si vous voyez<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Dans les listes d'utilisateurs et de groupes des clients, le problème est la traduction de l'ID de domaine de nom d'utilisateur ou de groupe entre Cloud Volumes Service et le client NFS. Pour éviter ce scénario, utilisez LDAP pour résoudre les informations d'utilisateur et de groupe entre les clients et Cloud Volumes Service.</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">Affichage des chaînes d'ID de nom pour NFSv4.1 sur les clients</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">Si vous utilisez NFSv4.1, un mappage de chaîne de nom a lieu lors des opérations NFS, comme décrit précédemment.</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">En plus de l'utilisation<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block> Pour trouver un problème avec les ID NFSv4, vous pouvez utiliser le<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> Commande sur le client NFS pour afficher les noms d'utilisateur qui sont correctement mappés au domaine NFSv4.</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">Par exemple, ceci est la sortie de la commande après un utilisateur qui peut être trouvé par le client et que Cloud Volumes Service accède à un montage NFSv4.x :</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">Lorsqu'un utilisateur qui ne se mappe pas correctement dans le domaine ID NFSv4.1 (dans ce cas,<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>) essaie d'accéder au même montage et touche un fichier, ils sont affectés<block ref="9a0f36d70a22b40baa26f3df113cd9eb" prefix=" " category="inline-code"></block>, comme prévu.</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">Le<block ref="600a8e1223f644dfc8fc6d9eaf7c6585" prefix=" " category="inline-code"></block> la sortie affiche l'utilisateur<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> à l'écran, mais pas<block ref="7ddf2462d5aa52ee60f5901c04ede944" prefix=" " category="inline-code"></block>; il s'agit de l'utilisateur anonyme dans notre règle d'export-policy <block ref="f9df942af967185fc775031b3c286856" prefix="(" category="inline-code"></block>).</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">Suivant: PME.</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Toutes les actions de gestion vers Cloud Volumes Service sont effectuées par l'intermédiaire d'une API. La gestion Cloud Volumes Service intégrée à la console GCP Cloud utilise également l'API Cloud Volumes Service.</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">Architecture du plan de contrôle</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">Précédent : architecture Cloud Volumes Service.</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">Gestion des identités et des accès</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">Gestion des identités et des accès <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>) Est un service standard qui vous permet de contrôler l'authentification (connexions) et l'autorisation (autorisations) des instances de projet Google Cloud. Google IAM fournit une piste d'audit complète des autorisations et des suppressions. Actuellement, Cloud Volumes Service ne fournit pas d'audit du plan de contrôle.</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">Présentation de l'autorisation/autorisation</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">liste complète des autorisations granulaires ici</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM propose des autorisations granulaires intégrées pour Cloud Volumes Service. Vous pouvez trouver un<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>.</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM propose également deux rôles prédéfinis appelés<block ref="4a5395c87dd91b3242056f83b7cedb9b" prefix=" " category="inline-code"></block> et<block ref="d8cd72eb52281636a72e12ef877b62f8" prefix=" " category="inline-code"></block>. Ces rôles peuvent être attribués à des utilisateurs ou à des comptes de service spécifiques.</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">Attribuez les rôles et les autorisations appropriés pour permettre aux utilisateurs IAM de gérer Cloud Volumes Service.</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">Voici quelques exemples d'utilisation d'autorisations granulaires :</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">Créez un rôle personnalisé avec uniquement les autorisations obtenir/liste/créer/mettre à jour pour que les utilisateurs ne puissent pas supprimer de volumes.</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">Utilisez un rôle personnalisé avec uniquement<block ref="984f6a68d5cd59b0b62580124dedfd98" prefix=" " category="inline-code"></block> Autorisations permettant de créer un compte de service utilisé pour créer une intégration Snapshot cohérente avec les applications.</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">Définissez un rôle personnalisé à déléguer<block ref="49fb6de34b20a50950c47f0a75513736" prefix=" " category="inline-code"></block> pour des utilisateurs spécifiques.</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">Comptes de service</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">Pour passer des appels API Cloud Volumes Service par le biais de scripts ou<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>, vous devez créer un compte de service avec<block ref="5e467dce18f46b1803b06097fae60b82" prefix=" " category="inline-code"></block> rôle. Vous pouvez utiliser ce compte de service pour générer les jetons JWT requis pour authentifier les requêtes API Cloud Volumes Service de deux manières différentes :</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">Générez une clé JSON et utilisez les API Google pour dériver un jeton JWT. C'est l'approche la plus simple, mais elle implique une gestion manuelle des secrets (clé JSON).</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">Emprunt d'identité du compte de service</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">Informations d'identification par défaut de l'application</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">Utiliser<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> avec<block ref="4d4344aa5ad9d43d63ab2f068115cadb" prefix=" " category="inline-code"></block>. Le code (script, Terraform, etc.) s'exécute avec<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> et emprunt de l'identité du compte de service pour obtenir ses autorisations. Cette approche reflète les bonnes pratiques de sécurité de Google.</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">Création de votre compte de service et de votre clé privée</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">Voir<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> Dans la documentation Google Cloud pour plus d'informations.</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">API Cloud Volumes Service</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">API Cloud volumes dans la documentation Google Cloud</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">L'API Cloud Volumes Service utilise une API REST en utilisant HTTPS (TLSv1.2) comme transport réseau sous-jacent. Vous trouverez la définition d'API la plus récente<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> Et des informations sur l'utilisation de l'API à l'adresse<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>.</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">Le terminal API est exploité et sécurisé par NetApp à l'aide de la fonctionnalité HTTPS standard (TLSv1.2).</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">Jetons JWT</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">L'authentification à l'API est effectuée avec des jetons de support JWT <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>). Les jetons JWT valides doivent être obtenus via l'authentification Google Cloud IAM. Pour ce faire, il faut récupérer un jeton depuis IAM en fournissant une clé JSON de compte de service.</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">Consignation des audits</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">Aucun journal d'audit du plan de contrôle accessible par l'utilisateur n'est actuellement disponible.</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">Next : architecture de plan de données.</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">De la même manière que d'autres services Google Cloud natifs, tels que CloudSQL, Google Cloud VMware Engine (GCVE) et filestore, Cloud Volumes Service utilise Google PSA pour fournir le service.</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Architecture Cloud Volumes Service</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">Peering de réseau VPC</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">De la même manière que d'autres services Google Cloud natifs, tels que CloudSQL, Google Cloud VMware Engine (GCVE) et filestore, utilise Cloud Volumes Service<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> pour fournir le service. Dans PSA, les services sont intégrés à un projet de producteur de services, qui utilise<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> pour se connecter au consommateur de services. Le producteur de service est fourni et exploité par NetApp, et le consommateur du service est un VPC dans un projet client qui héberge les clients souhaitant accéder aux partages de fichiers Cloud Volumes Service.</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">section architecture</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">La figure suivante, référencée à partir du<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> De la documentation Cloud Volumes Service, affiche une vue générale.</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">La partie au-dessus de la ligne pointillée montre le plan de contrôle du service, qui contrôle le cycle de vie du volume. La partie sous la ligne pointillée montre le plan de données. La zone bleue gauche représente le VPC (Service Consumer) de l'utilisateur, la zone bleue droite est le producteur de services fourni par NetApp. Les deux sont connectés via le peering VPC.</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">Modèle de location</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">Dans Cloud Volumes Service, chaque projet est considéré comme un locataire unique. Cela signifie que la manipulation des volumes et des copies Snapshot, etc., est effectuée sur la base de chaque projet. En d'autres termes, tous les volumes sont détenus par le projet dans lequel ils ont été créés, et seul ce projet peut gérer et accéder aux données qui leur sont propres par défaut. Cette vue est considérée comme le plan de contrôle du service.</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">VPC partagés</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">Dans la vue du plan de données, Cloud Volumes Service peut se connecter à un VPC partagé. Vous pouvez créer des volumes dans le projet d'hébergement ou dans l'un des projets de service connectés au VPC partagé. Tous les projets (hôte ou service) connectés à ce VPC partagé peuvent atteindre les volumes au niveau de la couche réseau (TCP/IP). Étant donné que tous les clients disposant d'une connectivité réseau sur le VPC partagé peuvent accéder aux données via les protocoles NAS, vous devez utiliser le contrôle d'accès sur chacun des volumes (listes de contrôle d'accès (ACL) d'utilisateur/de groupe, ainsi que les noms d'hôte/adresses IP pour les exportations NFS) pour contrôler qui peut accéder aux données.</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">Vous pouvez connecter Cloud Volumes Service à cinq VPC maximum par projet client. Sur le plan de contrôle, le projet vous permet de gérer tous les volumes créés, quel que soit le VPC auquel ils sont connectés. Sur le plan de données, les VPC sont isolés les uns des autres et chaque volume ne peut être connecté qu'à un VPC.</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">L'accès aux volumes individuels est contrôlé par des mécanismes de contrôle d'accès spécifiques à un protocole (NFS/SMB).</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">En d'autres termes, sur la couche réseau, tous les projets connectés au VPC partagé peuvent voir le volume, tandis que, du point de vue de la gestion, le plan de contrôle ne permet au projet propriétaire de voir le volume que.</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">Contrôles du service VPC</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">Les contrôles du service VPC établissent un périmètre de contrôle d'accès autour des services Google Cloud reliés à Internet et accessibles dans le monde entier. Ces services permettent le contrôle d'accès par le biais d'identités utilisateur, mais ne peuvent pas limiter les demandes d'emplacement réseau. Les contrôles de service VPC comblent ce fossé en introduisant des capacités permettant de limiter l'accès aux réseaux définis.</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Le plan de données Cloud Volumes Service n'est pas connecté à Internet externe mais à des VPC privés avec des limites de réseau bien définies (périmètres). Sur ce réseau, chaque volume utilise un contrôle d'accès spécifique au protocole. Toute connectivité réseau externe est créée de manière explicite par les administrateurs de projet Google Cloud. Le plan de contrôle, cependant, n'offre pas les mêmes protections que le plan de données et peut être accessible par n'importe qui à partir de n'importe où avec des informations d'identification valides (<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>).</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">En bref, le plan de données Cloud Volumes Service offre la possibilité de contrôler l'accès au réseau sans devoir prendre en charge les contrôles de service VPC et n'utilise pas explicitement les contrôles de service VPC.</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">Considérations relatives à la détection et à la détection des paquets</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">Les captures de paquets peuvent être utiles pour résoudre des problèmes réseau ou d'autres problèmes (autorisations NAS, connectivité LDAP, etc.), mais peuvent également être utilisées de manière malveillante pour obtenir des informations sur les adresses IP réseau, les adresses MAC, les noms d'utilisateurs et de groupes, ainsi que le niveau de sécurité utilisé sur les noeuds finaux. En raison de la configuration de la mise en réseau Google Cloud, des VPC et des règles de pare-feu, l'accès non autorisé aux paquets réseau devrait être difficile à obtenir sans identifiants de connexion utilisateur ou <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> dans les instances cloud. Les captures de paquets ne sont possibles que sur les terminaux (tels que les machines virtuelles) et uniquement sur les terminaux internes au VPC, à moins qu'un VPC partagé et/ou un tunnel/IP de réseau externe ne soit utilisé pour permettre explicitement le trafic externe vers les terminaux. Il n'y a pas de moyen de sniff trafic en dehors des clients.</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="inline-link-macro">Chiffrement SMB</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="inline-link-macro">DNS</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="inline-link-macro">Requêtes LDAP</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">Lorsque des VPC partagés sont utilisés, le chiffrement à la volée avec NFS Kerberos et/ou <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> peut masquer une grande partie des informations tirées de traces. Cependant, un certain trafic est encore envoyé en texte clair, par exemple <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> et <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>. La figure suivante montre une capture de paquet à partir d'une requête LDAP en texte clair provenant de Cloud Volumes Service et les informations d'identification potentielles qui sont exposées. Les requêtes LDAP dans Cloud Volumes Service ne prennent actuellement pas en charge le cryptage ou LDAP sur SSL. CVS-Performance prend en charge la signature LDAP, si Active Directory en fait la demande. CVS-SW ne prend pas en charge la signature LDAP.</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">UnixUserPassword est interrogé par LDAP et n'est pas envoyé en texte clair, mais plutôt dans un hash salé. Par défaut, Windows LDAP ne renseigne pas les champs unixUserPassword. Ce champ est uniquement obligatoire si vous devez utiliser Windows LDAP pour les connexions interactives via LDAP aux clients. Cloud Volumes Service ne prend pas en charge les connexions LDAP interactives vers les instances.</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">La figure suivante montre une capture de paquets d'une conversation Kerberos NFS à côté d'une capture de NFS sur AUTH_SYS. Notez que les informations disponibles dans une trace diffèrent entre les deux et que l'activation du cryptage à la volée offre une sécurité globale accrue pour le trafic NAS.</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">Interfaces réseau des VM</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">mode promiscueux</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">Une astuce peut tenter d'ajouter une nouvelle carte d'interface réseau (NIC) à une machine virtuelle dans<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> (Mise en miroir des ports) ou activez le mode promiscuous sur une carte réseau existante afin de sniiser tout le trafic. Dans Google Cloud, l'ajout d'une nouvelle carte réseau nécessite l'arrêt complet d'une machine virtuelle, ce qui génère des alertes, ce qui rend les pirates informatiques inaperçus.</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">De plus, les cartes réseau ne peuvent pas être configurées en mode promiscuous et déclencheront des alertes dans Google Cloud.</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">Suivant : architecture du plan de contrôle.</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service permet de connecter votre instance Cloud Volumes Service à un serveur Active Directory externe pour la gestion des identités tant pour les utilisateurs SMB que UNIX. La création d'une connexion Active Directory est nécessaire pour utiliser SMB dans Cloud Volumes Service.</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Considérations relatives à la création de connexions Active Directory</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">Précédent : double protocole/multiprotocole.</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">Accès privé à Google</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Bonnes pratiques avec Active Directory dans Google Cloud</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">La configuration offre plusieurs options qui nécessitent d'être prises en compte pour la sécurité. Le serveur Active Directory externe peut être une instance sur site ou un cloud natif. Si vous utilisez un serveur Active Directory sur site, n’exposez pas le domaine au réseau externe (par exemple avec une DMZ ou une adresse IP externe). Au lieu de cela, utilisez des tunnels privés sécurisés ou des VPN, des fiducies forestières à sens unique ou des connexions réseau dédiées aux réseaux sur site avec<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>. Consultez la documentation Google Cloud pour plus d'informations sur<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>.</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW nécessite que les serveurs Active Directory soient situés dans la même région. Si une connexion CC est tentée dans CVS-SW vers une autre région, la tentative échoue. Lorsque vous utilisez CVS-SW, veillez à créer des sites Active Directory incluant les DCS Active Directory, puis spécifiez des sites dans Cloud Volumes Service pour éviter les tentatives de connexion CC entre régions.</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Informations d'identification Active Directory</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">Lorsque SMB ou LDAP pour NFS est activé, Cloud Volumes Service interagit avec les contrôleurs Active Directory pour créer un objet de compte de machine à utiliser pour l'authentification. Ce n'est pas différent de la façon dont un client SMB Windows rejoint un domaine et nécessite les mêmes droits d'accès aux unités organisationnelles (UO) dans Active Directory.</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">Dans de nombreux cas, les groupes de sécurité n'autorisent pas l'utilisation d'un compte administrateur Windows sur des serveurs externes tels que Cloud Volumes Service. Dans certains cas, l'utilisateur de l'administrateur Windows est entièrement désactivé en tant que meilleure pratique de sécurité.</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">Autorisations nécessaires pour créer des comptes de machine SMB</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">autorisations déléguées pour créer et modifier des objets de compte machine</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Pour ajouter des objets machine Cloud Volumes Service à un Active Directory, un compte qui possède des droits d'administration sur le domaine ou a<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> À une UO spécifiée est nécessaire. Pour ce faire, vous pouvez créer une tâche personnalisée avec l’assistant délégation de contrôle d’Active Directory qui fournit un accès utilisateur à la création/suppression d’objets d’ordinateur avec les autorisations d’accès suivantes :</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">Lecture/écriture</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">Créer/Supprimer tous les objets enfants</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">Lire/écrire toutes les propriétés</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">Modifier/Réinitialiser le mot de passe</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">Cette opération ajoute automatiquement une liste de contrôle d’accès de sécurité pour l’utilisateur défini à l’UO dans Active Directory et réduit l’accès à l’environnement Active Directory. Après la délégation d'un utilisateur, ce nom d'utilisateur et ce mot de passe peuvent être fournis en tant qu'informations d'identification Active Directory dans cette fenêtre.</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">Le nom d'utilisateur et le mot de passe transmis au domaine Active Directory exploitent le chiffrement Kerberos lors de la requête et de la création d'objet de compte machine pour une sécurité supplémentaire.</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Détails de la connexion à Active Directory</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Détails de connexion Active Directory</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">Le<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> Indiquez les champs permettant aux administrateurs de fournir des informations spécifiques sur le schéma Active Directory pour le placement de compte machine, par exemple :</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">*Type de connexion Active Directory.* utilisé pour spécifier si la connexion Active Directory dans une région est utilisée pour les volumes de type de service Cloud Volumes Service ou CVS-Performance. Si ce paramètre n'est pas défini correctement sur une connexion existante, il est possible qu'il ne fonctionne pas correctement lorsqu'il est utilisé ou modifié.</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">*Domaine.* le nom de domaine Active Directory.</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">considérations</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">*Site.* limite les serveurs Active Directory à un site spécifique pour la sécurité et les performances<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>. Ceci est nécessaire lorsque plusieurs serveurs Active Directory s'étendent sur des régions car Cloud Volumes Service ne prend pas en charge actuellement l'autorisation d'autoriser les requêtes d'authentification Active Directory à des serveurs Active Directory dans une région différente de celle de l'instance Cloud Volumes Service. (Par exemple, le contrôleur de domaine Active Directory se trouve dans une région qui ne prend en charge que CVS-Performance mais vous voulez un partage SMB dans une instance CVS-SW.)</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">*Serveurs DNS.* serveurs DNS à utiliser dans les recherches de noms.</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Comment Cloud Volumes Service s'affiche dans Active Directory</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">*Nom NetBIOS (facultatif).* si vous le souhaitez, le nom NetBIOS du serveur. Ce qui est utilisé lorsque de nouveaux comptes machine sont créés à l'aide de la connexion Active Directory. Par exemple, si le nom NetBIOS est défini sur CVS-EAST, les noms des comptes machine seront CVS-EAST-{1234}. Voir la section <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">*Unité organisationnelle (UO).* l'UO spécifique pour créer le compte d'ordinateur. Ceci est utile si vous déléguez le contrôle à un utilisateur pour les comptes machine à une unité d'organisation spécifique.</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">*Cryptage AES.* vous pouvez également cocher ou décocher la case Activer le cryptage AES pour l'authentification AD. L'activation du cryptage AES pour l'authentification Active Directory offre une sécurité supplémentaire pour la communication entre Cloud Volumes Service et Active Directory au cours des recherches utilisateur et de groupe. Avant d'activer cette option, vérifiez auprès de votre administrateur de domaine que les contrôleurs de domaine Active Directory prennent en charge l'authentification AES.</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">Par défaut, la plupart des serveurs Windows ne désactivent pas les chiffrements plus faibles (tels QUE DES ou RC4-HMAC), mais si vous choisissez de désactiver les chiffrements plus faibles, confirmez que la connexion Cloud Volumes Service Active Directory a été configurée pour activer AES. Dans le cas contraire, des échecs d'authentification se produisent. L'activation du cryptage AES ne désactive pas les chiffrements plus faibles mais ajoute au contraire la prise en charge du chiffrement AES au compte de la machine Cloud Volumes Service SMB.</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Détails du domaine Kerberos</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">Cette option ne s'applique pas aux serveurs SMB. Elles sont plutôt utilisées lors de la configuration de Kerberos par NFS pour le système Cloud Volumes Service. Lorsque ces informations sont renseignées, le domaine Kerberos NFS est configuré (similaire à un fichier krb5.conf sous Linux) et utilisé lorsque NFS Kerberos est spécifié dans la création du volume Cloud Volumes Service, car la connexion Active Directory fait office de centre de distribution Kerberos NFS (KDC).</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">Actuellement, les KDC non Windows ne sont pas pris en charge pour une utilisation avec Cloud Volumes Service.</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">Région</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">Une région vous permet de spécifier l'emplacement où réside la connexion Active Directory. Cette région doit être la même région que le volume Cloud Volumes Service.</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">*Utilisateurs NFS locaux avec LDAP.* dans cette section, il existe également une option permettant aux utilisateurs NFS locaux avec LDAP. Cette option doit être désélectionnée si vous souhaitez étendre votre prise en charge d'appartenance à un groupe d'utilisateurs UNIX au-delà de la limite de 16 groupes de NFS (groupes étendus). Cependant, l'utilisation de groupes étendus nécessite un serveur LDAP configuré pour les identités UNIX. Si vous ne disposez pas d'un serveur LDAP, laissez cette option non sélectionnée. Si vous disposez d'un serveur LDAP et souhaitez également utiliser des utilisateurs UNIX locaux (comme root), sélectionnez cette option.</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">Utilisateurs de la sauvegarde</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">activation de l'audit de cet accès utilisateur</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">Cette option vous permet de spécifier les utilisateurs Windows disposant d'autorisations de sauvegarde sur le volume Cloud Volumes Service. Les privilèges de sauvegarde (SeBackupPrivilege) sont nécessaires pour que certaines applications puissent sauvegarder et restaurer correctement les données dans des volumes NAS. Cet utilisateur dispose d'un haut niveau d'accès aux données du volume. Vous devez donc tenir compte de cet aspect<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>. Une fois activée, les événements d'audit s'affichent dans Event Viewer &gt; Windows Logs &gt; Security.</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">Utilisateurs disposant des privilèges de sécurité</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">Tels que SQL Server</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">audit de l'accès des utilisateurs</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">Cette option vous permet de spécifier les utilisateurs Windows disposant d'autorisations de modification de sécurité pour le volume Cloud Volumes Service. Des privilèges de sécurité (SeSecurityPrivilege) sont nécessaires pour certaines applications <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>) pour définir correctement les autorisations lors de l'installation. Ce privilège est nécessaire pour gérer le journal de sécurité. Bien que ce privilège ne soit pas aussi puissant que SeBackupPrivilege, NetApp recommande<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> avec ce niveau de privilège, le cas échéant.</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">Privilèges spéciaux attribués à la nouvelle connexion</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">Pour plus d'informations, voir<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>.</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service apparaît dans Active Directory comme un objet de compte machine normal. Les conventions de nom sont les suivantes.</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB et NFS Kerberos créent des objets de compte de machine distincts.</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">Le protocole NFS avec LDAP activé crée un compte machine dans Active Directory pour les liaisons LDAP Kerberos.</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">Les volumes à double protocole avec LDAP partagent le compte de machine CIFS/SMB pour LDAP et SMB.</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">Les comptes de machine CIFS/SMB utilisent une convention de dénomination de NOM-1234 (identifiant aléatoire à quatre chiffres avec tiret ajouté à &lt;10 caractères name) pour le compte de machine. Vous pouvez définir LE NOM à l'aide du paramètre Nom NetBIOS de la connexion Active Directory (voir la section «<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>”).</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos utilise NFS-NAME-1234 comme convention de nommage (15 caractères au maximum). Si plus de 15 caractères sont utilisés, le nom est NFS-TRONQUÉ-NAME-1234.</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">Les instances CVS-Performance uniquement avec LDAP activées créent un compte de machine SMB pour la liaison au serveur LDAP avec la même convention de nommage que les instances CIFS/SMB.</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">« Partages masqués par défaut »</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">Lorsqu'un compte de machine SMB est créé, les partages admin masqués par défaut (voir la section <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Sont également créés (c$, admin$, ipc$), mais ces partages n'ont pas de listes de contrôle d'accès attribuées et sont inaccessibles.</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">Les objets de compte machine sont placés par défaut dans CN=Computers, mais un vous pouvez spécifier une autre UO si nécessaire. Voir la section «<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>” Pour plus d'informations sur les droits d'accès nécessaires pour ajouter/supprimer des objets de compte machine pour Cloud Volumes Service.</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Lorsque Cloud Volumes Service ajoute le compte de machine SMB à Active Directory, les champs suivants sont renseignés :</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">cn (avec le nom de serveur SMB spécifié)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">DnsHostName (avec SMBserver.domain.com)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">MSDS-SupportedEncryptionTypes (autorise LES_CBC_MD5, RC4_HMAC_MD5 si le chiffrement AES n'est pas activé ; si le chiffrement AES est activé, DES_CBC_MD5, RC4_HMAC_MD5, AES128_HMAC_SHA1_96, AES256_CTS_HMAC_SHA1 est autorisé pour l'échange avec le compte SMB_96)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">Nom (avec le nom du serveur SMB)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">SAMAccountName (avec SMBserver$)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">ServicePrincipalName (avec hôte/smbserver.domain.com et SPN hôte/smbserver pour Kerberos)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">Si vous souhaitez désactiver les types de cryptage Kerberos les plus faibles (type d'enc) sur le compte de la machine, vous pouvez modifier la valeur MSDS-SupportedEncryptionTypes sur le compte de la machine à l'une des valeurs du tableau suivant pour n'autoriser que AES.</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">MSDS-SupportedEncryptionTypes valeur</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">Type d'encan activé</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">AES128_CTS_HMAC_SHA1_96 UNIQUEMENT</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">AES256_CTS_HMAC_SHA1_96 UNIQUEMENT</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96 ET AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5, RC4_HMAC, AES128_CTS_HMAC_SHA1_96 ET AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">Pour activer le cryptage AES pour les comptes de machine SMB, cliquez sur Activer le cryptage AES pour l'authentification AD lors de la création de la connexion Active Directory.</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Consultez la documentation Cloud Volumes Service</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">Pour activer le chiffrement AES pour NFS Kerberos,<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>.</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">Suivant : autres dépendances du service d'infrastructure NAS (KDC, LDAP, DNS).</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">Informations supplémentaires, historique des versions et informations de contact</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">Précédent : opération d'entretien.</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Documentation Google Cloud pour Cloud Volumes Service</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Service privé Google</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">Documentation des produits NetApp</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">Programme de module de validation cryptographique : NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="list-text">Solution NetApp pour ransomware</block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">Tr-4616 : NFS Kerberos dans ONTAP</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">Dites-nous comment nous pourrions améliorer ce rapport technique.</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">Contactez-nous à l'adresse : mailto:doccomments@netapp.com[doccomments@netapp.com^]. Incluez LE RAPPORT TECHNIQUE 4918 dans la ligne d'objet.</block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB est un protocole de partage de fichiers réseau développé par Microsoft qui fournit une authentification utilisateur/groupe centralisée, des autorisations, un verrouillage et un partage de fichiers à plusieurs clients SMB sur un réseau Ethernet.</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">PME</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">Précédent : NFS.</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> Est un protocole de partage de fichiers réseau développé par Microsoft qui fournit une authentification utilisateur/groupe centralisée, des autorisations, un verrouillage et un partage de fichiers à plusieurs clients SMB sur un réseau Ethernet. Les fichiers et les dossiers sont présentés aux clients par le biais de partages, qui peuvent être configurés avec diverses propriétés de partage et offre un contrôle d'accès par le biais d'autorisations de niveau partage. SMB peut être présenté à n'importe quel client prenant en charge le protocole, y compris les clients Windows, Apple et Linux.</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service prend en charge les versions SMB 2.1 et 3.x du protocole.</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">Contrôle d'accès/partages SMB</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Lorsqu'un nom d'utilisateur Windows demande l'accès au volume Cloud Volumes Service, Cloud Volumes Service recherche un nom d'utilisateur UNIX en utilisant les méthodes configurées par les administrateurs Cloud Volumes Service.</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">Si un fournisseur d'identités UNIX externe (LDAP) est configuré et que les noms d'utilisateur Windows/UNIX sont identiques, les noms d'utilisateur Windows mappent les noms d'utilisateur 1:1 vers UNIX sans configuration supplémentaire. Lorsque LDAP est activée, Active Directory est utilisé pour héberger ces attributs UNIX pour les objets utilisateur et groupe.</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">“Utilisation du protocole LDAP pour le mappage de noms asymétrique”</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Si les noms Windows et UNIX ne correspondent pas de la même manière, LDAP doit être configurée pour permettre à Cloud Volumes Service d'utiliser la configuration du mappage de noms LDAP (voir la section <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>).</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">Si LDAP n'est pas utilisé, les utilisateurs Windows SMB mappent un utilisateur UNIX local par défaut nommé<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> À Cloud Volumes Service. Cela signifie que les fichiers écrits dans Windows par les utilisateurs qui font correspondre à<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Afficher la propriété UNIX sous<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Dans des environnements NAS multiprotocoles.<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> voici le<block ref="6e854442cd2a940c9e95941dce4ad598" prefix=" " category="inline-code"></block> Utilisateur dans les environnements Linux (UID 65534).</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">Dans les déploiements avec SMB uniquement, le<block ref="68b79d57b5efe5cd122cd25bf3570cb9" prefix=" " category="inline-code"></block> Le mappage a toujours lieu, mais cela n'a aucune importance, car la propriété des utilisateurs et des groupes Windows est correctement affichée et l'accès NFS au volume SMB uniquement n'est pas autorisé. De plus, les volumes SMB uniquement ne prennent pas en charge la conversion en volumes NFS ou à double protocole après leur création.</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows utilise Kerberos pour l'authentification par nom d'utilisateur avec les contrôleurs de domaine Active Directory, qui nécessitent un échange nom d'utilisateur/mot de passe avec les DCS AD, qui est externe à l'instance Cloud Volumes Service. L'authentification Kerberos est utilisée lors de l'utilisation de<block ref="cd2eba6db07c5178e47368d41d7c8ecb" prefix=" " category="inline-code"></block> Le chemin UNC est utilisé par les clients SMB et le suivant est vrai :</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">L'entrée DNS A/AAAA existe pour NOM_SERVEUR</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">Un code SPN valide pour l'accès SMB/CIFS existe pour NOM DE SERVEUR</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">« Comment Cloud Volumes Service s'affiche dans Active Directory. »</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Lorsqu'un volume SMB Cloud Volumes Service est créé, le nom du compte machine est créé comme défini dans la section <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Ce nom de compte machine devient également le chemin d'accès au partage SMB car Cloud Volumes Service utilise le DNS dynamique (DDNS) pour créer les entrées A/AAAA et PTR nécessaires dans le DNS et les entrées SPN nécessaires sur le principal du compte machine.</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">Pour que les entrées PTR soient créées, la zone de recherche inversée de l'adresse IP de l'instance Cloud Volumes Service doit exister sur le serveur DNS.</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">Par exemple, ce volume Cloud Volumes Service utilise le chemin de partage UNC suivant :<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>.</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">Dans Active Directory, il s'agit des entrées SPN générées par le service Cloud volumes :</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">Il s'agit du résultat de recherche DNS avant/arrière :</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">Par ailleurs, un contrôle d'accès plus important peut être appliqué en activant/exigeant un chiffrement SMB pour les partages SMB dans Cloud Volumes Service. Si le chiffrement SMB n'est pas pris en charge par l'un des noeuds finaux, l'accès n'est pas autorisé.</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">Utilisation des alias de nom SMB</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">Dans certains cas, les utilisateurs finaux ne pourront pas connaître le nom du compte de la machine utilisé pour Cloud Volumes Service et ce, sans problèmes de sécurité. Dans d'autres cas, vous souhaiterez peut-être fournir aux utilisateurs un chemin d'accès plus simple. Dans ces cas, vous pouvez créer des alias SMB.</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">Si vous souhaitez créer des alias pour le chemin du partage SMB, vous pouvez exploiter ce qu'on appelle un enregistrement CNAME dans DNS. Par exemple, si vous souhaitez utiliser le nom<block ref="87154d57e8c4e5c93755c1e158cd3257" prefix=" " category="inline-code"></block> pour accéder aux partages au lieu de<block ref="a1ee866c4518da1e9fbb52dd43e4e39d" prefix=" " category="inline-code"></block>, Mais vous souhaitez toujours utiliser l'authentification Kerberos, un CNAME dans DNS qui pointe vers l'enregistrement A/AAAA existant et un SPN supplémentaire ajouté au compte de machine existant fournit l'accès Kerberos.</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">Il s'agit du résultat de la recherche de transfert DNS après l'ajout d'un CNAME :</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">Il s'agit de la requête SPN qui s'affiche après l'ajout de nouveaux SPN :</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">Dans une capture de paquets, nous pouvons voir la demande de configuration de session en utilisant le SPN associé au CNAME.</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">Dialectes d'authentification SMB</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">dialectes</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service prend en charge les éléments suivants<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> Pour l'authentification SMB :</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">L'authentification Kerberos pour l'accès au partage SMB est le niveau d'authentification le plus sécurisé que vous pouvez utiliser. Avec le cryptage AES et SMB activé, le niveau de sécurité est encore amélioré.</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">Cloud Volumes Service prend également en charge la rétrocompatibilité pour l'authentification LM et NTLM. Lorsque Kerberos est mal configuré (par exemple lors de la création d'alias SMB), l'accès au partage revient à des méthodes d'authentification plus faibles (telles que NTLMv2). Comme ces mécanismes sont moins sécurisés, ils sont désactivés dans certains environnements Active Directory. Si les méthodes d'authentification les plus faibles sont désactivées et que Kerberos n'est pas configuré correctement, l'accès au partage échoue car il n'existe pas de méthode d'authentification valide pour revenir à.</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">Sécurité du réseau : niveau d'authentification de LAN Manager</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Pour plus d'informations sur la configuration/l'affichage des niveaux d'authentification pris en charge dans Active Directory, reportez-vous à la section<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>.</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">Modèles d'autorisation</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">Autorisations NTFS/File</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">Les autorisations NTFS sont les autorisations appliquées aux fichiers et dossiers dans les systèmes de fichiers qui adhèrent à la logique NTFS. Vous pouvez appliquer des autorisations NTFS dans<block ref="972e73b7a882d0802a4e3a16946a2f94" prefix=" " category="inline-code"></block> ou<block ref="9b6545e4cea9b4ad4979d41bb9170e2b" prefix=" " category="inline-code"></block> et peut être défini sur<block ref="45f0fb72a0defdfdb01de4b5a5a6876b" prefix=" " category="inline-code"></block> ou<block ref="3682d1665cf331373000c20680732d3a" prefix=" " category="inline-code"></block> pour le contrôle d'accès.</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">Les autorisations de base incluent les éléments suivants :</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">Contrôle total</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">Modifier</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">Lecture et exécution</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">Lecture</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">Écriture</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">Lorsque vous définissez les autorisations d'un utilisateur ou d'un groupe, appelées ACE, elles résident dans une liste de contrôle d'accès. Les autorisations NTFS utilisent les mêmes principes de base en lecture/écriture/exécution que les bits du mode UNIX, mais elles peuvent également s'étendre à des contrôles d'accès plus granulaires et étendus (également appelés autorisations spéciales), tels que prendre propriété, Créer des dossiers/ajouter des données, écrire des attributs, etc.</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">Les bits standard du mode UNIX ne fournissent pas le même niveau de granularité que les autorisations NTFS (par exemple, la possibilité de définir des autorisations pour des objets individuels utilisateur et groupe dans une ACL ou la définition d'attributs étendus). Cependant, les listes de contrôle d'accès NFSv4.1 offrent les mêmes fonctionnalités que les listes de contrôle d'accès NTFS.</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">Les autorisations NTFS sont plus spécifiques que les autorisations de partage et peuvent être utilisées conjointement avec les autorisations de partage. Avec les structures d'autorisation NTFS, la plus restrictive s'applique. Ainsi, les refus explicites d'un utilisateur ou d'un groupe remplacent même le contrôle total lors de la définition des droits d'accès.</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">Les autorisations NTFS sont contrôlées à partir de clients SMB Windows.</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">Partager les autorisations</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">Les autorisations de partage sont plus générales que les autorisations NTFS (lecture/modification/contrôle total uniquement) et contrôlez l'entrée initiale dans un partage SMB, à l'instar des règles de règles d'export NFS.</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">Bien que les règles d'export NFS contrôlent l'accès via des informations basées sur l'hôte telles que des adresses IP ou des noms d'hôte, les autorisations de partage SMB peuvent contrôler l'accès à l'aide d'ACE d'utilisateur et de groupe dans une liste de contrôle d'accès de partage. Vous pouvez définir des listes de contrôle d'accès de partage depuis le client Windows ou depuis l'interface utilisateur de gestion Cloud Volumes Service.</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">Par défaut, les listes de contrôle d'accès de partage et les listes de contrôle d'accès de volume initiales incluent tous les utilisateurs ayant un contrôle total. Les listes de contrôle d’accès du fichier doivent être modifiées, mais les autorisations de partage sont surdéfinies par les autorisations de fichier sur les objets du partage.</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">Par exemple, si un utilisateur n'est autorisé que l'accès en lecture à la liste de contrôle d'accès de fichier de volume Cloud Volumes Service, il est refusé d'accéder à la création de fichiers et de dossiers, même si la liste de contrôle d'accès du partage est définie sur tous les utilisateurs bénéficiant d'un contrôle total, comme indiqué dans la figure suivante.</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">Pour obtenir les meilleurs résultats en matière de sécurité, procédez comme suit :</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">Supprimez tout le monde des listes de contrôle d'accès de partage et de fichiers et définissez plutôt l'accès de partage pour les utilisateurs ou les groupes.</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">Pour faciliter la gestion des utilisateurs individuels, vous pouvez utiliser des groupes pour le contrôle d'accès, et pour accélérer la suppression et l'ajout d'utilisateurs pour partager ces listes via la gestion de groupes.</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">Autorisez un accès plus général et moins restrictif au partage aux ACE depuis les autorisations de partage et verrouillez l'accès aux utilisateurs et aux groupes avec des autorisations de fichier pour un contrôle d'accès plus granulaire.</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">Évitez l'utilisation générale des listes de contrôle d'accès de refus explicites, car elles remplacent les listes de contrôle d'accès d'autorisation. Limiter l'utilisation des listes de contrôle d'accès de refus explicites pour les utilisateurs ou les groupes qui doivent être restreints rapidement d'un accès à un système de fichiers.</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">Héritage ACL</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">Assurez-vous d'accorder votre attention au<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> paramètres lors de la modification des autorisations ; la définition de l'indicateur d'héritage au niveau supérieur d'un répertoire ou d'un volume avec un nombre élevé de fichiers signifie que chaque fichier sous ce répertoire ou volume possède des autorisations héritées ajoutées à celui-ci, ce qui peut créer un comportement indésirable tel qu'un accès/un refus involontaire et une longue perte de modification des autorisations au fur et à mesure que chaque fichier est ajusté.</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">Fonctionnalités de sécurité de partage SMB</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">Lorsque vous créez un volume avec accès SMB dans Cloud Volumes Service pour la première fois, vous disposez d'une série d'options pour sécuriser ce volume.</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">Les options suivantes dépendent du niveau Cloud Volumes Service (performances ou logiciels) et sont proposées :</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">*Rendre le répertoire snapshot visible (disponible pour CVS-Performance et CVS-SW).* cette option permet de contrôler si les clients SMB peuvent accéder au répertoire snapshot dans un partage SMB <block ref="f9f8c4c52f58b30f374525080a180c65" prefix="(" category="inline-code"></block> Et/ou l'onglet versions précédentes). Le paramètre par défaut n'est pas coché, ce qui signifie que le volume par défaut est masqué et interdit l'accès au<block ref="26bef40a7b3e14ad93e80f8f4be79090" prefix=" " category="inline-code"></block> Et aucune copie Snapshot n'apparaît dans l'onglet versions précédentes du volume.</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">Le masquage des copies Snapshot à partir des utilisateurs finaux peut être souhaité pour des raisons de sécurité, de performances (masquage de ces dossiers à partir d'analyses antivirus) ou de préférence. Les snapshots Cloud Volumes Service sont en lecture seule. Par conséquent, même si ces snapshots sont visibles, les utilisateurs finaux ne peuvent pas supprimer ou modifier les fichiers dans le répertoire Snapshot. Autorisations liées aux fichiers ou dossiers au moment de la copie Snapshot. Si les autorisations d'un fichier ou d'un dossier changent entre les copies Snapshot, les modifications s'appliquent également aux fichiers ou dossiers du répertoire Snapshot. Les utilisateurs et les groupes peuvent accéder à ces fichiers ou dossiers en fonction des autorisations. Lorsque des suppressions ou des modifications de fichiers dans le répertoire Snapshot ne sont pas possibles, il est possible de copier des fichiers ou des dossiers à partir du répertoire Snapshot.</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">*Activer le chiffrement SMB (disponible pour CVS-Performance et CVS-SW).* le chiffrement SMB est désactivé par défaut sur le partage SMB (non vérifié). La case active le chiffrement SMB, ce qui signifie que le trafic entre le client SMB et le serveur est crypté à la volée avec les niveaux de cryptage les plus élevés pris en charge négociés. Cloud Volumes Service prend en charge le chiffrement AES-256 pour SMB. L'activation du cryptage SMB a des retombées sur les performances de vos clients SMB, c'est-à-dire dans une plage de 10 à 20 %. NetApp encourage fortement les tests à vérifier si les performances sont acceptables.</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">*Masquer le partage SMB (disponible pour CVS-Performance et CVS-SW).* définir cette option masque le chemin du partage SMB à partir de la navigation normale. Cela signifie que les clients qui ne connaissent pas le chemin du partage ne peuvent pas voir les partages lorsqu'ils accèdent au chemin UNC par défaut (par exemple<block ref="eaf10dd9986e1d76c577b974d994e349" prefix=" " category="inline-code"></block>). Lorsque la case est cochée, seuls les clients qui connaissent explicitement le chemin du partage SMB ou qui ont le chemin du partage défini par un objet de stratégie de groupe peuvent y accéder (sécurité via obfuscation).</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">Comment fonctionne l'énumération basée sur l'accès (ABE) ?</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">*Activer l'énumération basée sur l'accès (ABE) (CVS-SW uniquement).* Ceci est similaire à masquer le partage SMB, sauf que les partages ou fichiers sont masqués uniquement des utilisateurs ou des groupes qui n'ont pas les autorisations d'accéder aux objets. Par exemple, si utilisateur Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> N'est pas autorisé au moins l'accès en lecture via les autorisations, puis l'utilisateur Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Impossible de voir le partage SMB ou les fichiers. Cette option est désactivée par défaut et vous pouvez l'activer en cochant la case. Pour en savoir plus sur ABE, consultez l'article de la base de connaissances NetApp<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">Partages SMB disponibles en permanence</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">*Activer le support de partage disponible en continu (CA) (CVS-Performance uniquement).*<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Offrir un moyen de réduire les interruptions des applications lors des basculements en répliquant les États de verrouillage sur les nœuds du système back-end Cloud Volumes Service. Il ne s'agit pas d'une fonctionnalité de sécurité, mais elle offre une meilleure résilience globale. Actuellement, seules les applications SQL Server et FSLogix sont prises en charge pour cette fonctionnalité.</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">Partages masqués par défaut</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">partages administratifs masqués</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">Lorsqu'un serveur SMB est créé dans Cloud Volumes Service, il y a<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> (Avec la convention de nommage $) créées en plus du partage SMB du volume de données. Il s'agit notamment de C$ (accès à l'espace de noms) et IPC$ (partage de canaux nommés pour la communication entre les programmes, tels que les appels de procédure distante (RPC) utilisés pour l'accès à la console MMC (Microsoft Management Console)).</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Windows interdit l'accès anonyme à ces partages par défaut</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">Le partage IPC$ ne contient pas de listes de contrôle d’accès partagées et ne peut pas être modifié – il est strictement utilisé pour les appels RPC et<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>.</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">Le partage C$ permet l'accès par défaut à BUILTIN/Administrators, mais l'automatisation Cloud Volumes Service supprime la liste de contrôle d'accès de partage et n'autorise l'accès à personne car l'accès au partage C$ permet la visibilité de tous les volumes montés dans les systèmes de fichiers Cloud Volumes Service. Par conséquent, tente de naviguer vers<block ref="33f61bb25149c01e06f9ef66d462e5a2" prefix=" " category="inline-code"></block> echec.</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">Comptes avec droits d'administrateur/de sauvegarde local/BUILTIN</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Les serveurs Cloud Volumes Service SMB conservent des fonctionnalités similaires aux serveurs Windows SMB classiques, dans la mesure où des groupes locaux (tels que BUILTIN\Administrators) appliquent des droits d'accès à certains utilisateurs et groupes de domaine.</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege et SeRestorePrivilege</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">Lorsque vous spécifiez un utilisateur à ajouter aux utilisateurs de sauvegarde, l'utilisateur est ajouté au groupe BULILTIN\opérateurs de sauvegarde de l'instance Cloud Volumes Service qui utilise cette connexion Active Directory, qui obtient ensuite le<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>.</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SQL Server sur des partages SMB</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">Lorsque vous ajoutez un utilisateur à des utilisateurs de privilèges de sécurité, l'utilisateur reçoit le privilège de sécurité, ce qui est utile dans certains cas d'utilisation d'application, tels que<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>.</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">Vous pouvez afficher les membres du groupe local Cloud Volumes Service par l'intermédiaire de la console MMC avec les privilèges appropriés. La figure suivante montre les utilisateurs qui ont été ajoutés à l'aide de la console Cloud Volumes Service.</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">Le tableau suivant présente la liste des groupes par défaut BUILTIN et les utilisateurs/groupes ajoutés par défaut.</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">Groupe local/BUILTIN</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">Membres par défaut</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">INTÉGRÉ\administrateurs*</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">Administrateurs DE DOMAINE</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">INTÉGRÉ\opérateurs de sauvegarde*</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">INTÉGRÉ\clients</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">Invités DOMAINE/domaine</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">UTILISATEURS INTENSIFS ET INTÉGRÉS</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">Utilisateurs DE DOMAINE/INTÉGRÉ</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">Utilisateurs DU DOMAINE</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">*Appartenance au groupe contrôlée dans la configuration de connexion Cloud Volumes Service Active Directory.</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">Vous pouvez afficher des utilisateurs et des groupes locaux (et des membres de groupe) dans la fenêtre MMC, mais vous ne pouvez pas ajouter ou supprimer des objets ou modifier les appartenances de groupe à partir de cette console. Par défaut, seul le groupe administrateurs de domaine et l'administrateur sont ajoutés au groupe BULILTIN\Administrators dans Cloud Volumes Service. Actuellement, vous ne pouvez pas le modifier.</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">Accès MMC/gestion de l'ordinateur</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">L'accès SMB dans Cloud Volumes Service fournit une connexion à la console MMC Computer Management, qui vous permet d'afficher les partages, de gérer les listes de contrôle d'accès de partage, d'afficher/gérer les sessions SMB et les fichiers ouverts.</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">Pour utiliser la console MMC pour afficher les partages et sessions SMB dans Cloud Volumes Service, l'utilisateur connecté doit actuellement être un administrateur de domaine. Les autres utilisateurs sont autorisés à accéder à l'affichage ou à la gestion du serveur SMB à partir de MMC et reçoivent une boîte de dialogue vous n'avez pas d'autorisations lors de la tentative d'affichage de partages ou de sessions sur l'instance SMB de Cloud Volumes Service.</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">Pour vous connecter au serveur SMB, ouvrez gestion de l'ordinateur, cliquez avec le bouton droit de la souris sur gestion de l'ordinateur, puis sélectionnez connexion à un autre ordinateur. La boîte de dialogue Sélectionner un ordinateur s'ouvre, dans laquelle vous pouvez saisir le nom du serveur SMB (dans les informations sur le volume Cloud Volumes Service).</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">Lorsque vous affichez des partages SMB avec les autorisations appropriées, tous les partages disponibles de l'instance Cloud Volumes Service partageant la connexion Active Directory s'affichent. Pour contrôler ce comportement, définissez l'option Masquer les partages SMB sur l'instance de volume Cloud Volumes Service.</block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">N'oubliez pas qu'une seule connexion Active Directory est autorisée par région.</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">Le tableau suivant présente la liste des fonctionnalités prises en charge/non prises en charge pour la console MMC.</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">Fonctions prises en charge</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">Fonctions non prises en charge</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">Afficher les partages</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">Afficher les sessions SMB actives</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">Afficher les fichiers ouverts</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">Affichez les utilisateurs et groupes locaux</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">Afficher les membres du groupe local</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">Énumérer la liste des sessions, des fichiers et des connexions d'arborescence dans le système</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">Fermez les fichiers ouverts dans le système</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">Fermer les sessions ouvertes</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">Création/gestion de partages</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">Création de nouveaux utilisateurs/groupes locaux</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">Gestion/affichage des utilisateurs/groupes locaux existants</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">Affichez les journaux d'événements ou de performances</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">La gestion du stockage</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">Gestion des services et des applications</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">Informations sur la sécurité du serveur SMB</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Le serveur SMB de Cloud Volumes Service utilise un ensemble d'options qui définissent les stratégies de sécurité des connexions SMB, notamment l'inclinaison de l'horloge Kerberos, l'ancienneté des tickets, le cryptage, etc.</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">Le tableau suivant contient la liste de ces options, leur rôle et les configurations par défaut, si elles peuvent être modifiées avec Cloud Volumes Service. Certaines options ne s'appliquent pas à Cloud Volumes Service.</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">Option de sécurité</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">Ce qu'il fait</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">Valeur par défaut</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">Est-il possible de modifier ?</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">Hauteur maximale de l'horloge Kerberos (minutes)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Décalage de temps maximal entre les contrôleurs Cloud Volumes Service et de domaine. Si l'écart de temps dépasse 5 minutes, l'authentification Kerberos échoue. Cette valeur est définie sur la valeur par défaut d'Active Directory.</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Durée de vie d'un ticket Kerberos (en heures)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">Durée maximale pendant laquelle un ticket Kerberos reste valide avant d'exiger un renouvellement. Si aucun renouvellement n'a lieu avant les 10 heures, vous devez obtenir un nouveau billet. Cloud Volumes Service effectue automatiquement ces renouvellements. 10 heures est la valeur par défaut d'Active Directory.</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">Renouvellement maximal de ticket Kerberos (jours)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">Nombre maximum de jours pendant lesquels un ticket Kerberos peut être renouvelé avant qu'une nouvelle demande d'autorisation ne soit nécessaire. Cloud Volumes Service renouvelle automatiquement les billets pour les connexions des PME. Sept jours est la valeur par défaut d'Active Directory.</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Expiration du délai de connexion KDC Kerberos (secondes)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">Nombre de secondes avant qu'une connexion KDC ne se soit interrompue.</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">Signature requise pour le trafic SMB entrant</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">Paramètre pour exiger la signature pour le trafic SMB. Si la valeur est true, les clients qui ne prennent pas en charge la connexion échouent.</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">Exiger la complexité du mot de passe pour les comptes d'utilisateur locaux</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">Utilisé pour les mots de passe des utilisateurs SMB locaux. Cloud Volumes Service ne prend pas en charge la création d'utilisateur local, donc cette option ne s'applique pas à Cloud Volumes Service.</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">Vrai</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Utilisez START_tls pour les connexions LDAP Active Directory</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Utilisé pour activer les connexions TLS de démarrage pour Active Directory LDAP. Cloud Volumes Service ne prend pas encore en charge la mise en œuvre de cette fonctionnalité.</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">Est compatible avec le chiffrement AES-128 et AES-256 pour Kerberos</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">Cette option permet de contrôler si le chiffrement AES est utilisé pour les connexions Active Directory et est contrôlé à l'aide de l'option Activer le chiffrement AES pour l'authentification Active Directory lors de la création/modification de la connexion Active Directory.</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">Niveau de compatibilité LM</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Niveau de dialectes d'authentification pris en charge pour les connexions Active Directory. Voir la section «<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>” pour plus d'informations.</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">ntlmv2-krb</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">Cryptage SMB requis pour le trafic CIFS entrant</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">Chiffrement SMB requis pour tous les partages. Cette fonction n'est pas utilisée par Cloud Volumes Service ; définissez plutôt le chiffrement par volume (voir la section «<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>”).</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">Sécurité de la session client</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">“Liaison de canal LDAP.”</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">Définit la signature et/ou le chiffrement pour la communication LDAP. Ce paramètre n'est pas actuellement défini dans Cloud Volumes Service mais peut être nécessaire dans les prochaines versions pour traiter . La résolution des problèmes d'authentification LDAP dus au correctif Windows est traitée dans la section <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>.</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">SMB2 activé pour les connexions CC</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">Utilise SMB2 pour les connexions CC. Activé par défaut.</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">Système par défaut</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">Poursuite des recommandations LDAP</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">Lors de l'utilisation de plusieurs serveurs LDAP, la recherche de références permet au client de se référer à d'autres serveurs LDAP de la liste lorsqu'une entrée est introuvable dans le premier serveur. Cette opération n'est actuellement pas prise en charge par Cloud Volumes Service.</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">Utilisez LDAPS pour les connexions Active Directory sécurisées</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">Permet l'utilisation de LDAP sur SSL. Actuellement non pris en charge par Cloud Volumes Service.</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">Le cryptage est requis pour la connexion CC</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">Nécessite un chiffrement pour des connexions CC réussies. Désactivé par défaut dans Cloud Volumes Service.</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">Ensuite : double protocole/multiprotocole.</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Avec Cloud Volumes Service dans Google Cloud, vous pouvez sécuriser vos données de manière native,</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Comment sécuriser vos données avec Cloud Volumes Service dans Google Cloud</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">Architecture et modèle de colocation sécurisés</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">« Architecture Cloud Volumes Service »</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">accès aux services privés</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service procure une architecture sécurisée dans Google Cloud en segmentant la gestion des services (plan de contrôle) et l'accès aux données (plan de contrôle) entre différents terminaux de sorte qu'ils ne puissent en aucun cas affecter l'autre (voir la section) <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>). Il utilise Google<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA) pour fournir le service. Cette structure distingue le producteur de services fourni et exploité par NetApp, et le consommateur de services, qui est un cloud privé virtuel (VPC) dans un projet client, en hébergeant les clients souhaitant accéder aux partages de fichiers Cloud Volumes Service.</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">« Modèle de colocation »</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">“VPC partagés”</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">Dans cette architecture, les locataires (voir la section <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>) Sont définis comme des projets Google Cloud complètement isolés les uns des autres, sauf s'ils sont explicitement connectés par l'utilisateur. Les locataires autorisent une isolation complète des volumes de données, des services de noms externes et des autres éléments essentiels de la solution par rapport à d'autres locataires via la plateforme de volumes Cloud Volumes Service. Comme la plateforme Cloud Volumes Service est connectée via le peering VPC, cette isolation s'applique également à celle-ci. Vous pouvez activer le partage de volumes Cloud Volumes Service entre plusieurs projets à l'aide d'un VPC partagé (voir la section) <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>). Vous pouvez appliquer des contrôles d'accès aux partages SMB et aux exportations NFS pour limiter les personnes ou les données qui peuvent afficher ou modifier les jeux de données.</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">Forte gestion des identités pour le plan de contrôle</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">Gestion des accès aux identités</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">Dans le plan de contrôle où se déroule la configuration Cloud Volumes Service, la gestion des identités est gérée à l'aide de<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>. IAM est un service standard qui vous permet de contrôler l'authentification (connexions) et l'autorisation (autorisations) des instances de projet Google Cloud. Toutes les configurations sont effectuées avec des API Cloud Volumes Service sur un transport HTTPS sécurisé via le cryptage TLS 1.2, et l'authentification est effectuée à l'aide de jetons JWT pour une sécurité accrue. L'interface utilisateur de la console Google pour Cloud Volumes Service convertit les entrées utilisateur en appels de l'API Cloud Volumes Service.</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">Renforcement de la sécurité - limitation des surfaces d'attaque</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">Une partie de la sécurité efficace limite le nombre de surfaces d'attaque disponibles dans un service. Les surfaces d'attaque peuvent inclure divers éléments, notamment les données au repos, les transferts à la volée, les connexions et les jeux de données eux-mêmes.</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">“Fonctionnement de l'entretien”,</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">Un service géré supprime certaines des surfaces d'attaque par nature dans sa conception. Gestion de l'infrastructure, comme décrit dans la section <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> est gérée par une équipe dédiée et automatisée afin de réduire le nombre d'interventions humaines liées aux configurations, ce qui permet de réduire le nombre d'erreurs intentionnelles et non intentionnelles. La mise en réseau est clôturée de sorte que seuls les services nécessaires peuvent accéder les uns aux autres. Le chiffrement est intégré au stockage des données et seul le plan de données nécessite une attention particulière de la part des administrateurs Cloud Volumes Service. En masquant la majeure partie de la gestion derrière une interface API, la sécurité est obtenue en limitant les surfaces d'attaque.</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">Modèle « zéro confiance »</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">Historiquement, la philosophie de sécurité INFORMATIQUE a été de faire confiance mais de vérifier, et se manifeste comme s'appuyant uniquement sur des mécanismes externes (tels que des pare-feu et des systèmes de détection d'intrusion) pour atténuer les menaces. Cependant, les attaques et les violations ont évolué pour contourner la vérification dans les environnements par le biais du phishing, de l'ingénierie sociale, des menaces internes et d'autres méthodes qui permettent de vérifier l'entrée en réseau et de causer des ravages.</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">La confiance zéro est devenue une nouvelle méthodologie de sécurité, avec le mantra actuel comme « n'avoir confiance en rien tout en vérifiant tout ». Par conséquent, aucun accès n'est autorisé par défaut. Ce mantra est appliqué de diverses façons, notamment les pare-feu standard et les systèmes de détection des intrusions (IDS), ainsi que les méthodes suivantes :</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">Méthodes d'authentification fortes (telles que les jetons Kerberos ou JWT chiffrés AES)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">Sources d'identités solides uniques (telles que Windows Active Directory, LDAP (Lightweight Directory Access Protocol) et Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">Segmentation réseau et colocation sécurisée (seuls les locataires sont autorisés à accéder par défaut)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">Contrôles d'accès granulaires avec les règles d'accès les moins privilégiées</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">Petites listes exclusives d'administrateurs dédiés et fiables avec audit numérique et pistes papier</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">L'exécution de Cloud Volumes Service dans Google Cloud adhère au modèle « zéro confiance » en mettant en œuvre la politique « confiance en rien et vérification de tout ».</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">Le cryptage</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">« Chiffrement des données au repos »</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">“Chiffrement SMB”</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">« Réplication inter-région »</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">“Chiffrement des données en transit”</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">« Réseau Google Cloud »</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">Chiffrement des données au repos (voir la section <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) En utilisant le chiffrement XTS-AES-256 avec NetApp Volume Encryption (NVE) et en transit avec <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> Ou NFS Kerberos 5p pris en charge. REST aisément accessible en sachant que les transferts de réplication entre régions sont protégés par le chiffrement TLS 1.2 (voir la section <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>). En outre, Google Networking fournit également des communications cryptées (voir la section <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>) pour une couche supplémentaire de protection contre les attaques. Pour plus d'informations sur le chiffrement de transport, reportez-vous à la section <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>.</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">Protection des données et sauvegardes</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="inline-link-macro">Sauvegarde Cloud Volumes Service</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">La sécurité ne se limite pas à la prévention des attaques. Il s'agit également de la manière dont nous parvenons à nous remettre des attaques si elles se produisent ou quand elles se produisent. Cette stratégie inclut la protection des données et les sauvegardes. Cloud Volumes Service propose des méthodes de réplication vers d'autres régions en cas de panne (voir la section) <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>) ou si un dataset est affecté par une attaque par ransomware. Il peut également effectuer des sauvegardes asynchrones de données vers des emplacements situés en dehors de l'instance Cloud Volumes Service à l'aide de <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>. Grâce aux sauvegardes régulières, la réduction des événements de sécurité peut prendre moins de temps et faire des économies et des problèmes d'administration.</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">Atténuation rapide des ransomwares grâce aux copies Snapshot leaders du secteur</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">« Copies Snapshot immuables »</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">“Fonctionnement de l'entretien”</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Outre la protection des données et les sauvegardes, Cloud Volumes Service prend en charge les copies Snapshot immuables (voir la section <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>) de volumes qui permettent la restauration suite à des attaques par ransomware (voir la section <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>) en quelques secondes après la découverte du problème et avec une interruption minimale. Le temps et les effets de la restauration dépendent du calendrier Snapshot. Toutefois, vous pouvez créer des copies Snapshot qui permettent de définir des données modifiées d'une heure ou moins dans le cadre d'attaques par ransomware. Les copies Snapshot ont un impact négligeable sur les performances et l'utilisation de la capacité. Elles constituent une approche à faible risque et à haut rendement pour la protection de vos datasets.</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">Suivant : considérations de sécurité et surfaces d'attaque.</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">Lorsque vous utilisez Cloud Volumes Service pour les partages NAS, certaines dépendances externes peuvent être requises pour assurer le bon fonctionnement des partages. Ces dépendances sont en jeu dans des circonstances spécifiques.</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">Autres dépendances des services d'infrastructure NAS (KDC, LDAP et DNS)</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">Précédent : considérations relatives à la création de connexions Active Directory.</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">Lorsque vous utilisez Cloud Volumes Service pour les partages NAS, certaines dépendances externes peuvent être requises pour assurer le bon fonctionnement des partages. Ces dépendances sont en jeu dans des circonstances spécifiques. Le tableau suivant présente différentes options de configuration et le cas échéant, quelles dépendances sont nécessaires.</block>
  <block id="254f642527b45bc260048e30704edb39" category="cell">Configuration</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">Dépendances requises</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">NFSv3 uniquement</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">Kerberos NFSv3 uniquement</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Windows Active Directory : * KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">NFSv4.1 uniquement</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">Configuration du mappage d'ID client (/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">NFSv4.1 Kerberos uniquement</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Windows Active Directory : LDAP KDC DNS</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">PME uniquement</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory : * KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">NAS multiprotocole (NFS et SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">Configuration du mappage des ID client (NFSv4.1 uniquement ; /etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">La rotation/mot de passe de l'onglet clé Kerberos est réinitialisée pour les objets du compte machine</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">Avec les comptes machine SMB, Cloud Volumes Service planifie régulièrement les réinitialisations de mots de passe pour le compte machine SMB. Ces réinitialisations de mot de passe se produisent à l'aide du chiffrement Kerberos et fonctionnent sur une programmation de tous les 4 dimanches à une heure aléatoire comprise entre 23 H et 1 H. Ces réinitialisations de mot de passe modifient les versions de clé Kerberos, font pivoter les onglets enregistrés sur le système Cloud Volumes Service et permettent de maintenir un niveau de sécurité supérieur pour les serveurs SMB exécutés dans Cloud Volumes Service. Les mots de passe du compte machine sont randomisés et ne sont pas connus des administrateurs.</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">Pour les comptes de machine Kerberos NFS, les réinitialisations de mot de passe n'ont lieu que lorsqu'un nouveau keytab est créé/échangé avec le KDC. Actuellement, il n'est pas possible de le faire dans Cloud Volumes Service.</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">Ports réseau à utiliser avec LDAP et Kerberos</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">Documentation Cloud Volumes Service sur les considérations de sécurité</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">Lorsque vous utilisez LDAP et Kerberos, vous devez déterminer les ports réseau utilisés par ces services. La liste complète des ports utilisés par Cloud Volumes Service se trouve dans le<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>.</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service agit comme un client LDAP et utilise des requêtes de recherche LDAP standard pour les recherches utilisateur et de groupe pour les identités UNIX. LDAP est nécessaire si vous avez l'intention d'utiliser des utilisateurs et des groupes en dehors des utilisateurs standard par défaut fournis par Cloud Volumes Service. LDAP est également nécessaire si vous prévoyez d'utiliser NFS Kerberos avec des principes utilisateur (tels que user1@domain.com). Actuellement, seul LDAP utilisant Microsoft Active Directory est pris en charge.</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Pour utiliser Active Directory en tant que serveur LDAP UNIX, vous devez renseigner les attributs UNIX nécessaires pour les utilisateurs et groupes que vous souhaitez utiliser pour les identités UNIX. Cloud Volumes Service utilise un modèle de schéma LDAP par défaut qui interroge les attributs sur la base<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>. Par conséquent, le tableau suivant montre les attributs Active Directory minimum requis pour remplir pour les utilisateurs et les groupes et pour quels attributs sont utilisés.</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">Gestion de l'accès double protocole.</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Pour plus d'informations sur la définition des attributs LDAP dans Active Directory, reportez-vous à la section<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">Attribut</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">uid*</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">Spécifie le nom d'utilisateur UNIX</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">Numéro uidNumber*</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">Spécifie l'ID numérique de l'utilisateur UNIX</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">Numéro gidNumber*</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">Spécifie l'ID numérique du groupe principal de l'utilisateur UNIX</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">Objectclass*</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">Spécifie le type d'objet utilisé ; Cloud Volumes Service nécessite que "user" soit inclus dans la liste des classes d'objets (inclus dans la plupart des déploiements Active Directory par défaut).</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">Informations générales sur le compte (nom réel, numéro de téléphone, etc., également connu sous le nom de gecos)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">Mot de passe unixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">Inutile de le définir ; non utilisé dans les recherches d'identité UNIX pour l'authentification NAS. Cette option place la valeur unixUserPassword configurée dans le texte en texte clair.</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">UnixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">Définit le chemin d'accès aux répertoires locaux UNIX lorsqu'un utilisateur s'authentifie auprès de LDAP à partir d'un client Linux. Définissez cette option si vous souhaitez utiliser la fonctionnalité de répertoire local LDAP pour UNIX.</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">LoginShell</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">Définit le chemin d'accès au shell bash/de profil pour les clients Linux lorsqu'un utilisateur s'authentifie auprès de LDAP.</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">*L'attribut Denotes est requis pour une fonctionnalité correcte avec Cloud Volumes Service. Les autres attributs sont uniquement destinés à un usage côté client.</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">cn*</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">Spécifie le nom du groupe UNIX. Lors de l'utilisation d'Active Directory pour LDAP, ce paramètre est défini lors de la création de l'objet, mais il peut être modifié ultérieurement. Ce nom ne peut pas être identique à celui des autres objets. Par exemple, si votre utilisateur UNIX nommé user1 appartient à un groupe nommé user1 sur votre client Linux, Windows n'autorise pas deux objets avec le même attribut cn. Pour contourner ce problème, renommez l'utilisateur Windows en un nom unique (tel que user1-UNIX) ; LDAP dans Cloud Volumes Service utilise l'attribut uid pour les noms d'utilisateur UNIX.</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">Spécifie l'ID numérique du groupe UNIX.</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">Indique le type d'objet utilisé ; Cloud Volumes Service nécessite que le groupe soit inclus dans la liste des classes d'objets (cet attribut est inclus par défaut dans la plupart des déploiements Active Directory).</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">MemberUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">Indique quels utilisateurs UNIX sont membres du groupe UNIX. Avec Active Directory LDAP dans Cloud Volumes Service, ce champ n'est pas nécessaire. Le schéma LDAP Cloud Volumes Service utilise le champ membre pour les appartenances de groupe.</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">Membre*</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">Requis pour les membres de groupe/groupes UNIX secondaires. Ce champ est rempli en ajoutant des utilisateurs Windows aux groupes Windows. Cependant, si les attributs UNIX des groupes Windows ne sont pas renseignés, ils ne sont pas inclus dans les listes d'appartenance aux groupes de l'utilisateur UNIX. Tous les groupes devant être disponibles dans NFS doivent remplir les attributs de groupe UNIX requis répertoriés dans ce tableau.</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">Informations de liaison LDAP</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">Pour interroger les utilisateurs dans LDAP, Cloud Volumes Service doit se lier (connexion) au service LDAP. Cette connexion possède des autorisations en lecture seule et est utilisée pour interroger les attributs LDAP UNIX pour les recherches de répertoire. Actuellement, les liaisons LDAP ne sont possibles qu'à l'aide d'un compte de machine SMB.</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">Vous pouvez uniquement activer LDAP pour<block ref="439d7969e09b4b31626fcf209b8fdcb7" prefix=" " category="inline-code"></block> Instances et s'utilisent pour les volumes NFS v3, NFS v4.1 ou double protocole. Une connexion Active Directory doit être établie dans la même région que le volume Cloud Volumes Service pour le déploiement réussi du volume LDAP.</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">Lorsque LDAP est activée, les opérations suivantes se produisent dans des scénarios spécifiques.</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Si seul NFSv3 ou NFSv4.1 est utilisé pour le projet Cloud Volumes Service, un nouveau compte machine est créé dans le contrôleur de domaine Active Directory et le client LDAP dans Cloud Volumes Service se lie à Active Directory à l'aide des informations d'identification du compte machine. Aucun partage SMB n'est créé pour le volume NFS et les partages administratifs masqués par défaut (voir la section <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>) Ont supprimé les ACL de partage.</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Si des volumes à double protocole sont utilisés pour le projet Cloud Volumes Service, seul le compte de machine unique créé pour l'accès SMB est utilisé pour lier le client LDAP de Cloud Volumes Service à Active Directory. Aucun compte machine supplémentaire n'est créé.</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">Si des volumes SMB dédiés sont créés séparément (avant ou après l'activation des volumes NFS avec LDAP), le compte machine pour les liaisons LDAP est partagé avec le compte de machine SMB.</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">Si NFS Kerberos est également activé, deux comptes machine sont créés : un pour les partages SMB et/ou des liaisons LDAP et un pour l'authentification Kerberos NFS.</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">Bien que les liaisons LDAP soient cryptées, les requêtes LDAP sont transmises sur le réseau en texte clair à l'aide du port LDAP commun 389. Ce port connu ne peut actuellement pas être modifié dans Cloud Volumes Service. Par conséquent, une personne ayant accès au sniffing de paquets dans le réseau peut voir les noms d'utilisateur et de groupe, les ID numériques et les appartenances de groupe.</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">“Considérations sur la capture et la détection des paquets.”</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">Cependant, les machines virtuelles Google Cloud ne peuvent pas sniff le trafic unicast d'autres machines virtuelles. Seules les machines virtuelles participant activement au trafic LDAP (c'est-à-dire en mesure de lier) peuvent voir le trafic à partir du serveur LDAP. Pour plus d'informations sur le sniffing de paquets dans Cloud Volumes Service, reportez-vous à la section <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">Paramètres par défaut de configuration du client LDAP</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Lorsque LDAP est activée dans une instance Cloud Volumes Service, une configuration client LDAP est créée par défaut avec des détails de configuration spécifiques. Dans certains cas, les options ne s'appliquent pas à Cloud Volumes Service (non prises en charge) ou ne peuvent pas être configurées.</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">Option client LDAP</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">Liste des serveurs LDAP</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">Définit les noms de serveur LDAP ou les adresses IP à utiliser pour les requêtes. Ceci n'est pas utilisé pour Cloud Volumes Service. À la place, Active Directory Domain est utilisé pour définir les serveurs LDAP.</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">Non défini</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Domaine Active Directory</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">Définit le domaine Active Directory à utiliser pour les requêtes LDAP. Cloud Volumes Service utilise les enregistrements SRV pour LDAP dans DNS pour trouver des serveurs LDAP dans le domaine.</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Définissez le domaine Active Directory spécifié dans la connexion Active Directory.</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">Serveurs Active Directory préférés</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">Définit les serveurs Active Directory préférés à utiliser pour LDAP. Non pris en charge par Cloud Volumes Service. Utilisez plutôt les sites Active Directory pour contrôler la sélection du serveur LDAP.</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">Non défini.</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">Lier à l'aide des informations d'identification du serveur SMB</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">Se lie à LDAP à l'aide du compte de machine SMB. Actuellement, la seule méthode de liaison LDAP prise en charge dans Cloud Volumes Service.</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">Modèle de schéma</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">Modèle de schéma utilisé pour les requêtes LDAP.</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">Port du serveur LDAP</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">Numéro de port utilisé pour les requêtes LDAP. Cloud Volumes Service utilise actuellement uniquement le port LDAP standard 389. Le port LDAPS/636 n'est pas pris en charge actuellement.</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">LDAPS est activé</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">Contrôle si LDAP sur SSL (Secure Sockets Layer) est utilisé pour les requêtes et les liaisons. Actuellement non pris en charge par Cloud Volumes Service.</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">Délai d'expiration de la requête (secondes)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">Délai d'attente pour les requêtes. Si les requêtes prennent plus de temps que la valeur spécifiée, les requêtes échouent.</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">Niveau d'authentification de liaison minimum</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">Niveau de liaison minimum pris en charge. Étant donné que Cloud Volumes Service utilise des comptes machine pour les liaisons LDAP et qu'Active Directory ne prend pas en charge les liaisons anonymes par défaut, cette option n'est pas en jeu pour la sécurité.</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">Anonyme</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">Lier DN</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">Nom d'utilisateur/nom distinctif (DN) utilisé pour les liaisons lorsque la liaison simple est utilisée. Cloud Volumes Service utilise des comptes machine pour les liaisons LDAP et ne prend actuellement pas en charge l'authentification BIND simple.</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">DN de base</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">Le DN de base utilisé pour les recherches LDAP.</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">Le domaine Windows utilisé pour la connexion Active Directory, au format DN (c.c.=domaine, c.c.=local).</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">Étendue de la recherche de base</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">Domaine de recherche pour les recherches de DN de base. Les valeurs peuvent inclure la base, l'élévation ou la sous-arborescence. Cloud Volumes Service prend uniquement en charge les recherches dans les sous-arborescences.</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">Sous-arbre</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">Nom unique de l'utilisateur</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">Définit le DN où l'utilisateur recherche les requêtes LDAP. Actuellement non pris en charge pour Cloud Volumes Service, toutes les recherches d'utilisateur commencent par le NA de base.</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">Étendue de la recherche utilisateur</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">Domaine de recherche pour les recherches de DN utilisateur. Les valeurs peuvent inclure la base, l'élévation ou la sous-arborescence. Cloud Volumes Service ne prend pas en charge la définition de l'étendue de la recherche utilisateur.</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">DN du groupe</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">Définit le DN où le groupe recherche les requêtes LDAP. Actuellement non pris en charge pour Cloud Volumes Service, toutes les recherches de groupe commencent par le NA de base.</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">Étendue de la recherche de groupe</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">Domaine de recherche pour les recherches de DN de groupe. Les valeurs peuvent inclure la base, l'élévation ou la sous-arborescence. Cloud Volumes Service ne prend pas en charge la définition de l'étendue de la recherche de groupe.</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">DN du groupe réseau</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">Définit le DN où le groupe réseau recherche les requêtes LDAP. Actuellement non pris en charge pour Cloud Volumes Service, toutes les recherches de groupe réseau commencent par le DN de base.</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">Domaine de recherche de groupe réseau</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">Domaine de recherche pour les recherches de DN de groupe réseau. Les valeurs peuvent inclure la base, l'élévation ou la sous-arborescence. Cloud Volumes Service ne prend pas en charge la définition de l'étendue de recherche du groupe réseau.</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">Utilisez START_tls sur LDAP</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">Utilise Start TLS pour les connexions LDAP basées sur des certificats via le port 389. Actuellement non pris en charge par Cloud Volumes Service.</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">Activez la recherche netgroup-by-host</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">Active les recherches de groupe réseau par nom d'hôte plutôt que d'étendre les groupes réseau pour répertorier tous les membres. Actuellement non pris en charge par Cloud Volumes Service.</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">DN netgroup-by-host</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">Définit le DN où les recherches de netgroup-par-hôte commencent pour les requêtes LDAP. Netgroup-by-host n'est actuellement pas pris en charge pour Cloud Volumes Service.</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">Étendue de recherche netgroup-by-host</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">Étendue de recherche pour les recherches de DN netgroup-par-hôte. Les valeurs peuvent inclure la base, l'élévation ou la sous-arborescence. Netgroup-by-host n'est actuellement pas pris en charge pour Cloud Volumes Service.</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">Sécurité de session client</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">Définit le niveau de sécurité de session utilisé par LDAP (signe, sceau ou aucun). La signature LDAP est prise en charge par CVS-Performance, sur demande d'Active Directory. CVS-SW ne prend pas en charge la signature LDAP. Pour les deux types d'entretien, le scellage n'est actuellement pas pris en charge.</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">Renvoi LDAP à la recherche</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">Filtre d'appartenance au groupe</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">Fournit un filtre de recherche LDAP personnalisé à utiliser lors de la recherche d'appartenance à un groupe à partir d'un serveur LDAP. Non pris en charge actuellement avec Cloud Volumes Service.</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">Utilisation de LDAP pour le mappage de noms asymétrique</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">Par défaut, Cloud Volumes Service mappe les utilisateurs Windows et les utilisateurs UNIX avec des noms d'utilisateur identiques, dans le même sens, sans configuration spéciale. Tant que Cloud Volumes Service peut trouver un utilisateur UNIX valide (avec LDAP), un mappage de nom 1:1 se produit. Par exemple, si utilisateur Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Est utilisé, alors, si Cloud Volumes Service peut trouver un utilisateur UNIX nommé<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Dans LDAP, le mappage de noms réussit pour cet utilisateur, tous les fichiers/dossiers créés par<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Affiche la propriété correcte de l'utilisateur et toutes les listes de contrôle d'accès qui affectent<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Sont honorés quel que soit le protocole NAS utilisé. Il s'agit d'un mappage de nom symétrique.</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">Le mappage de nom asymétrique est utilisé lorsque l'identité utilisateur Windows et l'identité utilisateur UNIX ne correspondent pas. Par exemple, si utilisateur Windows<block ref="cd4388c0c62e65ac8b99e3ec49fd9409" prefix=" " category="inline-code"></block> Possède une identité UNIX de<block ref="39ce7e2a8573b41ce73b5ba41617f8f7" prefix=" " category="inline-code"></block>, Cloud Volumes Service a besoin d'une façon d'être racontée sur la variation. Cloud Volumes Service ne prenant actuellement pas en charge la création de règles de mappage de noms statiques, LDAP doit être utilisé pour rechercher l'identité des utilisateurs pour les identités Windows et UNIX afin d'assurer la propriété correcte des fichiers et dossiers et des autorisations attendues.</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">Par défaut, Cloud Volumes Service inclut<block ref="2363dee608bcd9f6ce7f980bfdad5789" prefix=" " category="inline-code"></block> Dans le commutateur ns-switch de l'instance de la base de données de mappage de noms, afin de fournir une fonctionnalité de mappage de noms en utilisant LDAP pour les noms asymétriques, il vous suffit de modifier certains attributs utilisateur/groupe pour refléter ce que recherche Cloud Volumes Service.</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">Le tableau suivant indique quels attributs doivent être renseignés dans LDAP pour la fonctionnalité de mappage de noms asymétriques. Dans la plupart des cas, Active Directory est déjà configuré pour le faire.</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Attribut Cloud Volumes Service</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Valeur utilisée par Cloud Volumes Service pour le mappage de noms</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">ObjectClass de Windows à UNIX</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">Spécifie le type d'objet utilisé. (C'est-à-dire utilisateur, groupe, posixAccount, etc.)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">Doit inclure l'utilisateur (peut contenir plusieurs autres valeurs, si nécessaire).</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Attribut Windows à UNIX</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">Qui définit le nom d'utilisateur Windows lors de sa création. Cloud Volumes Service utilise cette fonction pour les recherches Windows vers UNIX.</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">Aucune modification n'est nécessaire ici ; sAMAccountName est identique au nom de connexion Windows.</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">Définit le nom d'utilisateur UNIX.</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">Nom d'utilisateur UNIX souhaité.</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service n'utilise actuellement pas de préfixes de domaine dans les recherches LDAP, de sorte que plusieurs environnements LDAP de domaine ne fonctionnent pas correctement avec les recherches de carte de noms LDAP.</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">L'exemple suivant montre un utilisateur portant le nom Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block>, Le nom UNIX<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Et le comportement suivant lors de l'écriture de fichiers à partir de SMB et NFS.</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">La figure suivante montre l'apparence des attributs LDAP à partir du serveur Windows.</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">À partir d'un client NFS, vous pouvez interroger le nom UNIX mais pas le nom Windows :</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">Lorsqu'un fichier est écrit à partir de NFS en tant que<block ref="a4e3d60786c42d81caec6aea737b5ce0" prefix=" " category="inline-code"></block>, Le résultat suivant est celui du client NFS :</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">À partir d'un client Windows, vous pouvez voir que le propriétaire du fichier est défini sur l'utilisateur Windows approprié :</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">Inversement, les fichiers créés par l'utilisateur Windows<block ref="188fda84cd10112124b8477615ee021d" prefix=" " category="inline-code"></block> À partir d'un client SMB, montrer le propriétaire UNIX approprié, comme indiqué dans le texte suivant.</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB :</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS :</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">Liaison de canal LDAP</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Avis de sécurité de Microsoft ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">En raison d'une vulnérabilité avec les contrôleurs de domaine Windows Active Directory,<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> Modifie la façon dont le DCS autorise les liaisons LDAP.</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">L'impact pour Cloud Volumes Service est le même que pour tous les clients LDAP. Cloud Volumes Service ne prend actuellement pas en charge la liaison de canaux. Étant donné que Cloud Volumes Service prend en charge la signature LDAP par défaut via la négociation, la liaison du canal LDAP ne doit pas poser problème. Si vous rencontrez des problèmes de liaison avec LDAP alors que la liaison des canaux est activée, suivez les étapes de correction décrites dans ADV190023 pour permettre aux liaisons LDAP à partir de Cloud Volumes Service de réussir.</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">DNS dynamique</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory et Kerberos ont tous deux des dépendances sur DNS pour la résolution du nom d'hôte à IP/IP vers le nom d'hôte. Le DNS requiert l'ouverture du port 53. Cloud Volumes Service n'apporte aucune modification aux enregistrements DNS et ne prend actuellement en charge l'utilisation de<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> sur les interfaces réseau.</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">Un DNS Windows sécurisé</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">Vous pouvez configurer Active Directory DNS pour limiter les serveurs qui peuvent mettre à jour les enregistrements DNS. Pour plus d'informations, voir<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>.</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Notez que les ressources d'un projet Google utilisent par défaut Google Cloud DNS, qui n'est pas connecté à Active Directory DNS. Les clients utilisant le DNS du cloud ne peuvent pas résoudre les chemins UNC renvoyés par Cloud Volumes Service. Les clients Windows joints au domaine Active Directory sont configurés pour utiliser Active Directory DNS et peuvent résoudre de tels chemins UNC.</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">Pourquoi mon client ne parvient-il pas à résoudre le nom NetBIOS du SMB ?</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">Pour joindre un client à Active Directory, vous devez configurer sa configuration DNS pour utiliser Active Directory DNS. Vous pouvez également configurer Cloud DNS pour transférer les demandes vers Active Directory DNS. Voir<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>pour en savoir plus.</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service ne prend pas actuellement en charge les requêtes DNSSEC et DNS sont exécutées en texte clair.</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">Audit de l'accès aux fichiers</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">Actuellement non pris en charge par Cloud Volumes Service.</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">Protection antivirus</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">Vous devez effectuer une analyse antivirus dans Cloud Volumes Service au niveau du client vers un partage NAS. Il n'existe actuellement pas d'intégration antivirus native avec Cloud Volumes Service.</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">Suivant : opération d'entretien.</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">Les protocoles NAS permettent à plusieurs clients sur un réseau d'accéder aux mêmes données sur un système de stockage, notamment Cloud Volumes Service sur GCP. NFS et SMB sont les protocoles NAS définis et fonctionnent sur une base client/serveur où Cloud Volumes Service fait office de serveur.</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">Notions de base sur les protocoles NAS</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">Précédent : présentation des protocoles NAS.</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">Les protocoles NAS permettent à plusieurs clients sur un réseau d'accéder aux mêmes données sur un système de stockage, notamment Cloud Volumes Service sur GCP. NFS et SMB sont les protocoles NAS définis et fonctionnent sur une base client/serveur où Cloud Volumes Service fait office de serveur. Les clients envoient des demandes d'accès, de lecture et d'écriture au serveur, et le serveur est responsable de la coordination des mécanismes de verrouillage des fichiers, du stockage des autorisations et du traitement des demandes d'identité et d'authentification.</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">Par exemple, le processus général suivant est suivi si un client NAS souhaite créer un nouveau fichier dans un dossier.</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">Le client demande au serveur des informations sur le répertoire (autorisations, propriétaire, groupe, ID de fichier, espace disponible, et ainsi de suite) ; le serveur répond avec les informations si le client et l'utilisateur demandeur disposent des autorisations nécessaires sur le dossier parent.</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">Si les autorisations du répertoire autorisent l'accès, le client demande alors au serveur si le nom de fichier en cours de création existe déjà dans le système de fichiers. Si le nom de fichier est déjà utilisé, la création échoue. Si le nom de fichier n'existe pas, le serveur indique au client qu'il peut continuer.</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">Le client envoie un appel au serveur pour créer le fichier avec le descripteur de répertoire et le nom du fichier et définit l'accès et les heures modifiées. Le serveur émet un ID de fichier unique pour s'assurer qu'aucun autre fichier n'est créé avec le même ID de fichier.</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">Le client envoie un appel pour vérifier les attributs du fichier avant l'opération D'ÉCRITURE. Si les autorisations le permettent, le client écrit le nouveau fichier. Si le verrouillage est utilisé par le protocole/l'application, le client demande au serveur un verrouillage pour empêcher les autres clients d'accéder au fichier lorsqu'il est verrouillé afin d'éviter la corruption des données.</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">Suivant : NFS.</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">L'équipe Cloud Volumes Service gère les services de back-end dans Google Cloud et exploite plusieurs stratégies pour sécuriser la plateforme et empêcher les accès non autorisés.</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">Opération d'entretien</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">Précédent : autres dépendances du service d'infrastructure NAS (KDC, LDAP, DNS).</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">Chaque client bénéficie de son propre sous-réseau unique, qui dispose d'un accès clôturé par défaut par rapport à d'autres clients. Par ailleurs, chaque locataire de Cloud Volumes Service dispose de son propre espace de noms et VLAN pour assurer l'isolation totale des données. Après l'authentification d'un utilisateur, le moteur de fourniture de services (SDE) peut uniquement lire les données de configuration spécifiques à ce locataire.</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">Sécurité physique</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">Une fois la préapprobation adéquate obtenue, seuls les ingénieurs sur site et les ingénieurs de support de terrain (FSE) certifiés NetApp ont accès à la cage et aux racks pour les travaux physiques. La gestion du réseau et du stockage n'est pas autorisée. Seules ces ressources sur site sont en mesure d'effectuer les tâches de maintenance du matériel.</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">Pour les ingénieurs sur site, un ticket est émis pour l'énoncé des travaux (SOW) qui inclut l'ID de rack et l'emplacement du périphérique (RU). Toutes les autres informations sont incluses dans le ticket. Pour les FSE NetApp, un ticket de visite sur site doit être levé avec la COLOCATION. Le ticket inclut également les détails, la date et l'heure du visiteur à des fins d'audit. Le cahier des charges du FSE est communiqué à NetApp en interne.</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">Équipe chargée des opérations</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">L'équipe des opérations de Cloud Volumes Service se compose de l'ingénierie de production et d'un ingénieur de fiabilité de site (SRE) pour les services de volume cloud, ainsi que des ingénieurs de support sur site de NetApp et des partenaires pour le matériel. Tous les membres de l'équipe des opérations sont accrédités pour travailler dans Google Cloud et des dossiers de travail détaillés sont conservés pour chaque billet émis. De plus, un processus rigoureux de contrôle et d'approbation du changement est en place pour s'assurer que chaque décision est examinée de façon appropriée.</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">L'équipe SRE gère le plan de contrôle et la manière dont les données sont acheminées depuis les demandes d'interface utilisateur vers le matériel et les logiciels back-end dans Cloud Volumes Service. L'équipe SRE gère également les ressources système, telles que les volumes et les volumes d'inode maximaux. Les SRES ne sont pas autorisés à interagir avec les données clients ou à y accéder. SRES assure également la coordination des autorisations de renvoi de matériel (RMA), telles que les demandes de remplacement de nouveau disque ou de mémoire pour le matériel interne.</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">Obligations du client</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Les clients de Cloud Volumes Service gèrent Active Directory et la gestion des rôles utilisateur de leur entreprise, ainsi que les opérations de volume et de données. Les clients peuvent disposer de rôles administratifs et déléguer des autorisations à d'autres utilisateurs au sein du même projet Google Cloud à l'aide des deux rôles prédéfinis de NetApp et Google Cloud (Administrateur et Viewer).</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">L'administrateur peut homologue à Cloud Volumes Service tout VPC dans le projet du client, que le client détermine approprié. Il est de la responsabilité du client de gérer l'accès à son abonnement à Google Cloud Marketplace et de gérer les VPC qui ont accès au plan de données.</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">Protection de SRE malveillante</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">Une préoccupation pouvant survenir est la façon dont Cloud Volumes Service protège-t-elle contre les scénarios dans lesquels il existe un SRE malveillant ou lorsque les informations d'identification des SRE ont été compromises ?</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">L'accès à l'environnement de production n'est possible qu'avec un nombre limité de SRE particuliers. Les privilèges administratifs sont en outre limités à une poignée d'administrateurs expérimentés. Toutes les actions réalisées par toute personne dans l'environnement de production Cloud Volumes Service sont consignées et toute anomalie affectant une activité de base ou suspecte est détectée par notre plateforme de veille centralisée des informations de sécurité et des événements (SIEM) pour les menaces. Ainsi, les actions malveillantes peuvent être suivies et atténuées avant que le back-end Cloud Volumes Service ne soit trop endommagé.</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">Cycle de vie du volume</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service gère uniquement les objets au sein du service, pas les données au sein des volumes. Seuls les clients qui accèdent aux volumes peuvent gérer les données, les listes de contrôle d'accès, les propriétaires de fichiers, etc. Les données de ces volumes sont chiffrées au repos et l'accès est limité aux locataires de l'instance Cloud Volumes Service.</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Le cycle de vie des volumes pour Cloud Volumes Service est create-update-delete. Les volumes conservent des copies Snapshot de volumes jusqu'à leur suppression et seuls les administrateurs Cloud Volumes Service validés peuvent supprimer des volumes dans Cloud Volumes Service. Lorsqu'un administrateur demande la suppression d'un volume, une étape supplémentaire de la saisie du nom du volume est requise pour vérifier la suppression. Un volume est supprimé et ne peut plus être restauré.</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">Dans les cas où un contrat Cloud Volumes Service a été résilié, NetApp marque la suppression des volumes au bout d'une période donnée. Avant l'expiration de cette période, vous pouvez récupérer des volumes à la demande du client.</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">Certifications</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">Conformité : sécurité et confidentialité des données</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Cloud volumes Services pour Google Cloud est actuellement certifié conforme aux normes ISO/IEC 27001:2013 et ISO/IEC 27018:2019. Le service a aussi récemment reçu son rapport d'attestation de type I de la SOC2. Pour plus d'informations sur l'engagement de NetApp en matière de sécurité et de confidentialité des données, consultez la page<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>.</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">LE RGPD</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">contrats clients</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">Addenda relatif au traitement des données client</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">Clauses contractuelles standard</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">Notre engagement en matière de confidentialité et de conformité avec le RGPD est disponible dans un certain nombre de nos <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>, comme notre<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>, qui inclut le <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> Fourni par la Commission européenne. Nous prenons également ces engagements dans notre politique de confidentialité, soutenue par les valeurs fondamentales énoncées dans notre Code de conduite d'entreprise.</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">Suivant : informations supplémentaires, historique des versions et informations de contact.</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service permet de partager les mêmes datasets avec les clients SMB et NFS tout en maintenant les autorisations d'accès adéquates protocole double. Pour ce faire, le mappage d'identités entre les protocoles et un serveur LDAP back-end centralisé permettent de fournir les identités UNIX à Cloud Volumes Service. Vous pouvez utiliser Windows Active Directory pour fournir à la fois aux utilisateurs Windows et UNIX la facilité d'utilisation.</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">Double protocole/multiprotocole</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">Précédent : SMB.</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">double protocole</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service permet de partager les mêmes datasets avec les clients SMB et NFS tout en maintenant les autorisations d'accès adéquates <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>). Pour ce faire, le mappage d'identités entre les protocoles et un serveur LDAP back-end centralisé permettent de fournir les identités UNIX à Cloud Volumes Service. Vous pouvez utiliser Windows Active Directory pour fournir à la fois aux utilisateurs Windows et UNIX la facilité d'utilisation.</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">Contrôle d'accès</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">« Comptes avec droits d'administrateur/de sauvegarde local/BUILTIN. »</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">MMC/gestion de l'ordinateur</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">*Partage des contrôles d'accès.* déterminer quels clients et/ou utilisateurs et groupes peuvent accéder à un partage NAS. Dans le cas de NFS, les export-policy et les règles contrôlent l'accès client aux exports. Les exportations NFS sont gérées à partir de l'instance Cloud Volumes Service. SMB utilise les partages CIFS/SMB et les listes de contrôle d'accès de partage pour fournir un contrôle plus granulaire au niveau de l'utilisateur et du groupe. Vous ne pouvez configurer des listes de contrôle d'accès au niveau du partage que depuis des clients SMB en utilisant<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Avec un compte disposant de droits d'administrateur sur l'instance Cloud Volumes Service (voir la section <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>).</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">*Contrôles d'accès aux fichiers.* les autorisations de contrôle au niveau d'un fichier ou d'un dossier sont toujours gérées à partir du client NAS. Les clients NFS peuvent utiliser les bits de mode classiques (rwx) ou les listes de contrôle d'accès NFSv4. Les clients SMB exploitent les autorisations NTFS.</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">Le contrôle d'accès pour les volumes qui fournissent des données à la fois aux protocoles NFS et SMB dépend du protocole utilisé. Pour plus d'informations sur les autorisations avec double protocole, reportez-vous à la section «<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>. »</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">Mappage d'utilisateurs</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">Lorsqu'un client accède à un volume, Cloud Volumes Service tente de mapper l'utilisateur entrant vers un utilisateur valide dans la direction opposée. Cela est nécessaire pour que l'accès soit déterminé dans l'ensemble des protocoles et pour s'assurer que l'utilisateur qui demande l'accès est bien celui qu'il prétend être.</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">Par exemple, si un utilisateur Windows nommé<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Tente d'accéder à un volume avec des autorisations UNIX via SMB, puis Cloud Volumes Service effectue une recherche pour trouver un utilisateur UNIX correspondant nommé<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block>. Le cas échéant, les fichiers qui sont écrits dans un partage SMB en tant qu'utilisateur Windows<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> S'affiche en tant qu'utilisateur UNIX<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> À partir de clients NFS.</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">Sinon, si un utilisateur UNIX nommé<block ref="8ff32489f92f33416694be8fdc2d4c22" prefix=" " category="inline-code"></block> Tente d'accéder à un volume Cloud Volumes Service avec des autorisations Windows, puis l'utilisateur UNIX doit pouvoir mapper un utilisateur Windows valide. Dans le cas contraire, l'accès au volume est refusé.</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">Création d'une connexion AD</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">Actuellement, seul Active Directory est pris en charge pour la gestion externe des identités UNIX avec LDAP. Pour plus d'informations sur la configuration de l'accès à ce service, reportez-vous à la section<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>.</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">Modèle d'autorisation</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">Lors de l'utilisation de configurations à double protocole, Cloud Volumes Service utilise des styles de sécurité pour les volumes afin de déterminer le type de liste de contrôle d'accès. Ces styles de sécurité sont définis en fonction du protocole NAS spécifié, ou dans le cas d'un double protocole, en fait l'option choisie au moment de la création du volume Cloud Volumes Service.</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">Si vous utilisez uniquement NFS, les volumes Cloud Volumes Service utilisent des autorisations UNIX.</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">Si vous utilisez uniquement SMB, les volumes Cloud Volumes Service utilisent des autorisations NTFS.</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">Si vous créez un volume à double protocole, vous pouvez choisir le style ACL lors de la création du volume. Cette décision doit être prise en fonction de la gestion des autorisations souhaitée. Si vos utilisateurs gèrent les autorisations des clients Windows/SMB, sélectionnez NTFS. Si vos utilisateurs préfèrent utiliser des clients NFS et chmod/chown, utilisez des styles de sécurité UNIX.</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">Suivant : considérations relatives à la création de connexions Active Directory.</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Tous les volumes Cloud Volumes Service sont chiffrés au repos à l'aide du chiffrement AES-256, qui signifie que toutes les données utilisateur écrites sur le support sont chiffrées et ne peuvent être déchiffrées qu'à l'aide d'une clé par volume.</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">Chiffrement des données au repos</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">Précédent : chiffrement des données en transit.</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">Pour CVS-SW, des clés générées par Google sont utilisées.</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">Pour CVS-Performance, les clés par volume sont stockées dans un gestionnaire de clés intégré dans Cloud Volumes Service.</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google Key Management Service (KMS).</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">Depuis novembre 2021, un aperçu des fonctionnalités de clés de chiffrement gérées par les clients (CMEK) a été disponible. Vous pouvez ainsi chiffrer les clés par volume avec une clé principale par projet et par région hébergée dans<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> LES KILOMÈTRES vous permettent d'associer des gestionnaires de clés externes.</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">La configuration des clés de chiffrement gérées par le client</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">Pour plus d'informations sur la configuration de KMS pour CVS-Performance, reportez-vous à la section<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>.</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">Suivant : pare-feu.</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service expose plusieurs ports TCP pour servir les partages NFS et SMB.</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">Pare-feu</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">Précédent : chiffrement des données au repos.</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service expose plusieurs ports TCP pour servir les partages NFS et SMB :</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">Ports requis pour l'accès NFS</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">Ports requis pour l'accès SMB</block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">configuré</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">Découverte de data Center basée sur DNS</block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">En outre, SMB, NFS avec LDAP, y compris Kerberos, et des configurations à double protocole requièrent l'accès à un domaine Windows Active Directory. Les connexions Active Directory doivent être de<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> par région. Les contrôleurs de domaine (DC) Active Directory sont identifiés à l'aide de<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> Utilisation des serveurs DNS spécifiés. Tous les DCS renvoyés sont utilisés. La liste des DCS admissibles peut être limitée en spécifiant un site Active Directory.</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">Intégration de la Cloud Volumes Service</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service atteint son niveau avec les adresses IP de la plage CIDR allouée à l'<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> commande pendant<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>. Vous pouvez utiliser ce CIDR comme adresses source pour configurer les pare-feu entrants sur vos contrôleurs de domaine Active Directory.</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">Exposer les ports aux rapports CIDR Cloud Volumes Service comme indiqué ici</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Les contrôleurs de domaine Active Directory doivent<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>.</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">Next : présentation des protocoles NAS.</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">L'architecture et la sécurité font partie des processus de confiance aux solutions cloud. Cette section décrit différents aspects de l'architecture Cloud Volumes Service de Google qui contribuent à réduire les risques de sécurisation des données et indique les domaines dans lesquels des étapes de configuration supplémentaires peuvent être nécessaires pour obtenir le déploiement le plus sécurisé.</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">Précédent : considérations de sécurité et surfaces d'attaque.</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">L'architecture générale d'Cloud Volumes Service peut être décomposée en deux composants principaux : le plan de contrôle et le plan de données.</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">Plan de contrôle</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Le plan de contrôle d'Cloud Volumes Service est l'infrastructure back-end gérée par les administrateurs Cloud Volumes Service et le logiciel d'automatisation natif de NetApp. Ce plan est totalement transparent pour les utilisateurs finaux. Il inclut des fonctionnalités de mise en réseau, du matériel de stockage, des mises à jour logicielles, etc. Pour que les solutions hébergées dans le cloud telles que Cloud Volumes Service puissent apporter de la valeur ajoutée.</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">Plan de données</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Le plan de données de Cloud Volumes Service inclut les volumes de données réels et la configuration Cloud Volumes Service globale (contrôle d'accès, authentification Kerberos, etc.). Le plan de données est entièrement sous le contrôle des utilisateurs finaux et des consommateurs de la plateforme Cloud Volumes Service.</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">La façon dont chaque plan est sécurisé et géré est différente. Ces différences sont en commençant par la présentation de l'architecture Cloud Volumes Service.</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">Ensuite : architecture Cloud Volumes Service.</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service pour Google Cloud exploite la structure d'accès aux services privés Google Cloud. Dans ce cadre, les utilisateurs peuvent se connecter à Cloud Volumes Service. Cette structure utilise des services de mise en réseau et des constructions de peering de VPC comme d'autres services Google Cloud, qui assurent une isolation complète entre les locataires.</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">Architecture de plan de données</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">Précédent : architecture du plan de contrôle.</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service pour Google Cloud s'appuie sur Google Cloud<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> structure. Dans ce cadre, les utilisateurs peuvent se connecter à Cloud Volumes Service. Cette structure utilise des services de mise en réseau et des constructions de peering de VPC comme d'autres services Google Cloud, qui assurent une isolation complète entre les locataires.</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Architecture pour Cloud Volumes Service</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Pour obtenir une présentation de l'architecture de Cloud Volumes Service pour Google Cloud, rendez-vous sur<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>.</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">Les VPC utilisateur (autonomes ou partagés) sont associés à des VPC au sein de projets de locataires gérés Cloud Volumes Service, qui hébergent les volumes.</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">La figure précédente montre un projet (projet CVS de milieu de gamme) avec trois réseaux VPC connectés à Cloud Volumes Service et plusieurs VM de moteur de calcul (GCE1-7) partageant des volumes :</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1 permet à GCE1 d’accéder aux volumes A et B.</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">Le VPC2 permet aux GCE2 et GCE4 d'accéder au volume C.</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">Le troisième réseau VPC est un VPC partagé, partagé avec deux projets de service. Il permet aux GCE3, GCE4, GCE5 et GCE6 d'accéder aux volumes D et E. Les réseaux VPC partagés ne sont pris en charge que pour les volumes du type de service CVS-Performance.</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">Le GCE7 ne peut accéder à aucun volume.</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">Les données peuvent être chiffrées à la fois en transit (par le chiffrement Kerberos et/ou SMB) et au repos dans Cloud Volumes Service.</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">Suivant : chiffrement des données en transit.</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="doc">Protocoles NAS</block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">Les protocoles NAS incluent NFS (v3 et v4.1) et SMB/CIFS (2.x et 3.x). Ces protocoles sont la façon dont CVS permet un accès partagé aux données entre plusieurs clients NAS. Par ailleurs, Cloud Volumes Service permet d'accéder simultanément aux clients NFS et SMB/CIFS (double protocole) tout en respectant l'ensemble des paramètres d'identité et d'autorisation sur les fichiers et les dossiers des partages NAS.</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">Présentation des protocoles NAS</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">Précédent : pare-feu.</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">Les protocoles NAS incluent NFS (v3 et v4.1) et SMB/CIFS (2.x et 3.x). Ces protocoles sont la façon dont CVS permet un accès partagé aux données entre plusieurs clients NAS. Par ailleurs, Cloud Volumes Service permet d'accéder simultanément aux clients NFS et SMB/CIFS (double protocole) tout en respectant l'ensemble des paramètres d'identité et d'autorisation sur les fichiers et les dossiers des partages NAS. Pour préserver un niveau maximal de sécurité des transferts de données, Cloud Volumes Service prend en charge le chiffrement de protocole à la volée avec le chiffrement SMB et NFS Kerberos 5p.</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">Le double protocole est disponible avec CVS-Performance uniquement.</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">Next : notions de base sur les protocoles NAS.</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">Pour comprendre comment sécuriser vos données, il faut d'abord identifier les risques et les surfaces d'attaque potentielles.</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">Considérations de sécurité et surfaces d'attaque</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">Précédent : comment Cloud Volumes Service dans Google Cloud sécurise vos données.</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">Pour comprendre comment sécuriser vos données, il faut d'abord identifier les risques et les surfaces d'attaque potentielles. Ces mesures comprennent (sans s'y limiter) les éléments suivants :</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">Administration et connexions</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">Au repos</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">Données en cours de vol</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">Réseau et pare-feu</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">Attaques par ransomware, logiciel malveillant et virus</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">Comprendre les surfaces d'attaque peut vous aider à mieux sécuriser vos environnements. Cloud Volumes Service dans Google Cloud prend déjà en compte bon nombre de ces sujets et implémente la fonctionnalité de sécurité par défaut, sans aucune interaction administrative.</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">Assurer des connexions sécurisées</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">Lors de la sécurisation des composants d'infrastructure critiques, il est impératif de s'assurer que seuls les utilisateurs approuvés peuvent se connecter et gérer vos environnements. Si de mauvais acteurs violent vos informations d'identification administratives, ils ont les clés du château et peuvent faire tout ce qu'ils veulent : changer de configuration, supprimer des volumes et des sauvegardes, créer des backdoors ou désactiver les planifications de snapshots.</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service pour Google Cloud protège contre les connexions administratives non autorisées grâce à l'obfuscation du stockage à la demande. Cloud Volumes Service est entièrement géré par le fournisseur cloud, sans qu'il soit possible de se connecter en externe. Toutes les opérations d'installation et de configuration sont entièrement automatisées. De ce fait, un administrateur humain n'a jamais à interagir avec les systèmes, sauf dans de rares circonstances.</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">« Architecture Cloud Volumes Service ».</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">Si vous devez vous connecter, Cloud Volumes Service dans Google Cloud sécurise vos connexions en maintenant une liste très courte d'administrateurs de confiance qui ont accès aux systèmes. Ce contrôle d'accès contribue à réduire le nombre de mauvais acteurs potentiels avec accès. De plus, la mise en réseau Google Cloud masque les systèmes derrière des couches de sécurité réseau et expose uniquement ce qui est nécessaire pour le monde extérieur. Pour plus d'informations sur Google Cloud, l'architecture Cloud Volumes Service, consultez la section <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">Mises à niveau et administration du cluster</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">Deux domaines présentant des risques de sécurité potentiels incluent l'administration du cluster (que se passe-t-il si un acteur défectueux a accès administrateur) et les mises à niveau (que se passe-t-il si une image logicielle est compromise).</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">L'administration du stockage</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">“Fonctionnement de l'entretien.”</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">Le stockage fourni à la demande élimine le risque supplémentaire d'exposition des administrateurs en les supprimant pour l'accès aux utilisateurs finaux en dehors du data Center cloud. En effet, la seule configuration effectuée concerne le plan d'accès aux données par les clients. Chaque locataire gère ses propres volumes, et aucun locataire ne peut accéder à d'autres instances Cloud Volumes Service. Le service est géré par l'automatisation, avec une très petite liste d'administrateurs de confiance qui ont accès aux systèmes via les processus décrits dans la section <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">Le type de service CVS-Performance offre une réplication entre régions en tant que possibilité de protéger les données vers une autre région en cas de défaillance d'une région. Dans ce cas, Cloud Volumes Service peut basculer vers une région non affectée pour maintenir l'accès aux données.</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">Mises à niveau du service</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">Les mises à jour permettent de protéger les systèmes vulnérables. Chaque mise à jour fournit des améliorations de sécurité et des correctifs de bogues qui réduisent les surfaces d'attaque. Les mises à jour logicielles sont téléchargées à partir de référentiels centralisés et sont validées avant que les mises à jour ne soient autorisées à vérifier que les images officielles sont utilisées et que les mises à niveau ne sont pas compromises par les acteurs défectueux.</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Avec Cloud Volumes Service, les mises à jour sont gérées par les équipes des fournisseurs cloud, ce qui élimine les risques pour les équipes d'administration. Les experts maîtrisent la configuration et les mises à niveau de manière automatisée et entièrement testée. Les mises à niveau ne entraînent pas de perturbation et Cloud Volumes Service effectue les mises à jour les plus récentes pour des résultats globaux optimaux.</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">Pour plus d'informations sur l'équipe d'administration qui effectue ces mises à niveau de service, reportez-vous à la section <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">Sécurisation des données au repos</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">Le chiffrement des données au repos est important pour protéger les données sensibles en cas de vol, de retour ou de reconversion d'un disque. Les données au repos Cloud Volumes Service sont protégées au moyen du chiffrement logiciel.</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Les clés générées par Google sont utilisées pour CVS-SW.</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">Certificat no FIPS 140-2-4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">Pour CVS-Performance, les clés par volume sont stockées dans un gestionnaire de clés intégré dans Cloud Volumes Service, qui utilise NetApp ONTAP CryptoMod pour générer des clés de cryptage AES-256. CryptoMod figure dans la liste des modules validés CCVP FIPS 140-2. Voir<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>.</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">Depuis novembre 2021, CVS-Performance a mis à disposition une fonctionnalité de chiffrement géré par le client (CMEK). Cette fonctionnalité vous permet de chiffrer les clés par volume avec des clés principales par projet et par région hébergées dans Google Key Management Service (KMS). LES KILOMÈTRES vous permettent d'associer des gestionnaires de clés externes.</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">Pour plus d'informations sur la configuration de KMS pour CVS-Performance,<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>.</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">Pour plus d'informations sur l'architecture, voir la section <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">Sécurisation des données à la volée</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">En plus de sécuriser les données au repos, vous devez également être à même de sécuriser les données lorsqu'elles sont en transit entre l'instance Cloud Volumes Service et un client ou une cible de réplication. Cloud Volumes Service permet le chiffrement des données à la volée sur les protocoles NAS à l'aide de méthodes de chiffrement, telles que le chiffrement SMB via Kerberos, la signature/chiffrement des paquets et NFS Kerberos 5p pour le chiffrement complet des transferts de données.</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">La réplication des volumes Cloud Volumes Service utilise le protocole TLS 1.2, qui tire parti des méthodes de chiffrement AES-GCM.</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">La plupart des protocoles en vol non sécurisés tels que telnet, NDMP, etc. Sont désactivés par défaut. Toutefois, le DNS n'est pas chiffré par Cloud Volumes Service (pas de prise en charge de DNS sec) et doit être chiffré en utilisant le cryptage réseau externe lorsque cela est possible. Voir la section <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> pour en savoir plus sur la sécurisation des données à la volée.</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">« Protocoles NAS ».</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">Pour plus d'informations sur le cryptage du protocole NAS, reportez-vous à la section <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">Utilisateurs et groupes pour les autorisations NAS</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">Une partie de la sécurisation de vos données dans le cloud implique une authentification adéquate des utilisateurs et des groupes, où les utilisateurs accédant aux données sont vérifiés en tant qu'utilisateurs réels dans l'environnement et où les groupes contiennent des utilisateurs valides. Ces utilisateurs et groupes offrent un accès initial au partage et à l'exportation, ainsi qu'une validation des autorisations pour les fichiers et dossiers du système de stockage.</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service utilise l'authentification standard d'utilisateur et de groupe Windows basée sur Active Directory pour les partages SMB et les autorisations de style Windows. Le service peut également tirer parti de fournisseurs d'identités UNIX tels que le LDAP pour les utilisateurs et groupes UNIX pour les exportations NFS, la validation des ID NFSv4, l'authentification Kerberos et les ACL NFSv4.</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">Actuellement, seul Active Directory LDAP est pris en charge avec la fonctionnalité Cloud Volumes Service pour LDAP.</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">La détection, la prévention et la réduction des ransomwares, des malwares et des virus</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">Les ransomwares, les malwares et les virus sont une menace persistante pour les administrateurs, et la détection, la prévention et la réduction de ces menaces sont toujours une priorité absolue pour les entreprises. En cas d'attaque par ransomware d'un jeu de données stratégique, vous pouvez coûter plusieurs millions de dollars. Il est donc préférable de faire ce que vous pouvez minimiser ce risque.</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">détection automatique des ransomwares</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Bien que Cloud Volumes Service n'inclut actuellement pas de mesures de détection ou de prévention natives, telles que la protection antivirus ou<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>, Il existe des moyens de récupérer rapidement après un événement ransomware en activant des planifications Snapshot régulières. Les copies Snapshot sont immuables et les pointeurs en lecture seule vers les blocs modifiés dans le système de fichiers sont quasi instantanés, ont un impact minimal sur les performances et utilisent uniquement de l'espace lorsque les données sont modifiées ou supprimées. Vous pouvez définir des calendriers pour les copies Snapshot en fonction de l'objectif de point de récupération (RPO)/objectif de durée de restauration (RTO) souhaité. Vous pouvez également conserver jusqu'à 1,024 copies Snapshot par volume.</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">La prise en charge des snapshots est incluse sans frais supplémentaires (en plus des frais de stockage de données pour les blocs/données modifiés conservés par les copies Snapshot) avec Cloud Volumes Service et, en cas d'attaque par ransomware, elle peut être utilisée pour restaurer la copie Snapshot avant l'attaque. Les restaurations Snapshot ne prennent que quelques secondes et vous permettent ensuite de rétablir le service des données normal. Pour plus d'informations, voir<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>.</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">Pour empêcher les ransomwares d'affecter votre activité, vous devez adopter une approche à plusieurs couches :</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">Protection des terminaux</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">Protection contre les menaces externes grâce à des pare-feu réseau</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">Détection des anomalies de données</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">Plusieurs sauvegardes (sur site et hors site) de jeux de données stratégiques</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">Tests réguliers de restauration des sauvegardes</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">Copies Snapshot NetApp immuables en lecture seule</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">Authentification multifacteur pour les infrastructures stratégiques</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">Audits de sécurité des connexions système</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">Cette liste est loin d'être exhaustive, mais elle constitue un bon plan à suivre pour gérer le potentiel d'attaques par ransomware. Cloud Volumes Service dans Google Cloud fournit plusieurs façons de vous protéger contre les événements par ransomware et de réduire leurs effets.</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">Copies Snapshot immuables</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service fournit de manière native des copies Snapshot immuables en lecture seule, qui sont mises en œuvre dans un calendrier personnalisable pour une restauration instantanée rapide en cas de suppression de données ou si un volume entier a été victime d'une attaque par ransomware. Les restaurations Snapshot vers les précédentes copies Snapshot sont rapides et limitent la perte de données en fonction de la période de conservation de vos planifications Snapshot et des objectifs RTO/RPO. L'impact de la technologie Snapshot sur les performances est négligeable.</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Étant donné que les copies Snapshot dans Cloud Volumes Service sont en lecture seule, elles ne peuvent pas être infectées par un ransomware à moins que ces dernières aient proliféré dans le dataset inaperçu et que les copies Snapshot ont été prises en compte par les données infectées par un ransomware. C'est pourquoi vous devez également envisager la détection par ransomware basée sur les anomalies de données. Cloud Volumes Service n'offre pas actuellement de fonction de détection native, mais vous pouvez utiliser un logiciel de surveillance externe.</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">Les sauvegardes et les restaurations</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service fournit des fonctionnalités standard de sauvegarde client NAS (sauvegardes sur NFS ou SMB).</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">réplication de volume</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS-Performance offre une réplication de volume entre régions vers d'autres volumes CVS-Performance. Pour plus d'informations, voir<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> Dans la documentation Cloud Volumes Service.</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">la sauvegarde dans le cloud</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW offre des fonctionnalités de sauvegarde/restauration de volume natives des services. Pour plus d'informations, voir<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> Dans la documentation Cloud Volumes Service.</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">La réplication de volume fournit une copie exacte du volume source pour un basculement rapide en cas d'incident, y compris en cas d'attaque par ransomware.</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">Réplication entre les régions</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS-Performance vous permet de répliquer en toute sécurité des volumes entre les régions Google Cloud pour la protection des données et les archives à l'aide du chiffrement TLS1.2 AES 256 GCM sur un réseau de service back-end contrôlé par NetApp à l'aide d'interfaces spécifiques utilisées pour la réplication sur le réseau Google. Un volume primaire (source) contient les données de production actives et effectue une réplication vers un volume secondaire (destination) afin de fournir une réplique exacte du jeu de données primaire.</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">La réplication initiale transfère tous les blocs, mais les mises à jour ne transmettent que les blocs modifiés dans un volume primaire. Par exemple, si une base de données de 1 To résidant sur un volume primaire est répliquée sur le volume secondaire, alors 1 To d'espace est transféré sur la réplication initiale. Si cette base de données a quelques centaines de lignes (hypothetiquement, quelques Mo) qui changent entre l'initialisation et la mise à jour suivante, seuls les blocs avec les lignes modifiées sont répliqués sur le secondaire (quelques Mo). Cela permet de s'assurer que les temps de transfert restent faibles et de limiter les coûts de réplication.</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">Toutes les autorisations des fichiers et dossiers sont répliquées sur le volume secondaire, mais les autorisations d'accès au partage (telles que les export-policies et les règles ou les partages SMB et les ACL de partage) doivent être gérées de manière indépendante. Dans le cas d'un basculement de site, le site de destination doit utiliser les mêmes services de nom et les mêmes connexions de domaine Active Directory pour assurer un traitement cohérent des identités et autorisations des utilisateurs et des groupes. En cas d'incident, il est possible d'utiliser un volume secondaire comme cible de basculement afin de briser la relation de réplication, qui convertit le volume secondaire en lecture/écriture.</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">Les répliques de volumes sont en lecture seule, ce qui permet d'obtenir une copie inaltérable des données hors site pour une restauration rapide des données lorsqu'un virus a infecté des données ou où un ransomware a chiffré le jeu de données principal. Les données en lecture seule ne sont pas cryptées, mais, en cas de volume primaire affecté et de réplication, les blocs infectés sont également répliqués. Vous pouvez utiliser des copies Snapshot plus anciennes et non affectées pour effectuer une restauration, mais les SLA peuvent tomber dans la plage des RTO/RPO promis en fonction de la rapidité de détection d'une attaque.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">Considérations de sécurité</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">De plus, vous pouvez empêcher les actions administratives malveillantes, telles que les suppressions de volumes, les suppressions de snapshots ou les modifications de planifications de snapshots, dans le cadre de la gestion de la réplication multi-région (CRR) dans Google Cloud. Pour ce faire, des rôles personnalisés séparent les administrateurs de volumes, qui peuvent supprimer des volumes source sans interrompre les miroirs et ne peuvent donc pas supprimer des volumes de destination des administrateurs CRR, qui ne peuvent pas effectuer d'opérations de volume. Voir<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> Dans la documentation Cloud Volumes Service pour les autorisations autorisées par chaque groupe d'administrateurs.</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Bien que Cloud Volumes Service assure une durabilité élevée des données, les événements externes peuvent entraîner des pertes de données. En cas d'incident de sécurité tel qu'un virus ou un ransomware, les sauvegardes et les restaurations sont essentielles pour la reprise de l'accès aux données en temps opportun. Un administrateur peut accidentellement supprimer un volume Cloud Volumes Service. Ou il suffit aux utilisateurs de conserver les versions de sauvegarde de leurs données pendant plusieurs mois et de conserver l'espace supplémentaire de copie Snapshot dans le volume peut représenter un défi de coût. Même si les copies Snapshot doivent être le moyen le plus conseillé de conserver les versions de sauvegarde pendant les dernières semaines pour restaurer les données perdues, elles se trouvent à l'intérieur du volume et sont perdues en cas de perte du volume.</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">Pour toutes ces raisons, NetApp Cloud Volumes Service propose des services de sauvegarde par l'intermédiaire de<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>.</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">La sauvegarde Cloud Volumes Service génère une copie du volume sur Google Cloud Storage (GCS). Il sauvegarde uniquement les données réelles stockées au sein du volume, et non l'espace libre. Cela fonctionne comme une opération incrémentielle à l'infini. Cela signifie qu'il transfère le contenu du volume une fois et depuis là, il continue de sauvegarder les données modifiées uniquement. Comparé aux concepts de sauvegarde classiques à plusieurs sauvegardes complètes, elle permet d'économiser une grande quantité de stockage de sauvegarde, ce qui réduit les coûts. Le prix mensuel de l'espace de sauvegarde est inférieur à celui d'un volume. C'est l'endroit idéal pour conserver les versions de sauvegarde plus longtemps.</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">Les utilisateurs peuvent utiliser une sauvegarde Cloud Volumes Service pour restaurer toute version de sauvegarde sur un volume identique ou différent dans la même région. Si le volume source est supprimé, les données de sauvegarde sont conservées et doivent être gérées indépendamment (par exemple, supprimées).</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Documentation de sauvegarde Cloud Volumes Service</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">nombre maximal de versions de sauvegarde prises en charge</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">tarifs</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service Backup est intégré à Cloud Volumes Service en option. Les utilisateurs peuvent décider des volumes à protéger en activant la sauvegarde Cloud Volumes Service sur la base de chaque volume. Voir la<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> pour plus d'informations sur les sauvegardes, le<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>, planification, et<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>.</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">Toutes les données de sauvegarde d'un projet sont stockées dans un compartiment GCS, géré par le service et non visible par l'utilisateur. Chaque projet utilise un compartiment différent. Actuellement, les compartiments se trouvent dans la même région que les volumes Cloud Volumes Service, mais davantage d'options sont présentées. Consultez la documentation pour connaître l'état le plus récent.</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">Le transport des données d'un compartiment Cloud Volumes Service vers GCS utilise des réseaux Google internes et externes avec HTTPS et TLS1.2. Les données sont chiffrées au repos à l'aide de clés gérées par Google.</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">roles/netappdevolumes.admin</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Pour gérer la sauvegarde Cloud Volumes Service (création, suppression et restauration de sauvegardes), un utilisateur doit disposer du<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> rôle.</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">Suivant : présentation de l'architecture.</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">Les données en transit peuvent être chiffrées au niveau de la couche de protocole NAS et le réseau Google Cloud lui-même est chiffré, comme décrit dans les sections suivantes.</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">Chiffrement des données en transit</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">Précédent : architecture de plan de données.</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Réseau Google Cloud</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">Chiffrement en transit</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud chiffre le trafic au niveau du réseau comme décrit à la section<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> Dans la documentation Google. Comme indiqué dans la section « architecture de services Cloud volumes », Cloud Volumes Service est fourni à partir d'un projet de production PSA contrôlé par NetApp.</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">Dans le cas de CVS-SW, le locataire exécute les machines virtuelles Google pour fournir le service. Le trafic entre les VM utilisateur et les machines virtuelles Cloud Volumes Service est automatiquement chiffré par Google.</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">De cryptage IEEE 802.1AE (MACSec)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">encapsulation</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">Bien que le chemin d'accès aux données de CVS-Performance ne soit pas intégralement chiffré sur la couche réseau, NetApp et Google utilisent une combinaison<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>,<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (Chiffrement des données) et des réseaux physiquement restreints pour protéger les données en transit entre le type de service Cloud Volumes Service CVS-Performance et Google Cloud.</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">Les protocoles NAS NFS et SMB fournissent un chiffrement de transport en option au niveau de la couche de protocoles.</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> Offre un cryptage de bout en bout des données SMB et protège les données contre les occurrences de réseaux non fiables. Vous pouvez activer le cryptage à la fois pour la connexion de données client/serveur (uniquement disponible pour les clients compatibles SMB3.x) et pour l'authentification du contrôleur serveur/domaine.</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">Lorsque le cryptage SMB est activé, les clients qui ne prennent pas en charge le cryptage ne peuvent pas accéder au partage.</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service prend en charge le chiffrement de sécurité RC4-HMAC, AES-128-CTS-HMAC-SHA1 et AES-256-CTS-HMAC-SHA1 pour le cryptage SMB. SMB négocie le type de cryptage le plus élevé pris en charge par le serveur.</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">Kerberos NFSv4.1</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">Pour NFSv4.1, CVS-Performance propose l'authentification Kerberos, comme décrit dans<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>. Vous pouvez activer Kerberos par volume.</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">Le type de chiffrement le plus puissant actuellement disponible pour Kerberos est AES-256-CTS-HMAC-SHA1. NetApp Cloud Volumes Service prend en charge AES-256-CTS-HMAC-SHA1, AES-128-CTS-HMAC-SHA1, DES3 et DES pour NFS. Il prend également en charge ARCFOUR-HMAC (RC4) pour le trafic CIFS/SMB, mais pas pour NFS.</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos propose trois niveaux de sécurité différents pour les montages NFS qui offrent des options de sécurité Kerberos.</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">Options de montage courantes</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">Selon RedHat<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> documentation :</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">En règle générale, plus le niveau de sécurité Kerberos est important, plus les performances sont faibles, car le client et le serveur passent du temps à chiffrer et déchiffrer les opérations NFS pour chaque paquet envoyé. De nombreux clients et serveurs NFS prennent en charge le transfert AES-ni vers les processeurs pour une meilleure expérience globale. Cependant, l'impact sur les performances de Kerberos 5p (chiffrement complet de bout en bout) est considérablement plus important que l'impact de Kerberos 5 (authentification utilisateur).</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">Le tableau ci-dessous présente les différences par rapport à chaque niveau pour la sécurité et les performances.</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">Niveau de sécurité</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="cell">Performance</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3 : sys</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">Moins sécurisé ; texte brut avec ID utilisateur numérique/ID de groupe</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">Possibilité d'afficher les UID, GID, adresses IP client, chemins d'exportation, noms de fichiers, autorisations dans les captures de paquets</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">Idéal pour la plupart des cas</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x — sys</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">Plus sûr que NFSv3 (ID client, correspondance de chaîne de nom/chaîne de domaine) mais texte brut</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">Possibilité d'afficher les UID, GID, adresses IP des clients, chaînes de noms, ID de domaine, chemins d'exportation, noms de fichiers, autorisations dans les captures de paquets</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">Adapté aux charges de travail séquentielles (VM, bases de données, fichiers volumineux)</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">Erreurs avec un nombre élevé de fichiers/métadonnées élevées (30 à 50 % en moins)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS - krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">Le chiffrement Kerberos pour les informations d'identification dans chaque paquet NFS — enveloppe l'UID/GID des utilisateurs/groupes dans les appels RPC dans l'encapsuleur GSS</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">L'utilisateur qui demande l'accès au montage a besoin d'un ticket Kerberos valide (via nom d'utilisateur/mot de passe ou par échange manuel de clés) ; le ticket expire après une période spécifiée et l'utilisateur doit de nouveau s'authentifier pour l'accès</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">Aucun chiffrement pour les opérations NFS ou les protocoles annexes tels que mount/portmapper/nlm (peut voir les chemins d'exportation, les adresses IP, les pointeurs de fichiers, les autorisations, les noms de fichiers, atime/mtime dans les captures de paquets)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">Le meilleur dans la plupart des cas pour Kerberos ; pire que AUTH_SYS</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS - krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">L'utilisateur qui demande l'accès au montage doit disposer d'un ticket Kerberos valide (via nom d'utilisateur/mot de passe ou échange manuel par onglet) ; le ticket expire après une période spécifiée et l'utilisateur doit de nouveau s'authentifier pour l'accès</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">La somme de contrôle GSS Kerberos est ajoutée à chaque paquet pour garantir que rien n'intercepte les paquets. Si les checksums correspondent, la conversation est autorisée.</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">Supérieur à krb5p parce que la charge NFS n'est pas chiffrée. Seule la surcharge supplémentaire par rapport à krb5 est la somme de contrôle d'intégrité. Les performances de krb5i ne seront pas beaucoup plus mauvais que krb5, mais il y aura une certaine dégradation.</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS – krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">L'utilisateur qui demande l'accès au montage doit disposer d'un ticket Kerberos valide (via nom d'utilisateur/mot de passe ou échange manuel de clavier) ; le ticket expire après la période spécifiée et l'utilisateur doit de nouveau s'authentifier pour l'accès</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">Tous les payload de paquets NFS sont cryptés avec l'encapsuleur GSS (ne peut pas voir les descripteurs de fichier, les autorisations, les noms de fichier, atime/mtime dans les captures de paquets).</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">Inclut le contrôle d'intégrité.</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">Le type d'opération NFS est visible (FSINFO, ACCESS, GETATTR, etc.).</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">Les protocoles auxiliaires (montage, portmap, nlm, etc.) ne sont pas cryptés (voir chemins d'exportation, adresses IP)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">Performances les plus faibles des niveaux de sécurité ; la krb5p doit chiffrer/décrypter plus.</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">Performances supérieures à celles du krb5p avec NFSv4.x pour les workloads avec un nombre élevé de fichiers.</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">Dans Cloud Volumes Service, un serveur Active Directory configuré est utilisé comme serveur Kerberos et serveur LDAP (pour rechercher les identités d'utilisateur à partir d'un schéma compatible RFC2307). Aucun autre serveur Kerberos ou LDAP n'est pris en charge. NetApp vous recommande vivement d'utiliser le protocole LDAP pour la gestion des identités dans Cloud Volumes Service. Pour plus d'informations sur l'affichage de Kerberos sur NFS dans les captures de paquets, reportez-vous à la section <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">Ensuite, chiffrement des données au repos.</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">La sécurité, notamment dans le cloud où l'infrastructure ne contrôle pas les administrateurs du stockage, est primordiale pour faire confiance aux données des offres de services des fournisseurs cloud. Ce document présente les offres de sécurité de NetApp Cloud Volumes Service pour Google Cloud.</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">Tr-4918 : présentation de la sécurité - NetApp Cloud Volumes Service dans Google Cloud</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">Oliver Krause, Justin Parisi, NetApp</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">Étendue du document</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service fournit dans Google Cloud</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">La sécurité, notamment dans le cloud où l'infrastructure ne contrôle pas les administrateurs du stockage, est primordiale pour faire confiance aux données des offres de services des fournisseurs cloud. Ce document présente les offres de sécurité de NetApp<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>.</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Public visé</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">Le public visé par ce document comprend, mais sans s'y limiter, les rôles suivants :</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">Fournisseurs de cloud</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">Administrateurs du stockage</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">Les architectes du stockage</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">Ressources sur site</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">Décideurs de l'entreprise</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">« Contactez-nous. »</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">Pour toute question sur le contenu de ce rapport technique, consultez la section <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">Abréviation</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">Définition</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service, CVS de type de service</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS-Performance</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">Cloud volumes Service, CVS-Performance type de service</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">Ensuite, comment Cloud Volumes Service dans Google Cloud sécurise vos données.</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">Contactez-nous à l'adresse : mailto:doccomments@netapp.com[doccomments@netapp.com^]. Incluez LE RAPPORT TECHNIQUE 4918 dans la ligne d'objet.</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">Solutions NetApp pour les fournisseurs de cloud hyperscale</block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">En savoir plus sur les solutions qui font appel à NetApp pour l'environnement VMware de chacun des hyperscalers : migration des workflows, extension/bursting vers le cloud, sauvegarde/restauration et reprise après incident.</block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">Solutions NetApp pour les environnements VMware</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">Que vous utilisiez un modèle de cloud hybride ou « Cloud First », NetApp propose une large gamme de solutions pour prendre en charge les cas d'utilisation les plus courants pour gérer les charges de travail dans un modèle de cloud ou de cloud hybride.</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">NetApp propose également des solutions pour le stockage provisionné en tant que stockage invité (connecté à l'invité) ou en tant que datastore NFS supplémentaire dans chacun des hyperscalers. Toutes les solutions sont classées en plusieurs catégories avec la classification VMware des charges de travail cloud. Ces classifications comprennent :</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">Pour plus d'informations sur les solutions disponibles pour chaque hyperscaler, consultez la page :</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">Solutions pour AWS/VMC</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">Solutions pour Azure/AVS</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">Solutions pour GCP/GCVE</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="summary">Cette solution requiert une communication réussie du cluster ONTAP sur site vers AWS FSX pour l'interconnexion de cluster NetApp ONTAP afin d'effectuer les opérations SyncMirror. Par ailleurs, un serveur de sauvegarde Veeam doit avoir accès à un compartiment AWS S3. Au lieu d'utiliser le transport Internet, une liaison VPN ou Direct Connect existante peut être utilisée comme liaison privée vers un compartiment S3.</block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">Sur site</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, y compris iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN. ONTAP supporte également les protocoles NFS (v3 et v4.1) et SMB ou S3 pour les connexions invité. Vous pouvez choisir ce qui fonctionne le mieux pour votre environnement et combiner des protocoles en fonction de vos besoins sur un seul système. Par exemple, vous pouvez augmenter l'utilisation générale des datastores NFS en utilisant quelques LUN iSCSI ou des partages invités.</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">Cette solution exploite les datastores NFS pour les datastores sur site pour les disques VMDK invités et iSCSI et NFS pour les données d'applications invité.</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="section-title">Réseaux clients</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">Les ports réseau VMkernel et le réseau Software-defined assurent la connectivité aux hôtes ESXi afin de communiquer avec des éléments externes à l'environnement VMware. La connectivité dépend du type d'interfaces VMkernel utilisées.</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">Pour cette solution, les interfaces VMkernel suivantes ont été configurées :</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">Gestion</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="section-title">Réseaux de stockage provisionnés</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">Une LIF (Logical interface) représente un point d'accès réseau à un nœud du cluster. Cela permet la communication avec les machines virtuelles de stockage qui hébergent les données auxquelles les clients ont accès. Vous pouvez configurer les LIF sur les ports sur lesquels le cluster envoie et reçoit des communications sur le réseau.</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">Pour cette solution, la LIF est configurée pour les protocoles de stockage suivants :</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="section-title">Options de connectivité cloud</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">Les clients disposent de nombreuses options pour connecter leur environnement sur site à des ressources cloud, notamment pour le déploiement de topologies VPN ou Direct Connect.</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="section-title">Réseau privé virtuel (VPN)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">Les VPN (réseaux privés virtuels) sont souvent utilisés pour créer un tunnel IPSec sécurisé avec des réseaux Internet ou MPLS privés. Un VPN est facile à configurer, mais il manque de fiabilité (si basé sur Internet) et de vitesse. Le point final peut être résilié dans le VPC AWS ou dans le SDDC VMware Cloud. Pour cette solution de reprise après incident, nous avons créé la connectivité à AWS FSX pour NetApp ONTAP à partir du réseau sur site. Il peut donc être résilié sur le VPC AWS (Virtual Private Gateway ou Transit Gateway) où FSX pour NetApp ONTAP est connecté.</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">La configuration VPN peut être basée sur une route ou sur des règles. Avec une configuration basée sur une route, les points de terminaison échangent automatiquement les routes et la configuration apprend la route vers les sous-réseaux nouvellement créés. Avec une configuration basée sur des règles, vous devez définir les sous-réseaux locaux et distants et, lorsque de nouveaux sous-réseaux sont ajoutés et autorisés à communiquer dans le tunnel IPSec, vous devez mettre à jour les routes.</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">Si le tunnel VPN IPSec n'est pas créé sur la passerelle par défaut, les routes réseau distantes doivent être définies dans les tables de routage via le point d'extrémité du tunnel VPN local.</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">La figure suivante illustre les options de connexion VPN types.</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="section-title">Connexion directe</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect fournit une liaison dédiée au réseau AWS. Les connexions dédiées créent des liaisons vers AWS à l'aide d'un port Ethernet de 1 Gbits/s, 10 Gbits/s ou 100 Gbits/s. Les partenaires AWS Direct Connect offrent des connexions hébergées via des liaisons réseau établies entre eux et AWS, et sont disponibles de 50 Mbit/s à 10 Gbit/s. Par défaut, le trafic est non chiffré. Toutefois, des options sont disponibles pour sécuriser le trafic avec MACsec ou IPsec. MACsec fournit un cryptage de couche 2 tandis que IPSec fournit un cryptage de couche 3. MACsec fournit une meilleure sécurité en masquant les appareils qui communiquent.</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">Les clients doivent disposer de leur équipement de routeur sur un site AWS Direct Connect. Pour ce faire, vous pouvez travailler avec le réseau de partenaires AWS (APN). Une connexion physique est établie entre ce routeur et le routeur AWS. Pour permettre l'accès à FSX pour NetApp ONTAP sur VPC, vous devez disposer d'une interface virtuelle privée ou d'une interface virtuelle de transit à partir de Direct Connect vers un VPC. Son interface virtuelle privée limite l'évolutivité de la connexion Direct Connect vers VPC.</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">La figure suivante illustre les options de l'interface Direct Connect.</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="section-title">Passerelle de transit</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">Documentation AWS Direct Connect</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">La passerelle de transit est une structure au niveau de la région qui permet une évolutivité accrue d'une connexion Direct Connect-to-VPC dans une région. Si une connexion inter-région est nécessaire, les passerelles de transit doivent être pétrées. Pour plus d'informations, consultez la<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>.</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="section-title">Considérations relatives au réseau cloud</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">Dans le cloud, l'infrastructure réseau sous-jacente est gérée par le fournisseur de services cloud, tandis que les clients doivent gérer les réseaux de VPC, les sous-réseaux, les tables d'acheminement, etc. Ils doivent également gérer les segments de réseau NSX à la périphérie de calcul. Le SDDC regroupe les routes pour le VPC et Transit Connect externe.</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">Lorsque la solution FSX pour NetApp ONTAP avec disponibilité de plusieurs zones de disponibilité est déployée sur un VPC connecté au cloud VMware, le trafic iSCSI reçoit les mises à jour de la table d'acheminement nécessaires pour permettre la communication. Par défaut, aucune route n'est disponible depuis VMware Cloud vers le sous-réseau NFS/SMB ONTAP FSX sur le VPC connecté pour les déploiements en plusieurs zones de disponibilité. Pour définir ce routage, nous avons utilisé le groupe VMware Cloud SDDC, qui est une passerelle de transit gérée par VMware, afin de permettre la communication entre les SDDC VMware Cloud dans la même région, ainsi qu'avec les VPC externes et d'autres passerelles de transit.</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">Des coûts de transfert de données sont associés à l'utilisation d'une passerelle de transit. Pour plus de détails sur les coûts spécifiques à une région, voir<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>.</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">Le déploiement de VMware Cloud SDDC peut s'effectuer dans une zone de disponibilité unique, à l'instar d'un seul data Center. Une option de cluster étendu est également disponible, ce qui ressemble à une solution NetApp MetroCluster qui offre une plus grande disponibilité et réduit les temps d'indisponibilité en cas de défaillance de zone de disponibilité.</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">Pour minimiser les coûts de transfert de données, conservez les instances ou services VMware Cloud SDDC et AWS dans la même zone de disponibilité. Il est préférable de la comparer avec un ID de zone de disponibilité plutôt qu'avec un nom, car AWS fournit la liste de commandes AZ propre au compte afin de répartir la charge entre les zones de disponibilité. Par exemple, un compte (US-East-1a) pourrait indiquer l'ID AZ 1 alors qu'un autre compte (US-East-1c) peut désigner l'ID AZ 1. L'ID de zone de disponibilité peut être récupéré de plusieurs façons. Dans l'exemple suivant, nous avons récupéré l'ID AZ du sous-réseau VPC.</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">Documentation VMware</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">Dans le SDDC VMware Cloud, la gestion du réseau est gérée avec NSX, et la passerelle de périphérie (routeur Tier 0) qui gère le port de liaison ascendante du trafic Nord-Sud est connectée au VPC AWS. La passerelle de calcul et les passerelles de gestion (routeurs de niveau 1) gèrent le trafic est-ouest. Si les ports de liaison ascendante de la périphérie sont utilisés de manière intensive, vous pouvez créer des groupes de trafic à associer à des adresses IP ou des sous-réseaux spécifiques à l'hôte. La création d'un groupe de trafic crée des nœuds de périphérie supplémentaires pour séparer le trafic. Vérifier le<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> Nombre minimal d'hôtes vSphere requis pour utiliser une configuration multi-périphérie.</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">Lorsque vous provisionnez l'SDDC VMware Cloud, les ports VMKernel sont déjà configurés et sont prêts à être utilisés. VMware gère ces ports, sans qu'aucune mise à jour ne soit nécessaire.</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">La figure suivante illustre un exemple d'informations sur le VMKernel de l'hôte.</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="section-title">Réseaux de stockage provisionnés (iSCSI, NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">Pour les réseaux de stockage invités d'ordinateurs virtuels, nous créons généralement des groupes de ports. Avec NSX, nous créons des segments qui sont utilisés sur vCenter en tant que groupes de ports. Comme les réseaux de stockage se trouvent dans un sous-réseau routable, vous pouvez accéder aux LUN ou monter les exportations NFS à l'aide de la carte réseau par défaut, même sans créer de segments de réseau distincts. Pour séparer le trafic de stockage, vous pouvez créer des segments supplémentaires, définir des règles et contrôler la taille de MTU sur ces segments. Pour assurer la tolérance aux pannes, il est préférable d'avoir au moins deux segments dédiés au réseau de stockage. Comme nous l'avons mentionné précédemment, si la bande passante de liaison ascendante devient un problème, vous pouvez créer des groupes de trafic et attribuer des préfixes IP et des passerelles pour effectuer un routage basé sur la source.</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">Nous recommandons de faire correspondre les segments du SDDC de reprise après incident à l'environnement source pour éviter de deviner le mappage de segments de réseau lors du basculement.</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="section-title">Groupes de sécurité</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">De nombreuses options de sécurité offrent une communication sécurisée sur le VPC AWS et le réseau SDDC VMware Cloud. Dans le réseau VMware Cloud SDDC, vous pouvez utiliser le flux de trace de NSX pour identifier le chemin, y compris les règles utilisées. Ensuite, vous pouvez utiliser un analyseur réseau sur le réseau VPC pour identifier le chemin, notamment les tables de routage, les groupes de sécurité et les listes de contrôle d'accès au réseau, qui sont consommées pendant le flux.</block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="summary">Cette solution utilise NetApp SnapCenter pour effectuer des sauvegardes cohérentes au niveau des applications de bases de données SQL Server et Oracle. Associé à Veeam Backup &amp; Replication pour la sauvegarde des VMDK de machines virtuelles, cette solution assure une reprise après incident complète pour les data centers sur site et dans le cloud.</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="section-title">Déploiement de Windows SnapCenter Server sur site</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">Centre de documentation NetApp</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">Le logiciel SnapCenter est disponible sur le site du support NetApp et peut être installé sur les systèmes Microsoft Windows résidant dans un domaine ou un groupe de travail. Un guide de planification détaillé et des instructions d'installation sont disponibles sur le<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>.</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">Le logiciel SnapCenter est disponible à l'adresse<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">Une fois installé, vous pouvez accéder à la console SnapCenter à partir d'un navigateur Web en utilisant _\https://Virtual_Cluster_IP_or_FQDN:8146_.</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="section-title">Ajout de contrôleurs de stockage à SnapCenter</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">Pour ajouter des contrôleurs de stockage à SnapCenter, procédez comme suit :</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">Dans le menu de gauche, sélectionnez systèmes de stockage, puis cliquez sur Nouveau pour lancer le processus d'ajout de vos contrôleurs de stockage à SnapCenter.</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">Dans la boîte de dialogue Ajouter un système de stockage, ajoutez l'adresse IP de gestion du cluster ONTAP local sur site, ainsi que le nom d'utilisateur et le mot de passe. Cliquez ensuite sur Submit pour lancer la détection du système de stockage.</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">Répétez cette procédure pour ajouter le système FSX ONTAP à SnapCenter. Dans ce cas, sélectionnez plus d'options en bas de la fenêtre Add Storage System (Ajouter un système de stockage), puis cliquez sur la case à cocher for Secondary afin de désigner le système FSX comme système de stockage secondaire mis à jour avec les copies SnapMirror ou nos snapshots de sauvegarde primaires.</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">Pour plus d'informations sur l'ajout de systèmes de stockage à SnapCenter, reportez-vous à la documentation à l'adresse<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>.</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="section-title">Ajouter des hôtes à SnapCenter</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">L'étape suivante consiste à ajouter des serveurs d'applications hôtes à SnapCenter. Le processus est similaire pour SQL Server et Oracle.</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">Dans le menu de gauche, sélectionnez hosts, puis cliquez sur Add pour lancer le processus d'ajout de contrôleurs de stockage à SnapCenter.</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">Dans la fenêtre Ajouter des hôtes, ajoutez le type d'hôte, le nom d'hôte et les informations d'identification du système hôte. Sélectionnez le type de plug-in. Pour SQL Server, sélectionnez le plug-in Microsoft Windows et Microsoft SQL Server.</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Pour Oracle, renseignez les champs requis dans la boîte de dialogue Ajouter un hôte et cochez la case du plug-in Oracle Database. Cliquez ensuite sur Envoyer pour lancer le processus de détection et ajouter l'hôte à SnapCenter.</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="section-title">Création de règles SnapCenter</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">Les stratégies définissent les règles spécifiques à suivre pour une tâche de sauvegarde. Notamment le calendrier de sauvegarde, le type de réplication et la manière dont SnapCenter gère la sauvegarde et la troncation des journaux de transactions.</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">Vous pouvez accéder aux stratégies dans la section Paramètres du client Web SnapCenter.</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">Documentation SnapCenter</block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">Pour obtenir des informations complètes sur la création de stratégies pour les sauvegardes SQL Server, reportez-vous à la section<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Pour obtenir des informations complètes sur la création de stratégies pour les sauvegardes Oracle, reportez-vous au<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">*Notes:*</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">Au fur et à mesure que vous progressez dans l'assistant de création de règles, prenez note spéciale de la section réplication. Dans cette section, vous devez spécifier les types de copies SnapMirror secondaires que vous souhaitez effectuer pendant le processus de sauvegarde.</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">Le paramètre « mettre à jour SnapMirror après la création d'une copie Snapshot locale » fait référence à la mise à jour d'une relation SnapMirror lorsqu'il existe entre deux machines virtuelles de stockage résidant sur le même cluster.</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">Le paramètre « Update SnapVault après création d'une copie Snapshot locale » permet de mettre à jour une relation SnapMirror entre deux clusters distincts et entre un système ONTAP sur site et Cloud Volumes ONTAP ou FSxN.</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">L'image suivante montre les options ci-dessus et leur apparence dans l'assistant de stratégie de sauvegarde.</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="section-title">Créer des groupes de ressources SnapCenter</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">Les groupes de ressources vous permettent de sélectionner les ressources de base de données que vous souhaitez inclure dans vos sauvegardes et les stratégies suivies pour ces ressources.</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">Accédez à la section Ressources du menu de gauche.</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">En haut de la fenêtre, sélectionnez le type de ressource à utiliser (dans ce cas, Microsoft SQL Server), puis cliquez sur Nouveau groupe de ressources.</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">La documentation SnapCenter fournit des informations détaillées sur la création de groupes de ressources pour les bases de données SQL Server et Oracle.</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">Pour la sauvegarde des ressources SQL, suivez<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>.</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Pour la sauvegarde des ressources Oracle, suivez<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>.</block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">Solutions multiclouds hybrides NetApp pour AWS/VMC</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="section-title">Compétences et connaissances</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Plusieurs compétences et informations sont nécessaires pour accéder à Cloud Volumes Service pour AWS :</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">Accès et connaissance de votre environnement sur site VMware et ONTAP.</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">Accès à VMware Cloud et AWS, et connaissance de cette solution.</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">L'accès à AWS et Amazon FSX ONTAP et leurs connaissances.</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">Connaissance des ressources SDDC et AWS</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">Connaissance de la connectivité réseau entre vos ressources sur site et cloud.</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">Connaissances approfondies des scénarios de reprise après incident</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">Connaissance pratique des applications déployées sur VMware.</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="section-title">Administration</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">Qu'ils interagissent avec les ressources sur site ou dans le cloud, les utilisateurs et les administrateurs doivent avoir la possibilité et les droits de provisionner ces ressources là où ils en ont besoin, selon leurs autorisations. L'interaction de vos rôles et de vos autorisations pour les systèmes sur site, notamment ONTAP et VMware, ainsi que vos ressources cloud, y compris VMware Cloud et AWS, est essentielle à la réussite du déploiement du cloud hybride.</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">Les tâches d'administration suivantes doivent être en place pour concevoir une solution de reprise après incident avec VMware et ONTAP sur site et VMware Cloud sur AWS et FSX ONTAP.</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">Rôles et comptes permettant de provisionner les éléments suivants :</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">Les ressources de stockage de ONTAP</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">Machines virtuelles VMware, datastores, etc</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">VPC AWS et groupes de sécurité</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">Le provisionnement d'un environnement VMware sur site et d'un environnement ONTAP</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">Environnement cloud VMware</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">Un système de fichiers Amazon pour FSX pour ONTAP</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">Connectivité entre votre environnement sur site et AWS</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">Connectivité pour votre VPC AWS</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">L'environnement virtuel VMware inclut des licences d'hôtes ESXi, de VMware vCenter Server, de réseau NSX et d'autres composants, comme illustré dans la figure suivante. Toutes les licences sont proposées différemment, et il est important de comprendre comment les composants sous-jacents consomment la capacité disponible sous licence.</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="section-title">Hôtes ESXi</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">Dans un environnement VMware, les hôtes de calcul sont déployés avec ESXi. Lorsqu'elle est sous licence avec vSphere sur différents niveaux de capacité, les machines virtuelles peuvent tirer parti des processeurs physiques sur chaque hôte et des fonctionnalités autorisées applicables.</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="section-title">VMware vCenter</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">La gestion des hôtes ESXi et du stockage est l'une des nombreuses fonctionnalités mises à la disposition de l'administrateur VMware avec vCenter Server. À partir de VMware vCenter 7.0, trois éditions de VMware vCenter sont disponibles, en fonction de la licence :</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">VCenter Server Essentials</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">VCenter Server Foundation</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">Standard du serveur vCenter</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="section-title">VMware NSX</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSX fournit aux administrateurs la flexibilité requise pour activer des fonctionnalités avancées. Les fonctions sont activées en fonction de la version de NSX-T Edition sous licence :</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">Professionnel</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">Avancé</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">Bureau distant/succursale</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">Les licences avec NetApp ONTAP désignent la façon dont les administrateurs peuvent accéder à différentes fonctionnalités de stockage. Une licence est un enregistrement d'un ou plusieurs droits logiciels. L'installation de clés de licence, également appelées codes de licence, vous permet d'utiliser certaines fonctionnalités ou services sur votre système de stockage. Par exemple, ONTAP prend en charge tous les principaux protocoles client standard (NFS, SMB, FC, FCoE, iSCSI, Et NVMe/FC) via la licence.</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Les licences de fonctions Data ONTAP sont émises sous forme de packages, chacun contenant plusieurs fonctions ou une seule fonctionnalité. Un package nécessite une clé de licence et l'installation de la clé vous permet d'accéder à toutes les fonctionnalités du package.</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">Les types de licence sont les suivants :</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">*Licence verrouillée par un nœud.* l'installation d'une licence verrouillée par un nœud donne droit à la fonctionnalité sous licence d'un nœud. Pour que le cluster utilise la fonctionnalité sous licence, au moins un nœud doit être sous licence pour la fonctionnalité.</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">*Licence maître/site.* Une licence maître ou site n'est pas liée à un numéro de série de système spécifique. Lorsque vous installez une licence de site, tous les nœuds du cluster ont droit à la fonctionnalité sous licence.</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">*Licence de démonstration/temporaire.* une licence de démonstration ou temporaire expire après un certain temps. Cette licence vous permet d'essayer certaines fonctionnalités logicielles sans avoir à acheter de droits.</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">*Licence de capacité (ONTAP Select et FabricPool uniquement).* une instance ONTAP Select est concédée sous licence en fonction de la quantité de données que l'utilisateur souhaite gérer. À partir de ONTAP 9.4, FabricPool nécessite une licence de capacité pour être utilisée avec un niveau de stockage tiers (par exemple, AWS).</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="section-title">NetApp SnapCenter</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter nécessite plusieurs licences pour permettre les opérations de protection des données. Le type de licence SnapCenter que vous installez dépend de votre environnement de stockage et des fonctionnalités que vous souhaitez utiliser. La licence SnapCenter Standard protège les applications, les bases de données, les systèmes de fichiers et les machines virtuelles. Avant d'ajouter un système de stockage à SnapCenter, vous devez installer une ou plusieurs licences SnapCenter.</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">Pour assurer la protection des applications, des bases de données, des systèmes de fichiers et des machines virtuelles, vous devez disposer d'une licence standard basée sur le contrôleur installée sur votre système de stockage FAS ou AFF, ou d'une licence standard basée sur la capacité, installée sur vos plateformes ONTAP Select et Cloud Volumes ONTAP.</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">Consultez les conditions préalables suivantes à la sauvegarde SnapCenter pour cette solution :</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">Un partage de volume et SMB créé sur le système ONTAP sur site pour localiser la base de données sauvegardée et les fichiers de configuration.</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">Relation SnapMirror entre le système ONTAP sur site et FSX ou CVO dans le compte AWS. Utilisé pour le transport de l'instantané contenant la base de données SnapCenter sauvegardée et les fichiers de configuration.</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">Windows Server installé dans le compte cloud, soit sur une instance EC2, soit sur une VM dans le SDDC VMware Cloud.</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">SnapCenter installé sur l'instance Windows EC2 ou le VM dans VMware Cloud.</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="section-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">Dans le cadre de cette validation, nous utilisons MS SQL pour démontrer la reprise sur incident.</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">Pour plus d'informations sur les meilleures pratiques avec MS SQL et NetApp ONTAP, vous pouvez suivre<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>.</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="section-title">Oracle</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">Dans le cadre de cette validation, nous utilisons ORACLE pour démontrer la reprise sur incident. Pour plus d'informations sur les meilleures pratiques avec ORACLE et NetApp ONTAP, vous pouvez suivre<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>.</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="section-title">Veeam</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">Dans le cadre de cette validation, nous utilisons Veeam pour démontrer la reprise sur incident. Pour plus d'informations sur les meilleures pratiques avec Veeam et NetApp ONTAP, vous trouverez ci-dessous<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>.</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">Vous devez être en mesure d'effectuer les tâches suivantes :</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">Déployer et configurer des services de domaine.</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">Déployez ONTAP FSX en fonction des exigences des applications dans un VPC donné.</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">Configurez le cloud VMware sur la passerelle de calcul AWS pour permettre le trafic depuis FSX ONTAP.</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">Configurez un groupe de sécurité AWS pour permettre la communication entre VMware Cloud sur les sous-réseaux AWS et les sous-réseaux VPC AWS lors du déploiement du service FSX ONTAP.</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="section-title">Cloud VMware</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">Configurer VMware Cloud sur un SDDC AWS</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="section-title">Vérification du compte Cloud Manager</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">Les ressources doivent être déployées avec NetApp Cloud Manager. Pour vérifier que vous pouvez effectuer les tâches suivantes :</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Inscrivez-vous à Cloud Central</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> si ce n'est pas déjà fait.</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Connectez-vous à Cloud Manager</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>.</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">Configurez des espaces de travail et des utilisateurs</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>.</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">Créer un connecteur</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>.</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="section-title">Amazon FSX pour NetApp ONTAP</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">Une fois un compte AWS créé, vous devez pouvoir effectuer la tâche suivante :</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">Créez un utilisateur d'administration IAM capable de provisionner Amazon FSX pour le système de fichiers NetApp ONTAP.</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="section-title">Conditions préalables à la configuration</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">Étant donné les différentes topologies dont les clients disposent, cette section se concentre sur les ports nécessaires pour permettre la communication entre les ressources sur site et dans le cloud.</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="section-title">Points requis pour les ports et le pare-feu</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">Les tableaux suivants décrivent les ports qui doivent être activés dans l'ensemble de votre infrastructure.</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Pour obtenir la liste plus complète des ports requis pour le logiciel Veeam Backup &amp; Replication, suivez ces instructions<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>.</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">Pour obtenir une liste plus complète des ports requis pour SnapCenter, suivez la<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>.</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">Le tableau suivant répertorie la configuration requise pour les ports Veeam pour Microsoft Windows Server.</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">De</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">À</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">Protocole</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">Port</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">Remarques</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">Serveur de sauvegarde</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Serveur Microsoft Windows</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Port requis pour le déploiement des composants Veeam Backup &amp; Replication.</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">Proxy de sauvegarde</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Port par défaut utilisé par le service Veeam installer.</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">Référentiel de sauvegarde</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500 à 3500</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">Plage par défaut de ports utilisés comme canaux de transmission de données et pour la collecte de fichiers journaux.</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">Montez le serveur</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Port par défaut utilisé par le Data Mover Veeam.</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">Pour chaque connexion TCP utilisée par un travail, un port de cette plage est affecté.</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">Le tableau suivant répertorie la configuration requise pour les ports Veeam pour Linux Server.</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Serveur Linux</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">Port utilisé comme canal de contrôle de la console vers l'hôte Linux cible.</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">Le tableau suivant répertorie la configuration requise pour le port de Veeam Backup Server.</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS, TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">Port par défaut utilisé pour les connexions à vCenter Server. Port utilisé comme canal de contrôle de la console vers l'hôte Linux cible.</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Microsoft SQL Server hébergeant la base de données de configuration Veeam Backup &amp; Replication</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Port utilisé pour la communication avec Microsoft SQL Server sur lequel la base de données de configuration Veeam Backup &amp; Replication est déployée (si vous utilisez une instance par défaut de Microsoft SQL Server).</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">Serveur DNS avec résolution de nom de tous les serveurs de sauvegarde</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">Port utilisé pour la communication avec le serveur DNS</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">Si vous utilisez vCloud Director, veillez à ouvrir le port 443 sur les serveurs vCenter sous-jacents.</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">Le tableau suivant répertorie la configuration requise pour le port de Veeam Backup Proxy.</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">Port par défaut utilisé par le service d'intégration Veeam Backup VSS pour créer un snapshot VSS au cours de la sauvegarde de partage de fichiers SMB.</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">Port de service Web VMware par défaut pouvant être personnalisé dans les paramètres de vCenter.</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">Le tableau suivant répertorie les exigences en matière de ports SnapCenter.</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">Type de port</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">Port de gestion SnapCenter</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">Ce port est utilisé pour la communication entre le client SnapCenter (l'utilisateur SnapCenter) et le serveur SnapCenter. Utilisé également pour la communication entre les hôtes du plug-in et le serveur SnapCenter.</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">Port de communication SMCore de SnapCenter</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">Ce port est utilisé pour la communication entre le serveur SnapCenter et les hôtes sur lesquels les plug-ins SnapCenter sont installés.</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Hôtes du plug-in Windows, installation</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135 février 445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">Ces ports sont utilisés pour la communication entre le serveur SnapCenter et l'hôte sur lequel le plug-in est installé. Les orifices peuvent être fermés après l'installation. De plus, Windows Instrumentation Services recherche les ports 49152 à 65535, qui doivent être ouverts.</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Hôtes de plug-in Linux, installation</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">Ces ports sont utilisés pour la communication entre le serveur SnapCenter et l'hôte sur lequel le plug-in est installé. Les ports sont utilisés par SnapCenter pour copier les binaires du package vers les hôtes du plug-in Linux.</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">Package de plug-ins SnapCenter pour Windows/Linux</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">Ce port est utilisé pour la communication entre SMCore et les hôtes sur lesquels les plug-ins SnapCenter sont installés.</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">Port du serveur VMware vSphere vCenter</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">Ce port est utilisé pour la communication entre le plug-in SnapCenter pour VMware vSphere et le serveur vCenter.</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">Plug-in SnapCenter pour port VMware vSphere</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">Ce port est utilisé pour les communications à partir du client Web vCenter vSphere et du serveur SnapCenter.</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="doc">Sauvegarde des bases de données SnapCenter pour la reprise après incident</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter permet la sauvegarde et la récupération de sa base de données MySQL sous-jacente et des données de configuration afin de restaurer le serveur SnapCenter en cas d'incident. Pour notre solution, nous avons restauré la base de données et la configuration d'SnapCenter sur une instance EC2 AWS résidant sur notre VPC. Pour plus d'informations sur cette étape, reportez-vous à la section<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>.</block>
  <block id="46137d274838eaef40c110eac160dabc" category="section-title">Conditions préalables à la sauvegarde SnapCenter</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">Les prérequis suivants sont requis pour la sauvegarde SnapCenter :</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">Un partage de volume et SMB créé sur le système ONTAP sur site pour localiser la base de données et les fichiers de configuration sauvegardés.</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">Relation SnapMirror entre le système ONTAP sur site et FSX ou CVO dans le compte AWS. Cette relation est utilisée pour le transport de l'instantané contenant la base de données SnapCenter sauvegardée et les fichiers de configuration.</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="section-title">Récapitulatif du processus de sauvegarde et de restauration SnapCenter</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">Créez un volume sur le système ONTAP sur site pour héberger les fichiers de base de données de sauvegarde et de configuration.</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">Configurer une relation SnapMirror entre le site et FSX/CVO.</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">Montez le partage SMB.</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">Récupérez le jeton d'autorisation de swagger pour effectuer des tâches API.</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">Démarrez le processus de restauration de la base de données.</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">Utilisez l'utilitaire xcopy pour copier le répertoire local du fichier de base de données et de configuration dans le partage SMB.</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">Sur la plateforme FSX, créez un clone du volume ONTAP (copié via SnapMirror depuis sur site).</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">Montez le partage SMB de FSX vers le cloud EC2/VMware.</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">Copiez le répertoire de restauration du partage SMB dans un répertoire local.</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">Exécutez le processus de restauration de SQL Server à partir de swagger.</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="section-title">Sauvegarder la base de données et la configuration de SnapCenter</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter fournit une interface client Web pour l'exécution des commandes de l'API REST. Pour plus d'informations sur l'accès aux API REST via swagger, consultez la documentation SnapCenter à l'adresse<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>.</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="section-title">Connectez-vous à swagger et obtenez le jeton d'autorisation</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Une fois que vous avez navigué vers la page swagger, vous devez récupérer un jeton d'autorisation pour lancer le processus de restauration de la base de données.</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">Accédez à la page Web de l'API SnapCenter swagger à l'adresse _\https://&lt;SnapCenter Server IP&gt;:8146/swagger/_.</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">Développez la section Auth et cliquez sur le bouton essayer.</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">Dans la zone UserOperationContext, renseignez les informations d'identification et le rôle SnapCenter, puis cliquez sur Exécuter.</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">Dans le corps de réponse ci-dessous, vous pouvez voir le jeton. Copiez le texte du token pour l'authentification lors de l'exécution du processus de sauvegarde.</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="section-title">Effectuez une sauvegarde de base de données SnapCenter</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">Passez ensuite à la zone de reprise sur incident de la page swagger pour lancer le processus de sauvegarde SnapCenter.</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">Développez la zone de reprise après sinistre en cliquant dessus.</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">Développez le<block ref="ff68c70c197c21bcd2eda286f1ff14b6" prefix=" " category="inline-code"></block> Et cliquez sur essayer.</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">Dans la section SmDRBackupRequest, ajoutez le chemin cible local correct et sélectionnez Exécuter pour lancer la sauvegarde de la base de données et de la configuration SnapCenter.</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">Le processus de sauvegarde ne permet pas de sauvegarder directement les données sur un partage de fichiers NFS ou CIFS.</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="section-title">Surveillez la procédure de sauvegarde depuis SnapCenter</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">Connectez-vous à SnapCenter pour consulter les fichiers journaux au démarrage du processus de restauration de la base de données. Dans la section moniteur, vous pouvez afficher les détails de la sauvegarde de reprise après incident du serveur SnapCenter.</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="section-title">Utilisez l'utilitaire XCOPY pour copier le fichier de sauvegarde de la base de données dans le partage SMB</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">Vous devez ensuite déplacer la sauvegarde du disque local du serveur SnapCenter vers le partage CIFS utilisé pour copier les données dans l'emplacement secondaire situé sur l'instance FSX d'AWS. Utilisez xcopy avec des options spécifiques qui conservent les autorisations des fichiers.</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">Ouvrez une invite de commande en tant qu'administrateur. Dans l'invite de commande, entrez les commandes suivantes :</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">Un plan et un environnement de reprise après incident éprouvés sont essentiels pour les entreprises pour garantir la restauration rapide des applications stratégiques en cas de panne majeure. Cette solution a été axée sur une démonstration de cas d'utilisation de reprise après incident en mettant l'accent sur les technologies VMware et NetApp, à la fois sur site et avec VMware Cloud sur AWS.</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">Tr-4931 : reprise après incident avec VMware Cloud sur Amazon Web Services et Guest Connect</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp dispose d'une longue expérience de l'intégration avec VMware, comme le prouvent les dizaines de milliers de clients qui ont choisi NetApp comme partenaire de stockage pour leur environnement virtualisé. Cette intégration continue également avec les options connectées à l'invité dans le cloud et les intégrations récentes avec les datastores NFS. Cette solution est axée sur l'utilisation communément appelée stockage connecté à l'invité.</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">Dans le cas d'un stockage connecté à l'invité, le VMDK invité est déployé sur un datastore provisionné par VMware. Les données d'application sont hébergées sur iSCSI ou NFS et mappées directement à la machine virtuelle. Les applications Oracle et MS SQL sont utilisées pour démontrer un scénario de reprise sur incident, comme illustré dans la figure suivante.</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">Fonctionnalités NetApp pour AWS VMC</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">En savoir plus sur les fonctionnalités que NetApp propose à AWS VMware Cloud (VMC) : de NetApp en tant que système de stockage connecté à l'invité ou un datastore NFS supplémentaire pour migrer les flux de travail, étendre/bursting sur le cloud, la sauvegarde/restauration et la reprise après incident.</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="inline-link-macro">Configuration de VMC dans AWS</block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="inline-link-macro">Options de stockage NetApp pour VMC</block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">Afficher les détails <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>.</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">Le stockage NetApp peut être utilisé de plusieurs façons - soit en tant que connexion soit en tant que datastore NFS supplémentaire - dans AWS VMC.</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">Afficher les détails <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>. Afficher les détails <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>.</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">Avec les solutions clouds NetApp et VMware, vous pouvez facilement déployer de nombreux cas d'utilisation dans votre système AWS VMC. Des cas d'utilisation sont définis pour chaque domaine de cloud défini par VMware :</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">Découvrez les solutions NetApp pour AWS VMC</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">Déploiement et configuration de l'environnement de virtualisation sur AWS</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">Comme sur site, la planification de VMware Cloud sur AWS est cruciale pour la réussite d'un environnement prêt à la production à créer des machines virtuelles et à migrer.</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">Le stockage invité est actuellement la seule méthode prise en charge pour connecter Cloud Volumes ONTAP (CVO) à AWS VMC.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="example-title">Déploiement et configuration de VMware Cloud pour AWS</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> Offre une expérience cloud native pour les charges de travail VMware dans l'écosystème AWS. Chaque SDDC (VMware Software-Defined Data Center) s'exécute dans un Amazon Virtual Private Cloud (VPC) et offre une pile VMware complète (y compris vCenter Server), la mise en réseau Software-defined NSX-T, le stockage Software-defined VSAN et un ou plusieurs hôtes ESXi qui fournissent des ressources de calcul et de stockage à vos charges de travail.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">Cette section décrit comment configurer et gérer VMware Cloud sur AWS et l'utiliser en association avec Amazon FSX pour NetApp ONTAP et/ou Cloud Volumes ONTAP sur AWS avec un système de stockage invité.</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">Créez un compte AWS</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">Compte Amazon Web Services</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="paragraph">S'inscrire pour obtenir un <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">Vous avez besoin d'un compte AWS pour démarrer, à condition qu'il n'y en ait pas encore créé. Nouveau ou existant, vous avez besoin de privilèges d'administration dans le compte pour de nombreuses étapes de cette procédure. Voir ceci <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> Pour plus d'informations sur les identifiants AWS.</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">Créez un compte My VMware</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">Mon infrastructure VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="paragraph">S'inscrire à un <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> compte.</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">Pour accéder au portefeuille cloud de VMware (y compris VMware Cloud sur AWS), vous avez besoin d'un compte client VMware ou d'un compte My VMware. Si ce n'est déjà fait, créez un compte VMware <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="example-title">Provisionner le SDDC dans VMware Cloud</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">Une fois le compte VMware configuré et le dimensionnement approprié effectués, le déploiement d'un Software-Defined Data Center constitue l'étape suivante évidente pour l'utilisation du service VMware Cloud sur AWS. Pour créer un SDDC, choisissez une région AWS qui l'héberge, donnez un nom au SDDC et spécifiez le nombre d'hôtes ESXi que vous souhaitez que le SDDC contienne. Si vous ne possédez pas encore de compte AWS, vous pouvez toujours créer un SDDC de configuration de démarrage contenant un hôte ESXi unique.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">Connectez-vous à VMware Cloud Console à l'aide de vos informations d'identification VMware existantes ou nouvellement créées.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">Configurer la région, le déploiement, le type d'hôte et le nom du SDDC :</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">Vous connecter au compte AWS souhaité et exécuter la pile AWS Cloud formation.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">La configuration à hôte unique est utilisée dans cette validation.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">Sélectionnez le VPC AWS souhaité pour connecter l'environnement VMC à.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">Configurez le sous-réseau de gestion VMC ; ce sous-réseau contient des services gérés par VMC tels que vCenter, NSX, etc. Ne choisissez pas un espace d'adressage qui se chevauchent avec les autres réseaux qui nécessitent une connexion à l'environnement SDDC. Enfin, suivez les recommandations relatives à la taille du CIDR indiquée ci-dessous.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">Examinez et acceptez la configuration SDDC, puis cliquez sur déployer le SDDC.</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">Le processus de déploiement prend généralement entre deux heures.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">Une fois cette opération terminée, le SDDC est prêt à l'emploi.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">Déployer un SDDC depuis la console VMC</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">Pour un guide détaillé de déploiement d'un SDDC, consultez la section <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">Pour connecter VMware Cloud à FSX ONTAP, procédez comme suit :</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">Une fois le déploiement de VMware Cloud terminé et connecté à AWS VPC, vous devez déployer Amazon FSX pour NetApp ONTAP dans un nouveau VPC plutôt que le VPC initial connecté (voir la capture d'écran ci-dessous). FSX (IP flottantes NFS et SMB) n'est pas accessible s'il est déployé sur le VPC connecté. Gardez à l'esprit que les terminaux ISCSI tels que Cloud Volumes ONTAP fonctionnent correctement du VPC connecté.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">Déployez un VPC supplémentaire dans la même région, puis déployez Amazon FSX pour NetApp ONTAP dans le nouveau VPC.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">La configuration d'un groupe SDDC dans la console VMware Cloud permet d'utiliser les options de configuration réseau requises pour se connecter au nouveau VPC où FSX est déployé. À l'étape 3, vérifiez que "la configuration de VMware Transit Connect pour votre groupe entraînera des frais par pièce jointe et transfert de données" est cochée, puis choisissez Créer un groupe. Ce processus peut prendre quelques minutes.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">Instructions pour connecter un VPC externe</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">Reliez le nouveau VPC créé au groupe SDDC juste créé. Sélectionnez l'onglet VPC externe et suivez la <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> au groupe. Ce processus peut prendre entre 10 et 15 minutes.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">Passerelle AWS Transit</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">Dans le cadre du processus VPC externe, vous êtes invité par le biais de la console AWS à accéder à une nouvelle ressource partagée via Resource Access Manager. La ressource partagée est le <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> Géré par VMware Transit Connect.</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Créez la pièce jointe de la passerelle de transit.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">De retour sur la console VMC, acceptez la connexion VPC. Ce processus peut prendre environ 10 minutes.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">Dans l'onglet VPC externe, cliquez sur l'icône Modifier dans la colonne routes et ajoutez les routes requises suivantes :</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">Adresses IP flottantes</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">Route pour la plage IP flottante pour Amazon FSX pour NetApp ONTAP <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Route pour la plage IP flottante pour Cloud Volumes ONTAP (le cas échéant).</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">Route pour l'espace d'adresse VPC externe récemment créé.</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">règles de pare-feu</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">étapes détaillées</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">Enfin, autoriser le trafic bidirectionnel <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> Pour l'accès à FSX/CVO. Suivez-les <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> Pour le calcul des règles de pare-feu de passerelle pour la connectivité de charge de travail SDDC.</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">Une fois les groupes de pare-feu configurés pour la passerelle de gestion et de calcul, vCenter est accessible de la manière suivante :</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">L'étape suivante consiste à vérifier que Amazon FSX ONTAP ou Cloud Volumes ONTAP est configuré en fonction de vos besoins et que les volumes sont provisionnés pour décharger les composants de stockage de VSAN afin d'optimiser le déploiement.</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">Disponibilité de région : datastore NFS supplémentaire pour VMC</block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">Option supplémentaire de datastore NFS dans AWS</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">Une fois VMware Cloud prêt et connecté à AWS VPC, vous devez déployer Amazon FSX pour NetApp ONTAP dans un nouveau VPC désigné plutôt que le VPC d'origine connecté ou existant.</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">Configuration d'un groupe SDDC dans le Cloud VMware</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">Pour commencer, déployez un VPC supplémentaire dans la même région et zone de disponibilité où réside le SDDC, puis déployez Amazon FSX pour NetApp ONTAP dans le nouveau VPC.<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> La console permet d'utiliser les options de configuration réseau requises pour se connecter au VPC nouvellement désigné où FSX pour ONTAP sera déployé.</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">Déployez la solution FSX pour ONTAP et bénéficiez de la même disponibilité que celle de VMware Cloud sur AWS SDDC.</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">Vous ne pouvez pas déployer FSX pour ONTAP dans le VPC connecté. Vous devez au contraire le déployer dans un nouveau VPC désigné, puis connecter le VPC à une passerelle de transit gérée VMware (vTGW) via des groupes SDDC.</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">Étape 1 : création d'Amazon FSX pour ONTAP dans un nouveau VPC désigné</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">Pour créer et monter le système de fichiers Amazon FSX pour NetApp ONTAP, effectuez la procédure suivante :</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">Ouvrez la console Amazon FSX à l'adresse<block ref="3cac88c5e8406527329e138d581346fe" prefix=" " category="inline-code"></block> Et choisissez *Créer système de fichiers* pour démarrer l'assistant *création de système de fichiers*.</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">Sur la page Select File System Type (Sélectionner un type de système de fichiers), sélectionnez *Amazon FSX pour NetApp ONTAP*, puis cliquez sur *Next* (Suivant). La page *Créer un système de fichiers* s'affiche.</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">Pour la méthode de création, choisissez *création standard*.</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">La taille du datastore varie légèrement d'un client à l'autre. Bien que le nombre recommandé de machines virtuelles par datastore NFS soit subjectif, de nombreux facteurs déterminent le nombre optimal de machines virtuelles qui peuvent être placées sur chaque datastore. Si la plupart des administrateurs ne considèrent que la capacité, le volume d'E/S simultanées envoyées au VMDK est l'un des facteurs les plus importants pour les performances globales. Utilisez les statistiques de performances sur site pour dimensionner les volumes du datastore en conséquence.</block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">Dans la section *Networking* pour le Cloud privé virtuel (VPC), choisissez le VPC et les sous-réseaux préférés appropriés ainsi que la table de routage. Dans ce cas, Demo- FSxforONTAP-VPC est sélectionné dans le menu déroulant.</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">Assurez-vous qu'il s'agit d'un nouveau VPC désigné et non du VPC connecté.</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">Par défaut, FSX pour ONTAP utilise 198.19.0.0/16 comme plage d'adresses IP de point de terminaison par défaut pour le système de fichiers. Assurez-vous que la plage d'adresse IP du terminal ne entre pas en conflit avec le VMC du SDDC AWS, les sous-réseaux VPC associés et l'infrastructure sur site. Si vous n'êtes pas certain, utilisez une plage non chevauchante sans conflit.</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">Dans la section *sécurité et chiffrement* pour la clé de chiffrement, choisissez la clé de chiffrement AWS Key Management Service (KMS AWS) qui protège les données du système de fichiers au repos. Pour le mot de passe d'administration *système de fichiers*, entrez un mot de passe sécurisé pour l'utilisateur fsxadmin.</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">Dans la section *default Storage Virtual machine Configuration*, spécifiez le nom de la SVM.</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">Dans la version GA, quatre datastores NFS sont pris en charge.</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">Dans la section *Configuration du volume par défaut*, spécifiez le nom et la taille du volume requis pour le datastore et cliquez sur *Suivant*. Il doit s'agir d'un volume NFSv3. Pour *efficacité du stockage*, choisissez *Enabled* pour activer les fonctionnalités d'efficacité du stockage ONTAP (compression, déduplication et compaction). Après la création, utilisez le shell pour modifier les paramètres du volume en utilisant *_volume modify_* comme suit :</block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">Réglage</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">Garantie de volume (style de garantie d'espace)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">Aucune (provisionnement fin) – défini par défaut</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">fractional_reserve (réserve fractionnaire)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0% – défini par défaut</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve (pourcentage-snapshot-space)</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0 %</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">Dimensionnement automatique (mode taille automatique)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Activé – défini par défaut</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">Suppression automatique</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">volume / plus ancien_en premier</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">Règle de Tiering du volume</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">Snapshot uniquement : définis par défaut</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">essayez_first</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">Croissance automatique</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">Règle Snapshot</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">Utiliser la commande SSH suivante pour créer et modifier des volumes :</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">*Commande permettant de créer un nouveau volume de datastore à partir du shell :*</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">*Remarque :* les volumes créés via shell prendront quelques minutes pour s'afficher dans la console AWS.</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">*Commande permettant de modifier les paramètres de volume qui ne sont pas définis par défaut :*</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">Lors du scénario de migration initial, la stratégie de snapshot par défaut peut entraîner des problèmes de capacité du datastore saturée. Pour la surmonter, modifiez la stratégie de snapshots en fonction des besoins.</block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">Vérifiez la configuration du système de fichiers indiquée sur la page *Créer un système de fichiers*.</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">Cliquez sur *Créer un système de fichiers*.</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">Répétez les étapes précédentes pour créer d'autres systèmes de fichiers ou machines virtuelles de stockage et les volumes du datastore en fonction des besoins en termes de capacités et de performances.</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link">Performances d'Amazon FSX pour NetApp ONTAP</block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">Pour en savoir plus sur les performances d'Amazon FSX pour ONTAP, consultez<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>.</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">Étape 2 : créer un groupe SDDC</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">Une fois les systèmes de fichiers et les SVM créés, utilisez VMware Console pour créer un groupe SDDC et configurer VMware Transit Connect. Pour ce faire, effectuez la procédure suivante et n'oubliez pas que vous devez naviguer entre VMware Cloud Console et la console AWS.</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">Connectez-vous à la console VMC à<block ref="80524a1862c565bfe10233035e45c5b3" prefix=" " category="inline-code"></block>.</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">Sur la page *Inventory*, cliquez sur *SDDC Groups*.</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">Dans l'onglet *SDDC Groups*, cliquez sur *ACTIONS* et sélectionnez *Create SDDC Group*. Pour des raisons de démonstration, le groupe SDDC est appelé<block ref="a34cf36b08316aadda6e1c15679a89f8" prefix=" " category="inline-code"></block>.</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">Dans la grille adhésion, sélectionnez les SDDC à inclure en tant que membres du groupe.</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">Vérifiez que "la configuration de VMware Transit Connect pour votre groupe entraînera des frais par pièce jointe et transfert de données" est cochée, puis sélectionnez *Create Group*. Ce processus peut prendre quelques minutes.</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">Étape 3 : configurer VMware Transit Connect</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">Instructions pour connecter un VPC externe au groupe</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">Reliez le nouveau VPC désigné au groupe SDDC. Sélectionnez l'onglet *VPC externe* et suivez la<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>. Ce processus peut prendre 10-15 minutes.</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">Cliquez sur *Ajouter un compte*.</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">Indiquez le compte AWS utilisé pour provisionner le système de fichiers FSX pour ONTAP.</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">Cliquez sur *Ajouter*.</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">Dans la console AWS, connectez-vous au même compte AWS et accédez à la page du service *Resource Access Manager*. Un bouton vous permet d'accepter le partage de ressources.</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">Dans le cadre du processus VPC externe, vous serez invité, via la console AWS, à accéder à une nouvelle ressource partagée via Resource Access Manager. La ressource partagée est la passerelle AWS Transit Gateway gérée par VMware Transit Connect.</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">Cliquez sur *accepter le partage de ressources*.</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">De retour dans la console VMC, vous voyez maintenant que le VPC externe est dans un état associé. L'affichage peut prendre plusieurs minutes.</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">Étape 4 : création d'une connexion de passerelle de transit</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">Dans la console AWS, accédez à la page de service VPC et naviguez jusqu'au VPC utilisé pour provisionner le système de fichiers FSX. Ici, vous créez une pièce jointe de passerelle de transit en cliquant sur *Transit Gateway Attachment* dans le volet de navigation à droite.</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">Sous *VPC Attachment*, vérifiez que la prise en charge DNS est cochée et sélectionnez le VPC dans lequel FSX pour ONTAP a été déployé.</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">Cliquez sur *Créer* *connexion passerelle de transit*.</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">À nouveau dans VMware Cloud Console, retournez à SDDC Group &gt; onglet VPC externe. Sélectionnez l'ID de compte AWS utilisé pour FSX, puis cliquez sur le VPC et cliquez sur *Accept*.</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">Cette option peut prendre plusieurs minutes pour s'afficher.</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">Dans l'onglet *VPC externe* de la colonne *routes*, cliquez sur l'option *Ajouter routes* et ajoutez les routes requises :</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">Route pour la plage IP flottante pour Amazon FSX pour les adresses IP flottantes ONTAP NetApp.</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">Étape 5 : configurer le routage (AWS VPC et SDDC) et les groupes de sécurité</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">Dans la console AWS, créez la route à nouveau vers le SDDC en localisant le VPC dans la page de service VPC et en sélectionnant la table *main* route pour le VPC.</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">Naviguez jusqu'à la table de routage dans le panneau inférieur et cliquez sur *Modifier les routes*.</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">Dans le panneau *Edit routes*, cliquez sur *Add route* et entrez le CIDR pour l'infrastructure SDDC en sélectionnant *Transit Gateway* et l'ID TGW associé. Cliquez sur *Enregistrer les modifications*.</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">L'étape suivante consiste à vérifier que le groupe de sécurité du VPC associé est mis à jour avec les règles entrantes correctes pour le CIDR SDDC Group.</block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="list-text">Mettre à jour la règle entrante avec le bloc CIDR de l'infrastructure SDDC.</block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">Vérifiez que la table de routage VPC (où réside FSX pour ONTAP) est mise à jour pour éviter les problèmes de connectivité.</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">Mettez à jour le groupe de sécurité pour accepter le trafic NFS.</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">Il s'agit de la dernière étape de préparation de la connectivité au SDDC approprié. Le système de fichiers étant configuré, les routes ajoutées et les groupes de sécurité mis à jour, il est temps de monter le ou les datastores.</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">Étape 6 : relier un volume NFS comme datastore au cluster SDDC</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">Une fois le système de fichiers provisionné et la connectivité en place, accédez à VMware Cloud Console pour monter le datastore NFS.</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">Dans la console VMC, ouvrez l'onglet *Storage* du SDDC.</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">Cliquez sur *ATTACHER DATASTORE* et remplissez les valeurs requises.</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">L'adresse du serveur NFS est l'adresse IP NFS qui peut être trouvée sous l'onglet FSX &gt; machines virtuelles de stockage &gt; noeuds finaux dans la console AWS.</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">Cliquez sur *ATTACH DATASTORE* pour relier le datastore au cluster.</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">Valider le datastore NFS en accédant à vCenter comme indiqué ci-dessous :</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="498fdd311192093265ba745435fc1476" category="doc">Déploiement et configuration de Veeam Backup Server</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Documentation technique sur le centre d'assistance Veeam</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">Le logiciel Veeam Backup &amp; Replication est utilisé dans la solution pour sauvegarder nos machines virtuelles d'applications et archiver une copie des sauvegardes dans un compartiment Amazon S3 à l'aide d'un référentiel de sauvegarde scale-out Veeam. Veeam est déployé sur un serveur Windows dans cette solution. Pour des conseils spécifiques sur le déploiement de Veeam, reportez-vous au<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>.</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="section-title">Configurez un référentiel de sauvegarde scale-out Veeam</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">Une fois que vous avez déployé et sous licence le logiciel, vous pouvez créer un référentiel de sauvegarde scale-out (SOBR) en tant que stockage cible pour les tâches de sauvegarde. Vous devez également inclure un compartiment S3 comme sauvegarde des données de machines virtuelles hors site pour la reprise après incident.</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">Consultez les conditions préalables suivantes avant de commencer.</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">Créez un partage de fichiers SMB sur votre système ONTAP sur site en tant que stockage cible pour les sauvegardes.</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">Créez un compartiment Amazon S3 à inclure dans le volume de stockage. Il s'agit d'un référentiel pour les sauvegardes hors site.</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="section-title">Ajout du stockage ONTAP à Veeam</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">Tout d'abord, ajoutez le cluster de stockage ONTAP et le système de fichiers SMB/NFS associé en tant qu'infrastructure de stockage dans Veeam.</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Ouvrez la console Veeam et connectez-vous. Accédez à Storage Infrastructure, puis sélectionnez Add Storage.</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">Dans l'assistant d'ajout de stockage, sélectionnez NetApp comme fournisseur de stockage, puis sélectionnez Data ONTAP.</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">Entrez l'adresse IP de gestion et cochez la case filer NAS. Cliquez sur Suivant.</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">Ajoutez vos identifiants pour accéder au cluster ONTAP.</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">Sur la page NAS Filer, choisissez les protocoles à analyser et sélectionnez Suivant.</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">Complétez les pages appliquer et Résumé de l'assistant et cliquez sur Terminer pour lancer le processus de détection du stockage. Une fois le scan terminé, on ajoute le cluster ONTAP ainsi que les filers NAS en tant que ressources disponibles.</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">Créez un référentiel de sauvegarde à l'aide des partages NAS récemment découverts. Dans Backup Infrastructure, sélectionnez Sauvegarder les référentiels et cliquez sur l'élément de menu Ajouter un référentiel.</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Documentation Veeam</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">Suivez toutes les étapes de l'Assistant Nouveau référentiel de sauvegarde pour créer le référentiel. Pour plus d'informations sur la création des référentiels de sauvegarde Veeam, consultez le<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>.</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="section-title">Ajoutez le compartiment Amazon S3 en tant que référentiel de sauvegarde</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">L'étape suivante consiste à ajouter le stockage Amazon S3 en tant que référentiel de sauvegarde.</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">Accédez à Backup Infrastructure &gt; référentiels de sauvegarde. Cliquez sur Ajouter un référentiel.</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">Dans l'assistant Ajouter un référentiel de sauvegarde, sélectionnez stockage objet, puis Amazon S3. L'assistant Nouveau référentiel de stockage objet démarre.</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">Fournissez un nom pour votre référentiel de stockage objet et cliquez sur Next (Suivant).</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">Dans la section suivante, indiquez vos identifiants. Vous avez besoin d'une clé d'accès et d'une clé secrète AWS.</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Une fois la configuration Amazon chargée, choisissez votre data Center, votre compartiment et votre dossier, puis cliquez sur « Apply » (appliquer). Enfin, cliquez sur Terminer pour fermer l'assistant.</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="section-title">Création d'un référentiel de sauvegarde scale-out</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">Maintenant que nous avons ajouté nos référentiels de stockage à Veeam, nous pouvons créer la solution SOBR afin de hiérarchiser automatiquement les copies de sauvegarde dans notre stockage objet Amazon S3 hors site pour la reprise après incident.</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">Dans l'infrastructure de sauvegarde, sélectionnez référentiels scale-out, puis cliquez sur l'élément de menu Ajouter un référentiel scale-out.</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">Dans le nouveau référentiel de sauvegarde scale-out, indiquez un nom pour le SOBR et cliquez sur Suivant.</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">Pour le niveau de performances, choisissez le référentiel de sauvegarde contenant le partage SMB résidant sur votre cluster ONTAP local.</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">Pour la stratégie de placement, choisissez l'emplacement des données ou les performances en fonction de vos besoins. Sélectionnez Next (Suivant).</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">Pour le niveau de capacité, nous avons étendu la solution SOBR avec le stockage objet Amazon S3. Pour les besoins de reprise après incident, sélectionnez Copier les sauvegardes vers le stockage objet dès leur création afin de fournir nos sauvegardes secondaires dans les délais.</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">Enfin, sélectionnez appliquer et Terminer pour finaliser la création du SOBR.</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="section-title">Création des tâches de référentiel de sauvegarde scale-out</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Documentation technique du centre d'aide Veeam</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">La dernière étape de configuration de Veeam consiste à créer des tâches de sauvegarde en utilisant le SOBR nouvellement créé comme destination de sauvegarde. La création de travaux de sauvegarde fait partie intégrante du répertoire de tout administrateur de stockage et nous ne abordons pas les étapes détaillées ici. Pour plus d'informations sur la création de tâches de sauvegarde dans Veeam, consultez le<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="doc">Restauration des VM applications grâce à la restauration complète Veeam</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="section-title">Création d'un référentiel de sauvegardes et importation des sauvegardes à partir de S3</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">Depuis le serveur Veeam secondaire, importez les sauvegardes depuis le stockage S3 et restaurez les machines virtuelles SQL Server et Oracle sur votre cluster VMware Cloud.</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">Pour importer les sauvegardes à partir de l'objet S3 inclus dans le référentiel de sauvegarde scale-out sur site, procédez comme suit :</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">Accédez aux référentiels de sauvegarde et cliquez sur Ajouter un référentiel dans le menu supérieur pour lancer l'assistant Ajouter un référentiel de sauvegarde. Sur la première page de l'assistant, sélectionnez stockage objet comme type de référentiel de sauvegarde.</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">Sélectionnez Amazon S3 comme type de stockage objet.</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">Dans la liste d'Amazon Cloud Storage Services, sélectionnez Amazon S3.</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">Sélectionnez vos identifiants pré-saisis dans la liste déroulante ou ajoutez de nouvelles informations d'identification pour accéder à la ressource de stockage cloud. Cliquez sur Suivant pour continuer.</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">Sur la page compartiment, entrez le data Center, le compartiment, le dossier et les options souhaitées. Cliquez sur appliquer.</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">Enfin, sélectionnez Terminer pour terminer le processus et ajouter le référentiel.</block>
  <block id="076951b7756435f95654310ef960f866" category="section-title">Importation des sauvegardes à partir du stockage objet S3</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">Pour importer les sauvegardes à partir du référentiel S3 ajouté à la section précédente, procédez comme suit.</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">Dans le référentiel de sauvegardes S3, sélectionnez Importer les sauvegardes pour lancer l'assistant Importer les sauvegardes.</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">Une fois les enregistrements de la base de données pour l'importation créés, sélectionnez Suivant, puis Terminer à l'écran de résumé pour lancer le processus d'importation.</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">Une fois l'importation terminée, vous pouvez restaurer les machines virtuelles dans le cluster VMware Cloud.</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="section-title">Restauration des VM applicatives avec restauration complète Veeam dans VMware Cloud</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">Pour restaurer des machines virtuelles SQL et Oracle vers VMware Cloud sur un domaine ou un cluster de workloads avec AWS, effectuez les étapes suivantes.</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">Dans la page d'accueil Veeam, sélectionnez le stockage d'objets contenant les sauvegardes importées, sélectionnez les machines virtuelles à restaurer, puis cliquez avec le bouton droit de la souris et sélectionnez Restaurer la machine virtuelle entière.</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">Sur la première page de l'assistant de restauration complète de VM, modifiez les VM à sauvegarder si vous le souhaitez et sélectionnez Suivant.</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">Sur la page mode de restauration, sélectionnez Restaurer à un nouvel emplacement ou avec des paramètres différents.</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">Sur la page hôte, sélectionnez l'hôte ou le cluster ESXi cible pour restaurer la machine virtuelle.</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">Sur la page datastores, sélectionnez l'emplacement du datastore cible pour les fichiers de configuration et le disque dur.</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">Sur la page réseau, mappez les réseaux d'origine sur la machine virtuelle aux réseaux du nouvel emplacement cible.</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">Sélectionnez si vous souhaitez analyser la machine virtuelle restaurée à la recherche d'un programme malveillant, consultez la page de résumé et cliquez sur Terminer pour lancer la restauration.</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="summary">Pour effectuer un basculement de nos VM applicatifs et de nos volumes de base de données vers les services VMware Cloud volumes exécutés dans AWS, il était nécessaire d'installer et de configurer une instance d'exécution à la fois de SnapCenter Server et de Veeam Backup and Replication Server. À la fin du basculement, ces outils doivent également être configurés pour reprendre les opérations de sauvegarde normales, jusqu'à ce que la restauration du data Center sur site soit planifiée et exécutée.</block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="doc">Outils de sauvegarde dans le cloud</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="section-title">Déploiement des outils de sauvegarde</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">Le serveur SnapCenter et le serveur Veeam Backup &amp; Replication peuvent être installés dans le SDDC VMware Cloud ou sur des instances EC2 résidant dans un VPC avec la connectivité réseau dans l'environnement VMware Cloud.</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="section-title">Serveur SnapCenter</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">Centre de documentation NetApp</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">Le logiciel SnapCenter est disponible sur le site du support NetApp et peut être installé sur les systèmes Microsoft Windows résidant dans un domaine ou dans un groupe de travail. Un guide de planification détaillé et des instructions d'installation sont disponibles sur le <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>.</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">Le logiciel SnapCenter est disponible à l'adresse<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">Vous pouvez installer le serveur Veeam Backup &amp; Replication sur un serveur Windows dans VMware Cloud sur AWS ou sur une instance EC2. Pour obtenir des conseils détaillés sur la mise en œuvre, reportez-vous au<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="section-title">Les outils de sauvegarde et la configuration</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">Une fois installés, SnapCenter et Veeam Backup &amp; Replication doivent être configurés pour que la restauration des données vers VMware Cloud sur AWS s'effectue sur les tâches nécessaires.</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="section-title">Configuration SnapCenter</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">Pour restaurer les données d'application mises en miroir vers FSX ONTAP, vous devez d'abord effectuer une restauration complète de la base de données SnapCenter sur site. Une fois ce processus terminé, la communication avec les machines virtuelles est rétablie, et les sauvegardes des applications peuvent maintenant reprendre l'utilisation de FSX ONTAP comme stockage primaire.</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">Déployez un serveur SnapCenter secondaire Windows</block>
  <block id="520d23cd5df8582645ee42124b69ccae" category="paragraph">Pour obtenir la liste des étapes à suivre sur le serveur SnapCenter résidant dans AWS, consultez la section <block ref="a29fcfa081b59708af69951be417dc25" category="inline-link-macro-rx"></block>.</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Pour restaurer les machines virtuelles qui ont été sauvegardées sur le stockage Amazon S3, le serveur Veeam doit être installé sur un serveur Windows et configuré pour communiquer avec VMware Cloud, FSX ONTAP, ainsi qu'avec le compartiment S3 contenant le référentiel de sauvegarde d'origine. Le service informatique doit également configurer un nouveau référentiel de sauvegarde sur FSX ONTAP afin de réaliser de nouvelles sauvegardes sur les machines virtuelles une fois restaurées.</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">Déploiement du système Veeam Backup etamp secondaire ; Replication Server</block>
  <block id="82a8a7d9b8f053ce73af1c1b5b8694ff" category="paragraph">Pour obtenir la liste complète des étapes requises pour effectuer le basculement des machines virtuelles d'application, consultez la section <block ref="83d03cb08c05a76f36dedd6b85344746" category="inline-link-macro-rx"></block>.</block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="summary">Le cas d'utilisation présenté dans cette documentation est axé sur les technologies de reprise sur incident qui ont fait leurs preuves et qui mettent en avant l'intégration entre NetApp et VMware. Les systèmes de stockage NetApp ONTAP fournissent des technologies de mise en miroir des données éprouvées qui permettent aux entreprises de concevoir des solutions de reprise après incident s'intégrant aux technologies ONTAP et sur site des principaux fournisseurs cloud.</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">La solution FSX pour ONTAP sur AWS est un outil qui permet une intégration transparente avec SnapCenter et SyncMirror pour la réplication des données d'application vers le cloud. Veeam Backup &amp; Replication est une autre technologie connue qui s'intègre bien aux systèmes de stockage NetApp ONTAP et peut fournir un basculement vers le stockage natif vSphere.</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">Cette solution de reprise après incident a présentée un stockage « Guest Connect » à partir d'un système ONTAP hébergeant les données d'applications SQL Server et Oracle. SnapCenter avec SnapMirror constitue une solution simple à gérer pour protéger les volumes d'applications dans les systèmes ONTAP et les répliquer vers FSX ou CVO résidant dans le cloud. SnapCenter est une solution de reprise d'activité pour le basculement de toutes les données applicatives vers VMware Cloud sur AWS.</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">Liens vers la documentation de la solution</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">Une fois le processus de basculement terminé avec succès dans cette solution, SnapCenter et Veeam reprendre leurs fonctions de sauvegarde s'exécutant dans AWS, et FSX pour ONTAP est désormais désigné comme stockage principal sans relation SnapMirror avec le data Center sur site d'origine. Une fois le fonctionnement normal rétabli sur site, vous pouvez utiliser un processus identique à celui décrit dans la présente documentation pour reproduire les données sur le système de stockage ONTAP sur site.</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">Comme indiqué dans cette documentation, vous pouvez configurer SnapCenter de manière à mettre en miroir les volumes de données d'application de FSX pour ONTAP vers un système de stockage ONTAP résidant sur site. De la même façon, vous pouvez configurer Veeam pour répliquer les copies de sauvegarde vers Amazon S3 à l'aide d'un référentiel de sauvegarde scale-out. Ainsi, ces sauvegardes sont accessibles à un serveur de sauvegarde Veeam résidant dans le data Center sur site.</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">Le basculement automatique ne fait pas partie du périmètre de ces documents, mais le retour arrière diffère légèrement du processus détaillé présenté ici.</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">Options de stockage connecté à un système invité NetApp pour AWS</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS prend en charge le stockage NetApp connecté à l'invité avec le service FSX natif (FSX ONTAP) ou avec Cloud Volumes ONTAP (CVO).</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">ONTAP FSX</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">Amazon FSX pour NetApp ONTAP est un service entièrement géré qui offre un stockage de fichiers extrêmement fiable, évolutif, haute performance et riche en fonctionnalités, basé sur le système de fichiers populaire ONTAP de NetApp. FSX for ONTAP associe les fonctionnalités, performances, capacités et opérations d'API connues des systèmes de fichiers NetApp, ainsi que l'agilité, l'évolutivité et la simplicité d'un service AWS entièrement géré.</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">FSX pour ONTAP offre un stockage de fichiers partagés riche en fonctionnalités, rapide et flexible, accessible depuis les instances de calcul Linux, Windows et MacOS exécutées dans AWS ou sur site. La solution FSX pour ONTAP offre un stockage SSD hautes performances avec des latences inférieures à la milliseconde. La solution FSX pour ONTAP vous permet d'atteindre des niveaux SSD de performances pour votre charge de travail tout en payant le stockage SSD pour une fraction seulement de vos données.</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">La gestion de vos données avec FSX pour ONTAP est plus simple car vous pouvez effectuer des instantanés, cloner et répliquer vos fichiers en un seul clic. De plus, FSX for ONTAP hiérarchise automatiquement vos données vers un stockage flexible et moins coûteux, en réduisant les besoins en matière de provisionnement ou de gestion de la capacité.</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">FSX pour ONTAP fournit également un stockage durable et haute disponibilité avec des sauvegardes entièrement gérées et prend en charge la reprise après incident inter-région. Afin de simplifier la protection et la sécurité de vos données, FSX pour ONTAP prend en charge les applications courantes de sécurité de données et antivirus.</block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="example-title">Configuration d'Amazon FSX pour NetApp ONTAP avec VMware Cloud sur AWS</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">Amazon FSX pour NetApp ONTAP Files partages et LUN peuvent être montés depuis les machines virtuelles créées dans l'environnement VMware SDDC au sein de VMware Cloud au sein d'AWS. Les volumes peuvent également être montés sur le client Linux et mappés sur le client Windows à l'aide du protocole NFS ou SMB. Les LUN sont accessibles sur les clients Linux ou Windows sous forme de périphériques de bloc lorsqu'ils sont montés sur iSCSI. Vous pouvez configurer rapidement Amazon FSX pour le système de fichiers NetApp ONTAP en procédant comme suit.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">Amazon FSX pour NetApp ONTAP et VMware Cloud sur AWS doivent se trouver dans la même zone de disponibilité afin d'améliorer les performances et d'éviter les frais de transfert de données entre les zones de disponibilité.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="example-title">Création et montage d'Amazon FSX pour les volumes ONTAP</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">Pour créer et monter un système de fichiers Amazon FSX pour NetApp ONTAP, procédez comme suit :</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Console Amazon FSX</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">Ouvrez le <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> Et choisissez Créer un système de fichiers pour démarrer l'assistant de création de système de fichiers.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">Sur la page Select File System Type, choisissez Amazon FSX pour NetApp ONTAP, puis cliquez sur Next. La page Créer un système de fichiers s'affiche.</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">Dans la section mise en réseau, pour le cloud privé virtuel (VPC), choisissez le VPC (Virtual Private Cloud) approprié et les sous-réseaux préférés, ainsi que la table de routage. Dans ce cas, vmcfsx2.vpc est sélectionné dans la liste déroulante.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">Pour la méthode de création, choisissez création standard. Vous pouvez également choisir création rapide, mais ce document utilise l'option création standard.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">Dans la section sécurité et chiffrement, pour la clé de chiffrement, choisissez la clé de chiffrement AWS Key Management Service (KMS AWS) qui protège les données du système de fichiers au repos. Pour le mot de passe administrateur système de fichiers, entrez un mot de passe sécurisé pour l'utilisateur fsxadmin.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">Sous l'ordinateur virtuel et spécifiez le mot de passe à utiliser avec vsadmin pour administrer le ONTAP via les API REST ou l'interface de ligne de commande. Si aucun mot de passe n'est spécifié, un utilisateur fsxadmin peut être utilisé pour administrer la SVM. Dans la section Active Directory, veillez à joindre Active Directory au SVM pour le provisionnement des partages SMB. Dans la section Configuration de Storage Virtual machine par défaut, indiquez un nom pour le stockage dans cette validation, les partages SMB sont provisionnés à l'aide d'un domaine Active Directory autogéré.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">Dans la section Configuration du volume par défaut, spécifiez le nom et la taille du volume. Il s'agit d'un volume NFS. Pour l'efficacité du stockage, choisissez activé pour activer les fonctionnalités d'efficacité du stockage ONTAP (compression, déduplication et compaction) ou désactivez-les.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">Vérifiez la configuration du système de fichiers indiquée sur la page Créer un système de fichiers.</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">Cliquez sur Créer un système de fichiers.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">Mise en route avec Amazon FSX pour NetApp ONTAP</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">Pour plus d'informations, reportez-vous à la section <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">Une fois le système de fichiers créé comme ci-dessus, créez le volume avec la taille et le protocole requis.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">Ouvrez le <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">Dans le volet de navigation de gauche, choisissez systèmes de fichiers, puis choisissez le système de fichiers ONTAP pour lequel vous souhaitez créer un volume.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Sélectionnez l'onglet volumes.</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Sélectionnez l'onglet Créer un volume.</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">La boîte de dialogue Créer un volume s'affiche.</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">À des fins de démonstration, un volume NFS est créé dans cette section, sur laquelle il peut être facilement monté sur des machines virtuelles qui s'exécutent sur VMware Cloud sur AWS. nfsdemovol01 est créé comme décrit ci-dessous :</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="example-title">Montez le volume ONTAP FSX sur le client Linux</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">Pour monter le volume ONTAP FSX créé à l'étape précédente. Depuis les VM Linux dans VMC sur AWS SDDC, effectuez les opérations suivantes :</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">Ouvrez un terminal sur l'instance à l'aide de Secure Shell (SSH) et connectez-vous avec les informations d'identification appropriées.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">Créer un répertoire pour le point de montage du volume avec la commande suivante :</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">Montez le volume NFS Amazon FSX pour NetApp ONTAP dans le répertoire créé à l'étape précédente.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">Une fois exécutée, exécutez la commande df pour valider le montage.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="example-title">Connexion de volumes ONTAP FSX aux clients Microsoft Windows</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Pour gérer et mapper des partages de fichiers sur un système de fichiers Amazon FSX, l'interface graphique dossiers partagés doit être utilisée.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">Ouvrez le menu Démarrer et exécutez fsmgmt.msc en utilisant Exécuter en tant qu'administrateur. Cette opération ouvre l'outil GUI dossiers partagés.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">Cliquez sur action &gt; toutes les tâches et choisissez connexion à un autre ordinateur.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">Pour un autre ordinateur, entrez le nom DNS de la machine virtuelle de stockage (SVM). Par exemple, FSXSMBTESTIN01.FSXTESTING.LOCAL est utilisé dans cet exemple.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP recherchez le nom DNS du SVM sur la console Amazon FSX, choisissez Storage Virtual machines, choisissez SVM, puis faites défiler jusqu'aux terminaux pour trouver le nom DNS SMB. Cliquez sur OK. Le système de fichiers Amazon FSX s'affiche dans la liste des dossiers partagés.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">Dans l'outil dossiers partagés, choisissez partages dans le volet gauche pour afficher les partages actifs pour le système de fichiers Amazon FSX.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">Choisissez un nouveau partage et suivez l'assistant Créer un dossier partagé.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">Création de partages SMB</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Pour en savoir plus sur la création et la gestion de partages SMB sur un système de fichiers Amazon FSX, reportez-vous à la section <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">Une fois la connectivité en place, le partage SMB peut être connecté et utilisé pour les données d'application. Pour ce faire, copiez le chemin du partage et utilisez l'option Map Network Drive pour monter le volume sur la machine virtuelle exécutée sur VMware Cloud sur le SDDC AWS.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="example-title">Connectez un LUN FSX pour NetApp ONTAP à un hôte utilisant iSCSI</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">Le trafic iSCSI pour FSX traverse la passerelle de transit VMware Transit Connect/AWS via les routes fournies dans la section précédente. Pour configurer un LUN dans Amazon FSX pour NetApp ONTAP, suivez la documentation qui s'y trouve <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Sur les clients Linux, assurez-vous que le démon iSCSI est en cours d'exécution. Une fois les LUN provisionnées, reportez-vous aux conseils détaillés sur la configuration iSCSI avec Ubuntu (par exemple) <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">Dans ce document, la connexion du LUN iSCSI à un hôte Windows est décrite ci-dessous :</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="example-title">Provisionnement d'un LUN dans FSX pour NetApp ONTAP :</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">Accédez à l'interface de ligne de commande de NetApp ONTAP à l'aide du port de gestion du système FSX pour le système de fichiers ONTAP.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">Créer les LUN avec la taille requise, comme indiqué dans la sortie du dimensionnement.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">Dans cet exemple, nous avons créé une LUN de taille 5g (5368709120).</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">Créez les igroups nécessaires pour contrôler quels hôtes ont accès à des LUN spécifiques.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">Deux entrées ont été affichées.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">Mappez les LUN sur des igroups à l'aide de la commande suivante :</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">Connectez le nouveau LUN provisionné à une machine virtuelle Windows :</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">Pour connecter le nouveau LUN tor à un hôte Windows résidant sur le cloud VMware dans AWS SDDC, effectuez les opérations suivantes :</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">RDP sur la machine virtuelle Windows hébergée sur le SDDC VMware Cloud pour AWS.</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Accédez à Server Manager &gt; Tableau de bord &gt; Outils &gt; initiateur iSCSI pour ouvrir la boîte de dialogue Propriétés de l'initiateur iSCSI.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">Dans l'onglet cibles, sélectionnez la cible découverte, puis cliquez sur connexion ou connexion.</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">Sélectionnez Activer Multipath, puis sélectionnez “Restaurer automatiquement cette connexion au démarrage de l’ordinateur” ou “Ajouter cette connexion à la liste des cibles favorites”. Cliquez sur Avancé.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">Les LUN de la machine virtuelle de stockage (SVM) apparaissent sous forme de disques pour l'hôte Windows. Les nouveaux disques ajoutés ne sont pas automatiquement découverts par l'hôte. Déclencher une nouvelle analyse manuelle pour détecter les disques en procédant comme suit :</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Lorsqu'un nouvel LUN est accédé pour la première fois par l'hôte Windows, il n'a pas de partition ni de système de fichiers. Initialisez la LUN et, éventuellement, formatez-la avec un système de fichiers en effectuant la procédure suivante :</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="example-title">Déploiement de la nouvelle instance Cloud Volumes ONTAP dans AWS (faites vous-même)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Les partages et les LUN Cloud Volumes ONTAP peuvent être montés sur les VM créées dans le cloud VMware dans un environnement SDDC d'AWS. Les volumes peuvent également être montés sur des clients Windows Linux natifs d'AWS VM, et les LUN sont accessibles sur des clients Linux ou Windows en tant que périphériques de blocs lorsqu'ils sont montés sur iSCSI, car Cloud Volumes ONTAP prend en charge les protocoles iSCSI, SMB et NFS. Les volumes Cloud Volumes ONTAP peuvent être configurés en quelques étapes simples.</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">Pour répliquer des volumes depuis un environnement sur site vers le cloud à des fins de reprise d'activité ou de migration, établissez une connectivité réseau vers AWS à l'aide d'un VPN site à site ou de DirectConnect. La réplication des données entre les sites et Cloud Volumes ONTAP n'est pas traitée dans ce document. Pour répliquer les données entre les systèmes Cloud Volumes ONTAP et sur site, consultez la section <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">Utilisez le <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Pour dimensionner précisément les instances Cloud Volumes ONTAP. Surveillez également les performances sur site pour les utiliser comme entrées dans le dimensionnement Cloud Volumes ONTAP.</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">Connectez-vous à NetApp Cloud Central ; l'écran Fabric View s'affiche. Localisez l'onglet Cloud Volumes ONTAP et sélectionnez accéder à Cloud Manager. Une fois connecté, l'écran Canvas s'affiche.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Sur la page d'accueil de Cloud Manager, cliquez sur Add a Working Environment, puis sélectionnez AWS comme cloud et le type de configuration système.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">Fournissez les détails de l'environnement à créer, y compris le nom de l'environnement et les identifiants d'administrateur. Cliquez sur Continuer .</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">Sélectionnez les services d'extension pour le déploiement Cloud Volumes ONTAP, notamment Cloud Data Sense, Cloud Backup et Cloud Insights. Cliquez sur Continuer .</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">Sur la page modèles de déploiement HA, choisissez la configuration plusieurs zones de disponibilité.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">Sur la page région et VPC, entrez les informations du réseau, puis cliquez sur Continuer.</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">Sur la page Connectivité et authentification SSH, choisissez les méthodes de connexion pour la paire HA et le médiateur.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">Spécifiez les adresses IP flottantes, puis cliquez sur Continuer.</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">Sélectionnez les tables de routage appropriées pour inclure des routes vers les adresses IP flottantes, puis cliquez sur Continuer.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">Sur la page chiffrement des données, choisissez le chiffrement géré par AWS.</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">Sélectionnez l'option de licence : paiement à l'utilisation ou BYOL pour l'utilisation d'une licence existante. Dans cet exemple, l'option paiement à l'utilisation est utilisée.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">Sélectionnez parmi plusieurs packages préconfigurés disponibles en fonction du type de workload à déployer sur les machines virtuelles exécutées sur le cloud VMware sur AWS SDDC.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">Sélectionnez l'instance CVO pour créer le volume, puis cliquez sur l'option Create Volume. Choisissez la taille appropriée et Cloud Manager choisit l'agrégat contenant ou utilisez un mécanisme d'allocation avancée pour placer sur un agrégat spécifique. Pour cette démonstration, SMB est sélectionné comme protocole.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">Une fois le volume provisionné, celui-ci est disponible sous le volet volumes. Comme un partage CIFS est provisionné, vous devez donner à vos utilisateurs ou groupes une autorisation aux fichiers et dossiers et vérifier que ces utilisateurs peuvent accéder au partage et créer un fichier.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">Une fois le volume créé, utilisez la commande mount pour vous connecter au partage à partir de la machine virtuelle exécutée sur VMware Cloud dans les hôtes SDDC AWS.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">Copiez le chemin suivant et utilisez l'option Map Network Drive pour monter le volume sur la machine virtuelle exécutée sur VMware Cloud dans AWS SDDC.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Pour connecter le LUN Cloud Volumes ONTAP à un hôte, procédez comme suit :</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Sur la page Canvas de Cloud Manager, double-cliquez sur l'environnement de travail Cloud Volumes ONTAP pour créer et gérer des volumes.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">Cliquez sur Ajouter un volume &gt; Nouveau volume, sélectionnez iSCSI, puis cliquez sur Créer un groupe d'initiateurs. Cliquez sur Continuer .</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">Pour appliquer la même opération à l'hôte résidant sur le SDDC VMware Cloud basé sur AWS, effectuez les opérations suivantes :</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP vers la VM hébergée sur VMware Cloud sur AWS.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">Sélectionnez Activer Multipath, puis sélectionnez Restaurer automatiquement cette connexion au démarrage de l'ordinateur ou Ajouter cette connexion à la liste des cibles favorites. Cliquez sur Avancé.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">+<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">Les LUN du SVM apparaissent comme des disques vers l'hôte Windows. Les nouveaux disques ajoutés ne sont pas automatiquement découverts par l'hôte. Déclencher une nouvelle analyse manuelle pour détecter les disques en procédant comme suit :</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Sur les clients Linux, assurez-vous que le démon iSCSI est en cours d'exécution. Une fois les LUN provisionnées, reportez-vous aux instructions détaillées sur la configuration iSCSI pour votre distribution Linux. Par exemple, la configuration iSCSI Ubuntu est disponible <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. Pour vérifier, exécutez lsblk cmd à partir du shell.</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">Pour monter le système de fichiers Cloud Volumes ONTAP (DIY) depuis des VM dans le VMC sur le SDDC AWS, effectuez la procédure suivante :</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">Tr-4938 : monter Amazon FSX pour ONTAP en tant que datastore NFS avec VMware Cloud sur AWS</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">Chaque organisation réussie est sur le chemin de la transformation et de la modernisation. Dans le cadre de ce processus, les entreprises utilisent généralement leurs investissements VMware existants pour tirer parti des avantages du cloud et étudier comment migrer, rafale, étendre et garantir la reprise sur incident de manière aussi transparente que possible. Les clients qui migrent vers le cloud doivent évaluer les cas d'utilisation en termes de flexibilité et de rafale, de sortie de data Center, de consolidation de data Center, de scénarios de fin de vie, de fusion, des acquisitions, etc.</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">intégration récente</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">Même si VMware Cloud sur AWS est l'option de prédilection de la plupart des clients, c'est parce qu'il fournit des fonctionnalités hybrides uniques à un client, les options de stockage natif limitées ont limité son utilité pour les entreprises qui utilisent des charges de travail fortement lourdes. Le stockage étant directement lié aux hôtes, la seule façon de faire évoluer le stockage consiste à ajouter d'autres hôtes, ce qui permet d'augmenter les coûts de 35 à 40 % ou plus pour les charges de travail consommatrices de stockage. Ces charges de travail ont besoin de stockage supplémentaire et de performances isolées, sans puissance supplémentaire, ce qui signifie que des frais supplémentaires sont en charge des hôtes. C'est là que le<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> La solution FSX pour ONTAP est disponible pour les workloads de stockage et exigeants en performances avec VMware Cloud sur AWS.</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">Examinons le scénario suivant : un client nécessite huit hôtes pour la puissance (vCPU/vmem), mais qui doivent également présenter des exigences importantes en matière de stockage. En fonction de leur évaluation, ils nécessitent 16 hôtes pour répondre aux besoins en stockage. Cela augmente le coût total de possession global car ils doivent acheter toute cette puissance supplémentaire lorsque c'est la capacité de stockage requise. Cette fonctionnalité est applicable à toutes les utilisations, y compris la migration, la reprise sur incident, l'bursting, le développement/test, et ainsi de suite.</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">Ce document vous présente les étapes de provisionnement et de connexion de FSX pour ONTAP en tant que datastore NFS pour VMware Cloud sur AWS.</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">Zone technique cloud VMware</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">Cette solution est également disponible auprès de VMware. Veuillez visiter le <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">Options de connectivité</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">Cette section décrit l'architecture de connectivité de haut niveau et les étapes nécessaires à la mise en œuvre de la solution pour étendre le stockage dans un cluster SDDC sans ajouter d'hôtes supplémentaires.</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">Les étapes de déploiement de haut niveau sont les suivantes :</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">Créez Amazon FSX pour ONTAP dans un nouveau VPC désigné.</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">Créer un groupe SDDC.</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">Créez VMware Transit Connect et une pièce jointe TGW.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">Configuration du routage (VPC AWS et SDDC) et des groupes de sécurité</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">Joignez un volume NFS en tant que datastore au cluster SDDC.</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">Mise en route de VMware Cloud sur AWS</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">Avant de provisionner et de connecter FSX pour ONTAP en tant que datastore NFS, vous devez d'abord configurer un environnement VMware sur un cloud SDDC ou obtenir une mise à niveau existante vers v1.20 ou une version ultérieure. Pour plus d'informations, reportez-vous à la section <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>.</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">FSX pour ONTAP n'est actuellement pas pris en charge avec les clusters étirés.</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">Ce document aborde les étapes nécessaires à la configuration d'Amazon FSX pour ONTAP avec VMware Cloud sur AWS. Amazon FSX pour ONTAP offre d'excellentes options pour déployer et gérer les charges de travail applicatives et les services de fichiers, tout en réduisant le coût total de possession en rendant les données requises transparentes pour la couche applicative. Quel que soit le cas d'utilisation, choisissez VMware Cloud sur AWS et Amazon FSX pour ONTAP pour bénéficier rapidement des avantages du cloud, d'une infrastructure cohérente et des opérations sur site vers AWS, de la portabilité bidirectionnelle des charges de travail, et d'une capacité et des performances élevées. Il s'agit du même processus et des mêmes procédures que ceux utilisés pour connecter le stockage. N'oubliez pas que c'est seulement la position des données qui ont changé avec de nouveaux noms. Les outils et les processus restent les mêmes, et Amazon FSX pour ONTAP contribue à optimiser le déploiement global.</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">Pour en savoir plus sur ce processus, n'hésitez pas à suivre la vidéo de présentation détaillée.</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="doc">De déduplication</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">Précédent : présentation de la solution.</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">Cette solution inclut des technologies innovantes de NetApp, VMware, Amazon Web Services (AWS) et Veeam.</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="section-title">VMware</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="section-title">Socle cloud VMware</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">La plateforme VMware Cloud Foundation intègre plusieurs offres de produits qui permettent aux administrateurs de provisionner les infrastructures logiques sur un environnement hétérogène. Ces infrastructures (appelées domaines) assurent des opérations cohérentes entre les clouds privés et publics. Le logiciel Cloud Foundation associé est une nomenclature qui identifie les composants prévalidés et qualifiés pour réduire les risques des clients et faciliter le déploiement.</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Les composants du BOM Cloud Foundation sont les suivants :</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">Créateur de cloud</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">SDDC Manager</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">Appliance VMware vCenter Server</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">Automatisation vRealize</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">VRealize Suite Lifecycle Manager</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">Insight de journalisation vRealize</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">Documentation VMware Cloud Foundation</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">Pour en savoir plus sur VMware Cloud Foundation, rendez-vous sur le<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>.</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere est une plateforme de virtualisation qui transforme les ressources physiques en pools de calcul, de réseau et de stockage pouvant être utilisés pour répondre aux exigences des applications et de la charge de travail des clients. Les principaux composants de VMware vSphere sont les suivants :</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">*ESXi.* cet hyperviseur VMware permet l'abstraction des processeurs de calcul, de la mémoire, du réseau et d'autres ressources et les met à disposition des machines virtuelles et des charges de travail de conteneurs.</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">*VCenter.* VMware vCenter crée une expérience de gestion centralisée pour interagir avec les ressources de calcul, le réseau et le stockage dans le cadre de votre infrastructure virtuelle.</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">Les clients prennent conscience du potentiel de leur environnement vSphere à l'aide de NetApp ONTAP, qui propose une intégration poussée des produits, un support robuste, et des fonctionnalités puissantes et d'efficacité du stockage pour créer une architecture multicloud hybride robuste.</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">Pour plus d'informations sur VMware vSphere, veuillez suivre<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>.</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">Pour plus d'informations sur les solutions NetApp avec VMware, suivez<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>.</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">Communément appelé hyperviseur réseau, VMware NSX utilise un modèle Software-defined pour connecter les charges de travail virtualisées. VMware NSX est omniprésent sur site et dans VMware Cloud sur AWS, où il est en mesure d'assurer la virtualisation et la sécurité du réseau pour les applications et les workloads des clients.</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">Pour plus d'informations sur VMware NSX, consultez<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>.</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">Depuis près de vingt ans, le logiciel NetApp ONTAP est une solution de stockage leader pour les environnements VMware vSphere. Il continue d'ajouter des fonctionnalités innovantes pour simplifier la gestion, tout en réduisant les coûts. L'association de ONTAP et de vSphere permet de réduire les dépenses liées au matériel hôte et aux logiciels VMware. Vous pouvez également protéger vos données à moindre coût grâce à des performances élevées prévisibles tout en profitant des fonctionnalités natives d'efficacité du stockage.</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">Pour plus d'informations sur NetApp ONTAP, suivez<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="section-title">Outils NetApp ONTAP pour VMware</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">Les outils ONTAP pour VMware combinent plusieurs plug-ins dans une seule appliance virtuelle qui permet de gérer de bout en bout le cycle de vie des machines virtuelles dans des environnements VMware qui utilisent les systèmes de stockage NetApp. Les outils ONTAP pour VMware comprennent les éléments suivants :</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">*Virtual Storage Console (VSC)* exécute des tâches administratives complètes pour les machines virtuelles et les datastores grâce au stockage NetApp.</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">*VASA Provider pour ONTAP.* permet une gestion basée sur des règles de stockage (SPBM) avec les volumes virtuels VMware (vvols) et le stockage NetApp.</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">*Storage Replication adapter (SRA)*. Restauration de datastores vCenter et de machines virtuelles en cas de défaillance associée à VMware site Recovery Manager (SRM).</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">Les outils ONTAP pour VMware permettent aux utilisateurs de gérer non seulement le stockage externe, mais également de l'intégrer à vvols, ainsi qu'à VMware site Recovery Manager. Cela simplifie considérablement le déploiement et l'exploitation des systèmes de stockage NetApp à partir de votre environnement vCenter.</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">Pour plus d'informations sur les outils NetApp ONTAP pour VMware, suivez<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>.</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">Le logiciel SnapCenter est une plateforme qui permet de coordonner et de gérer facilement et en toute sécurité la protection de vos données sur l'ensemble des applications, bases de données et systèmes de fichiers. SnapCenter simplifie la sauvegarde, la restauration et la gestion du cycle de vie des clones en les transférant aux propriétaires d'applications, sans qu'il soit possible de superviser et de réguler l'activité au niveau des systèmes de stockage. Grâce à la gestion des données basée sur le stockage, SnapCenter améliore la performance et la disponibilité, tout en réduisant les temps consacré au développement et aux tests.</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">Le plug-in SnapCenter pour VMware vSphere prend en charge les opérations de sauvegarde et de restauration cohérentes avec les machines virtuelles (VM), les datastores et les disques de machines virtuelles (VMDK). Il prend également en charge les plug-ins SnapCenter spécifiques aux applications pour protéger les opérations de sauvegarde et de restauration cohérentes au niveau des applications pour les bases de données virtualisées et les systèmes de fichiers.</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">Pour plus d'informations sur NetApp SnapCenter, suivez<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>.</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">Protection des données tierce</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replication est une solution de sauvegarde, de restauration et de gestion des données pour les charges de travail cloud, virtuelles et physiques. Veeam Backup &amp; Replication dispose d'intégrations spécialisées avec la technologie NetApp Snapshot pour une protection renforcée des environnements vSphere.</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Pour plus d'informations sur Veeam Backup &amp; Replication, consultez<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>.</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">Cloud public</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="section-title">Gestion des identités et des accès AWS</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">Les environnements AWS contiennent une grande variété de produits, notamment le calcul, le stockage, les bases de données, le réseau, l'analytique et bien plus encore pour permettre aux entreprises de relever les défis. Les entreprises doivent être en mesure de définir qui est autorisé à accéder à ces produits, services et ressources. Il est tout aussi important de déterminer dans quelles conditions les utilisateurs sont autorisés à manipuler, modifier ou ajouter des configurations.</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS Identity and Access Management (AIM) propose un plan de contrôle sécurisé pour la gestion de l'accès aux services et produits AWS. Des utilisateurs, des clés d'accès et des autorisations correctement configurés permettent de déployer VMware Cloud sur AWS et Amazon FSX.</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">Pour plus d'informations sur AIM, suivez la<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>.</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud sur AWS permet au logiciel SDDC de VMware d'entreprise d'accéder au cloud AWS grâce à un accès optimisé aux services AWS natifs. Optimisée par VMware Cloud Foundation, VMware Cloud on AWS intègre les produits de virtualisation du calcul, du stockage et du réseau de VMware (VMware vSphere, VMware VSAN et VMware NSX), ainsi que la solution de gestion de VMware vCenter Server, optimisée pour s'exécuter sur une infrastructure AWS dédiée, élastique et sans système d'exploitation.</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">Pour plus d'informations sur VMware Cloud sur AWS, suivez<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">Amazon FSX pour NetApp ONTAP est un système ONTAP entièrement intégré et entièrement géré, disponible en tant que service AWS natif. Il repose sur NetApp ONTAP et comprend des fonctionnalités déjà connues tout en offrant la simplicité d'un service cloud entièrement géré.</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">Amazon FSX pour ONTAP offre une prise en charge multiprotocole pour divers types de calcul, notamment VMware dans le cloud public ou sur site. Disponible pour les cas d'utilisation connectés à l'invité et les datastores NFS dans la présentation technique, Amazon FSX pour ONTAP permet aux entreprises de bénéficier des fonctionnalités familières de leurs environnements sur site et dans le cloud.</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">Pour plus d'informations sur Amazon FSX pour NetApp ONTAP, suivez<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>.</block>
  <block id="f201deaeba7cc565253f52d974008543" category="summary">Pour effectuer un basculement des VM applicatives et des volumes de base de données vers les services VMware Cloud volumes exécutés dans AWS, vous devez installer et configurer une instance en cours d'exécution de SnapCenter Server et Veeam Backup and Replication Server. Une fois le basculement terminé, vous devez également configurer ces outils pour reprendre les opérations de sauvegarde normales jusqu'à ce que la restauration du data Center sur site soit planifiée et exécutée.</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="doc">Outils et configuration de sauvegarde dans le cloud</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="section-title">Déploiement d'un serveur Windows SnapCenter secondaire</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">Le serveur SnapCenter est déployé dans le SDDC VMware Cloud ou installé sur une instance EC2 résidant dans un VPC avec une connectivité réseau vers l'environnement VMware Cloud.</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">Le logiciel SnapCenter est disponible sur le site du support NetApp et peut être installé sur les systèmes Microsoft Windows résidant dans un domaine ou un groupe de travail. Un guide de planification détaillé et des instructions d'installation sont disponibles sur le<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>.</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">Le logiciel SnapCenter est disponible sur la page<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="section-title">Configurez le serveur SnapCenter secondaire</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">Pour restaurer les données d'application en miroir vers FSX ONTAP, vous devez d'abord effectuer une restauration complète de la base de données SnapCenter sur site. Une fois ce processus terminé, la communication avec les machines virtuelles est rétablie, et les sauvegardes des applications peuvent maintenant reprendre en utilisant FSX ONTAP comme stockage primaire.</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">Pour ce faire, vous devez effectuer les opérations suivantes sur le serveur SnapCenter :</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">Configurez le nom de l'ordinateur pour qu'il soit identique au serveur SnapCenter sur site d'origine.</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">Configurez le réseau pour communiquer avec VMware Cloud et l'instance FSX ONTAP.</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">Terminez la procédure de restauration de la base de données SnapCenter.</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">Vérifiez que SnapCenter est en mode reprise après incident pour vous assurer que FSX est désormais le stockage principal pour les sauvegardes.</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">Confirmer que la communication est rétablie avec les machines virtuelles restaurées.</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">Processus de restauration de base de données SnapCenter</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">Pour plus d'informations sur ces étapes, reportez-vous à la section à <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>.</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">Vous pouvez installer le serveur Veeam Backup &amp; Replication sur un serveur Windows dans le cloud VMware sur AWS ou sur une instance EC2. Pour obtenir des conseils détaillés sur la mise en œuvre, reportez-vous au<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Pour effectuer une restauration des machines virtuelles qui ont été sauvegardées sur le stockage Amazon S3, vous devez installer Veeam Server sur un serveur Windows et le configurer pour qu'il communique avec VMware Cloud, FSX ONTAP et le compartiment S3 qui contient le référentiel de sauvegarde d'origine. Le système informatique doit également configurer un nouveau référentiel de sauvegarde sur FSX ONTAP afin de réaliser de nouvelles sauvegardes des machines virtuelles après leur restauration.</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">Pour effectuer ce processus, les éléments suivants doivent être effectués :</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">Configuration du réseau pour communiquer avec VMware Cloud, FSX ONTAP et un compartiment S3 contenant le référentiel de sauvegarde d'origine</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">Configurez un partage SMB sur FSX ONTAP en tant que nouveau référentiel de sauvegarde.</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">Montez le compartiment S3 d'origine utilisé dans le référentiel de sauvegarde scale-out sur site.</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">Après la restauration de la machine virtuelle, établir de nouvelles tâches de sauvegarde afin de protéger les machines virtuelles SQL et Oracle.</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">Restauration des VM applications avec Veeam Full Restore</block>
  <block id="5ad23c05d5054f7daf749b3a328903be" category="paragraph">Pour plus d'informations sur la restauration des VM à l'aide de Veeam, reportez-vous à la section <block ref="145e19bb138e7c87e2d24d78a1c11e93" category="inline-link-macro-rx"></block>.</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="summary">SnapCenter peut mettre à jour les relations SnapMirror dans le système de stockage primaire (primaire &gt; miroir) et vers des systèmes de stockage secondaires (primaire &gt; archivage sécurisé) pour l'archivage et la conservation à long terme. Pour ce faire, vous devez établir et initialiser une relation de réplication des données entre un volume de destination et un volume source à l'aide de SnapMirror.</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="doc">Configurez des relations SnapMirror et des planifications de conservation</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">Les systèmes ONTAP source et destination doivent se trouver dans des réseaux qui sont peering via Amazon VPC, une passerelle de transit, AWS Direct Connect ou un VPN AWS.</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">Les étapes suivantes sont requises pour la configuration des relations SnapMirror entre un système ONTAP sur site et FSX ONTAP :</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">FSX pour ONTAP – Guide de l'utilisateur ONTAP</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="paragraph">Reportez-vous à la<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> Pour plus d'informations sur la création de relations SnapMirror avec FSX.</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="section-title">Enregistrer les interfaces logiques intercluster source et destination</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">Pour le système ONTAP source résidant sur site, vous pouvez récupérer les informations LIF inter-cluster depuis System Manager ou depuis l'interface de ligne de commandes.</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">Dans ONTAP System Manager, accédez à la page Network Overview et récupérez les adresses IP de type intercluster configurées pour communiquer avec le VPC AWS où FSX est installé.</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">Pour récupérer les adresses IP intercluster pour FSX, connectez-vous à l'interface de ligne de commande et exécutez la commande suivante :</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="section-title">Établir le peering de cluster entre ONTAP et FSX</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">Pour établir le peering de cluster entre clusters ONTAP, une phrase secrète unique saisie au niveau du cluster ONTAP à l'origine doit être confirmée dans l'autre cluster.</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">Configurez le peering sur le cluster FSX de destination à l'aide de l'<block ref="9b5825a8b104756a9fc62c8432005be0" prefix=" " category="inline-code"></block> commande. Lorsque vous y êtes invité, saisissez une phrase secrète unique utilisée ultérieurement sur le cluster source pour finaliser le processus de création.</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">Sur le cluster source, vous pouvez établir la relation de pairs de cluster à l'aide de ONTAP System Manager ou de l'interface de ligne de commandes. Dans ONTAP System Manager, accédez à protection &gt; Présentation et sélectionnez Peer Cluster.</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">Dans la boîte de dialogue Peer Cluster, saisissez les informations requises :</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">Saisissez la phrase de passe utilisée pour établir la relation de cluster homologue sur le cluster FSX de destination.</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">Sélectionnez<block ref="93cba07454f06a4a960172bbd6e2a435" prefix=" " category="inline-code"></block> pour établir une relation chiffrée.</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">Entrer les adresses IP du LIF intercluster du cluster FSX de destination.</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">Cliquez sur initier le peering de cluster pour finaliser le processus.</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">Vérifiez l'état de la relation cluster peer à partir du cluster FSX avec la commande suivante :</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="section-title">Établir une relation de peering de SVM</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">L'étape suivante consiste à configurer une relation de SVM entre les machines virtuelles de stockage de destination et source qui contiennent les volumes qui seront dans les relations SnapMirror.</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">Depuis le cluster FSX source, utiliser la commande suivante depuis l'interface de ligne de commande afin de créer la relation SVM peer :</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">Depuis le cluster ONTAP source, acceptez la relation de peering avec ONTAP System Manager ou l'interface de ligne de commandes.</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">Dans ONTAP System Manager, accédez à protection &gt; Présentation et sélectionnez des VM de stockage homologues sous les pairs de machines virtuelles de stockage.</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">Dans la boîte de dialogue de la VM de stockage homologue, remplissez les champs requis :</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">La VM de stockage source</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">Cluster destination</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">L'VM de stockage de destination</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">Cliquez sur Peer Storage VM pour terminer le processus de peering de SVM.</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="section-title">Création d'une règle de conservation des snapshots</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter gère les planifications de conservation pour les sauvegardes qui existent sous forme de copies Snapshot sur le système de stockage primaire. Ceci est établi lors de la création d'une règle dans SnapCenter. SnapCenter ne gère pas de stratégies de conservation pour les sauvegardes conservées sur des systèmes de stockage secondaires. Ces règles sont gérées séparément via une règle SnapMirror créée sur le cluster FSX secondaire et associée aux volumes de destination faisant partie d'une relation SnapMirror avec le volume source.</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">Lors de la création d'une règle SnapCenter, vous avez la possibilité de spécifier une étiquette de règle secondaire ajoutée au label SnapMirror de chaque Snapshot généré lors de la création d'une sauvegarde SnapCenter.</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">Sur le stockage secondaire, ces étiquettes sont mises en correspondance avec les règles de règle associées au volume de destination pour assurer la conservation des snapshots.</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">L'exemple suivant montre une étiquette SnapMirror présente sur tous les snapshots générés dans le cadre d'une règle utilisée pour les sauvegardes quotidiennes de notre base de données SQL Server et des volumes des journaux.</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">Pour plus d'informations sur la création de stratégies SnapCenter pour une base de données SQL Server, reportez-vous au<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">Vous devez d'abord créer une règle SnapMirror avec des règles qui imposent le nombre de copies Snapshot à conserver.</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">Création de la règle SnapMirror sur le cluster FSX</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">Ajoutez des règles à la règle avec des étiquettes SnapMirror qui correspondent aux étiquettes de règles secondaires spécifiées dans les règles de SnapCenter.</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">Le script suivant fournit un exemple de règle qui peut être ajoutée à une règle :</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">Créer des règles supplémentaires pour chaque étiquette SnapMirror et le nombre de snapshots à conserver (période de conservation).</block>
  <block id="2f061612da9689d76bf56673168e2297" category="section-title">Créer des volumes de destination</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">Pour créer un volume de destination sur FSX qui sera le destinataire des copies snapshot à partir de nos volumes source, exécutez la commande suivante sur FSX ONTAP :</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="section-title">Création des relations SnapMirror entre les volumes source et de destination</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">Pour créer une relation SnapMirror entre un volume source et un volume de destination, exécutez la commande suivante sur FSX ONTAP :</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="section-title">Initialiser les relations SnapMirror</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">Initialiser la relation SnapMirror Ce processus lance un nouveau snapshot généré à partir du volume source et le copie vers le volume de destination.</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">Pour créer un volume, exécutez la commande suivante sur FSX ONTAP :</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="doc">Présentation – reprise sur incident du stockage connecté à l'invité AWS</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">Cette section fournit des instructions destinées à aider les utilisateurs à vérifier, configurer et valider leurs environnements sur site et cloud pour une utilisation avec NetApp et VMware. Cette solution est plus particulièrement axée sur l'utilisation connectée au système invité VMware avec ONTAP AFF sur site et VMware Cloud et AWS FSX ONTAP pour le cloud. Cette solution est présentée avec deux applications : Oracle et MS SQL en cas de reprise après incident.</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Solutions NetApp pour Amazon VMware Managed Cloud (VMC)</block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">En savoir plus sur les solutions NetApp pour AWS.</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">Reprise après incident avec VMC sur AWS (connecté à l'invité)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">Migrez vos charges de travail vers le datastore FSxN à l'aide de VMware HCX</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="doc">Restaurez les données applicatives SQL Server</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">Le processus suivant explique comment restaurer un serveur SQL dans VMware Cloud Services dans AWS en cas d'incident rendant le site inutilisable.</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">Les prérequis suivants sont supposés être terminés pour poursuivre les étapes de restauration :</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">La machine virtuelle Windows Server a été restaurée dans le SDDC VMware Cloud à l'aide de Veeam Full Restore.</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">Récapitulatif du processus de sauvegarde et de restauration SnapCenter.</block>
  <block id="fe51b70218e2191f0338d4bcb01eb4a7" category="list-text">Un serveur SnapCenter secondaire a été établi et la restauration et la configuration de la base de données SnapCenter ont été effectuées en suivant les étapes décrites dans la section <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="section-title">VM : configuration post-restauration pour SQL Server VM</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">Une fois la restauration de la machine virtuelle terminée, vous devez configurer la mise en réseau et d'autres éléments en vue de redécouvrir la machine virtuelle hôte dans SnapCenter.</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">Attribuez de nouvelles adresses IP pour la gestion et iSCSI ou NFS.</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">Joignez l'hôte au domaine Windows.</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">Ajoutez les noms d'hôte au serveur DNS ou au fichier hosts du serveur SnapCenter.</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">Si le plug-in SnapCenter a été déployé avec des informations d'identification de domaine différentes du domaine actuel, vous devez modifier le compte connexion pour le service Plug-in pour Windows sur la machine virtuelle SQL Server. Après avoir modifié le compte de connexion, redémarrez SnapCenter les services SMCore, Plug-in pour Windows et Plug-in pour SQL Server.</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">Pour redécouvrir automatiquement les machines virtuelles restaurées dans SnapCenter, le FQDN doit être identique à la machine virtuelle qui a été ajoutée à l'origine au système SnapCenter sur site.</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="section-title">Configurez le stockage FSX pour la restauration SQL Server</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">Pour mettre en œuvre le processus de restauration de reprise après incident pour une machine virtuelle SQL Server, vous devez interrompre la relation SnapMirror existante à partir du cluster FSX et accorder l'accès au volume. Pour ce faire, procédez comme suit.</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">Pour interrompre la relation SnapMirror existante pour les volumes de base de données SQL Server et de journaux, exécutez la commande suivante à partir de la CLI FSX :</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">Autoriser l'accès à la LUN en créant un groupe initiateur contenant l'IQN iSCSI de la machine virtuelle SQL Server Windows :</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">Enfin, mappez les LUN sur le groupe initiateur que vous venez de créer :</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">Pour trouver le nom du chemin d'accès, exécutez le<block ref="b8fdaa53ba08988f3b422c1226f85a2a" prefix=" " category="inline-code"></block> commande.</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="section-title">Configurer la machine virtuelle Windows pour l'accès iSCSI et découvrir les systèmes de fichiers</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">À partir de la VM SQL Server, configurez votre carte réseau iSCSI pour communiquer sur le Port Group VMware qui a été établi avec la connectivité aux interfaces cibles iSCSI de votre instance FSX.</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">Ouvrez l'utilitaire iSCSI Initiator Properties (Propriétés de l'initiateur iSCSI) et effacez les anciens paramètres de connectivité dans les onglets Discovery, Favorite Targets (cibles favorites) et Targets (cibles).</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">Recherchez les adresses IP permettant d'accéder à l'interface logique iSCSI sur l'instance/le cluster FSX. Cela peut être trouvé dans la console AWS, sous Amazon FSX &gt; ONTAP &gt; Storage Virtual machines.</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">Dans l'onglet découverte, cliquez sur Discover Portal et entrez les adresses IP de vos cibles iSCSI FSX.</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">Dans l'onglet cible, cliquez sur connecter, sélectionnez Activer le multichemin si nécessaire pour votre configuration, puis cliquez sur OK pour vous connecter à la cible.</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">Ouvrez l'utilitaire gestion de l'ordinateur et connectez les disques. Vérifiez qu'ils conservent les mêmes lettres de lecteur qu'ils étaient auparavant.</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="section-title">Reliez les bases de données SQL Server</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">À partir de la VM SQL Server, ouvrez Microsoft SQL Server Management Studio et sélectionnez attacher pour démarrer le processus de connexion à la base de données.</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">Cliquez sur Ajouter et naviguez jusqu'au dossier contenant le fichier de base de données primaire SQL Server, sélectionnez-le, puis cliquez sur OK.</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">Si les journaux de transactions se trouvent sur un lecteur distinct, choisissez le dossier qui contient le journal de transactions.</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">Lorsque vous avez terminé, cliquez sur OK pour joindre la base de données.</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="section-title">Confirmez la communication SnapCenter avec le plug-in SQL Server</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">Une fois la base de données SnapCenter restaurée à son état précédent, elle redécouvre automatiquement les hôtes SQL Server. Pour que cela fonctionne correctement, gardez à l'esprit les conditions préalables suivantes :</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter doit être placé en mode de reprise après incident. Ceci peut être réalisé via l'API swagger ou dans Paramètres globaux sous récupération après sinistre.</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">Le FQDN de SQL Server doit être identique à l'instance qui s'exécutait dans le data Center sur site.</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">La relation SnapMirror d'origine doit être rompue.</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">Les LUN contenant la base de données doivent être montés sur l'instance SQL Server et la base de données attachée.</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">Pour confirmer que SnapCenter est en mode reprise après sinistre, accédez à Paramètres depuis le client Web SnapCenter. Accédez à l'onglet Paramètres globaux, puis cliquez sur reprise après sinistre. Assurez-vous que la case Activer la reprise après sinistre est activée.</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38631d978812c49b6f395a78becd9750" category="summary">Le processus suivant explique comment restaurer les données d'application Oracle dans VMware Cloud Services dans AWS en cas d'incident rendant le site inutilisable.</block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="doc">Restaurez les données de l'application Oracle</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">Pour continuer les étapes de récupération, suivez les conditions préalables suivantes :</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">La machine virtuelle du serveur Oracle Linux a été restaurée dans le SDDC VMware Cloud à l'aide de Veeam Full Restore.</block>
  <block id="66d808fa42d45f6883d1a223ee26eb0c" category="list-text">Un serveur SnapCenter secondaire a été établi et la base de données SnapCenter et les fichiers de configuration ont été restaurés à l'aide des étapes décrites dans cette section <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="section-title">Configurer FSX pour la restauration Oracle – interrompre la relation SnapMirror</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">Pour rendre les volumes de stockage secondaire hébergés sur l'instance FSxN accessibles aux serveurs Oracle, vous devez d'abord interrompre la relation SnapMirror existante.</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">Après avoir ouvert une session dans la CLI FSX, exécutez la commande suivante pour afficher les volumes filtrés par le nom correct.</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">Exécutez la commande suivante pour interrompre les relations SnapMirror existantes.</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Mettez à jour le chemin de jonction dans le client Web Amazon FSX :</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">Ajoutez le nom du chemin de jonction et cliquez sur mettre à jour. Préciser cette Junction path lors du montage du volume NFS depuis le serveur Oracle.</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="section-title">Montez les volumes NFS sur Oracle Server</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">Dans Cloud Manager, vous pouvez obtenir la commande mount avec l'adresse IP correcte de la LIF NFS pour le montage des volumes NFS qui contiennent les fichiers et les journaux de la base de données Oracle.</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">Dans Cloud Manager, accédez à la liste des volumes de votre cluster FSX.</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">Dans le menu d'action, sélectionnez la commande Mount pour afficher et copier la commande mount à utiliser sur notre serveur Oracle Linux.</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">Montez le système de fichiers NFS sur le serveur Oracle Linux. Les répertoires de montage du partage NFS existent déjà sur l'hôte Oracle Linux.</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">À partir du serveur Oracle Linux, utilisez la commande mount pour monter les volumes NFS.</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Répétez cette étape pour chaque volume associé aux bases de données Oracle.</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">Pour rendre le montage NFS persistant au redémarrage, modifiez le<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> fichier à inclure les commandes de montage.</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Redémarrez le serveur Oracle. Les bases de données Oracle doivent démarrer normalement et être disponibles pour une utilisation.</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">Tr 4942 : migrer les charges de travail vers le datastore ONTAP FSX à l'aide de VMware HCX</block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">Présentation : migration de machines virtuelles avec VMware HCX, les datastores supplémentaires FSX ONTAP et VMware Cloud</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">L'une des utilisations courantes de VMware Cloud (VMC) sur Amazon Web Services (AWS) et de son datastore NFS supplémentaire sur Amazon FSX pour NetApp ONTAP est la migration des charges de travail VMware. VMware HCX est l'option privilégiée : il offre plusieurs méthodes de migration pour déplacer des machines virtuelles sur site et leurs données, s'exécutant sur n'importe quel datastore VMware pris en charge, vers des datastores VMC, notamment des datastores NFS supplémentaires sur FSX pour ONTAP.</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX est principalement une plateforme de mobilité conçue pour simplifier la migration des charges de travail, le rééquilibrage des charges de travail et la continuité de l'activité dans les clouds. Il est inclus dans VMware Cloud sur AWS et offre de nombreuses façons de migrer les charges de travail, et peut être utilisé pour les opérations de reprise après incident.</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">Ce document fournit des recommandations détaillées pour le déploiement et la configuration de VMware HCX, notamment tous ses principaux composants, sur site et côté data Center dans le cloud, qui permet d'utiliser divers mécanismes de migration de VM.</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">Introduction aux déploiements HCX</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">Installer la liste de contrôle B - HCX avec un environnement VMware Cloud sur AWS SDDC destination</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">Pour plus d'informations, voir<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> et<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>.</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">Cette liste fournit les étapes générales d'installation et de configuration de VMware HCX :</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">Activer HCX pour le Software-Defined Data Center (SDDC) du VMC via VMware Cloud Services Console</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">Téléchargez et déployez le programme d'installation OVA du connecteur HCX dans le serveur vCenter sur site.</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">Activer HCX avec une clé de licence.</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">Couplez le connecteur VMware HCX sur site avec VMC HCX Cloud Manager.</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(Facultatif) exécutez l'extension réseau pour étendre le réseau et éviter une nouvelle adresse IP.</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">Préparation de l'installation HCX</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">Avant de commencer, assurez-vous que les conditions préalables suivantes sont remplies. Pour plus d'informations, voir<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>. Une fois les prérequis en place, y compris la connectivité, configurez et activez HCX en générant une clé de licence à partir de la console VMware HCX sur VMC. Une fois que HCX est activé, le plug-in vCenter est déployé et est accessible via la console vCenter pour la gestion.</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">Les étapes d'installation suivantes doivent être effectuées avant de procéder à l'activation et au déploiement du système HCX :</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">Lien VMware</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">Nous utilisons un SDDC VMC existant ou créons un SDDC après ce processus<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> ou ceci<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>.</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">Le chemin réseau depuis l'environnement vCenter sur site vers le SDDC VMC doit prendre en charge la migration des VM à l'aide de vMotion.</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">Assurez-vous que le nécessaire<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> Sont autorisées pour le trafic vMotion entre vCenter Server sur site et SDDC vCenter.</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">Le volume FSX pour ONTAP NFS doit être monté en tant que datastore supplémentaire dans le SDDC VMC. Pour attacher les datastores NFS au cluster approprié, suivez les étapes décrites dans ce document<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> ou ceci<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>.</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">À des fins de test, l'environnement de laboratoire sur site utilisé pour cette validation a été connecté par le biais d'un VPN site à site vers AWS VPC, qui permettait la connectivité sur site à AWS et au SDDC cloud VMware via une passerelle de transport externe. La migration HCX et le trafic des extensions réseau transitent par Internet entre le SDDC de destination sur site et le SDDC de destination sur le cloud VMware. Cette architecture peut être modifiée pour utiliser les interfaces virtuelles privées Direct Connect.</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">L'image suivante représente l'architecture de haut niveau.</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">Étape 1 : activez HCX via VMC SDDC en utilisant l'option Add-ons</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">Connectez-vous à la console VMC à<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> Et accéder à l'inventaire.</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">Pour sélectionner le SDDC approprié et accéder aux Add- ons, cliquez sur View Details dans SDDC et sélectionnez l'onglet Add ans.</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">Cliquez sur Activer pour VMware HCX.</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">Cette étape peut prendre jusqu'à 25 minutes.</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">Une fois le déploiement terminé, validez le déploiement en vérifiant que HCX Manager et les plug-ins associés sont disponibles dans vCenter Console.</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">Créez les pare-feu de passerelle de gestion appropriés pour ouvrir les ports nécessaires pour accéder à HCX Cloud Manager.HCX Cloud Manager est maintenant prêt pour les opérations HCX.</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">Pour que le connecteur sur site communique avec HCX Manager dans VMC, assurez-vous que les ports pare-feu appropriés sont ouverts dans l'environnement sur site.</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">Dans la console VMC, accédez au tableau de bord HCX, allez à Administration et sélectionnez l'onglet mise à jour des systèmes. Cliquez sur demander un lien de téléchargement pour l'image OVA du connecteur HCX.</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">Avec le connecteur HCX téléchargé, déployez le fichier OVA dans le serveur vCenter sur site. Cliquez avec le bouton droit de la souris sur cluster vSphere et sélectionnez l'option déployer le modèle OVF.</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Entrez les informations requises dans l'assistant déployer modèle OVF, cliquez sur Suivant, puis sur Terminer pour déployer le connecteur OVA VMware HCX.</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">Mettez l'appliance virtuelle sous tension manuellement.pour obtenir des instructions détaillées, reportez-vous à la section<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">Après avoir déployé le connecteur OVA VMware HCX sur site et démarré l'appliance, procédez comme suit pour activer le connecteur HCX. Générez la clé de licence à partir de la console VMware HCX sur VMC et entrez la licence lors de la configuration du connecteur VMware HCX.</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">Dans VMware Cloud Console, allez dans Inventory, sélectionnez le SDDC et cliquez sur View Details. Dans l'onglet Add ans, dans la mosaïque VMware HCX, cliquez sur Ouvrir HCX.</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">Dans l'onglet clés d'activation, cliquez sur Créer une clé d'activation. Sélectionnez le type de système comme connecteur HCX et cliquez sur confirmer pour générer la clé. Copier la clé d'activation.</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">Une clé distincte est requise pour chaque connecteur HCX déployé sur site.</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">Connectez-vous au connecteur VMware HCX sur site à<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> utilisation des informations d'identification administrateur.</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">Dans la section Licence, entrez la clé d'activation copiée à partir de l'étape 2 et cliquez sur Activer.</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">Le connecteur HCX sur site doit disposer d'un accès Internet pour que l'activation puisse s'effectuer correctement.</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">Sous Datacenter Location, indiquez l'emplacement souhaité pour l'installation sur site de VMware HCX Manager. Cliquez sur Continuer .</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">Sous Nom du système, mettez à jour le nom et cliquez sur Continuer.</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">Sélectionnez Oui, puis Continuer.</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">Sous connecter votre vCenter, indiquez l'adresse IP ou le nom de domaine complet (FQDN), ainsi que les informations d'identification du serveur vCenter, puis cliquez sur Continuer.</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">Utilisez le FQDN pour éviter les problèmes de communication plus tard.</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">Sous configurer SSO/PSC, indiquez le FQDN ou l'adresse IP du contrôleur Platform Services Controller et cliquez sur Continuer.</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">Entrez l'adresse IP ou le FQDN du serveur vCenter.</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">Vérifiez que les informations saisies sont correctes et cliquez sur redémarrer.</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">Une fois l'opération terminée, le serveur vCenter s'affiche en vert. VCenter Server et SSO doivent avoir les paramètres de configuration corrects, qui doivent être identiques à la page précédente.</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">Ce processus dure environ 10 à 20 minutes et le plug-in peut être ajouté à vCenter Server.</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">Étape 4 : coupler le connecteur VMware HCX sur site avec VMC HCX Cloud Manager</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">Pour créer une paire de sites entre vCenter Server sur site et le SDDC VMC, connectez-vous au serveur vCenter sur site et accédez au plug-in client Web HCX vSphere.</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">Sous Infrastructure, cliquez sur Ajouter un couplage de site. Pour authentifier le site distant, entrez l'URL ou l'adresse IP du VMC HCX Cloud Manager et les informations d'identification du rôle CloudAdmin.</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">Les informations HCX peuvent être récupérées à partir de la page des paramètres SDDC.</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">Pour lancer le couplage du site, cliquez sur connecter.</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">Le connecteur VMware HCX doit pouvoir communiquer avec l'IP HCX Cloud Manager via le port 443.</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">Le dispositif VMware HCX Interconnect (HCX-IX) offre des fonctionnalités de tunnel sécurisées par Internet et des connexions privées au site cible qui permettent la réplication et les fonctionnalités vMotion. L'interconnexion permet le cryptage, l'ingénierie du trafic et un réseau SD-WAN. Pour créer l'appliance d'interconnexion HCI-IX, effectuez les opérations suivantes :</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">Sous Infrastructure, sélectionnez Interconnexion &gt; maillage de service multisite &gt; profils de calcul &gt; Créer un profil de calcul.</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">Les profils de calcul contiennent les paramètres de déploiement de calcul, de stockage et de réseau requis pour déployer une appliance virtuelle d'interconnexion. Ils précisent également quelle partie du data Center VMware sera accessible au service HCX.</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">Création d'un profil de calcul</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">Pour obtenir des instructions détaillées, reportez-vous à la section<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>.</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">Une fois le profil de calcul créé, créez le profil réseau en sélectionnant maillage de service multisite &gt; profils réseau &gt; Créer un profil réseau.</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">Le profil réseau définit une plage d'adresses IP et de réseaux qui seront utilisés par HCX pour ses appliances virtuelles.</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">Cela nécessite au moins deux adresses IP. Ces adresses IP seront attribuées du réseau de gestion aux appliances virtuelles.</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">Création d'un profil réseau</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">Pour obtenir des instructions détaillées, reportez-vous à la section<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>.</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">Si vous vous connectez à un réseau SD-WAN via Internet, vous devez réserver des adresses IP publiques dans la section réseau et sécurité.</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">Pour créer un maillage de service, sélectionnez l'onglet maillage de service dans l'option interconnexion et sélectionnez sites SDDC locaux et VMC.</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">Le maillage de service établit une paire de profils réseau et de calcul locale et distante.</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">Ce processus implique notamment le déploiement d'appliances HCX qui seront automatiquement configurées sur les sites source et cible, créant ainsi une structure de transport sécurisée.</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">Sélectionnez les profils de calcul source et distant, puis cliquez sur Continuer.</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">Sélectionnez le service à activer et cliquez sur Continuer.</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Une licence HCX Enterprise est requise pour la migration par réplication assistée vMotion, l'intégration SRM et la migration assistée par système d'exploitation.</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">Créez un nom pour le maillage de service et cliquez sur Terminer pour lancer le processus de création. Le déploiement devrait prendre environ 30 minutes. Une fois le maillage de service configuré, l'infrastructure virtuelle et la mise en réseau nécessaires pour migrer les VM de la charge de travail ont été créées.</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">Étape 6 : migration des workloads</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX offre des services de migration bidirectionnels entre deux environnements distincts ou plus, tels que les SDDC sur site et VMC. Les charges de travail applicatives peuvent être migrées depuis et vers des sites activés HCX à l'aide de diverses technologies de migration telles que la migration en bloc HCX, HCX vMotion, la migration à froid HCX, l'option vMotion par réplication assistée par HCX (disponible avec HCX Enterprise Edition) et la migration assistée par système d'exploitation HCX (disponible avec l'édition HCX Enterprise).</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">Pour en savoir plus sur les technologies de migration HCX disponibles, consultez<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">L'appliance HCX-IX utilise le service Mobility Agent pour effectuer des migrations vMotion, Cold et Replication Assisted vMotion (RAV).</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">L'appliance HCX-IX ajoute le service Mobility Agent en tant qu'objet hôte dans vCenter Server. Les ressources processeur, mémoire, stockage et réseau affichées sur cet objet ne représentent pas la consommation réelle sur l'hyperviseur physique hébergeant l'appliance IX.</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">Cette section décrit le mécanisme HCX vMotion. Cette technologie de migration utilise le protocole VMware vMotion pour migrer une machine virtuelle vers un SDDC VMC. L'option de migration vMotion permet de migrer l'état d'une machine virtuelle unique à la fois. Il n'y a pas d'interruption de service pendant cette méthode de migration.</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">L'extension réseau doit être en place (pour le groupe de ports dans lequel la machine virtuelle est connectée) afin de migrer la machine virtuelle sans avoir à modifier l'adresse IP.</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">Depuis le client vSphere sur site, accédez à Inventory, faites un clic droit sur la machine virtuelle à migrer, puis sélectionnez HCX actions &gt; Migrate to HCX site cible.</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">Dans l'assistant de migration d'ordinateur virtuel, sélectionner Remote site Connection (VMC SDDC cible).</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">Ajoutez un nom de groupe et sous transfert et placement, mettez à jour les champs obligatoires (réseau de cluster, de stockage et de destination), puis cliquez sur Valider.</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">Une fois les vérifications de validation terminées, cliquez sur Go pour lancer la migration.</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">Comprendre VMware HCX vMotion et la migration à froid</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">Le transfert vMotion capture la mémoire active de la machine virtuelle, son état d'exécution, son adresse IP et son adresse MAC. Pour plus d'informations sur les exigences et les limites de HCX vMotion, voir<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>.</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">Vous pouvez contrôler la progression et l'achèvement de vMotion dans le tableau de bord HCX &gt; migration.</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMware Replication Assisted vMotion</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">Comme vous l'avez peut-être remarqué dans la documentation VMware, VMware HCX Replication Assisted vMotion (RAV) combine les avantages de la migration en bloc et de vMotion. La migration en bloc utilise la réplication vSphere pour migrer plusieurs machines virtuelles en parallèle : la machine virtuelle est redémarrée lors du basculement. HCX vMotion migre sans temps d'indisponibilité, mais il est exécuté en série une machine virtuelle à la fois dans un groupe de réplication. RAV réplique la machine virtuelle en parallèle et la synchronise jusqu'à ce que la fenêtre de basculement s'affiche. Lors du processus de basculement, il migre une machine virtuelle à la fois, sans temps d'indisponibilité pour la machine virtuelle.</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">La capture d'écran suivante montre le profil de migration sous la forme Replication Assisted vMotion.</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">La durée de la réplication peut être plus longue que celle de vMotion d'un petit nombre de machines virtuelles. Avec RAV, synchronisez uniquement les données modifiées et incluez le contenu de la mémoire. Voici une capture d'écran du statut de migration : elle montre comment l'heure de début de la migration est identique et l'heure de fin est différente pour chaque machine virtuelle.</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">Pour plus d'informations sur les options de migration HCX et sur la façon de migrer des workloads sur site vers VMware Cloud sur AWS à l'aide du modèle HCX, consultez le<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion nécessite un débit de 100 Mbit/s ou plus.</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">L'espace nécessaire au datastore VMC FSX cible pour ONTAP doit être suffisant pour prendre en charge la migration.</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">Que vous cibliez les clouds 100 % cloud ou hybrides et les données résidant sur un stockage de n'importe quel type ou fournisseur sur site, Amazon FSX pour NetApp ONTAP et HCX offrent d'excellentes options pour déployer et migrer les charges de travail tout en réduisant le coût total de possession grâce à une intégration transparente des données à la couche applicative. Quels que soient les cas d'utilisation, choisissez la solution VMC et la solution FSX pour ONTAP datastore pour bénéficier rapidement des avantages du cloud, d'une infrastructure cohérente et des opérations entre plusieurs clouds et sur site, de la portabilité bidirectionnelle des charges de travail, et de la capacité et des performances de grande qualité. Il s'agit du même processus et procédures que celui utilisé pour connecter le stockage et migrer les machines virtuelles à l'aide de la réplication VMware vSphere, de VMware vMotion ou même de la copie NFC.</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">Il est désormais possible d'utiliser Amazon FSX ONTAP en tant que datastore avec VMC SDDC.</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">Vous pouvez facilement migrer des données depuis n'importe quel data Center sur site vers VMC exécuté avec FSX pour le datastore ONTAP</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">Vous pouvez facilement étendre et réduire le datastore ONTAP FSX en vue de répondre aux exigences en termes de capacités et de performances lors de l'activité de migration.</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">Documentation VMware Cloud</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">Documentation Amazon FSX pour NetApp ONTAP</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="summary">En cas d'incident survenant dans le data Center principal sur site, notre scénario inclut un basculement vers un site secondaire résidant sur l'infrastructure Amazon Web Services à l'aide de VMware Cloud sur AWS. Nous partons du principe que les machines virtuelles et notre cluster ONTAP sur site ne sont plus accessibles. En outre, les machines virtuelles SnapCenter et Veeam ne sont plus accessibles et doivent être reconstruites dans notre site secondaire.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="doc">Basculement</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="section-title">Un incident se produit sur le site primaire</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">Cette section traite du basculement de notre infrastructure vers le cloud, et aborde les sujets suivants :</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">Restauration de la base de données SnapCenter. Après l'établissement d'un nouveau serveur SnapCenter, restaurez la base de données MySQL et les fichiers de configuration, puis basculez la base de données en mode de reprise après sinistre afin de permettre au stockage FSX secondaire de devenir le périphérique de stockage principal.</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Restauration des machines virtuelles d'applications à l'aide de Veeam Backup &amp; Replication Connectez le stockage S3 contenant les sauvegardes de machines virtuelles, importez les sauvegardes et restaurez-les dans VMware Cloud sur AWS.</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">Restauration des données applicatives SQL Server à l'aide de SnapCenter</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">Restaurez les données d'application Oracle à l'aide de SnapCenter.</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="section-title">Processus de restauration de la base de données SnapCenter</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter prend en charge les scénarios de reprise après incident en permettant la sauvegarde et la restauration de sa base de données MySQL et de ses fichiers de configuration. L'administrateur peut ainsi conserver des sauvegardes régulières de la base de données SnapCenter sur le data Center sur site et restaurer ensuite cette base de données vers une base de données SnapCenter secondaire.</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">Pour accéder aux fichiers de sauvegarde SnapCenter sur le serveur SnapCenter distant, procédez comme suit :</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">Faire un break de la relation SnapMirror depuis le cluster FSX, ce qui fait du volume la lecture/écriture.</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">Créer un serveur CIFS (si nécessaire) et créer un partage CIFS pointant vers la Junction path du volume cloné.</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">Utilisez xcopy pour copier les fichiers de sauvegarde dans un répertoire local sur le système SnapCenter secondaire.</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">Installez SnapCenter v4.6.</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">Assurez-vous que le serveur SnapCenter possède le même FQDN que le serveur d'origine. Cette opération est nécessaire pour que la restauration de la base de données soit réussie.</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">Pour démarrer le processus de restauration, procédez comme suit :</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">Accédez à la page Web de l'API swagger pour le serveur SnapCenter secondaire et suivez les instructions précédentes pour obtenir un jeton d'autorisation.</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Accédez à la section récupération après sinistre de la page de swagger, puis sélectionnez<block ref="533e3565b4ab97ee497d4500afcfa0ca" prefix=" " category="inline-code"></block>, Puis cliquez sur essayer.</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">Collez le jeton d'autorisation et, dans la section SmDRResterRequest, collez le nom de la sauvegarde et le répertoire local sur le serveur SnapCenter secondaire.</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">Cliquez sur le bouton Exécuter pour lancer le processus de restauration.</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">Dans SnapCenter, accédez à la section moniteur pour afficher la progression de la tâche de restauration.</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">Pour activer les restaurations SQL Server à partir du stockage secondaire, vous devez basculer la base de données SnapCenter en mode de reprise après incident. Cette opération est exécutée séparément et lancée sur la page Web de l'API swagger.</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">Accédez à la section reprise sur incident et cliquez sur<block ref="6f4ce9a3fde10d5d540991396641c75c" prefix=" " category="inline-code"></block>.</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">Collez le jeton d'autorisation utilisateur.</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">Dans la section SmSetDisasterRecovery ySettingRequest, modifiez<block ref="b7332a241d968e08b968a292c8d519aa" prefix=" " category="inline-code"></block> à<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>.</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">Cliquez sur Exécuter pour activer le mode de reprise après sinistre pour SQL Server.</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">Voir les commentaires concernant les procédures supplémentaires.</block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="summary">VMware vSphere fournit une infrastructure virtualisée dans le data Center et dans tous les principaux fournisseurs cloud. Cet écosystème est idéal pour les scénarios de reprise après incident pour lesquels le calcul virtualisé reste cohérent, quel que soit l'emplacement. Cette solution utilise les ressources de calcul virtualisées VMware à la fois sur l'emplacement du data Center et dans le cloud VMware sur AWS.</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="doc">Calcul</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">Cette solution utilise des serveurs HPE ProLiant DL360 Gen 10 exécutant VMware vSphere v7.0U3. Nous avons déployé six instances de calcul pour fournir les ressources adéquates à nos serveurs SQL Server et Oracle.</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">Nous avons déployé 10 machines virtuelles Windows Server 2019 exécutant SQL Server 2019 avec des tailles de base de données variables et 10 machines virtuelles Oracle Linux 8.5 qui exécutent Oracle 19c, une nouvelle fois, avec des bases de données de tailles variables.</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">Nous avons déployé un SDDC dans VMware Cloud sur AWS avec deux hôtes pour fournir les ressources adéquates afin d'exécuter les machines virtuelles restaurées à partir de notre site principal.</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="summary">Les systèmes NetApp AFF A-Series offrent une infrastructure de stockage haute performance avec des options flexibles de gestion des données, adaptées à un large éventail de scénarios d'entreprise. Dans cette solution, nous avons utilisé un système ONTAP AFF A300 comme système de stockage local principal.</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">NetApp ONTAP, associé aux outils ONTAP pour VMware et SnapCenter, a été utilisé dans la solution pour fournir des fonctionnalités complètes de gestion et de sauvegarde des applications étroitement intégrées à VMware vSphere.</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">Nous avons utilisé le stockage ONTAP pour les datastores VMware qui hébergeaient les machines virtuelles et leurs fichiers VMDK. VMware prend en charge plusieurs protocoles de stockage pour les datastores connectés. Dans cette solution, nous avons utilisé des volumes NFS pour les datastores sur les hôtes ESXi. Cependant, les systèmes de stockage ONTAP prennent en charge tous les protocoles pris en charge par VMware.</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">La figure suivante décrit les options de stockage VMware.</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">Les volumes ONTAP ont été utilisés pour le stockage connecté aux invités iSCSI et NFS pour nos machines virtuelles applicatives. Nous avons utilisé les protocoles de stockage suivants pour les données d'application :</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">Volumes NFS pour les fichiers de base de données Oracle connectés à l'invité.</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">LUN iSCSI pour les bases de données Microsoft SQL Server connectées à l'invité et les journaux de transactions.</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">Système d'exploitation</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">Type de base de données</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">Protocole de stockage</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">Description du volume</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="cell">Windows Server 2019</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">Fichiers de base de données</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">Fichiers journaux</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Binaire Oracle</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Données Oracle</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Fichiers de restauration Oracle</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">Nous avons également utilisé le stockage ONTAP pour le référentiel de sauvegarde Veeam principal ainsi que pour une cible de sauvegarde pour les sauvegardes de base de données SnapCenter.</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Partage SMB pour le référentiel de sauvegarde Veeam.</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">Partage SMB en tant que cible des sauvegardes de bases de données SnapCenter.</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="section-title">Le stockage cloud</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">Cette solution inclut VMware Cloud sur AWS pour l'hébergement de machines virtuelles restaurées dans le cadre du processus de basculement. À ce jour, VMware prend en charge le stockage VSAN pour les datastores hébergeant les machines virtuelles et les VMDK.</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">La solution FSX pour ONTAP est utilisée comme stockage secondaire pour les données d'application mises en miroir à l'aide de SnapCenter et SyncMirror. Dans le cadre du processus de basculement, le cluster FSX pour ONTAP est converti en stockage primaire et les applications de base de données peuvent reprendre le fonctionnement normal s'exécutant sur le cluster de stockage FSX.</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="section-title">Configuration d'Amazon FSX pour NetApp ONTAP</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Pour déployer AWS FSX pour NetApp ONTAP à l'aide de Cloud Manager, suivez les instructions indiquées à l'adresse<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>.</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">Une fois FSX ONTAP déployé, effectuez un glisser-déposer des instances ONTAP sur site dans FSX ONTAP pour lancer la configuration de la réplication des volumes.</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">La figure suivante représente notre environnement FSX ONTAP.</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="section-title">Interfaces réseau créées</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">FSX pour NetApp ONTAP dispose d'interfaces réseau préconfigurées et prêtes à l'emploi pour les réseaux iSCSI, NFS, SMB et inter-cluster.</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="section-title">Stockage de datastore de VM</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">Le SDDC VMware Cloud est fourni avec deux datastores VSAN nommés<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> et<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>. Nous avons utilisé<block ref="c6a4bd2172044149e40e139792052ab8" prefix=" " category="inline-code"></block> Pour héberger des VM de gestion avec accès limité aux informations d'identification cloud admin Pour les charges de travail, nous avons utilisé<block ref="8ca7ba8bcaef71f95d69539e78c555c3" prefix=" " category="inline-code"></block>.</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">Dans cette solution, SnapCenter fournit des snapshots cohérents au niveau des applications pour les données des applications SQL Server et Oracle. Combinée à la technologie SnapMirror, cette configuration assure une réplication des données ultra-rapide entre nos clusters AFF et FSX ONTAP sur site. De plus, Veeam Backup &amp; Replication offre des fonctionnalités de sauvegarde et de restauration pour nos machines virtuelles.</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">Dans cette section, nous allons parler de la configuration de SnapCenter, SnapMirror et Veeam pour la sauvegarde et la restauration.</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">Les sections suivantes couvrent la configuration et les étapes nécessaires pour effectuer le basculement sur le site secondaire :</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="list-text">Déploiement et configuration de Windows SnapCenter Server sur site</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">Découvrez les fonctionnalités que NetApp propose aux trois (3) principaux hyperscalers : qu'il s'agisse d'un système de stockage connecté à l'invité ou d'un datastore NFS supplémentaire pour migrer les flux de travail, étendre/bursting sur le cloud, la sauvegarde/restauration et la reprise après incident.</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">Choisissez votre cloud et laissez NetApp faire le reste !</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">Pour afficher les fonctionnalités d'un hyperscaler, cliquez sur l'onglet approprié.</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">VMware dans la configuration des hyperscalers</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">Options de stockage NetApp</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="ccb4d111a650d51ca9a8feb2542610be" category="paragraph">Le stockage NetApp peut être utilisé de différentes façons, soit en tant que datastore NFS supplémentaire, au sein de chacun des 3 principaux hyperscalers.</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">Avec les solutions cloud NetApp et VMware, vous pouvez facilement déployer dans l'hyperscaler de votre choix. VMware définit les principales utilisations des workloads cloud comme suit :</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">Découvrez les solutions NetApp pour AWS/VMC</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">Découvrez les solutions NetApp pour Azure/AVS</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Découvrez les solutions NetApp pour Google Cloud Platform (GCP) / GCVE</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">Série de blogs portant sur les fonctionnalités de la solution dans tout le contenu Solutions NetApp</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">Solutions NetApp : blogs</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">Présentation des blogs portant sur des fonctionnalités spécifiques des nombreuses solutions NetApp.</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">Intelligence artificielle</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">Anglais</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;F:@facette_soultion_mktg=[ai,analytique,intelligence artificielle]+[blogs IA sur NetApp.com]</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">Blogs IA sur thePub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="open-title">Base de données d'entreprise</block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Modernisez vos bases de données Oracle dans le cloud hybride avec le stockage Amazon FSX</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">Solutions de base de données pour le cloud hybride avec SnapCenter</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">Automatisez votre infrastructure de bases de données Oracle dans le cloud hybride</block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">Multicloud hybride avec VMware</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">Optimisation du stockage pour les déploiements VMware basés sur le cloud</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">Lancez-vous avec la solution Azure VMware grâce aux offres cloud NetApp</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">Configurer le cloud hybride avec FSX pour NetApp ONTAP et VMware Cloud sur AWS SDDC par l'intermédiaire de VMware HCX</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp et VMware Cloud Foundation (VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">Partie 1 : pour commencer</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">Partie 2 : stockage principal de VCF et de ONTAP</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">Partie 3 : stockage principal des éléments et des VCF</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">Partie 4 : Outils ONTAP pour VMware et stockage supplémentaire</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Utilisations d'Astra DevOps :</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">Protégez facilement votre pipeline Kubernetes ci/CD avec NetApp Astra Control</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">DevOps avec NetApp : utilisez Astra Control pour réaliser une analyse post-mortem et restaurer votre application</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center : le bouton simple de la gestion des données de votre application</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Installation de NetApp Trident sur Red Hat OpenShift – Comment résoudre le problème de Docker « toomanyRequests » !</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="list-text"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">Utilisation de VMware Tanzu avec ONTAP pour accélérer votre transition vers Kubernetes</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">&lt;Nom de la solution&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">Auteur(s) : &lt;nom&gt;, &lt;titre&gt;, &lt;entreprise&gt;</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="section-title">Objectif</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">Cette solution répond aux cas d'utilisation suivants :</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">&lt;cas d'utilisation 1&gt;</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">&lt;cas d'utilisation 2&gt; ...</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">&lt;cas d'utilisation n&gt;</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">Public</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">Cette solution est destinée au &lt;rôle&gt; qui s'intéresse à &lt;objectif&gt;.</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">OU</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">Cette solution est destinée à :</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">&lt;rôle&gt;, intéressé par &lt;objectif&gt;,</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">&lt;rôle&gt;, qui est intéressé par &lt;objectif&gt;.</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">Environnement de test/validation de la solution</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">Le test/validation de cette solution a été effectué dans un laboratoire qui peut correspondre ou non à l'environnement de déploiement final. Pour plus d'informations, reportez-vous aux sections suivantes.</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">Diagramme de l'architecture de la solution</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="example-title">Composants matériels/logiciels</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*Matériel*</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">&lt;nom du matériel&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">&lt;modèle/version&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">Plus d'informations</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*Logiciel*</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">&lt;nom du logiciel&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">&lt;version&gt;</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="example-title">Remarques supplémentaires</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">Remarque 1</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">Note 2 ...</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">Remarque n</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">Le déploiement de cette solution peut être effectué :</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">Manuellement en suivant les instructions détaillées avec les captures d'écran,</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">Manuellement en suivant avec des vidéos montrant les étapes à exécuter, ou</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">Suivez automatiquement les instructions de la section automatisation.</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">Instructions détaillées</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">Étape 1 : &amp;lt;description du nom de l'étape&amp;gt;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">Tâche 1</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">Tâche 2 ...</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">Tâche n</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">Étape 2 : &amp;lt;description du nom de l'étape&amp;gt;</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">Étape n: &amp;Lt;description du nom de l'étape&amp;gt;</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">Présentation vidéo</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">&lt;incluez les détails de la ou des vidéo(s) ici&gt;</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">Déploiement automatisé</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">&lt;incluez les étapes/processus/vidéos automatisées ici&gt;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">Autres options de déploiement</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">&amp;Lt;Description de l'option 1&amp;gt;</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">&lt;entrez les détails de l'option ici&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">&amp;Lt;Description de l'option 2&amp;gt;</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">&amp;Lt;Description de l'option n&amp;gt ;</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">Description du document</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">Description d'un autre document</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">Série de vidéos et démonstrations montrant les fonctionnalités de nombreuses solutions NetApp</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">Solutions NetApp : vidéos et démonstrations</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">Présentation des vidéos et des démonstrations illustrant les fonctionnalités spécifiques des nombreuses solutions NetApp.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">Solutions NetApp d'IA</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">Les bases de données et les applications d'entreprise</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">Cluster SQL haute disponibilité sur Azure NetApp Files</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">Clonage de base de données enfichable mutualisé Oracle à l'aide des snapshots de stockage</block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Déploiement automatisé d'Oracle 19c RAC sur FlexPod avec Ansible</block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">*Étude de cas*</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">SAP sur Azure NetApp Files</block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="example-title">Multicloud hybride (HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[Souligné]#*vidéos pour AWS/VMC*#</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">Déploiement et configuration de VMware HCX pour VMC</block>
  <block id="c6434a9743fb403cd78cd2d3a42d9683" category="video-title">Démonstration de VMotion avec VMware HCX pour VMC et FSxN</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">Démonstration de la migration à froid avec VMware HCX pour VMC et FSxN</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[Souligné]#*vidéos pour Azure/AVS*#</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">Démonstration de la migration à froid avec VMware HCX pour AVS et ANF</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">Démonstration de VMotion avec VMware HCX pour AVS et ANF</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">Démonstration de la migration en bloc avec VMware HCX pour AVS et ANF</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">Collection de vidéos VMware</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">Conteneurs/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">Vidéos NetApp pour Anthos de Google</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">Vidéos NetApp avec VMware Tanzu</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">Vidéos NetApp pour le DevOps</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">Vidéos NetApp avec Red Hat OpenShift</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="example-title">Automatisation de la solution</block>
  <block id="881214767967db331c99550277ceb793" category="summary">Cette page décrit l'architecture Splunk, y compris les définitions clés, les déploiements distribués Splunk, Splunk SmartStore, le flux de données, exigences matérielles et logicielles, exigences uniques et multisites, etc.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Architecture Splunk</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">Précédent : fonctionnalités flexibles de StorageGRID pour Splunk SmartStore.</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">Définitions de clés</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">Les deux tableaux suivants répertorient les composants Splunk et NetApp utilisés dans le déploiement Splunk distribué.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">Les composants matériels Splunk pour la configuration distribuée de Splunk Enterprise sont répertoriés dans ce tableau.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Composant Splunk</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">Indexeur</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Référentiel pour les données d'entreprise Splunk</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">Transitaire universel</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">Responsable de l'acquisition des données et de leur transfert vers ces indexeurs</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">En-tête de recherche</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">Le frontal utilisateur utilisé pour rechercher des données dans les indexeurs</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">Maître de cluster</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Gestion de l'installation de dispositifs d'indexation et de têtes de recherche dans Splunk</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">Console de surveillance</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">Outil de surveillance centralisée utilisé pour l'ensemble du déploiement</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">Maître de licence</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">Le maître de licence gère les licences Splunk Enterprise</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">Serveur de déploiement</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">Met à jour les configurations et distribue les applications au composant de traitement</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">Composant de stockage</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">Stockage 100 % Flash utilisé pour gérer les données fortement sollicitées. Également appelé stockage local.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">Stockage objet S3 utilisé pour gérer les données de Tier chaud. Utilisé par SmartStore pour déplacer des données entre le niveau chaud et le niveau chaud. Également appelé stockage à distance.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">Ce tableau répertorie les composants de l'architecture de stockage Splunk.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">Composant responsable</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">SmartStore</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">Indexeurs avec la possibilité de transférer les données depuis un stockage local vers le stockage objet.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">Chaud</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">Le lieu d'atterrissage où les transitaires universels placent des données récemment écrites. Le stockage est inscriptible et les données sont consultables. Ce niveau de données comprend généralement des disques SSD ou des disques durs rapides.</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">Gestionnaire de cache</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">Gère le cache local des données indexées, extrait les données utiles du stockage distant lors d'une recherche et supprime les données les moins utilisées du cache.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">Chaud</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">Les données sont déplacées de manière logique dans le compartiment, puis renommées dans le Tier chaud en premier depuis le Tier actif. Les données de ce niveau sont protégées et, comme le niveau à chaud, peuvent être composées de disques durs ou SSD plus grande capacité. Les sauvegardes incrémentielles et complètes sont prises en charge à l'aide de solutions communes de protection des données.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">De déploiements distribués Splunk</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">Pour prendre en charge des environnements de taille supérieure dans lesquels les données proviennent de plusieurs machines, vous devez traiter d'importants volumes de données. Si de nombreux utilisateurs doivent rechercher les données, vous pouvez faire évoluer le déploiement en distribuant les instances Splunk Enterprise sur plusieurs machines. Il s'agit d'un déploiement distribué.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">Dans un déploiement distribué standard, chaque instance Splunk Enterprise effectue une tâche spécialisée et réside sur l'un des trois tiers de traitement correspondant aux principales fonctions de traitement.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">Le tableau suivant répertorie les tiers de traitement Splunk Enterprise.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">Niveau</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">Saisie de données</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">Transitaire</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">Un transitaire consomme des données et les transfère ensuite vers un groupe d'indexeurs.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">Indexation</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">Un indexeur indexe les données entrantes qu'il reçoit habituellement d'un groupe de transitaires. L'indexeur transforme les données en événements et stocke les événements dans un index. L'indexeur recherche également les données indexées en réponse aux demandes de recherche à partir d'un tête de recherche.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">Gestion des recherches</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">Un en-tête de recherche sert de ressource centrale pour la recherche. Les en-têtes de recherche d'un cluster sont interchangeables et ont accès aux mêmes recherches, tableaux de bord, objets Knowledge, etc., à partir de n'importe quel membre du cluster de tête de recherche.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">Le tableau suivant répertorie les composants importants utilisés dans un environnement distribué Splunk Enterprise.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">Responsabilité</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">Maître de cluster d'index</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">Coordonne les activités et les mises à jour d'un groupe d'indexeur</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">Gestion de l'index</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">Groupe d'index</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">Groupes d'indexeurs Splunk Enterprise configurés pour répliquer les données les uns avec les autres</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">Déployeur de tête de recherche</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">Gère le déploiement et les mises à jour du maître de cluster</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">Gestion des têtes de recherche</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">Rechercher le groupe de têtes de recherche</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">Groupe d'en-têtes de recherche qui sert de ressource centrale pour la recherche</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">Balancers de charge</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">Utilisé par les composants en cluster pour gérer la demande croissante par les têtes de recherche, les indexeurs et la cible S3 pour répartir la charge entre les composants en cluster.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">Gestion des charges pour les composants en cluster</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Découvrez les avantages des déploiements distribués Splunk Enterprise :</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">Accédez à des sources de données diverses ou dispersées</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">Fournir des fonctionnalités capables de gérer les besoins en données des entreprises de toute taille et de toute complexité</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">Bénéficiez d'une haute disponibilité et d'une reprise après incident grâce à la réplication des données et au déploiement multisite</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore est une fonctionnalité d'indexeur qui permet aux magasins d'objets distants comme Amazon S3 de stocker des données indexées. Étant donné que le volume de données d'un déploiement augmente, la demande de stockage dépasse les attentes en matière de ressources de calcul. SmartStore vous permet de gérer vos ressources de stockage et de calcul d'indexeur de manière rentable en faisant évoluer ces ressources séparément.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore présente un niveau de stockage distant et un gestionnaire de cache. Ces fonctionnalités permettent aux données de résider localement sur les indexeurs ou sur le Tier de stockage distant. Le gestionnaire de cache gère le déplacement des données entre l'indexeur et le niveau de stockage distant, qui est configuré sur l'indexeur.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">Avec SmartStore, vous pouvez réduire au minimum l'empreinte de stockage des indexeur et choisir des ressources de calcul optimisées en E/S. Le plus grand nombre de données réside dans le stockage distant L'indexeur gère un cache local qui contient une quantité minimale de données : compartiments actifs, copies de compartiments chauds participant à des recherches actives ou récentes, et métadonnées de compartiment.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Flux de données Splunk SmartStore</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">Lorsque les données entrantes de différentes sources atteignent les indexeurs, les données sont indexées et sauvegardées localement dans un compartiment chaud. L'indexeur réplique également les données du compartiment chaud sur les indexeurs cibles. Jusqu'à présent, le flux de données est identique au flux de données pour les index non SmartStore.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">Le flux de données diverge lorsque le godet chaud se déplace vers la chaleur. L'indexeur source copie le compartiment chaud dans le magasin d'objets distant (Tier de stockage distant) tout en laissant la copie existante dans son cache, car les recherches ont tendance à s'exécuter sur les données récemment indexées. Toutefois, les indexeurs cibles suppriment leurs copies, car le magasin distant offre une haute disponibilité sans conserver plusieurs copies locales. La copie principale du compartiment réside à présent dans le magasin distant.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">L'image suivante présente le flux de données Splunk SmartStore.</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">Le gestionnaire de cache sur l'indexeur est central dans le flux de données SmartStore. Il extrait des copies de godets de la boutique à distance, si nécessaire, pour traiter les demandes de recherche. Il supprime également les copies plus anciennes ou moins recherchées des compartiments du cache, car la probabilité de leur participation aux recherches diminue au fil du temps.</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">Le travail du gestionnaire de cache consiste à optimiser l'utilisation du cache disponible tout en s'assurant que les recherches ont un accès immédiat aux compartiments dont elles ont besoin.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">Le tableau ci-dessous répertorie les composants logiciels requis pour implémenter la solution. Ils peuvent varier selon l'implémentation de la solution et les besoins du client.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">Famille de produits</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">Nom du produit</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">Version du produit</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">Stockage objet StorageGRID</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise avec SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">Exigences uniques et multisites</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">Dans un environnement Splunk d'entreprise (déploiements de taille moyenne ou grande) où les données proviennent de nombreuses machines et où de nombreux utilisateurs ont besoin de rechercher les données, vous pouvez faire évoluer votre déploiement en distribuant les instances Splunk Enterprise sur un ou plusieurs sites.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">Le tableau suivant répertorie les composants utilisés dans un environnement distribué Splunk Enterprise.</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">Groupe d'indexeurs Splunk Enterprise configurés pour la réplication des données les uns des autres</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">Équilibreurs de charge</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">Gestion de la charge des composants en cluster</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">Cette figure illustre un exemple de déploiement distribué sur un seul site.</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">Cette figure illustre un exemple de déploiement distribué multisite.</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">Les tableaux suivants répertorient le nombre minimal de composants matériels requis pour implémenter la solution. Ils peuvent varier selon les besoins du client et dans une implémentation spécifique de la solution.</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">Que vous ayez déployé Splunk SmartStore et StorageGRID dans un seul site ou sur plusieurs sites, tous les systèmes sont gérés depuis une seule interface depuis StorageGRID GRID Manager. Pour plus de détails, reportez-vous à la section « gestion simple avec Grid Manager ».</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">Ce tableau répertorie le matériel utilisé pour un seul site.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">Disque</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">Capacité exploitable</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">Remarque</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">Nœud d'administration et équilibreur de charge</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48, 8 TO (HDD NL-SAS)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1 PO</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">Stockage distant</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">Ce tableau répertorie le matériel utilisé pour une configuration multisite (par site).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">Nœud d'administration et équilibreur de charge</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">Équilibreur de charge StorageGRID NetApp : système SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">Le stockage objet nécessite l'utilisation d'un équilibreur de charge afin de présenter le namespace du stockage cloud. StorageGRID prend en charge des équilibreurs de charge tiers provenant de grands fournisseurs tels que F5 et Citrix, mais de nombreux clients choisissent l'équilibreur StorageGRID haute performance pour privilégier la simplicité, la résilience et la performance. Le équilibreur de charge StorageGRID est disponible en tant que VM, conteneur ou appliance dédiée.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">Le système StorageGRID SG1000 facilite l'utilisation de groupes haute disponibilité (HA) et de l'équilibrage intelligent de la charge pour les connexions de chemin d'accès aux données S3. Aucun autre système de stockage objet sur site ne fournit un équilibreur de charge personnalisé.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">L'appareil SG1000 offre les fonctionnalités suivantes :</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">Un équilibreur de charge et, en option, un nœud d'administration fonctionnent pour un système StorageGRID</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">Le programme d'installation de l'appliance StorageGRID simplifie le déploiement et la configuration des nœuds</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">Configuration simplifiée des terminaux S3 et du protocole SSL</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">Bande passante dédiée (au lieu de partager un équilibreur de charge avec d'autres applications)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">Jusqu'à 4 x 100 Gbit/s de bande passante Ethernet agrégée</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">L'image suivante montre l'appliance SG1000 Gateway Services.</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">L'appliance StorageGRID SG6060 inclut un contrôleur de calcul (SG6060) et un tiroir de contrôleur de stockage (E-Series E2860) qui contient deux contrôleurs de stockage et 60 disques. Cet appareil offre les fonctions suivantes :</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">Évoluez jusqu'à 400 po dans un seul espace de noms.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">Jusqu'à 4 x 25 Gbit/s de bande passante Ethernet agrégée.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">Inclut le programme d'installation de l'appliance StorageGRID pour simplifier le déploiement et la configuration des nœuds.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">Chaque appliance SG6060 peut posséder un ou deux tiroirs d'extension supplémentaires pour un total de 180 disques.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">Deux contrôleurs E2800 de la gamme E-Series (configuration duplex) pour une prise en charge du basculement du contrôleur de stockage.</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">Tiroir disque à cinq tiroirs contenant soixante disques de 3.5 pouces (deux disques SSD et 58 disques NL-SAS).</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">L'image suivante montre l'appliance SG6060.</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Conception Splunk</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">Le tableau suivant répertorie la configuration Splunk pour un seul site.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">Cœurs</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">Mémoire</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 cœurs</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GO DE RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">Gère les données utilisateur</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">L'utilisateur frontal recherche les données dans les indexeurs</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">Permet de gérer les mises à jour des clusters de têtes de recherche</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Gère l'installation et les indexeurs Splunk</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">Console de surveillance et maître de licence</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Contrôle centralisé de l'ensemble du déploiement Splunk et gère les licences Splunk</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">Les tableaux suivants décrivent la configuration de Splunk pour les configurations multisites.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">Ce tableau répertorie la configuration Splunk pour une configuration multisite (site A).</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">Responsable de l'acquisition des données et de leur transfert vers ces indexeurs.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Contrôle centralisé de l'ensemble du déploiement Splunk et gère les licences Splunk.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">Ce tableau répertorie la configuration Splunk pour une configuration multisite (site B).</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">Suivant : performances SmartStore sur un seul site.</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp est un outil natif utilisé pour les copies intercluster et intracluster de grande taille. Le processus de distCp de base d'Hadoop est un workflow de sauvegarde standard qui utilise des outils natifs Hadoop tels que MapReduce pour copier des données Hadoop d'une source HDFS vers une cible correspondante.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Protection des données Hadoop et NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">Précédent : Data Fabric optimisée par NetApp pour l'architecture Big Data.</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DistCp est un outil natif utilisé pour les copies intercluster et intracluster de grande taille. Le processus de distribution Hadoop présenté dans la figure ci-dessous illustre un workflow de sauvegarde standard utilisant des outils natifs Hadoop tels que MapReduce pour copier les données Hadoop d'une source HDFS vers une cible correspondante. L'accès direct NetApp NFS permet aux clients de définir NFS en tant que destination cible pour l'outil Hadoop DistCp afin de copier les données à partir d'une source HDFS vers un partage NFS via MapReduce. L'accès direct NFS NetApp joue le rôle de pilote NFS pour l'outil DistCp.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">Next : présentation des cas d'utilisation de la protection des données Hadoop.</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">Cette section couvre le matériel et les logiciels utilisés pour la certification de confluent. Ces informations s'appliquent au déploiement Kafka avec le stockage NetApp.</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">Précédent : bonnes pratiques.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Le dimensionnement Kafka peut être effectué avec quatre modes de configuration : simples, granulaires, inverses et partitions.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">Simplicité</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">Le mode simple est adapté aux utilisateurs Apache Kafka pour la première fois ou aux cas d'utilisation précoces. Dans ce mode, vous indiquez des exigences telles que le débit Mbit/s, la lecture de l'extraction, la conservation et le pourcentage d'utilisation des ressources (60 % par défaut). Vous entrez également dans cet environnement, comme sur site (bare-Metal, VMware, Kubernetes ou OpenStack) ou dans le cloud. Sur la base de ces informations, le dimensionnement d'un cluster Kafka indique le nombre de serveurs requis pour le courtier, le gardien de domaine, les employés Apache Kafka Connect, le registre de schéma, un proxy REST, ksqlDB et le centre de contrôle confluent.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">Pour le stockage à plusieurs niveaux, tenez compte du mode de configuration granulaire pour le dimensionnement d'un cluster Kafka. Le mode granulaire est adapté aux utilisateurs Apache Kafka expérimentés ou aux cas d'utilisation bien définis. Cette section décrit le dimensionnement des producteurs, des processeurs de flux et des consommateurs.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">Producteurs</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Pour décrire les producteurs d'Apache Kafka (par exemple un client natif, un proxy REST ou un connecteur Kafka), fournissez les informations suivantes :</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*Nom.* Spark.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">*Type Producteur.* application ou service, proxy (REST, MQTT, autre) et base de données existante (SGBDR, NOSQL, autre). Vous pouvez également sélectionner « Je ne sais pas ».</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*Débit moyen.* en événements par seconde (1,000,000 par exemple).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*Débit maximal.* en événements par seconde (4,000,000 par exemple).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*Taille moyenne des messages.* en octets non compressés (max 1MB; 1000 par exemple).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">*Format de message.* les options incluent Avro, JSON, tampons de protocole, binaire, texte, « Je ne sais pas » et autres.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*Facteur de réplication.* les options sont 1, 2, 3 (recommandation confluent), 4, 5, ou 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*Temps de rétention.* un jour (par exemple). Combien de temps souhaitez-vous que vos données soient stockées dans Apache Kafka ? Entrez -1 avec n'importe quelle unité pour une durée infinie. La calculatrice suppose un temps de rétention de 10 ans pour une rétention infinie.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">Cochez la case « Activer le stockage à plusieurs niveaux pour réduire le nombre de courtiers et autoriser le stockage Infinite Storage ? ».</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">Lorsque le stockage à plusieurs niveaux est activé, les champs de conservation contrôlent le jeu actif des données stockées localement sur le courtier. Les champs de conservation d'archivage contrôlent la durée de stockage des données dans le stockage objet d'archivage.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* Conservation du stockage d'archives.* un an (par exemple). Combien de temps souhaitez-vous que vos données soient stockées dans vos archives ? Entrez -1 avec n'importe quelle unité pour une durée infinie. La calculatrice suppose une rétention de 10 ans pour une rétention infinie.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*Multiplicateur de croissance.* 1 (par exemple). Si la valeur de ce paramètre est basée sur le débit actuel, réglez-la sur 1. Pour une taille basée sur une croissance supplémentaire, définissez ce paramètre sur un multiplicateur de croissance.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*Nombre d'instances d'apporteurs.* 10 (par exemple). Combien d'instances d'apporteurs s'exécutent ? Cette entrée est nécessaire pour incorporer la charge CPU dans le calcul du dimensionnement. Une valeur vide indique que la charge CPU n'est pas intégrée au calcul.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">Sur la base de cet exemple d'entrée, le dimensionnement a l'effet suivant sur les producteurs :</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">Débit moyen en octets non compressés : 1 Gbits/s Débit maximal en octets non compressés : 4 Gbit/s Débit moyen en octets compressés : 400 Mbit/s. Débit maximal en octets compressés : 1,6 Gbit/s Ceci est basé sur un taux de compression par défaut de 60 % (vous pouvez modifier cette valeur).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">Stockage total des jeux d'accès on-broker requis : 31 104 To, incluant la réplication, compressé. Stockage d'archivage hors courtier total requis : 378 432 To, compressé. Utiliser <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> Pour le dimensionnement des StorageGRID.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">Les processeurs stream doivent décrire leurs applications ou services qui consomment les données d'Apache Kafka et les produisent dans Apache Kafka. Dans la plupart des cas, ces systèmes sont basés sur des flux ksqlDB ou Kafka.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*Nom.* Spark streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*Temps de traitement.* combien de temps ce processeur prend-il pour traiter un seul message?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ms (transformation simple sans état) [exemple], 10 ms (fonctionnement avec état en mémoire).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ms (fonctionnement avec état du réseau ou du disque), 1 000 ms (appels REST tiers).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">J'ai évalué ce paramètre et je sais exactement combien de temps il prend.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*Conservation de la sortie.* 1 jour (exemple). Un processeur de flux reproduit son débit vers Apache Kafka. Combien de temps souhaitez-vous que ces données soient stockées dans Apache Kafka ? Entrez -1 avec n'importe quelle unité pour une durée infinie.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">Cochez la case « Activer le stockage à plusieurs niveaux pour réduire le nombre de courtiers et autoriser le stockage Infinite Storage ? ».</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* Conservation du stockage d'archives.* 1 an (par exemple). Combien de temps souhaitez-vous que vos données soient stockées dans vos archives ? Entrez -1 avec n'importe quelle unité pour une durée infinie. La calculatrice suppose une rétention de 10 ans pour une rétention infinie.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*Pourcentage de Passthrough de sortie.* 100 (par exemple). Un processeur de flux reproduit son débit vers Apache Kafka. Quel pourcentage du débit entrant sera reputé dans Apache Kafka ? Par exemple, si le débit entrant est de 20 Mbit/s et que cette valeur est de 10, le débit de sortie est de 2 Mbit/s.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">À partir de quelles applications est-ce lu ? Sélectionnez « Spark », le nom utilisé dans le dimensionnement basé sur le type d'apporteur. En vous basant sur les données ci-dessus, vous pouvez vous attendre à ce que les effets suivants de dimensionnement sur les instances de processus de flux et les estimations de partition de rubrique :</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">Cette application de processeur de flux nécessite le nombre d'instances suivant. Les sujets entrants requièrent probablement aussi ce grand nombre de partitions. Contactez confluent pour confirmer ce paramètre.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 pour le débit moyen sans multiplicateur de croissance</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">4,000 pour un débit maximal sans multiplicateur de croissance</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 pour le débit moyen avec un multiplicateur de croissance</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">4,000 pour un débit maximal avec un multiplicateur de croissance</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">Consommateurs</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Décrivez vos applications ou services qui consomment les données d'Apache Kafka et qui ne produisent pas de retour dans Apache Kafka, par exemple un client natif ou un connecteur Kafka.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*Nom.* Spark consumer.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*Temps de traitement.* combien de temps ce consommateur prend-il pour traiter un seul message?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ms (par exemple, une tâche simple avec état, comme la journalisation)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ms (écritures rapides vers un datastore)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ms (écritures lentes dans un datastore)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1 000 ms (appel REST tiers)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">Un autre processus de test de durée connue.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*Type de client.* application, proxy ou évier à un datastore existant (RDBMS, NoSQL, autre).</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">À partir de quelles applications est-ce lu ? Connectez ce paramètre avec le dimensionnement du producteur et du flux déterminé précédemment.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">En vous basant sur les données ci-dessus, vous devez déterminer le dimensionnement des instances grand public et des estimations de partition de rubrique. Une application client nécessite le nombre d'instances suivant.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">2,000 pour le débit moyen, pas de multiplicateur de croissance</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">8,000 pour le débit maximal, pas de multiplicateur de croissance</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">2,000 pour le débit moyen, y compris le multiplicateur de croissance</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">8,000 pour le débit maximal, y compris le multiplicateur de croissance</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">Les rubriques entrantes ont probablement également besoin de ce nombre de partitions. Contactez le confluent pour confirmer.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">En plus des exigences des producteurs, des transformateurs de flux et des consommateurs, vous devez fournir les exigences supplémentaires suivantes :</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*Temps de reconstruction.* par exemple, 4 heures. Si un hôte de courtier Apache Kafka échoue, ses données sont perdues et un nouvel hôte est provisionné pour remplacer l'hôte défaillant, à quel rythme ce nouvel hôte doit-il se reconstruire lui-même ? Laissez ce paramètre vide si la valeur est inconnue.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*Objectif d'utilisation des ressources (pourcentage).* par exemple, 60. De quelle manière souhaitez-vous que vos hôtes soient en débit moyen ? Confluent recommande une utilisation de 60 %, à moins d'utiliser des clusters d'auto-équilibrage fluides, dans lesquels le taux d'utilisation peut être plus élevé.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">Décrivez votre environnement</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*Quel environnement votre cluster sera-t-il exécuté ?* Amazon Web Services, Microsoft Azure, plateforme cloud Google, bare-Metal sur site, VMware sur site, OpenStack sur site ou Kubernates sur site ?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*Détails de l'hôte.* nombre de cœurs : 48 (par exemple), type de carte réseau (10 GbE, 40 GbE, 16 GbE, 1 GbE ou un autre type).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*Volumes de stockage.* hôte : 12 (par exemple). Combien de disques durs ou SSD sont pris en charge par hôte ? Confluent recommande 12 disques durs par hôte.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*Capacité de stockage/volume (en Go).* 1000 (par exemple). Quelle quantité de stockage un seul volume peut-il stocker en gigaoctets ? Le confluent recommande des disques de 1 To.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*Configuration du stockage.* Comment les volumes de stockage sont-ils configurés ? Confluent recommande RAID10 pour tirer profit de toutes les caractéristiques confluentes. JBOD, SAN, RAID 1, RAID 0, RAID 5, et d'autres types sont également pris en charge.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*Débit volumique unique (Mbit/s).* 125 (par exemple). Quelle est la vitesse à laquelle un volume de stockage peut-il lire ou écrire en mégaoctets par seconde ? Confluent recommande des disques durs standard dont le débit est généralement de 125 Mbit/s.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*Capacité de mémoire (Go).* 64 (par exemple).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">Une fois les variables d'environnement déterminées, sélectionnez Size My Cluster (taille du cluster). Sur la base des exemples de paramètres indiqués ci-dessus, nous avons déterminé le dimensionnement suivant pour Kafka confluent :</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka.* Courtier nombre: 22. Votre cluster est lié au stockage. Envisagez d'activer un stockage à plusieurs niveaux afin de réduire le nombre d'hôtes et d'autoriser une capacité de stockage infinie.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper.* nombre: 5; Apache Kafka Connect Employés: Count: 2; Schéma Registry: Count: 2; proxy REST: Count: 2; ksqlDB: Count: 2; Confluent Control Center: Count: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">Utilisez le mode inverse pour les équipes chargées des plateformes en toute sérénité. Utilisez le mode partitions pour calculer le nombre de partitions requises par une seule rubrique. Voir<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> pour le dimensionnement en fonction des modes inverse et partitions.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">Tr-4623 : systèmes NetApp E-Series E5700 et Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">Ce test de vérification a atteint 31,74 Gbit/s de débit de Tiering en association avec un contrôleur de stockage NetApp ONTAP.</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">Précédent : directives sur les meilleures pratiques en matière de performances.</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">Ce test de vérification a atteint 31,74 Gbit/s de débit de Tiering en collaboration avec le contrôleur de stockage NetApp ONTAP.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Qu'est-ce que le confluent ?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">Détails des paramètres de l'évier S3</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 dans les bonnes pratiques ONTAP</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">Gestion du stockage objet S3</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">Septembre 2022</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">Dans cette validation, nous avons utilisé quatre serveurs comme serveurs NSD (Network Shared Disk) pour fournir des disques physiques pour GPFS. GPFS est créé sur les disques NSD pour les exporter comme des exportations NFS, de sorte que les clients NFS puissent y accéder, comme illustré dans la figure ci-dessous. Nous avons utilisé XCP pour copier les données de GPFS- exportés NFS vers un volume NFS NetApp.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS jusqu'au NFS NetApp ONTAP</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">Précédent : solution de transfert de données pour l'IA.</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">Les fondamentaux de GPFS</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">Les types de nœud suivants sont utilisés dans GPFS :</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*Admin node.* Spécifie un champ facultatif contenant un nom de noeud utilisé par les commandes d'administration pour communiquer entre les noeuds. Par exemple, le nœud admin<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> impossible de transmettre une vérification réseau à tous les autres nœuds du cluster.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*Noeud quorum.* détermine si un noeud est inclus dans le pool de noeuds dont le quorum est dérivé. Vous avez besoin d'au moins un nœud comme nœud quorum.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*Nœud gestionnaire.* indique si un nœud fait partie du pool de nœuds à partir duquel les gestionnaires de système de fichiers et les gestionnaires de jetons peuvent être sélectionnés. Il est recommandé de définir plusieurs nœuds en tant que nœud gestionnaire. Le nombre de nœuds que vous désignez en tant que Manager dépend de la charge de travail et du nombre de licences de serveur GPFS dont vous disposez. Si vous exécutez des tâches parallèles volumineuses, vous aurez peut-être besoin de plus de nœuds de gestion que dans un cluster à quatre nœuds prenant en charge une application Web.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD Server.* le serveur qui prépare chaque disque physique à utiliser avec GPFS.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*Protocol node.* le nœud qui partage les données GPFS directement via n'importe quel protocole Secure Shell (SSH) avec NFS. Ce nœud requiert une licence de serveur GPFS.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">Liste des opérations pour GPFS, NFS et XCP</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">Cette section fournit la liste des opérations qui créent GPFS, exportent GPFS comme une exportation NFS et transfèrent les données à l'aide de XCP.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">Créer GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">Pour créer GPFS, procédez comme suit :</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Téléchargez et installez l'accès aux données à l'échelle du spectre pour la version Linux sur l'un des serveurs.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">Installez le package prérequis (Chef par exemple) sur tous les nœuds et désactivez Security-Enhanced Linux (SELinux) sur tous les nœuds.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">Configurez le nœud d'installation et ajoutez le nœud admin et le nœud GPFS au fichier de définition de cluster.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">Ajoutez le nœud gestionnaire, le nœud quorum, les serveurs NSD et le nœud GPFS.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">Ajoutez l'interface graphique, les nœuds d'administration et GPFS, et ajoutez un serveur d'interface graphique supplémentaire si nécessaire.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">Ajoutez un autre nœud GPFS et vérifiez la liste de tous les nœuds.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">Spécifiez un nom de cluster, un profil, un binaire de shell distant, un binaire de copie de fichier distant et une plage de ports à définir sur tous les nœuds GPFS du fichier de définition de cluster.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">Affichez les paramètres de configuration de GPFS et ajoutez un nœud d'administration supplémentaire.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">Désactivez la collecte de données et téléchargez le paquet de données sur le centre de support IBM.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">Activez le protocole NTP et vérifiez les configurations avant l'installation.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">Configurez, créez et vérifiez les disques NSD.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">Créez le GPFS.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">Montez le GPFS.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">Vérifiez et fournissez les autorisations requises pour le GPFS.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">Vérifiez que GPFS est en lecture et en écriture en exécutant le<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">Exporter GPFS dans NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">Pour exporter le GPFS dans NFS, procédez comme suit :</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">Exportez GPFS en tant que NFS<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">Installez les modules de serveur NFS requis.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">Démarrer le service NFS.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">Répertoriez les fichiers dans GPFS pour valider le client NFS.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">Configurez le client NFS</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">Pour configurer le client NFS, procédez comme suit :</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">Exportez le GPFS en tant que NFS via le<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">Démarrez les services client NFS.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">Montez le GPFS via le protocole NFS sur le client NFS.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">Validez la liste des fichiers GPFS dans le dossier monté NFS.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">Déplacer les données de GPFS exportés NFS vers NetApp NFS à l'aide de XCP.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">Valider les fichiers GPFS sur le client NFS.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">Next : HDFS et MapR-FS sur ONTAP NFS.</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">Les solutions NetApp d'analytique moderne sont un ensemble de fonctionnalités stratégiques et technologiques qui prouvent les fonctionnalités du stockage NetApp dans l'ensemble de l'environnement d'IA.</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">Solutions NetApp d'analytique moderne</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">Cette page décrit les meilleures pratiques en matière d'amélioration des performances de cette solution.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">Instructions sur les bonnes pratiques en matière de performances</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">Précédent : tests de performances avec générateur de charges de travail produisant de consommation</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">Pour ONTAP, lorsque possible, utilisez une taille D'OBTENTION &gt;=1 Mo.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">Croissantes<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> et<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> dans<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> Sur les nœuds de courtage, vous pouvez envoyer davantage d'activités de Tiering vers le Tier S3. Ces résultats sont obtenus avec<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> et<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> réglez sur 32.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">Les compartiments S3 doivent cibler huit composants par agrégat de membres.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">Les liaisons Ethernet conduisant le trafic S3 doivent utiliser une MTU de 9 000 si possible sur le stockage et le client.</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">Cette section décrit de manière détaillée les cas d'utilisation de protection des données qui constituent le centre de ce document. Les sections restantes fournissent des informations détaillées sur chaque cas d'utilisation, telles que le problème d'un client (scénario), les exigences, les défis et les solutions.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Présentation des cas d'utilisation de protection des données Hadoop</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">Précédent : protection des données Hadoop et NetApp.</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="817ac2975197bd6c376a7918a798981f" category="section-title">Cas d'utilisation 1 : sauvegarde des données Hadoop</block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">Pour cette utilisation, le module d'analytique sur place a permis à une grande institution financière de réduire les longues fenêtres de sauvegarde de plus de 24 heures à un peu moins de quelques heures.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="section-title">Cas d'utilisation 2 : sauvegarde et reprise après incident du cloud vers les environnements sur site</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">En utilisant Data Fabric optimisé par NetApp comme éléments de base, une grande entreprise de diffusion a pu satisfaire aux exigences de sauvegarde instantanée des données cloud dans son data Center sur site, selon les différents modes de transfert de données, comme à la demande, Ou en fonction de la charge du cluster Hadoop/Spark.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="section-title">Cas d'utilisation 3 : activation de DevTest sur les données Hadoop existantes</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">Les solutions NetApp ont permis à un distributeur de musique en ligne de créer rapidement plusieurs clusters Hadoop peu encombrants dans différentes succursales pour créer des rapports et exécuter des tâches quotidiennes DevTest à l'aide de règles planifiées.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="section-title">Cas d'utilisation 4 : protection des données et connectivité multicloud</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">Un grand fournisseur de services a utilisé la Data Fabric optimisée par NetApp pour fournir des fonctionnalités d'analytique multicloud à ses clients à partir de différentes instances de cloud.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="section-title">Cas d'utilisation 5 : accélération des workloads d'analytique</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">L'une des plus grandes banques d'investissement et de services financiers a eu recours à la solution de stockage NAS de NetApp pour réduire le temps d'attente des E/S et accélérer sa plateforme d'analytique financière quantitative.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">Ensuite, utilisez le cas d'utilisation 1 : sauvegarde des données Hadoop.</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">Analytique moderne : différentes solutions pour différentes stratégies d'analytique</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">Ce livre blanc présente les stratégies des solutions d'analytique modernes de NetApp. Vous y trouverez des informations détaillées sur les résultats commerciaux, les défis des clients, les tendances technologiques, l'architecture existante concurrente, les workflows modernes, cas d'utilisation, secteurs, cloud, partenaires technologiques, mécanismes de déplacement des données, NetApp Active IQ, le kit NetApp DataOps, Hadoop to Spark, le stockage Software-defined avec NetApp Astra Control, les conteneurs, la gestion des données d'entreprise, l'archivage et le Tiering pour atteindre les objectifs de l'IA et de l'analytique, et la façon dont NetApp et ses clients modernisent leur architecture de données.</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">La Data Fabric optimisée par NetApp simplifie et intègre la gestion des données entre les environnements cloud et sur site afin d'accélérer la transformation digitale. La Data Fabric optimisée par NetApp offre des services et des applications de gestion des données intégrés et cohérents (éléments de base) pour la visibilité, l'exploitation, l'accès, le contrôle ainsi que la protection et la sécurité des données.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">Data Fabric optimisée par NetApp pour l'architecture Big Data</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">La Data Fabric optimisée par NetApp simplifie et intègre la gestion des données entre les environnements cloud et sur site afin d'accélérer la transformation digitale.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">La Data Fabric optimisée par NetApp offre des services et des applications de gestion des données intégrés et cohérents (éléments de base) pour la visibilité, l'exploitation, l'accès, le contrôle ainsi que la protection et la sécurité des données, comme l'illustre la figure ci-dessous.</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">Cas d'utilisation prouvés pour Data Fabric</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">La Data Fabric optimisée par NetApp offre les neuf cas d'utilisation suivants :</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">Accélérez les workloads d'analytique</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">Accélérez la transformation DevOps</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">Créer une infrastructure d'hébergement cloud</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">Intégrez des services de données cloud</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">Protégez et sécurisez les données</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">Optimiser les données non structurées</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">Améliorez l'efficacité du data Center</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">Exploitez et contrôlez vos données</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">Simplifier et automatiser</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">Ce document couvre deux des neuf cas d'utilisation (ainsi que leurs solutions) :</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">Accès direct NetApp NFS</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">L'accès direct NetApp NFS (précédemment appelé NetApp in-place Analytics module) (illustré dans la figure ci-dessous) permet aux clients d'exécuter des tâches d'analytique Big Data sur leurs données NFSv3 ou nouveau, ou NFSv4, sans déplacer ou copier les données. Elle empêche plusieurs copies de données et n'a plus besoin de synchroniser les données avec une source. Par exemple, dans le secteur financier, le transfert des données d'un endroit à un autre doit respecter les obligations légales, ce qui n'est pas une tâche facile. Dans ce scénario, l'accès direct NetApp NFS analyse les données financières à partir de leur emplacement d'origine. L'autre avantage clé est que l'accès direct NetApp NFS simplifie la protection des données Hadoop grâce aux commandes Hadoop natives et permet d'activer des workflows de protection des données à partir de la gamme riche de solutions NetApp de gestion des données.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">L'accès direct NetApp NFS propose deux types d'options de déploiement pour les clusters Hadoop/Spark :</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">Par défaut, les clusters Hadoop/Spark utilisent le système Hadoop Distributed File System (HDFS) pour le stockage des données et le système de fichiers par défaut. L'accès direct NetApp NFS peut remplacer le système HDFS par défaut par un stockage NFS comme système de fichiers par défaut, permettant ainsi des opérations d'analytique directe sur les données NFS.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">Dans une autre option de déploiement, l'accès direct NetApp NFS prend en charge la configuration de NFS en tant que stockage supplémentaire avec HDFS dans un seul cluster Hadoop/Spark. Dans ce cas, le client peut partager des données via les exports NFS et y accéder depuis le même cluster, ainsi que des données HDFS.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">Voici les principaux avantages de l'accès direct NetApp NFS :</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">Analyse les données de leur emplacement actuel, ce qui empêche la tâche fastidieuse de transférer des données analytiques vers une infrastructure Hadoop telle que HDFS.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">Réduit le nombre de répliques de trois à un.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">Permet aux utilisateurs de découpler les ressources de calcul et de stockage.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">Protège les données grâce aux fonctionnalités avancées de gestion d'ONTAP.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Est certifiée avec la plateforme de données Hortonworks.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">Déploiements dans l'analytique hybride</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">Réduit le temps de sauvegarde grâce à la fonctionnalité multithread dynamique.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">Les éléments de base du Big Data</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">La Data Fabric optimisée par NetApp intègre des services et des applications de gestion des données (éléments de base) pour l'accès, le contrôle, la protection et la sécurité des données, comme l'illustre la figure ci-dessous.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">Les éléments de base de la figure ci-dessus sont les suivants :</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">*NetApp NFS Direct Access.* fournit les derniers clusters Hadoop et Spark avec un accès direct aux volumes NFS NetApp sans configuration logicielle ni pilote supplémentaire.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">*NetApp Cloud Volumes ONTAP et Cloud volumes Services.* stockage Software-defined basé sur ONTAP s'exécutant dans Amazon Web Services (AWS) ou Azure NetApp Files (ANF) dans les services cloud Microsoft Azure.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">*Technologie NetApp SnapMirror*. Fournit des fonctionnalités de protection des données entre les instances sur site et ONTAP Cloud ou NPS.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*Fournisseurs de services cloud.* ces fournisseurs incluent AWS, Microsoft Azure, Google Cloud et IBM Cloud.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.* services d'analytique cloud tels qu'Amazon Elastic MapReduce (EMR) et Databricks dans AWS, ainsi que Microsoft Azure HDInsight et Azure Databricks.</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">Ensuite, la protection des données Hadoop et NetApp.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">Dans ce configuration, nous vous montrons comment lire et écrire des sujets dans le stockage objet depuis Kafka directement à l'aide du connecteur lavabo Kafka s3. Pour ce test, nous avons utilisé un cluster Confluent autonome, mais cette configuration s'applique à un cluster distribué.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Connecteur s3 confluent</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">Précédent : tests de performances avec évolutivité.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Le connecteur d'évier Amazon S3 exporte les données des sujets Apache Kafka vers des objets S3 au format Avro, JSON ou octets. Le connecteur d'évier Amazon S3 interroge régulièrement les données depuis Kafka et les télécharge à son tour sur S3. Un partitionneur est utilisé pour diviser les données de chaque partition Kafka en segments. Chaque bloc de données est représenté en tant qu'objet S3. Le nom de clé encode le sujet, la partition Kafka et le décalage de début de ce segment de données.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Téléchargez le livre confluent Kafka depuis le site Web confluent.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">Déballez le paquet dans un dossier de votre serveur.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">Exporter deux variables.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">Pour une configuration autonome que Kafka confluent, le cluster crée un dossier racine temporaire dans<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>. Cette solution crée également Zookeeper, Kafka, un registre de schéma, Connect, un serveur ksql, et les dossiers du centre de contrôle et copie leurs fichiers de configuration respectifs à partir de<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>. Voir l'exemple suivant :</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">Configurer le Zookeeper. Vous n’avez rien à changer si vous utilisez les paramètres par défaut.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">Dans la configuration ci-dessus, nous avons mis à jour le<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> propriété. Par défaut, vous avez besoin de trois zoopers pour la sélection du leader Kafka.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">Nous avons créé un fichier myID dans<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> Avec un ID unique :</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">Nous avons utilisé le dernier nombre d'adresses IP pour le fichier myID. Nous avons utilisé des valeurs par défaut pour Kafka, Connect, control-Center, Kafka, Kafka-REST, configurations de serveur ksql et de registre de schéma.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Démarrer les services Kafka</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">Il existe un dossier journal pour chaque configuration, ce qui permet de résoudre les problèmes. Dans certains cas, le démarrage des services prend plus de temps. Assurez-vous que tous les services sont opérationnels.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Installez Kafka Connect à l'aide de<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block>.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">Vous pouvez également installer une version spécifique en utilisant<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">Par défaut,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> est installé dans<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">Mettez à jour le chemin du plug-in avec le nouveau<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Arrêtez les services de confluent et redémarrez-les.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">Configurez l'ID d'accès et la clé secrète dans le<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">Vérifier que le godet est accessible.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">Configurez le fichier de propriétés s3-lavabo pour s3 et la configuration de compartiment.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">Importez quelques enregistrements dans le compartiment s3.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">Chargez le connecteur de l'évier s3.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">Vérifiez l'état de l'évier s3.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">Vérifiez le journal pour vous assurer que s3-lavabo est prêt à accepter les rubriques.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Vérifiez les sujets dans Kafka.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">Vérification des objets dans le compartiment s3</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">Pour vérifier le contenu, copiez chaque fichier depuis S3 vers votre système de fichiers local à l'aide de la commande suivante :</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Archives Apache</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">Pour imprimer les enregistrements, utilisez avro-tools-1.11.0.1.jar (disponible dans le<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>).</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">Suivant : les clusters à auto-rééquilibrage courants.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">Dans un cluster Big Data, les données sont stockées dans les systèmes HDFS ou HCFS, par exemple MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google. Nous avons effectué des tests avec HDFS, MapR-FS et S3 en tant que source pour copier les données vers l'exportation NFS NetApp ONTAP, à l'aide de NIPAM, à l'aide de la commande hadoop distcp provenant de la source.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">Précédent : défis des clients.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">Dans un cluster Big Data, les données sont stockées dans les systèmes HDFS ou HCFS, par exemple MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google. Nous avons effectué des tests avec HDFS, MapR-FS et S3, afin de copier les données vers l'exportation NFS NetApp ONTAP à l'aide du protocole NIPAM<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande à partir de la source.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">Le diagramme suivant illustre le déplacement type des données d'un cluster Spark doté d'un système de stockage HDFS vers un volume NFS NetApp ONTAP, afin que NVIDIA puisse traiter les opérations d'IA.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> La commande utilise le programme MapReduce pour copier les données. NIPAM fonctionne avec MapReduce pour servir de pilote au cluster Hadoop lors de la copie de données. NIPAM peut distribuer une charge sur plusieurs interfaces réseau pour une exportation unique. Ce processus optimise le débit du réseau en répartissant les données sur plusieurs interfaces réseau lorsque vous copiez les données de HDFS ou HCFS sur NFS.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM n'est pas pris en charge ni certifié avec MapR.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">Ensuite, solution de déplacement des données pour l'IA.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">Pour cette solution, NetApp a validé la migration des données du data Lake (HDFS) et du cluster MapR vers ONTAP NFS. Les données résidaient dans MapR-FS et HDFS. NetApp XCP a introduit une nouvelle fonctionnalité qui migre directement les données d'un système de fichiers distribué tel que HDFS et MapR-FS vers ONTAP NFS.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS et MapR-FS sur ONTAP NFS</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">Précédent : GPFS vers NetApp ONTAP NFS.</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">Pour cette solution, NetApp a validé la migration des données du data Lake (HDFS) et du cluster MapR vers ONTAP NFS. Les données résidaient dans MapR-FS et HDFS. NetApp XCP a introduit une nouvelle fonctionnalité qui migre directement les données d'un système de fichiers distribué tel que HDFS et MapR-FS vers ONTAP NFS. XCP utilise des threads asynchrones et des appels API HDFS C pour communiquer et transférer des données de MapR-FS ainsi que HDFS. La figure ci-dessous illustre la migration des données entre le data Lake (HDFS) et MapR-FS et le protocole ONTAP NFS. Grâce à cette nouvelle fonctionnalité, il n'est pas nécessaire d'exporter la source en tant que partage NFS.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">Pourquoi les clients passent-ils de HDFS et de MapR-FS au NFS ?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">La plupart des distributions Hadoop, telles qu'Cloudera et Hortonworks, utilisent les distributions HDFS et MapR, utilise leur propre système de fichiers appelé Mapr-FS pour stocker les données. Les données HDFS et MapR-FS offrent des informations exploitables aux data Scientists qui peuvent être exploitées dans le machine learning (ML) et le deep learning (DL). Les données dans HDFS et MapR-FS ne sont pas partagées, ce qui signifie qu'elles ne peuvent pas être utilisées par d'autres applications. Les clients recherchent des données partagées, notamment dans le secteur bancaire où les données sensibles des clients sont utilisées par de multiples applications. La dernière version d'Hadoop (3.x ou version ultérieure) prend en charge les sources de données NFS, qui sont accessibles sans logiciel tiers supplémentaire. Avec la nouvelle fonctionnalité NetApp XCP, les données peuvent être transférées directement de HDFS et de MapR-FS vers NetApp NFS afin de fournir un accès à plusieurs applications</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">Les tests ont été réalisés dans Amazon Web Services (AWS) pour transférer les données de MapR-FS vers NFS, dans le cadre du test de performance initial avec 12 nœuds APR et 4 serveurs NFS.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">Taille</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">VCPU</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">Le réseau</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">Serveur NFS</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488 Gio</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8 x SSD NVMe 7500</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">Nœuds MAPR</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384 Gio</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4 x 7500 SSD NVMe</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">Selon les tests initiaux, nous avons obtenu un débit de 20 Gbit/s et sommes parvenus à transférer 2 po de données par jour.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">Tr-4863 : TR-4863 : instructions sur les meilleures pratiques pour NetApp XCP - Data Mover, migration de fichiers et analyse</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">Pour plus d'informations sur la migration de données HDFS sans exporter HDFS vers NFS, reportez-vous à la section « étapes de déploiement - NAS » du<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">Suivant : avantages commerciaux.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">Cette section présente les leçons tirées de cette certification.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">Recommandations sur les bonnes pratiques</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">Précédent : clusters à auto-rééquilibrage fluide.</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">Sur la base de notre validation, le stockage objet S3 convient parfaitement au maintien fluide des données.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Nous pouvons utiliser un SAN haut débit (notamment FC) pour conserver les données actives du courtier ou le disque local, car, en termes de configuration du stockage multi-niveaux, la taille des données stockées dans le répertoire des courtiers dépend de la taille du segment et de la durée de conservation lorsque les données sont déplacées vers le stockage objet.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">Les magasins d'objets offrent de meilleures performances lorsque segment.octets est plus élevé ; nous avons testé 512 Mo.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Dans Kafka, la longueur de la clé ou de la valeur (en octets) pour chaque enregistrement produit sur le sujet est contrôlée par le<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> paramètre. Pour StorageGRID, les valeurs d'ingestion et de récupération d'objets S3 sont supérieures à la valeur supérieure. Par exemple, 512 octets fournis pour une récupération de 5,8 Gbit/s, 1024 octets fournis pour 7,5Gbit/s S3 en récupération et 2048 octets fournis à proximité de 10 Gbit/s.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">La figure suivante présente l'ingestion et la récupération d'objet S3 basées sur<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Kafka Tuning.* pour améliorer les performances du stockage à plusieurs niveaux, vous pouvez augmenter TierFetcherNumThreads et TierArchiverNumThreads. En règle générale, vous souhaitez augmenter TierFetcherNumThreads afin qu'ils correspondent au nombre de cœurs de CPU physiques et qu'ils augmentent TierArchiverNumThreads à la moitié du nombre de cœurs de CPU. Par exemple, dans les propriétés du serveur, si vous avez une machine avec huit cœurs physiques, définissez confluent.Tier.fetcher.num.threads = 8 et confluent.Tier.archiver.num.threads = 4.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*Intervalle de temps pour les suppressions de rubrique.* lorsqu'une rubrique est supprimée, la suppression des fichiers de segment de journal dans le stockage d'objet ne commence pas immédiatement. Il y a plutôt un intervalle de temps avec une valeur par défaut de 3 heures avant la suppression de ces fichiers. Vous pouvez modifier la configuration, confluent.tier.topic.delete.check.interval.ms, pour modifier la valeur de cet intervalle. Si vous supprimez une rubrique ou un cluster, vous pouvez également supprimer manuellement les objets du compartiment correspondant.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*Listes de contrôle d’accès sur les sujets internes de stockage à plusieurs niveaux.* Une meilleure pratique recommandée pour les déploiements sur site consiste à activer un approbateur ACL sur les sujets internes utilisés pour le stockage à plusieurs niveaux. Définissez les règles ACL pour limiter l'accès à ces données à l'utilisateur du courtier uniquement. Cela sécurise les sujets internes et empêche les accès non autorisés aux données et aux métadonnées de stockage hiérarchisées.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">Remplacer l'utilisateur<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> avec le véritable courtier principal dans votre déploiement.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">Par exemple, la commande<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> Définit les listes de contrôle d'accès sur la rubrique interne pour le stockage à plusieurs niveaux. Actuellement, une seule rubrique interne est consacrée au stockage à plusieurs niveaux. L'exemple crée une liste de contrôle d'accès qui fournit l'autorisation Kafka principale pour toutes les opérations sur le sujet interne.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">Suivant : dimensionnement.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-macro"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">Dans ce scénario, une plateforme d'analyse des services financiers et des banques d'investissement a été modernisée avec la solution de stockage NFS NetApp afin d'améliorer considérablement l'analyse des risques d'investissement et des produits dérivés de sa gestion des actifs et de sa business unit quantitative.</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">Précédent : cas d'utilisation 4 : protection des données et connectivité multicloud.</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">Scénario</block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">Dans l'environnement existant du client, l'infrastructure Hadoop utilisée pour la plateforme d'analytique exploite le stockage interne des serveurs Hadoop. En raison de la nature exclusive de l'environnement JBOD, de nombreux clients internes de l'entreprise n'ont pas pu tirer parti de leur modèle quantitatif Monte Carlo, une simulation qui s'appuie sur les échantillons récurrents de données en temps réel. La capacité sous-optimale de comprendre les effets de l'incertitude dans les mouvements du marché était de ne pas être favorable à l'unité commerciale de gestion quantitative des actifs.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">Besoins et défis</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">L'unité commerciale quantitative de la banque voulait une méthode de prévision efficace pour obtenir des prévisions précises et opportunes. Elle a ainsi reconnu la nécessité de moderniser l'infrastructure, de réduire le temps d'attente des E/S existantes et d'améliorer les performances des applications d'analytique telles que Hadoop et Spark pour simuler efficacement des modèles d'investissement, mesurer les gains potentiels et analyser les risques.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">Solution</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">Le client disposait d'une solution JBOD pour sa solution Spark existante. NetApp ONTAP, NetApp StorageGRID et MiniO Gateway to NFS ont ensuite été utilisés pour réduire le temps d'attente des E/S du groupe financier quantitatif de la banque qui exécute des simulations et des analyses sur des modèles d'investissement permettant d'évaluer les gains et risques potentiels. Cette image présente la solution Spark avec du stockage NetApp.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">Comme illustré ci-dessus, les systèmes AFF A800, A700 et StorageGRID ont été déployés pour accéder aux fichiers parquet via les protocoles NFS et S3 dans un cluster Hadoop à six nœuds avec Spark, et LES services de métadonnées YARN et Hive pour les opérations d'analytique.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">Dans l'ancien environnement de client, une solution DAS (Direct-Attached Storage) avait des inconvénients : faire évoluer indépendamment les ressources de calcul et de stockage. Avec la solution NetApp ONTAP pour Spark, l'unité commerciale dédiée aux analyses financières de la banque a pu dissocier le stockage des ressources de calcul et ajouter de manière transparente les ressources d'infrastructure en fonction des besoins.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">Grâce à ONTAP avec NFS, les processeurs du serveur de calcul étaient presque pleinement utilisés pour les tâches Spark SQL et le temps d'attente en E/S a été réduit de près de 70 %, ce qui optimise la puissance de calcul et les performances des charges de travail Spark. Par la suite, l'augmentation de l'utilisation du CPU a également permis au client d'exploiter des GPU, tels que GPUDirect, pour poursuivre la modernisation de la plateforme. En outre, StorageGRID offre une option de stockage économique pour les charges de travail Spark et la passerelle MiniO permet un accès sécurisé aux données NFS via le protocole S3. Pour les données dans le cloud, NetApp recommande Cloud Volumes ONTAP, Azure NetApp Files et NetApp Cloud Volumes Service.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">Cette page décrit les composants utilisés pour compléter cette solution, notamment NetApp StorageGRID, Splunk Enterprise et Splunk SmartStore.</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">Précédent : hiérarchisation intelligente et réduction des coûts.</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID est une plateforme de stockage objet haute performance et économique. Il propose une gestion des données globale intelligente et pilotée par des règles sur une architecture de grid distribuée basée sur des nœuds. Elle simplifie la gestion de pétaoctets de données non structurées et de milliards d'objets grâce à son espace de noms d'objet global universel unique et à des fonctionnalités avancées de gestion des données. Un accès aux objets unique s'étend sur tous les sites et simplifie les architectures haute disponibilité tout en assurant un accès continu aux objets, quelles que soient les pannes au niveau du site ou de l'infrastructure.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">La colocation permet de prendre en charge plusieurs applications de données non structurées cloud et d'entreprise de manière sécurisée dans un même grid, ce qui améliore le ROI et les utilisations de StorageGRID. Plusieurs niveaux de services peuvent être créés avec des règles de cycle de vie des objets basées sur des métadonnées pour optimiser la durabilité, la protection, la performance et la localisation sur plusieurs sites. Les utilisateurs peuvent adapter ces règles et ajuster l'environnement de données de manière non disruptive, à mesure que leurs exigences changent.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore exploite StorageGRID comme Tier de stockage distant et permet aux clients de déployer plusieurs sites répartis géographiquement pour une disponibilité et une durabilité robustes, présentées comme un seul espace de noms d'objet. Ainsi, Splunk SmartStore peut exploiter les performances élevées de StorageGRID avec une capacité dense et évoluer vers des centaines de nœuds sur plusieurs sites physiques à l'aide d'une seule URL pour interagir avec les objets. Cette URL unique permet également d'étendre le stockage, de mettre à niveau et de réparer sans interruption, même au-delà d'un seul site. Le moteur de règles unique de gestion des données de StorageGRID optimise les niveaux de performance et de durabilité, ainsi que le respect des exigences en matière de localisation des données.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk, leader de la collecte et de l'analyse de données générées par des machines, simplifie et modernise L'IT grâce à ses fonctionnalités d'analytique opérationnelle. Ce logiciel étend également l'analytique business, la sécurité et les utilisations de l'IoT. Le stockage est un facteur stratégique pour réussir le déploiement des logiciels Splunk.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">Les données générées par la machine sont le type de Big Data qui connaît la croissance la plus rapide. Le format est imprévisible et provient de nombreuses sources différentes, souvent à des taux élevés et en grands volumes. Ces caractéristiques de charge de travail sont souvent appelées échappement numérique. Grâce à cette solution, Splunk SmartStore peut comprendre ces données et propose un Tiering intelligent des données pour optimiser le placement des données actives et utiles sur le Tier de stockage le plus économique.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore est une fonctionnalité d'indexeur qui utilise un stockage objet (également appelé stockage distant ou tiers de stockage distant), tel que StorageGRID pour stocker des données actives à l'aide du protocole S3.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">Étant donné que le volume de données d'un déploiement augmente, la demande de stockage dépasse les attentes en matière de ressources informatiques. SmartStore vous permet de gérer vos ressources de stockage et de calcul d'indexeur de manière rentable en faisant évoluer séparément les ressources de calcul et de stockage.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore introduit un niveau de stockage distant à l'aide du protocole S3 et d'un gestionnaire de cache. Ces fonctionnalités permettent aux données de résider localement sur des indexeurs ou sur un stockage distant. Le gestionnaire de cache, qui réside sur l'indexeur, gère le déplacement des données entre l'indexeur et le Tier de stockage distant. Les données sont stockées dans des compartiments (chaud et chaud) avec les métadonnées de compartiment.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">Grâce à SmartStore, vous pouvez réduire au minimum l'encombrement du stockage des indexeur et choisir les ressources de calcul optimisées en E/S car la plupart des données résident sur le Tier de stockage distant. L'indexeur conserve un cache local, représentant la quantité minimale de données nécessaires pour renvoyer les résultats demandés et prévus. Le cache local contient des compartiments à chaud, des copies de compartiments utiles faisant partie des recherches actives ou récentes, et des métadonnées de compartiment.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Avec Splunk SmartStore associé à StorageGRID, les clients peuvent faire évoluer leur environnement de façon incrémentielle grâce à un stockage distant haute performance et économique, tout en bénéficiant d'une grande flexibilité à la solution globale. Les clients peuvent ainsi ajouter des composants (stockage à chaud et/ou stockage S3 chaud) à n'importe quelle quantité donnée, à tout moment, qu'ils aient besoin d'index supplémentaires, de changer la conservation des données ou d'augmenter le taux d'entrée sans interruption.</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">Next : fonctionnalités flexibles de StorageGRID pour Splunk SmartStore.</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">Ce document explique comment déplacer des données depuis les systèmes d'analytique Big Data et d'informatique haute performance (HPC) pour qu'elles puissent être utilisées dans des workflows d'intelligence artificielle (IA). L'IA traite généralement les données NFS par le biais d'exports NFS. Vous pouvez cependant avoir vos données d'IA dans une plateforme d'analytique Big Data et de calcul haute performance (HPC). Il peut s'agir du système HDFS (Hadoop Distributed File System), d'un grand objet binaire (Blob), d'un stockage S3 ou du système GPFS (General Parallel File System) d'IBM. Dans ce document, nous décrivons comment déplacer les données d'une plateforme d'analytique Big Data et de GPFS vers NFS à l'aide de commandes natives Hadoop, du module d'analytique sur place NetApp (NIPAM) et de NetApp XCP. Ce document présente également les avantages du transfert de données du Big Data et de l'informatique haute performance vers l'IA.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">Cette section récapitule les solutions de stockage NetApp pour Apache Spark.</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">Précédent : scripts Python pour chaque cas d'utilisation majeur.</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">Dans ce document, nous présenterons l'architecture Apache Spark, les utilisations client et le portefeuille de solutions de stockage NetApp en ce qui concerne le Big Data, l'analytique moderne, l'IA, LE ML et le DL. Dans le cadre de tests de validation des performances basés sur des outils de banc d'essai standard et sur la demande client, les solutions NetApp Spark offrent des performances supérieures à celles des systèmes Hadoop natifs. La combinaison des cas d'utilisation clients et des résultats de performances présentés dans ce rapport peut vous aider à choisir la solution Spark la mieux adaptée à votre déploiement.</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">Cette section fournit les étapes détaillées requises pour configurer GPFS et transférer les données vers NFS à l'aide de NetApp XCP.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">Étapes détaillées de GPFS vers NFS</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">Précédent : avantages pour l'entreprise.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">Configurer GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Téléchargez et installez Spectrum Scale Data Access pour Linux sur l'un des serveurs.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">Installez le pack prérequis (y compris les en-têtes du chef et du noyau) sur tous les nœuds.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">Désactivez SELinux sur tous les nœuds.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">Configurez le nœud d'installation.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">Ajoutez le nœud admin et le nœud GPFS au fichier de définition de cluster.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">Ajoutez le nœud gestionnaire et le nœud GPFS.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">Ajoutez le nœud quorum et le nœud GPFS.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">Ajoutez les serveurs NSD et le nœud GPFS.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">Ajoutez l'interface graphique, les nœuds d'administration et GPFS.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">Ajouter un autre serveur d'interface graphique.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">Ajouter un autre nœud GPFS.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">Vérifiez et répertoriez tous les nœuds.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">Spécifiez un nom de cluster dans le fichier de définition de cluster.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">Spécifiez le profil.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">Spécifiez le binaire du shell distant à utiliser par GPFS ; utiliser<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">Spécifiez le binaire de copie de fichier distant à utiliser par GPFS ; utilisez<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">Spécifiez la plage de ports à définir sur tous les nœuds GPFS ; utilisez<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">Afficher les paramètres de configuration GPFS.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">Ajouter un noeud admin.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">Activez le protocole NTP.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">Vérifiez d'abord les configurations avant l'installation.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">Configurez les disques NSD.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">Créer les disques NSD.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">Vérifiez l'état du disque NSD.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">Vérifiez et fournissez les autorisations requises pour le GPFS.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">Vérifiez que GPFS est lu et écrit en exécutant le<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">Pour exporter GPFS dans NFS, procédez comme suit :</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">Répertorier les fichiers dans GPFS pour valider le client NFS.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">Configurez le client NFS</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">Installez les modules dans le client NFS.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">Validez la liste des fichiers GPFS dans le dossier monté sur NFS.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">Déplacer les données du NFS GPFS- exporté vers le NFS NetApp en utilisant XCP.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">Next : de MapR-FS sur le protocole ONTAP NFS.</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">Dans ce cas d'utilisation, l'entreprise a besoin de créer rapidement et efficacement de nouveaux clusters Hadoop/Spark basés sur un cluster Hadoop existant contenant un grand nombre de données d'analytique pour DevTest et la création de rapports dans le même data Center et sur des sites distants.</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">Précédent : cas d'utilisation 2 : sauvegarde et reprise après incident depuis le cloud vers des environnements sur site.</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">Dans ce scénario, plusieurs clusters Spark/Hadoop sont conçus à partir d'une implémentation d'un data Lake Hadoop volumineux sur site et dans des sites de reprise après incident.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">Voici les principaux défis et exigences de cette utilisation :</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">Créez plusieurs clusters Hadoop pour le DevTest, l'assurance qualité ou tout autre objectif nécessitant l'accès aux mêmes données de production. Le défi ici est de cloner un cluster Hadoop de très grande taille plusieurs fois instantanément et de façon très compacte.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">Synchronisation des données Hadoop avec les équipes de DevTest et de création de rapports pour une efficacité opérationnelle optimale</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">Distribution des données Hadoop à l'aide des mêmes identifiants sur les nouveaux clusters et environnements de production.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">Utilisez des règles planifiées pour créer efficacement des clusters d'assurance qualité sans affecter le cluster de production.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">La technologie FlexClone est utilisée pour répondre aux exigences décrites précédemment. La technologie FlexClone constitue la copie de lecture/écriture d'une copie Snapshot. Il lit les données de la copie Snapshot parent et consomme uniquement de l'espace supplémentaire pour les blocs nouveaux/modifiés. Elle est rapide et compacte.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">Tout d'abord, une copie Snapshot du cluster existant a été créée à l'aide d'un groupe de cohérence NetApp.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">Copies snapshot dans NetApp System Manager ou l'invite d'administrateur du stockage. Les copies Snapshot de groupe de cohérence sont des copies Snapshot de groupe cohérentes au niveau des applications et le volume FlexClone est créé à partir des copies Snapshot de groupe de cohérence. Il est utile de mentionner qu'un volume FlexClone hérite des règles d'exportation NFS du volume parent. Une fois la copie Snapshot créée, un nouveau cluster Hadoop doit être installé à des fins de DevTest et de création de rapports, comme illustré dans la figure ci-dessous. Le module d'analytique sur place accède au volume NFS cloné à partir du nouveau cluster Hadoop via les utilisateurs du module d'analytique sur place et les autorisations de groupe pour les données NFS.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">Pour avoir un accès approprié, le nouveau cluster doit avoir le même UID et le même GUID pour les utilisateurs configurés dans les utilisateurs et les configurations de groupes du module d'analytique sur place.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">Cette image représente le cluster Hadoop pour DevTest.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">Suivant : cas d'utilisation 4 - protection des données et connectivité multicloud.</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp possède trois gammes de solutions de stockage : FAS/AFF, E-Series et Cloud Volumes ONTAP. Nous avons validé AFF et le système de stockage E-Series avec ONTAP pour les solutions Hadoop avec Apache Spark. La Data Fabric optimisée par NetApp intègre des services et des applications de gestion des données (éléments de base) pour l'accès, le contrôle, la protection et la sécurité des données.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">Présentation des solutions NetApp Spark</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">Précédent : technologie de la solution.</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">Nous portefeuilles de solutions de stockage FAS/AFF, E-Series et Cloud Volumes ONTAP Nous avons validé AFF et le système de stockage E-Series avec ONTAP pour les solutions Hadoop avec Apache Spark. La Data Fabric optimisée par NetApp intègre des services et des applications de gestion des données (éléments de base) pour l'accès, le contrôle, la protection et la sécurité des données, comme l'illustre la figure ci-dessous.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Data Fabric offre des services et des applications de gestion de données.</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">*NetApp NFS Direct Access.* fournit les derniers clusters Hadoop et Spark avec un accès direct aux volumes NFS NetApp sans configuration logicielle ni pilote supplémentaire.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">*La technologie NetApp SnapMirror* fournit des fonctionnalités de protection des données entre les instances sur site et ONTAP Cloud ou NPS.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">La figure suivante décrit la solution Spark avec du stockage NetApp.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">Spark, solution avec le stockage NetApp.</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">La solution ONTAP Spark utilise le protocole NetApp NFS à accès direct pour l'analytique sur place et les workflows d'IA, DE ML et de DL en utilisant un accès aux données de production existantes. Les données de production disponibles aux nœuds Hadoop sont exportées pour effectuer des tâches analytiques sur place et d'IA, DE ML et de DL. Vous pouvez accéder aux données à traiter dans les nœuds Hadoop avec l'accès direct NetApp NFS ou sans Dans Spark avec l'autonome ou<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Cluster Manager vous permet de configurer un volume NFS à l'aide de<block ref="9e2ac298651bd7b0cfb93c36f03ec623" prefix=" " category="inline-code"></block>. Nous avons validé trois cas d'utilisation avec des jeux de données différents. Les détails de ces validations sont présentés dans la section « Résultats des tests ». (xréf)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">La figure suivante représente le positionnement du stockage NetApp Apache Spark/Hadoop.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">Positionnement du stockage NetApp Apache Spark/Hadoop</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">Nous avons identifié les fonctionnalités uniques de la solution E-Series Spark, de la solution AFF/FAS ONTAP Spark et de la solution StorageGRID Spark, et nous avons effectué une validation et des tests détaillés. D'après nos observations, NetApp recommande la solution E-Series pour les installations nouvelles et les déploiements évolutifs. En outre, la solution AFF/FAS assure la prise en charge de l'analytique sur place, de l'IA, DU ML et du DL qui exploite les données NFS existantes, ainsi que StorageGRID pour l'IA, LE ML et le DL et l'analytique des données moderne lorsque le stockage objet est requis.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Solutions NetApp recommandées pour Spark</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">Un data Lake est un référentiel de stockage pour les datasets volumineux de forme native qui peut être utilisé pour les tâches d'analytique, d'IA, DE ML et de DL. Nous avons créé un référentiel de data Lake pour les solutions E-Series, AFF/FAS et StorageGRID SG6060 Spark. Le système E-Series fournit un accès HDFS au cluster Hadoop Spark, tandis que les données de production existantes sont accessibles via le protocole d'accès direct NFS au cluster Hadoop. Pour les datasets qui résident dans le stockage objet, NetApp StorageGRID fournit un accès sécurisé S3 et S3a.</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">Suivant : synthèse des cas d'utilisation.</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">Ce document fournit des recommandations sur les bonnes pratiques pour l'utilisation de Kafka avec le stockage NetApp, notamment les tests de certification Fluent Kafka, les résultats de performances, le réglage, les connecteurs Kafka et la fonctionnalité d'auto-rééquilibrage.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">Précédent : dimensionnement.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">Ce document fournit des recommandations sur les meilleures pratiques pour l'utilisation en traitant le stockage à plusieurs niveaux avec un stockage NetApp, notamment des tests de vérification, des résultats de performances de stockage à plusieurs niveaux, un réglage, des connecteurs S3 confluent et la fonctionnalité d'équilibrage automatique. Compte tenu des règles ILM, des performances fluides avec de multiples tests de performances pour la vérification et des API S3 standard, le stockage objet NetApp StorageGRID est la solution idéale pour parler du stockage hiérarchisé.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Qu'est-ce que Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Stockage infini dans une plateforme fluide</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Stockage à plusieurs niveaux confluent : meilleures pratiques et dimensionnement</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Connecteur de dissipateur Amazon S3 pour plate-forme de raccordement</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Dimensionnement de Kafka</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">Dimensionnement de StorageGRID</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Cas d'utilisation de Kafka</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Clusters Kafka autoéquilibrant dans la plateforme confluent 6.0</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">Décembre 2021</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">Cette section traite du matériel et des logiciels utilisés pour la vérification des performances en concourant le déploiement de plateforme avec NetApp ONTAP pour le stockage hiérarchisé. Le tableau suivant couvre l'architecture de la solution et les composants de base.</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Le contrôleur de stockage AFF A900 de Confluent et NetApp optimisé par ONTAP est des systèmes distribués conçus pour les flux de données. Ces deux types de technologies sont évolutives à l'horizontale, tolérantes aux pannes, et offrent d'excellentes performances sous charge. Elles se complètent les unes aux autres en streaming et en traitement des flux de données distribuées avec des coûts de stockage inférieurs grâce à des technologies de réduction des données qui réduisent l'empreinte des données. Le contrôleur de stockage AFF A900 offre des performances exceptionnelles, permettant ainsi de dissocier les ressources de calcul et de stockage. L'administration du système est ainsi simplifiée et les ressources peuvent évoluer de manière indépendante.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">Image illustrant la présentation de la solution.</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="section-title">Détails de l'architecture de la solution</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">Composant de plate-forme</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">Configuration de l'environnement</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Plate-forme Confluent version 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3 x zoopers</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 serveurs de courtage</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 serveurs d'outils</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x centre de contrôle</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">Système d'exploitation sur tous les nœuds</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux (ubuntu 18.04)</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP pour les compartiments chauds</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 paire AFF A900 haute disponibilité (HA)</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 SSD 24 x 800</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">Protocole S3</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100 GbE</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 serveurs Fujitsu PRIMERGY RX2540</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 processeurs, 16 cœurs physiques au total</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">Intel Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256 Go de mémoire physique</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">Deux ports 100 GbE</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">Cette page décrit les performances de Splunk SmartStore sur un contrôleur NetApp StorageGRID. Splunk SmartStore déplace les données actives vers un stockage distant, qui est le stockage objet StorageGRID lors de la validation des performances.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">Performances SmartStore sur un seul site</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">Précédent : architecture Splunk.</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">Cette section décrit les performances de Splunk SmartStore sur un contrôleur NetApp StorageGRID. Splunk SmartStore déplace les données actives vers un stockage distant, qui, dans ce cas, est le stockage objet StorageGRID dans la validation des performances.</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">Nous avons utilisé EF600 pour le stockage à chaud/cache et StorageGRID 6060 pour le stockage distant. Nous avons utilisé l'architecture suivante pour valider les performances. Nous avons utilisé deux têtes de recherche, quatre gros porteurs pour transférer les données à des indexeurs, sept générateurs d'événements Splunk (Eventgens) pour générer les données en temps réel et 18 indexeurs pour le stockage des données.</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">Ce tableau répertorie le matériel utilisé pour la validation des performances SmartStorage.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">Transitaire lourd</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 cœurs</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">L'utilisateur frontal recherche les données dans les indexeurs</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">Validation des performances du magasin à distance SmartStore</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">Dans cette validation des performances, nous avons configuré le cache SmartStore en stockage local sur tous les indexeurs pour 10 jours de données. Nous avons activé<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (750 Mo de taille de compartiment) dans le gestionnaire de clusters Splunk, puis retransmis les modifications à tous les indexeurs. Afin de mesurer les performances du téléchargement, nous avons ingéré 10 To par jour pendant 10 jours et déployé tous les compartiments à chaud simultanément. Nous avons ainsi capturé le débit maximal et moyen par instance et l'ensemble du déploiement à partir du tableau de bord de la console de surveillance SmartStore.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">Cette image montre les données ingérées en une journée.</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">Nous avons exécuté la commande suivante à partir du cluster master (le nom de l'index est<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>). Nous avons ensuite capturé le débit de chargement maximal et moyen par instance et par déploiement dans l'ensemble des tableaux de bord de la console de surveillance SmartStore.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">Le maître de cluster possède une authentification sans mot de passe pour tous les indexeurs (rtp-idx0001…rtp-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">Pour mesurer les performances de téléchargement, nous avons supprimé toutes les données du cache en exécutant deux fois l'interface CLI supprimée à l'aide de la commande suivante.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">Nous avons exécuté la commande suivante à partir de cluster master et exécuté la recherche à partir de la tête de recherche sur les 10 jours de données du magasin distant de StorageGRID. Nous avons ensuite capturé le débit de chargement maximal et moyen par instance et par déploiement dans l'ensemble des tableaux de bord de la console de surveillance SmartStore.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">Les configurations d'indexeur ont été transmises à partir du maître de cluster SmartStore. Le maître de cluster possède la configuration suivante pour l'indexeur.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">Nous avons exécuté la requête de recherche suivante sur l'en-tête de recherche pour collecter la matrice de performance.</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">Nous avons collecté les informations de performances à partir du maître de cluster. Ses performances maximales ont été 61,34 Gbit/s.</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">Les performances moyennes étaient d'environ 29 Gbit/s.</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">Performances d'StorageGRID</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">Eventgen</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">Les performances de SmartStore reposent sur la recherche de modèles et de chaînes spécifiques à partir de grandes quantités de données. Dans cette validation, les événements sont générés à l'aide de<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> Sur un index Splunk (eventgen-test) spécifique via l'en-tête de recherche, la demande sera envoyée à StorageGRID pour la plupart des requêtes. L'image suivante montre les résultats et les échecs des données de requête. Les données de réussite proviennent du disque local et les données de base proviennent du contrôleur StorageGRID.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">La couleur verte indique les données de résultats et la couleur orange indique les données de non-respect.</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">Lors de l'exécution de la requête sur StorageGRID, le taux de récupération S3 à partir de StorageGRID est affiché dans l'image suivante.</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">Utilisation du matériel StorageGRID</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">L'instance StorageGRID dispose d'un équilibreur de charge et de trois contrôleurs StorageGRID. Le taux d'utilisation du processeur pour les trois contrôleurs passe de 75 à 100 %.</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">SmartStore avec contrôleur de stockage NetApp : avantages pour le client</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*Découplage des ressources de calcul et de stockage*.* l'environnement Splunk SmartStore dissocie le calcul et le stockage, ce qui vous permet de les faire évoluer de manière indépendante.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*Données à la demande.* SmartStore met les données à proximité des ressources de calcul à la demande et fournit l'élasticité et l'efficacité des coûts de calcul et de stockage afin d'obtenir une rétention des données plus longue à grande échelle.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*Compatible avec l'API AWS S3.* SmartStore utilise l'API AWS S3 pour communiquer avec le stockage de restauration, un magasin d'objets AWS S3 et compatible avec l'API S3 tel qu'StorageGRID.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">* Réduit les besoins en stockage et les coûts.* SmartStore réduit les besoins en stockage pour les données âgées (chaud/froid). Il ne requiert qu'une seule copie des données car le stockage NetApp assure la protection des données, en veillant aux défaillances et à la haute disponibilité.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*Défaillance matérielle.* défaillance de nœud dans un déploiement SmartStore ne rend pas les données inaccessibles et a une récupération d'indexeur beaucoup plus rapide à partir d'une défaillance matérielle ou d'un déséquilibre des données.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">Cache orienté applications et données.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">Indexeurs supplémentaires et cluster de configuration à la demande.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">Le niveau de stockage n'est plus lié au matériel.</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">Cette page présente les challenges que peuvent relever les clients lorsqu'ils cherchent à accéder aux données issues de l'analytique Big Data pour les opérations d'IA.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">Défis des clients</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">Lorsque vous essayez d'accéder aux données issues de l'analytique Big Data pour les opérations d'IA, vous devez :</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">Les données des clients se trouvent dans un référentiel de data Lake. Le data Lake peut contenir différents types de données, qu'elles soient structurées, non structurées, semi-structurées, journaux ou encore machines à machines. L'ensemble de ces types de données doit être traité dans des systèmes d'IA.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">L'IA n'est pas compatible avec les systèmes de fichiers Hadoop. Une architecture d'IA standard n'est pas en mesure d'accéder directement aux données HDFS et HCFS, qui doit être déplacée vers un système de fichiers compréhensible par l'IA (NFS).</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">Le déplacement des données du data Lake vers l'IA nécessite généralement des processus spécialisés. Le volume de données dans le data Lake peut être très élevé. Un client doit disposer d'un moyen efficace, haut débit et économique de déplacer des données vers des systèmes d'IA.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">Synchronisation des données. Si un client souhaite synchroniser des données entre la plateforme Big Data et l'IA, parfois les données traitées par l'IA peuvent être utilisées avec le Big Data à des fins de traitement analytique.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">Ensuite, une solution de déplacement des données.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">Cette section décrit les avantages commerciaux de cette solution.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">Avantages pour l'entreprise</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">Précédent : HDFS et MapR-FS sur ONTAP NFS.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">Le déplacement des données de l'analytique Big Data vers l'IA présente plusieurs avantages :</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">La possibilité d'extraire les données de différents systèmes de fichiers Hadoop et GPFS dans un système de stockage NFS unifié</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Transfert de données automatisé et intégré à Hadoop</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Réduction du coût de développement de la librairie pour le déplacement des données à partir des systèmes de fichiers Hadoop</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">Performances maximales grâce au débit agrégé de plusieurs interfaces réseau à partir d'une seule source de données à l'aide de NIPAM</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">Méthodes planifiées et à la demande pour le transfert des données</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">L'efficacité du stockage et une fonctionnalité de gestion d'entreprise pour les données NFS unifiées grâce au logiciel de gestion des données ONTAP</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Transfert de données sans coût supplémentaire avec la méthode Hadoop</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">Suivant : étapes GPFS vers NFS détaillées.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">Ce cas d'utilisation s'pertinentes pour les partenaires de services clouds chargés d'assurer une connectivité multicloud pour les données d'analytique Big Data des clients.</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">Précédent : cas d'utilisation 3 - activation de DevTest sur les données Hadoop existantes.</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">Dans ce scénario, des données IoT reçues dans AWS de différentes sources sont stockées dans un emplacement central dans NPS. Le stockage NPS est connecté aux clusters Spark/Hadoop situés dans AWS et Azure, ce qui permet aux applications d'analytique Big Data exécutées dans plusieurs clouds d'accéder aux mêmes données.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">Les clients veulent exécuter les tâches d'analytique sur les mêmes données à l'aide de plusieurs clouds.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">Les données doivent être reçues de différentes sources, telles que les données sur site et dans le cloud, par le biais de différents capteurs et concentrateurs.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">La solution doit être efficace et économique.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">Le principal défi consiste à concevoir une solution efficace et économique qui propose des services d'analytique hybride entre les environnements sur site et cloud.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">Cette image illustre la solution de protection des données et de connectivité multicloud.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">Comme illustré dans la figure ci-dessus, les données provenant des capteurs sont transmises et ingérées sur le cluster AWS Spark via Kafka. Les données sont stockées dans un partage NFS hébergé sur NPS, situé en dehors du fournisseur cloud au sein d'un data Center Equinix. Étant donné que NetApp NPS est connecté à Amazon AWS et Microsoft Azure via les connexions Direct Connect et Express route, respectivement, les clients peuvent utiliser le module d'analytique sur place pour accéder aux données à la fois depuis les clusters d'analytique Amazon et AWS. Cette approche résout l'analytique cloud de plusieurs hyperscalers.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">Par conséquent, comme le stockage sur site et NPS exécute le logiciel ONTAP, SnapMirror peut mettre en miroir les données NPS dans le cluster sur site, pour une analytique de cloud hybride entre les environnements sur site et clouds.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">Pour optimiser les performances, NetApp recommande généralement d'utiliser plusieurs interfaces réseau et des routes directes/express pour accéder aux données à partir des instances cloud.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">Suivant : cas d'utilisation 5 - accélération des workloads d'analytique.</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">Nous avons réalisé le test du stockage sur plusieurs niveaux avec trois à quatre nœuds pour les charges de travail produire et grand public grâce à la configuration NetApp StorageGRID.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">Tests de performances avec évolutivité</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">Précédent : vérification confluent.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">Nous avons réalisé le test du stockage sur plusieurs niveaux avec trois à quatre nœuds pour les charges de travail des producteurs et des consommateurs, grâce à la configuration NetApp StorageGRID. Selon nos tests, le temps d'exécution et les résultats en termes de performances étaient directement proportionnels au nombre de nœuds StorageGRID. Le setup StorageGRID a nécessité au moins trois nœuds.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">La durée des opérations de production et de production a diminué de façon linéaire lorsque le nombre de nœuds de stockage augmente.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">Les performances de l'opération de récupération s3 augmentent de façon linéaire en fonction du nombre de nœuds StorageGRID. StorageGRID prend en charge jusqu'à 200 nœuds StorageGRID.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">Suivant : connecteur s3 confluent.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">Nous avons obtenu la certification avec Kafka pour le stockage hiérarchisé du stockage NetApp StorageGRID.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Vérification confluent</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">Nous avons effectué une vérification avec le stockage hiérarchisé Confluent Platform 6.2 dans NetApp StorageGRID. Les équipes NetApp et confluent ont collaboré à cette vérification et ont exécuté les cas de test requis pour la vérification.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Configuration de la plate-forme Confluent</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">Nous avons utilisé la configuration suivante pour la vérification.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">À des fins de vérification, nous avons utilisé trois zoopers, cinq courtiers, cinq serveurs d'exécution de scripts de test, des serveurs d'outils nommés avec 256 Go de RAM et 16 processeurs. Pour le stockage NetApp, nous avons utilisé StorageGRID avec un équilibreur de charge SG1000 et avec quatre SGF6024s. Le stockage et les courtiers étaient connectés via des connexions 100 GbE.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">La figure suivante montre la topologie réseau de la configuration utilisée pour la vérification de confluent.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">Les serveurs d'outils agissent comme des clients d'application qui envoient des demandes aux nœuds de confluent.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Configuration du stockage multi-niveaux fluide</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">La configuration de stockage à plusieurs niveaux nécessite les paramètres suivants dans Kafka :</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">À des fins de vérification, nous avons utilisé StorageGRID avec le protocole HTTP, mais HTTPS fonctionne également. La clé d'accès et la clé secrète sont stockées dans le nom de fichier fourni dans le<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">Stockage objet NetApp - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">Nous avons configuré la configuration du site unique dans StorageGRID pour la vérification.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">Tests de vérification</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">Nous avons complété les cinq tests suivants pour la vérification. Ces tests sont exécutés sur le cadre de Trogdor. Les deux premiers étaient les tests de fonctionnalité et les trois autres étaient les tests de performance.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">Test d'exactitude du magasin d'objets</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">Ce test détermine si toutes les opérations de base (par exemple GET/PUT/delete) de l'API du magasin d'objets fonctionnent bien selon les besoins du stockage hiérarchisé. C'est un test de base que chaque service de magasin d'objets devrait s'attendre à passer avant les tests suivants. C'est un test d'assurance qui réussit ou échoue.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">Test d'exactitude des fonctionnalités de hiérarchisation</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">Ce test détermine si la fonctionnalité de stockage à plusieurs niveaux fonctionne correctement avec un test assertif qui réussit ou échoue. Le test crée un sujet de test qui est configuré par défaut avec le Tiering activé et une taille de groupe de signets très réduite. Il produit un flux d'événements vers le nouveau sujet de test créé, il attend que les courtiers archivent les segments dans le magasin d'objets, puis il utilise le flux d'événements et valide que le flux consommé correspond au flux produit. Le nombre de messages produits au flux d'événements est configurable, ce qui permet à l'utilisateur de générer une charge de travail suffisamment importante en fonction des besoins du test. La taille réduite du hot set garantit que les fetches du consommateur en dehors du segment actif ne sont servies qu'à partir du magasin d'objets ; cela permet de tester l'exactitude du magasin d'objets pour les lectures. Nous avons effectué ce test avec et sans injection de défaut dans le magasin d'objets. Nous avons simulé une panne des nœuds en arrêtant le service Service Manager dans l'un des nœuds de StorageGRID et en validant que la fonctionnalité de bout en bout fonctionne avec le stockage objet.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">Banc d'essai de récupération de Tier</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">Ce test a validé les performances de lecture du stockage d'objets hiérarchisés et vérifié les demandes de lecture de plage en charge lourde à partir des segments générés par le banc d'essai. Dans ce banc d'essai, confluent a développé des clients personnalisés pour traiter les demandes d'extraction de niveau.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">Banc d'essai des charges de travail « production »</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">Ce test a généré indirectement le workload d'écriture sur le magasin d'objets via l'archivage de segments. Le workload de lecture (segments lus) a été généré à partir du stockage objet lorsque les groupes de consommateurs ont extrait les segments. Ce workload a été généré par le script de test. Ce test a vérifié les performances de lecture et d'écriture sur le stockage objet dans les threads parallèles. Nous avons testé avec et sans injection de panne dans le magasin d'objets, comme nous l'avons fait pour le test d'exactitude de la fonctionnalité de Tiering.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">Banc d'essai des workloads de conservation</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">Ce test a permis de vérifier les performances de suppression d'un magasin d'objets sous un workload de conservation des rubriques lourd. La charge de travail de rétention a été générée à l'aide d'un script de test qui produit de nombreux messages en parallèle à un sujet de test. La rubrique de test était configurée avec un paramètre de conservation basé sur la taille et le temps agressif qui a provoqué la purge continue du flux d'événements du magasin d'objets. Les segments ont ensuite été archivés. Cela a entraîné de nombreuses suppressions dans le stockage objet par le courtier et la collecte des performances des opérations de suppression du magasin d'objets.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">Next : tests de performances avec évolutivité.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">Ce document fournit des instructions sur le transfert des données d'analytique Big Data et des données HPC vers l'IA à l'aide de NetApp XCP et NIPAM. Nous présentons également les avantages commerciaux du transfert de données du Big Data et de l'informatique haute performance vers l'IA.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">Tr-4732 : analytique Big Data dans l'intelligence artificielle</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">Ce document explique comment déplacer des données d'analytique Big Data et des données HPC vers l'IA. L'IA traite les données NFS par le biais d'exportations NFS, alors que les clients disposent souvent de leurs données d'IA dans une plateforme d'analytique Big Data, comme le stockage HDFS, Blob ou S3, ainsi que des plateformes HPC comme GPFS. Ce document fournit des instructions sur le transfert des données d'analytique Big Data et des données HPC vers l'IA à l'aide de NetApp XCP et NIPAM. Nous présentons également les avantages commerciaux du transfert de données du Big Data et de l'informatique haute performance vers l'IA.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">Concepts et composants</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">Stockage analytique Big Data</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">L'analytique Big Data est le premier fournisseur de stockage pour HDFS. Un client utilise souvent un système de fichiers compatible Hadoop (HCFS), tel que Windows Azure Blob Storage, MapR File System (MapR-FS) et le stockage objet S3.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">Système de fichiers parallèle général</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">Le GPFS d’IBM est un système de fichiers d’entreprise qui constitue une alternative au HDFS. GPFS offre la flexibilité pour les applications et permet de choisir la taille de bloc et la disposition de la réplication, qui assurent de bonnes performances et une bonne efficacité.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">Module d'analytique sur place NetApp</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">Tr-4382 : module d'analytique sur place NetApp.</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">Le module d'analytique sur place (NIPAM) de NetApp sert de pilote pour que les clusters Hadoop puissent accéder aux données NFS. Il comporte quatre composants : un pool de connexions, un InputStream NFS, un cache de descripteur de fichier et un OutputStream NFS. Pour plus d'informations, voir<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Copie distribuée Hadoop</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) est un outil de copie distribué utilisé pour les tâches de gestion inter-cluster et intra-cluster volumineuses. Cet outil utilise MapReduce pour la distribution des données, le traitement des erreurs et le reporting. Elle étend la liste des fichiers et répertoires et les saisit pour mapper les tâches afin de copier les données de la liste source. L'image ci-dessous présente l'opération DistCp dans HDFS et non HDFS.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Le DistCp Hadoop déplace les données entre les deux systèmes HDFS sans utiliser de pilote supplémentaire. NetApp est le pilote des systèmes non HDFS. Pour une destination NFS, NIPAM fournit au pilote la copie des données utilisées par Hadoop DistCp pour communiquer avec les destinations NFS lors de la copie des données.</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service est un service de fichiers cloud natif offrant des performances extrêmes. Ce service permet aux clients d'accélérer les délais de mise sur le marché en faisant rapidement tourner les ressources vers la hausse ou la baisse et en utilisant les fonctionnalités NetApp pour améliorer la productivité et réduire les temps d'indisponibilité du personnel. Cloud Volumes Service constitue une alternative idéale pour la reprise après incident et la sauvegarde dans le cloud, car elle réduit l'empreinte globale du data Center et consomme moins de stockage de cloud public natif.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP est un logiciel client qui permet une migration de données rapide et fiable, de tout type à NetApp et de NetApp à NetApp. Cet outil est conçu pour copier un grand nombre de données NAS non structurées depuis n'importe quel système NAS vers un contrôleur de stockage NetApp. L'outil de migration XCP utilise un moteur de streaming d'E/S multi-cœurs capable de traiter de nombreuses demandes en parallèle, comme la migration des données, la liste des fichiers ou des répertoires et la génération de rapports sur l'espace. Il s'agit de l'outil de migration des données NetApp par défaut. Vous pouvez utiliser XCP pour copier les données d'un cluster Hadoop et d'HPC vers un stockage NFS NetApp. Le schéma ci-dessous présente le transfert des données d'un cluster Hadoop et HPC vers un volume NFS NetApp utilisant XCP.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync est un logiciel SaaS de réplication des données hybride qui permet de transférer et de synchroniser les données NFS, S3 et CIFS de façon transparente et sécurisée entre votre stockage sur site et votre stockage dans le cloud. Ce logiciel est utilisé pour la migration des données, l'archivage, la collaboration, l'analytique, et bien plus encore. Une fois les données transférées, Cloud Sync les synchronise de manière continue entre la source et la destination. En avant, il transfère ensuite le delta. Elles sécurisent également les données dans votre propre réseau, dans le cloud ou sur site. Ce logiciel vous est basé sur un modèle de paiement basé sur l'utilisation. Il offre une solution économique et propose des fonctionnalités de surveillance et de reporting pour vos transferts de données.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">Ensuite : les défis des clients.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">Ce document présente les solutions de données de cloud hybride qui utilisent les systèmes de stockage NetApp AFF et FAS, NetApp Cloud Volumes ONTAP, les systèmes de stockage connectés NetApp et la technologie FlexClone pour Spark et Hadoop. Ces architectures de solution permettent aux clients de choisir la solution de protection des données adaptée à leur environnement. NetApp a conçu ces solutions en fonction des interactions avec les clients et de leurs utilisations.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">Tr-4657 : solutions de données de cloud hybride NetApp - Spark et Hadoop en fonction des cas d'utilisation clients</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam et Satish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">Ce document présente les solutions de données de cloud hybride qui utilisent les systèmes de stockage NetApp AFF et FAS, NetApp Cloud Volumes ONTAP, les systèmes de stockage connectés NetApp et la technologie FlexClone pour Spark et Hadoop. Ces architectures de solution permettent aux clients de choisir la solution de protection des données adaptée à leur environnement. NetApp a conçu ces solutions en fonction des interactions avec les clients et de leurs utilisations. Ce document fournit les informations détaillées suivantes :</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Pourquoi nous devons nous doter d'une solution de protection des données pour les environnements Spark et Hadoop et les défis des clients.</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">La Data Fabric optimisée par la vision NetApp, ainsi que ses éléments de base et ses services.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">Ces éléments de base peuvent être utilisés pour concevoir des flux de travail flexibles de protection des données.</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">Les avantages et les inconvénients de plusieurs architectures basées sur des cas d'utilisation réels de clients. Chaque cas d'utilisation propose les composants suivants :</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">Scénarios clients</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">NetApp</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">Résumé des solutions</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Pourquoi choisir la protection des données Hadoop ?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Dans un environnement Hadoop et Spark, les problèmes suivants doivent être résolus :</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*Pannes logicielles ou humaines.* une erreur humaine dans les mises à jour logicielles lors de l'exécution des opérations de données Hadoop peut entraîner un comportement défectueux qui peut entraîner des résultats inattendus de la tâche. Dans ce cas, nous devons protéger les données pour éviter les défaillances ou les résultats déraisonnables. Par exemple, suite à une mise à jour logicielle mal exécutée vers une application d'analyse de signal de trafic, une nouvelle fonction qui ne parvient pas à analyser correctement les données de signal de trafic sous forme de texte brut. Le logiciel analyse encore des formats JSON et d'autres formats de fichiers non texte, ce qui entraîne l'analyse en temps réel du contrôle du trafic, produisant des résultats de prédiction qui manquent de points de données. Cette situation peut entraîner des sorties défectueuses qui peuvent entraîner des accidents au niveau des signaux de circulation. La protection des données peut résoudre ce problème et permet de restaurer rapidement la version précédente de l'application de travail.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*Taille et échelle.* la taille des données analytiques augmente jour après jour en raison du nombre toujours croissant de sources de données et de volumes. Les médias sociaux, les applications mobiles, l'analytique et les plateformes de cloud computing sont les principales sources de données sur le marché actuel du Big Data, qui augmente très rapidement. Par conséquent, les données doivent être protégées pour assurer la précision des opérations.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">*La protection native des données de Hadoop.* Hadoop a une commande native pour protéger les données, mais cette commande n'assure pas la cohérence des données pendant la sauvegarde. Elle prend uniquement en charge la sauvegarde au niveau des répertoires. Les snapshots créés par Hadoop sont en lecture seule et ne peuvent pas être utilisés pour réutiliser directement les données de sauvegarde.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Défis posés par la protection des données pour les clients Hadoop et Spark</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Le défi commun des clients d'Hadoop et d'Spark est de réduire le temps de sauvegarde et d'augmenter la fiabilité des sauvegardes sans nuire aux performances du cluster de production pendant la protection des données.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">Les clients doivent également réduire les temps d'indisponibilité liés aux objectifs de point de récupération (RPO) et de durée de restauration (RTO), et contrôler leurs sites de reprise après incident sur site et dans le cloud pour assurer la continuité de l'activité. Ce contrôle vient généralement d'avoir des outils de gestion au niveau de l'entreprise.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Les environnements Hadoop et Spark se compliquent parce que non seulement le volume des données croît et exponentielle, mais que le débit de ces données augmente. Dans ce scénario, il est difficile de créer rapidement des environnements DevTest et QA efficaces et à jour à partir des données source. NetApp reconnaît ces défis et propose les solutions présentées dans ce livre blanc.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">Next : Data Fabric optimisée par NetApp pour l'architecture Big Data.</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">Ce document présente les bancs d'essai sur les performances de la plateforme confluent sur NetApp ONTAP grâce à un kit de test des performances de stockage à plusieurs niveaux.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">Tr-4941 : association avec les contrôleurs de stockage NetApp ONTAP</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, confluent</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Pour que la plateforme confluent soit plus évolutive et plus élastique, elle doit pouvoir faire évoluer et équilibrer les charges de travail très rapidement. Le stockage à plusieurs niveaux permet le stockage de volumes massifs de données en parfaite maîtrise, en réduisant cette charge opérationnelle. Il s'agit de séparer le stockage des données du traitement, ce qui facilite la mise à niveau de chacun de manière indépendante.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">Chargé d'innovations de pointe, le logiciel de gestion des données NetApp ONTAP apporte une maîtrise parfaite des avantages, quel que soit le lieu où résident les données.</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">Ensuite, la solution.</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">Cette section couvre le matériel et les logiciels utilisés pour la vérification de confluent. Ces informations s'appliquent pour couramment le déploiement des plateformes avec le stockage NetApp. Le tableau suivant couvre l'architecture de la solution testée et les composants de base.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Kafka confluent version 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">Trois zoogardiens</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">Cinq serveurs de courtage</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">Cinq serveurs d'outils</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">Un seul Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">Un centre de contrôle</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">Tous les serveurs</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID pour le stockage à plusieurs niveaux</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">Logiciel StorageGRID</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000 (équilibreur de charge)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100 GbE (connectivité réseau entre le courtier et les instances StorageGRID)</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">Chacun équipé de : * 2 processeurs, 16 cœurs physiques au total * mémoire physique Intel Xeon * 256 Go * double port 100 GbE</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">Ce test repose sur la fonctionnalité de clusters d'auto-équilibrage qui automatise le rééquilibrage en fonction des modifications de la topologie du cluster ou des charges irrégulières.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Clusters d'auto-équilibrage fluides</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">Précédent : connecteur Kafka s3.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">Si vous avez déjà géré un cluster Kafka, vous connaissez probablement les défis liés à la réaffectation manuelle des partitions vers différents courtiers afin de vous assurer que la charge de travail est équilibrée sur le cluster. Pour les entreprises dotées de déploiements Kafka volumineux, la nécessité de déstocker d'importants volumes de données peut s'avérer fastidieux, fastidieuse et risquée, en particulier si les applications stratégiques sont intégrées au cluster. Toutefois, même dans les cas d'utilisation de Kafka les plus petits, le processus prend du temps et est sujet aux erreurs humaines.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">Nous avons testé la fonctionnalité de clusters d'auto-équilibrage courants qui automatise le rééquilibrage en fonction des modifications de la topologie du cluster ou des charges irrégulières. Le test de rééquilibrage courant permet de mesurer le temps nécessaire à l'ajout d'un nouveau courtier en cas de défaillance du nœud ou d'évolution nécessitant un rééquilibrage des données dans les différents courtiers. Dans les configurations Kafka classiques, le volume de données à rééquilibrer augmente avec la croissance du cluster, mais dans le stockage à plusieurs niveaux, le rééquilibrage est limité à une petite quantité de données. Basé sur notre validation, le rééquilibrage du stockage à plusieurs niveaux ne prend que quelques secondes ou minutes dans une architecture Kafka classique, ce qui augmente de façon linéaire à mesure que le cluster augmente.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">Dans les clusters à auto-équilibrage, le rééquilibrage des partitions est entièrement automatisé afin d'optimiser le débit de Kafka, d'accélérer l'évolutivité des courtiers et de réduire la charge opérationnelle liée à l'exécution d'un grand cluster. Dans un état stable, les clusters à auto-équilibrage surveillent l'inclinaison des données dans les « courtiers » et réaffirment en permanence les partitions afin d'optimiser les performances du cluster. Lorsque la plateforme peut évoluer verticalement ou horizontalement, les clusters à équilibrage automatique reconnaissent automatiquement la présence de nouveaux courtiers ou le retrait d'anciens courtiers et déclenchent une réaffectation ultérieure des partitions. Vous pouvez ainsi ajouter et désaffecter facilement des courtiers et, ce qui rend vos clusters Kafka fondamentalement plus élastiques. Ces avantages sont sans intervention manuelle, mathématiques complexes ou risque d'erreur humaine que les réaffectations de partition entraînent généralement. Le rééquilibrage des données se fait donc en beaucoup moins de temps. Il reste à votre disposition des projets de streaming à plus forte valeur ajoutée, plutôt que de devoir superviser constamment vos clusters.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">Ensuite : recommandations sur les bonnes pratiques.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">Elle permet d'ajouter des ressources de calcul, de stockage à chaud ou S3 pour répondre à la demande croissante en matière de nombre d'utilisateurs ou de taux d'ingestion pour des déploiements dans un ou plusieurs sites.</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*Performance.* la combinaison de Splunk SmartStore et de NetApp StorageGRID permet une migration rapide des données entre des compartiments actifs et des compartiments chauds à l'aide du stockage objet. StorageGRID accélère le processus de migration en fournissant des performances rapides pour les workloads d'objets volumineux.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*Multisite Ready.* l'architecture distribuée StorageGRID permet à Splunk SmartStore d'étendre les déploiements sur un seul et plusieurs sites via un espace de noms global unique où les données sont accessibles depuis n'importe quel site, quel que soit l'emplacement où elles résident.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*Évolutivité améliorée.* faites évoluer les ressources de stockage indépendamment des ressources de calcul pour répondre à l'évolution des besoins et des demandes de votre environnement Splunk, tout en améliorant le coût total de possession.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*Capacité* Découvrez les volumes en pleine croissance dans un déploiement Splunk avec StorageGRID en faisant évoluer un seul namespace jusqu'à plus de 560 po.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*Disponibilité des données.* optimisation de la disponibilité des données, des performances, de la répartition géographique, de la conservation, de la protection, et les coûts de stockage grâce à des règles basées sur des métadonnées qui peuvent s'adapter de façon dynamique afin de rester en phase avec la valeur commerciale de vos données.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Instructions fournies par Splunk</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">Améliorez vos performances grâce au cache SmartStore, composant de l'indexeur qui gère le transfert de copies de compartiment entre le stockage local (chaud) et le stockage distant (chaud). Le dimensionnement de cette solution repose sur<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>. Elle permet d'ajouter des ressources de calcul, de stockage à chaud ou S3 pour répondre à la demande croissante en matière de nombre d'utilisateurs ou de taux d'ingestion pour des déploiements dans un ou plusieurs sites.</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">Ensuite : hiérarchisation intelligente et réduction des coûts.</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">Scripts Python pour chaque utilisation majeure</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">Précédent : solution cloud hybride.</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">Les trois scripts Python suivants correspondent aux trois principaux cas d'utilisation testés. Tout d'abord<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>.</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">Le deuxième script est<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">Le troisième script est<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>.</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">Cette section fournit les étapes détaillées requises pour transférer les données de MapR-FS vers ONTAP NFS à l'aide de NetApp XCP.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MAPR-FS pour ONTAP NFS</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">Précédent : GPFS vers NFS - étapes détaillées.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">Provisionnez trois LUN pour chaque nœud de MapR et offrez la propriété de tous les nœuds MapR.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">Lors de l'installation, sélectionnez les LUN récemment ajoutées pour les disques de cluster MapR utilisés pour MapR-FS.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">Documentation de MapR 6.1</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">Installez un cluster MapR en fonction du<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Vérifiez les opérations Hadoop de base à l'aide des commandes MapReduce telles que<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">Conservez les données clients dans la solution de MapR-FS. Par exemple, nous avons généré environ un téraoctet de données d'échantillon dans MapR-FS en utilisant Teragen.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">Configurez MAPR-FS comme exportation NFS.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">Désactivez le service nlockmgr sur tous les nœuds de MapR.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">Exportez des dossiers spécifiques à partir de MapR-FS sur tous les nœuds MAPR de la<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> fichier. N'exportez pas le dossier parent avec des autorisations différentes lorsque vous exportez des sous-dossiers.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">Actualisez le service NFS de MapR-FS.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">Attribuez une plage d'adresses IP virtuelles à un serveur spécifique ou à un ensemble de serveurs du cluster MapR. Le cluster MapR attribue ensuite une adresse IP à un serveur spécifique pour l'accès aux données NFS. Les adresses IP permettent la haute disponibilité, ce qui signifie que, si un serveur ou un réseau présentant une défaillance IP particulière, l'adresse IP suivante de la plage d'adresses IP peut être utilisée pour l'accès NFS.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">Pour fournir un accès NFS à partir de tous les nœuds MapR, vous pouvez attribuer un ensemble d'adresses IP virtuelles à chaque serveur et utiliser les ressources de chaque nœud de MapR pour l'accès aux données NFS.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">Vérifiez les adresses IP virtuelles attribuées à chaque nœud de MapR et utilisez-les pour accéder aux données NFS.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">Montez le MAPR-FS exporté par NFS à l'aide de l'IP virtuelle attribuée pour vérifier l'opération NFS. Toutefois, cette étape n'est pas requise pour le transfert de données via NetApp XCP.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">Configurer NetApp XCP pour transférer les données de la passerelle NFS de MapR-FS vers le protocole NFS ONTAP</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">Configurer l'emplacement du catalogue pour XCP.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">Copiez le fichier de licence dans<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">Activer XCP à l'aide du<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> commande.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">Vérifier la source de l'exportation NFS.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">Transférez les données en utilisant XCP de plusieurs nœuds de MapR des IP source multiples et des adresses IP de destination multiples (LIF ONTAP).</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">Vérifier la répartition de charge sur le contrôleur de stockage.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise est une solution SIEM leader du marché qui favorise la réussite des équipes de sécurité, D'IT et de DevOps. L'utilisation de Splunk a considérablement augmenté dans l'ensemble des organisations de nos clients. Il est donc nécessaire d'ajouter davantage de sources de données tout en conservant les données pendant une période plus longue, ce qui met l'infrastructure Splunk à l'épreuve.</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">Précédent : performances de SmartStore sur un seul site.</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">L'association de Splunk SmartStore et de NetApp StorageGRID a pour objectif de fournir une architecture évolutive qui permet aux entreprises de améliorer les performances d'entrée des données avec le stockage objet SmartStore et StorageGRID, ainsi qu'une meilleure évolutivité pour un environnement Splunk répartis sur plusieurs régions géographiques.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">Ressources de documentation NetApp StorageGRID</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Documentation Splunk Enterprise</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise à propos de SmartStore</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Manuel de déploiement distribué Splunk Enterprise</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Solutions Splunk Enterprise pour la gestion d'indexeurs et de clusters d'indexeurs</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">Juillet 2022</block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">Cette page décrit la validation des performances de confluent dans les paramètres de cette solution.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Validation des performances confluentes</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">Nous avons effectué la vérification avec une plateforme confluent pour le stockage hiérarchisé sur NetApp ONTAP. Les équipes NetApp et confluent ont collaboré sur cette vérification et ont exécuté les cas de test requis pour l'équipe informatique.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Configuration confluent</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">Pour cette configuration, nous avons utilisé trois zoopers, cinq courtiers et cinq serveurs de test avec 256 Go de RAM et 16 processeurs. Pour le stockage NetApp, nous avons utilisé ONTAP avec une paire haute disponibilité AFF A900. Le stockage et les courtiers étaient connectés via des connexions 100 GbE.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">La figure suivante montre la topologie réseau de la configuration utilisée pour la vérification du stockage à plusieurs niveaux.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">Ce graphique présente la topologie réseau de la configuration utilisée pour la vérification du stockage à plusieurs niveaux.</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">Les serveurs d'outils agissent comme des clients d'application qui envoient ou reçoivent des événements vers ou depuis des nœuds de confluent.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">Nous avons utilisé les paramètres de test suivants :</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">À des fins de vérification, nous avons utilisé ONTAP avec le protocole HTTP, mais HTTPS était également utilisé. La clé d'accès et la clé secrète sont stockées dans le nom de fichier fourni dans le<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> paramètre.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">Contrôleur de stockage NetApp – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">Nous avons configuré une configuration de paires haute disponibilité uniques dans ONTAP à des fins de vérification.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">Ce graphique illustre la configuration de l'environnement en tant qu'une seule paire haute disponibilité à des fins de vérification.</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">Résultats de la vérification</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">Nous avons complété les cinq tests suivants pour la vérification. Les deux premiers étaient les tests de fonctionnalité et les trois autres étaient les tests de performance.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">Ce test effectue les opérations de base comme obtenir, placer et supprimer dans le magasin d'objets utilisé pour le stockage hiérarchisé à l'aide d'appels d'API.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">Ce test vérifie la fonctionnalité de bout en bout du stockage objet. Il crée un sujet, produit un flux d'événements vers le sujet nouvellement créé, attend que les courtiers archivent les segments vers le stockage objet, utilisent le flux d'événements et valide les correspondances des flux consommés avec le flux produit. Nous avons effectué ce test avec et sans injection de défaut dans le magasin d'objets. Nous avons simulé une panne des nœuds en arrêtant le service Service Manager dans l'un des nœuds de ONTAP et en validant que la fonctionnalité de bout en bout fonctionne avec le stockage objet.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">Générateur de charges de travail consommant le produit</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">Ce test génère indirectement un workload d'écriture sur le magasin d'objets via l'archivage de segments. Le workload de lecture (segments lus) a été généré à partir du stockage objet lorsque les groupes de consommateurs ont extrait les segments. Cette charge de travail a été générée par un script TOCC. Ce test a vérifié les performances de lecture et d'écriture sur le stockage objet dans les threads parallèles. Nous avons testé avec et sans injection de panne dans le magasin d'objets, comme nous l'avons fait pour le test d'exactitude de la fonctionnalité de Tiering.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">Générateur de charges de travail de rétention</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">Ce test a permis de vérifier les performances de suppression d'un stockage objet sous une charge de travail de conservation des rubriques élevée. La charge de travail de rétention a été générée à l'aide d'un script TOCC qui produit de nombreux messages en parallèle à un sujet de test. La rubrique de test était configurée avec un paramètre de conservation basé sur la taille et le temps agressif qui a provoqué la purge continue du flux d'événements du magasin d'objets. Les segments ont ensuite été archivés. Cela a entraîné de nombreuses suppressions dans le stockage objet par le courtier et la collecte des performances des opérations de suppression du magasin d'objets.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">Confluent</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">Pour plus d'informations sur la vérification, reportez-vous au<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> site web.</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">Ensuite : tests de performances avec un générateur de charges de travail consommant les produits.</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID est doté d'une grande variété de fonctionnalités que les utilisateurs peuvent exploiter et personnaliser pour s'adapter à leur environnement en constante évolution. De votre déploiement à l'évolutivité de votre environnement Splunk SmartStore, votre environnement exige une adoption rapide des changements, sans interruption des activités dans Splunk. Grâce aux règles flexibles de gestion des données (ILM) et aux classificateurs du trafic (QoS) de StorageGRID, vous pouvez planifier et s'adapter à votre environnement.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Fonctionnalités StorageGRID flexibles pour Splunk SmartStore</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Gestion simple avec Grid Manager</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager est une interface graphique basée sur navigateur qui vous permet de configurer, de gérer et de surveiller votre système StorageGRID sur des emplacements répartis à travers le monde, dans une seule fenêtre, comme l'illustre l'image suivante.</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Effectuez les tâches suivantes avec l'interface Grid Manager :</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">Gérez des référentiels d'objets répartis à travers le monde de plusieurs pétaoctets, tels que des images, des vidéos et des dossiers.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">Surveiller les nœuds et les services du grid pour assurer la disponibilité des objets.</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">Gérez le placement des données d'objet au fil du temps à l'aide de règles de gestion du cycle de vie des informations (ILM). Ces règles régissent ce qui arrive aux données d'un objet après son ingestion, mais aussi leur protection contre la perte, l'emplacement de stockage des données d'objet et leur durée.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">Surveillance des transactions, des performances et des opérations dans le système</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">NetApp StorageGRID application pour Splunk</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">L'application NetApp StorageGRID pour Splunk est une application spécifique à Splunk Enterprise. Cette application fonctionne en association avec le module complémentaire NetApp StorageGRID pour Splunk. Cet outil permet d'identifier l'état de santé des StorageGRID, les informations sur l'utilisation des comptes, les informations d'audit de sécurité, l'utilisation et la surveillance des ressources, etc.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">L'image suivante présente l'application StorageGRID pour Splunk.</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">Règles ILM</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID propose des règles de gestion des données flexibles qui incluent le stockage de plusieurs copies de vos objets et l'utilisation de schémas EC (codage d'effacement) comme 2+1 et 4+2 (et de nombreux autres) pour stocker vos objets en fonction de besoins de performances et de protection des données spécifiques. Les exigences et les charges de travail évoluent au fil du temps. Les règles ILM doivent également évoluer au fil du temps. La modification des règles ILM est une fonction centrale, qui permet aux clients StorageGRID de s'adapter rapidement et facilement à l'évolution permanente de leur environnement.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID assure une évolutivité des performances en ajoutant des nœuds supplémentaires, qui peuvent être des machines virtuelles ou des appliances bare Metal ou dédiées telles que SG5712, SG5760, SG6060 ou SGF6024. Lors de nos tests, nous avons dépassé les exigences de performance clés de SmartStore avec un grid à trois nœuds de taille minimale utilisant l'appliance SG6060. À mesure que les clients font évoluer leur infrastructure Splunk à l'aide d'indexeurs supplémentaires, ils peuvent ajouter des nœuds de stockage pour augmenter la performance et la capacité.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">Load Balancer et la configuration des noeuds d'extrémité</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">Les nœuds d'administration d'StorageGRID fournissent l'interface utilisateur Grid Manager (interface utilisateur) et le terminal d'API REST pour afficher, configurer et gérer votre système StorageGRID, ainsi que des journaux d'audit pour suivre l'activité du système. Pour fournir un terminal S3 hautement disponible pour le stockage distant Splunk SmartStore, nous avons implémenté l'équilibreur de charge StorageGRID, qui s'exécute en tant que service sur les nœuds d'administration et les nœuds de passerelle. En outre, l'équilibreur de charge gère également le trafic local et communique avec le GSLB (Global Server Load Balancing) pour faciliter la reprise après incident.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">Pour améliorer encore la configuration des terminaux, StorageGRID fournit des règles de classification du trafic intégrées au nœud d'administration, vous permet de surveiller le trafic des workloads et d'appliquer diverses limites de qualité de service à vos charges de travail. Les règles de classification du trafic sont appliquées aux terminaux du service StorageGRID Load Balancer pour les nœuds de passerelle et les nœuds d'administration. Ces règles peuvent vous aider à limiter le trafic et à surveiller le trafic.</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">Next : architecture Splunk.</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">Dans ce scénario, le client dispose d'un grand référentiel Hadoop sur site et souhaite le sauvegarder à des fins de reprise après incident. Toutefois, la solution de sauvegarde actuelle du client est coûteuse et nécessite une longue fenêtre de sauvegarde de plus de 24 heures.</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">Précédent : présentation des cas d'utilisation de la protection des données Hadoop.</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">Rétrocompatibilité logicielle :</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">La solution de sauvegarde proposée doit être compatible avec les versions logicielles actuellement utilisées dans le cluster Hadoop de production.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">Pour respecter les contrats de niveau de service (SLA) signés, la solution alternative proposée doit permettre d'atteindre des RPO et des RTO très faibles.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">La sauvegarde créée par la solution de sauvegarde NetApp peut être utilisée dans le cluster Hadoop intégré localement au data Center ainsi que dans le cluster Hadoop exécuté sur le site de reprise sur incident sur le site distant.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">La solution proposée doit être économique.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">La solution proposée doit réduire l'impact sur les performances des tâches d'analytique en production actuellement en cours d'exécution pendant les durées de sauvegarde.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">Solution de sauvegarde existante du client</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">La figure ci-dessous présente la solution de sauvegarde native Hadoop de départ.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">Les données de production sont protégées sur bande via le cluster de sauvegarde intermédiaire :</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">Les données HDFS1 sont copiées vers HDFS2 en exécutant le<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">Le cluster de sauvegarde fait office de passerelle NFS et les données sont copiées manuellement sur bande via Linux<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> commande via la bibliothèque de bandes.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Voici quelques avantages offerts par la solution de sauvegarde Hadoop native :</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">La solution repose sur les commandes natives Hadoop qui évite à l'utilisateur d'apprendre à maîtriser de nouvelles procédures.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">La solution exploite l'architecture et le matériel standard.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">Les inconvénients de la solution de sauvegarde native Hadoop initiale sont les suivants :</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">La longue fenêtre de sauvegarde dépasse 24 heures, ce qui rend les données de production vulnérables.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">Une dégradation significative des performances du cluster durant les heures de sauvegarde</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">La copie sur bande est un processus manuel.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">La solution de sauvegarde est coûteuse en termes de matériel et d'heures de travail nécessaires aux processus manuels.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">Solutions de sauvegarde</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">En fonction de ces défis et exigences, et en tenant compte du système de sauvegarde existant, trois solutions de sauvegarde possibles ont été suggérées. Les sous-sections suivantes décrivent chacune de ces trois solutions de sauvegarde, intitulées solution A à la solution C.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">Solution A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">Solution A ajoute le module d'analytique sur place au cluster Hadoop de sauvegarde, qui permet de réaliser des sauvegardes secondaires sur les systèmes de stockage NFS NetApp, éliminant ainsi les besoins en bande, comme illustré dans la figure ci-dessous.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">Les tâches détaillées de la solution A incluent :</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">Le cluster Hadoop de production dispose des données d'analytique de l'entreprise dans le système HDFS qui requiert une protection.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">Le cluster Hadoop de sauvegarde avec HDFS sert d'emplacement intermédiaire pour les données. Une simple concaténation de disques durs (JBOD) permet de stocker le système HDFS à la fois dans les clusters Hadoop de production et de sauvegarde.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Protéger les données de production Hadoop est protégé du cluster HDFS de production vers le cluster de sauvegarde HDFS en exécutant le<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> commande.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Le snapshot Hadoop protège les données de la production vers le cluster Hadoop de sauvegarde.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">Le contrôleur de stockage NetApp ONTAP fournit un volume exporté NFS, provisionné vers le cluster Hadoop de sauvegarde.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">En exécutant le<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> Grâce à MapReduce et à plusieurs mappeurs, les données d'analytique sont protégées du cluster Hadoop de sauvegarde vers NFS à l'aide du module d'analytique sur place.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">Une fois les données stockées dans NFS sur le système de stockage NetApp, les technologies NetApp Snapshot, SnapRestore et FlexClone sont utilisées pour sauvegarder, restaurer et dupliquer les données Hadoop selon les besoins.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">Les données Hadoop peuvent être protégées sur le cloud et les emplacements de reprise après incident grâce à la technologie SnapMirror.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">La solution A présente plusieurs avantages :</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Les données de production Hadoop sont protégées du cluster de sauvegarde.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">Les données HDFS sont protégées par le biais de NFS qui assure la protection des données dans les sites cloud et de reprise après incident.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">Améliore les performances en redirigeant les opérations de sauvegarde vers le cluster de sauvegarde.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">Élimine les opérations manuelles de bande</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">Fonctions de gestion d'entreprise via les outils NetApp</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">Elle ne nécessite que des changements minimes de l'environnement existant.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">Est une solution économique.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">L'inconvénient de cette solution est qu'elle nécessite un cluster de sauvegarde et des mappeurs supplémentaires pour améliorer les performances.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">Le client a récemment déployé la solution A en raison de sa simplicité, de son coût et de ses performances globales.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">Avec cette solution, les disques SAN de ONTAP peuvent être utilisés à la place d'un JBOD. Cette option décharge la charge du stockage du cluster de sauvegarde vers ONTAP, mais l'inconvénient est que des commutateurs de structure SAN sont nécessaires.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">Solution B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">La solution B ajoute le module d'analytique sur place au cluster Hadoop de production, ce qui évite d'avoir recours au cluster de sauvegarde Hadoop, comme l'illustre la figure ci-dessous.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">Les tâches détaillées de la solution B incluent :</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">Le contrôleur de stockage NetApp ONTAP provisionne l'exportation NFS vers le cluster Hadoop de production.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Hadoop natif<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> Cette commande protège les données Hadoop du cluster de production HDFS vers NFS via le module d'analytique sur place.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">Une fois les données stockées dans NFS sur le système de stockage NetApp, les technologies Snapshot, SnapRestore et FlexClone sont utilisées pour sauvegarder, restaurer et dupliquer les données Hadoop selon les besoins.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">La solution B présente plusieurs avantages :</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">Le cluster de production est légèrement modifié pour la solution de sauvegarde, ce qui simplifie l'implémentation et réduit les coûts d'infrastructure supplémentaires.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">Aucun cluster de sauvegarde n'est requis pour l'opération de sauvegarde.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">Dans la conversion des données NFS, les données de production HDFS sont protégées.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">La solution permet de gérer l'entreprise à l'aide des outils NetApp.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">L'inconvénient de cette solution est qu'elle est implémentée dans le cluster de production, ce qui peut ajouter des tâches d'administrateur supplémentaires dans le cluster de production.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">Solution C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">Dans la solution C, les volumes SAN NetApp sont directement provisionnés vers le cluster de production Hadoop pour le stockage HDFS, comme illustré dans la figure ci-dessous.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">Les étapes détaillées de la solution C incluent :</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">Le stockage SAN NetApp ONTAP est provisionné au niveau du cluster Hadoop de production pour le stockage des données HDFS.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">Les technologies NetApp Snapshot et SnapMirror sont utilisées pour sauvegarder les données HDFS à partir du cluster Hadoop de production.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">La sauvegarde n'a aucun impact sur les performances de production du cluster Hadoop/Spark au cours du processus de sauvegarde de copie Snapshot, car elle se trouve au niveau de la couche de stockage.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">La technologie Snapshot effectue des sauvegardes en quelques secondes, quelle que soit la taille des données.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">La solution C présente plusieurs avantages :</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">La technologie Snapshot permet de créer des sauvegardes compactes.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">Ensuite, cas d'utilisation 2 : sauvegarde et reprise d'activité depuis le cloud vers des environnements sur site.</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">Ce rapport technique présente les avantages offerts par NetApp à une solution Splunk SmartStore tout en démontrant une structure pour la conception et le dimensionnement des solutions Splunk SmartStore dans votre environnement. Il en résulte une solution simple, évolutive et résiliente, qui offre un coût total de possession exceptionnel.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">Tr-4869 : NetApp StorageGRID avec Splunk SmartStore</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">Karthikeyan Nagalingam, Bobby Oommen, Joseph Kandatillaparambil</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise est la solution de gestion des informations et des événements de sécurité leader du marché, qui améliore les résultats des équipes IT, de sécurité et DevOps. Les volumes de données continuent de croître à un rythme exponentiel, ce qui représente de belles opportunités pour les entreprises pouvant exploiter cette vaste ressource. Splunk Enterprise continue d'être adopté dans de nombreux cas d'usage. À mesure que les besoins évoluent, les volumes de données ingérées et processus sont croissants par Splunk Enterprise. L'architecture classique de Splunk Enterprise est une conception scale-out distribuée qui assure un accès et une disponibilité exceptionnels aux données. Toutefois, les entreprises qui utilisent cette architecture doivent faire face aux coûts croissants liés à l'évolutivité pour répondre au volume croissant de données.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore avec NetApp StorageGRID permet de relever ce défi en proposant un nouveau modèle de déploiement dans lequel les ressources de calcul et de stockage sont découplées. Cette solution libère également une évolutivité et une élasticité inégalées pour les environnements Splunk Enterprise, qui permettent aux entreprises de monter en charge sur un ou plusieurs sites, et réduit les coûts en permettant aux ressources de calcul et de stockage d'évoluer de manière indépendante et en ajoutant le Tiering intelligent au stockage objet S3 basé sur le cloud, à moindre coût.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">Cette solution optimise la quantité de données dans le stockage local tout en maintenant les performances de recherche, permettant ainsi l'évolutivité à la demande du calcul et du stockage. SmartStore évalue automatiquement les modèles d'accès aux données pour déterminer les données devant être accessibles pour l'analytique en temps réel et les données qui doivent résider dans le stockage objet S3 à moindre coût.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">Ce rapport technique présente les avantages offerts par NetApp à une solution Splunk SmartStore tout en démontrant une structure pour la conception et le dimensionnement des solutions Splunk SmartStore dans votre environnement. Il en résulte une solution simple, évolutive et résiliente, qui offre un coût total de possession exceptionnel. StorageGRID propose un stockage objet basé sur des API/protocole S3, évolutif et économique, également appelé stockage distant, qui permet aux entreprises de faire évoluer leur solution Splunk à moindre coût tout en augmentant la résilience.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore fait référence au stockage objet en tant que magasins distants ou tiers de stockage distant.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">À propos de NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID est une solution logicielle de stockage objet pour les archives volumineuses, les référentiels multimédias et les datastores Web. Avec StorageGRID, NetApp s'appuie sur deux décennies d'expérience en matière de solutions de gestion de données et d'innovation de pointe. Les entreprises peuvent ainsi gérer et optimiser la valeur de leurs données à la fois sur site et dans des déploiements de cloud public, privé ou hybride.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID offre un stockage sécurisé et durable pour les données non structurées à grande échelle. Des règles intégrées de gestion du cycle de vie basées sur des métadonnées optimisent l'emplacement des données tout au long de leur vie. Les contenus sont placés au bon endroit, au bon moment et sur le Tier de stockage adéquat pour réduire les coûts. Avec un seul namespace, les données sont accessibles via un seul appel, quel que soit l'emplacement géographique du stockage StorageGRID. Les entreprises peuvent déployer et gérer plusieurs instances StorageGRID entre les data centers et dans l'infrastructure cloud.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">Un système StorageGRID se compose de nœuds hétérogènes, redondants et répartis à travers le monde, pouvant être intégrés aux applications client existantes et nouvelle génération.</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape a récemment désigné NetApp leader dans son dernier rapport : IDC MarketScape : évaluation mondiale des fournisseurs de stockage objet 2019. Avec près de 20 ans de déploiements en production dans les secteurs les plus exigeants, StorageGRID est un leader reconnu dans le domaine des données non structurées.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">Grâce à StorageGRID, vous pouvez obtenir les avantages suivants :</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">Déploiement de plusieurs instances StorageGRID pour accéder aux données depuis n'importe quel emplacement entre les data centers et le cloud via un seul namespace dont l'évolutivité se mesure facilement jusqu'à des centaines de pétaoctets.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">Gagnez en flexibilité en matière de déploiement et de gestion centralisée de vos différentes infrastructures.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">Bénéficiez d'une durabilité inégalée, avec une durabilité de 99,9999999999999 % grâce au code d'effacement à plusieurs couches.</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Exploitez davantage de fonctionnalités de multicloud hybride avec des intégrations validées dans Amazon S3 Glacier et Azure Blob.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">Respecter les obligations réglementaires et faciliter la conformité grâce à une conservation sécurisée des données sans API propriétaires ni dépendance vis-à-vis d'un fournisseur.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">Page d'accueil de NetApp StorageGRID</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">Pour plus d'informations sur la façon dont StorageGRID vous aide à résoudre vos problèmes les plus complexes en matière de gestion des données non structurées, consultez le<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>.</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">À propos de Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise est une plateforme qui permet de transformer ces données en actions. Les données générées par diverses sources (fichiers journaux, sites web, périphériques, capteurs et applications) sont envoyées et analysées par les indexeurs Splunk, ce qui vous permet de générer des informations exploitables à partir des données. Il peut identifier les failles de données, mettre en évidence les tendances produits et clients, identifier les opportunités d'optimisation de l'infrastructure ou créer des informations exploitables pour de nombreux cas d'usage.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">À propos de Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore étend les avantages de l'architecture Splunk et simplifie son évolutivité économique. En effet, le découplage des ressources de calcul et de stockage permet des nœuds d'indexeur optimisés pour les E/S et des besoins de stockage considérablement réduits, car ils ne stockent qu'un sous-ensemble de données en cache. Inutile d'ajouter du stockage ou des ressources de calcul supplémentaire lorsque seule une de ces ressources est nécessaire, ce qui vous permet de réaliser d'importantes économies. Vous pouvez utiliser un stockage objet S3 économique et évolutif, ce qui simplifie encore davantage l'environnement, réduit les coûts et vous permet de conserver un jeu de données plus volumineux.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore apporte des avantages significatifs aux entreprises, notamment :</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">Réduire les coûts du stockage en transférant les données utiles vers un stockage objet S3 économique</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">Évolutivité transparente en dissociant le stockage et le calcul</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">Simplification de la continuité de l'activité grâce à un stockage cloud résilient</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">Ensuite, les avantages de cette solution.</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">Cette page décrit la technologie utilisée dans cette solution.</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">Précédent : solution.</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="paragraph">Cette section décrit la technologie utilisée dans cette solution.</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">Contrôleur de stockage NetApp ONTAP</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP est un système d'exploitation du stockage haute performance.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 intègre la prise en charge des API Amazon simple Storage Service (S3). ONTAP prend en charge un sous-ensemble d'actions d'API Amazon Web Services (AWS) S3 et permet de représenter les données en tant qu'objets dans des systèmes ONTAP entre fournisseurs cloud (AWS, Azure et GCP) et environnements sur site.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">Le logiciel NetApp StorageGRID est la solution NetApp phare pour le stockage objet. ONTAP complète StorageGRID en fournissant un point d'entrée et de prétraitement sur la périphérie, puis en étendant l'environnement Data Fabric optimisé par NetApp pour les données d'objet et en améliorant la valeur du portefeuille de produits NetApp.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">L'accès à un compartiment S3 est fourni par le biais des applications utilisateur et client autorisées. Le schéma suivant montre l'application accédant à un compartiment S3.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">Cette illustration montre l'application accédant à un compartiment S3.</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">Principales utilisations</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">L'objectif principal de la prise en charge des API S3 est de fournir un accès aux objets sur ONTAP. L'architecture de stockage unifié ONTAP prend désormais en charge les fichiers (NFS et SMB), les blocs (FC et iSCSI) et les objets (S3).</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">Applications S3 natives</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">De plus en plus d'applications peuvent utiliser la prise en charge de ONTAP pour l'accès aux objets via S3. Bien qu'elles soient adaptées aux charges de travail d'archivage haute capacité, les besoins de hautes performances des applications S3 natives ne cessent de croître et comprennent :</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analytique</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">Intelligence artificielle</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">Ingestion périphérie/cœur</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="list-text">Apprentissage machine</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">Les clients peuvent désormais utiliser les outils de gestion familiers tels qu'ONTAP System Manager pour le provisionnement rapide du stockage objet haute performance pour le développement et les opérations dans ONTAP, en tirant parti des fonctionnalités d'efficacité et de sécurité du stockage ONTAP, comme ils le font.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">Terminaux FabricPool</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">À partir de ONTAP 9.8, FabricPool prend en charge le Tiering dans les compartiments ONTAP, permettant le Tiering d'ONTAP vers ONTAP. Il s'agit d'une excellente option pour les clients qui souhaitent reconvertir leur infrastructure FAS existante en tant que terminal de magasin d'objets.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool prend en charge le Tiering vers ONTAP de deux manières :</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*Hiérarchisation locale du cluster.* les données inactives sont envoyées vers un compartiment situé sur le cluster local à l'aide de LIF de cluster.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*Hiérarchisation du cluster à distance.* les données inactives sont envoyées vers un compartiment situé sur un cluster distant d'une manière similaire à un niveau de cloud FabricPool classique à l'aide de LIF IC sur le client FabricPool et de LIF de données dans le magasin d'objets ONTAP.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3 est adapté si vous souhaitez utiliser des fonctionnalités S3 dans les clusters déjà en place, sans nécessiter de matériel ni de gestion supplémentaire. Pour des déploiements de plus de 300 To, le logiciel NetApp StorageGRID reste la solution phare de NetApp pour le stockage objet. Une licence FabricPool n'est pas requise si vous utilisez ONTAP ou StorageGRID comme Tier cloud.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP pour le stockage hiérarchisé confluent</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">Chaque data Center doit assurer le fonctionnement continu des applications stratégiques, ainsi que la disponibilité et la sécurité des données importantes. Le nouveau système NetApp AFF A900 est optimisé par le logiciel ONTAP Enterprise Edition et une résilience élevée. Notre nouveau système de stockage NVMe ultrarapide élimine les interruptions des opérations stratégiques, réduit les réglages de performance et protège vos données contre les attaques par ransomware.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Du déploiement initial à l'évolutivité de votre cluster hétérogène, votre environnement exige une adaptation rapide aux changements qui ne fonctionnent pas aux applications stratégiques. Grâce aux fonctions de gestion des données d'entreprise, de qualité de service et de performances de ONTAP, vous pouvez planifier et adapter votre environnement à vos besoins.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">L'utilisation conjointe du système NetApp ONTAP et du stockage hiérarchisé centralisé simplifie la gestion des clusters Apache Kafka en utilisant le système ONTAP comme cible de stockage scale-out. Ce système permet ainsi une évolutivité indépendante des ressources de calcul et de stockage pour mieux comprendre les besoins.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">Un serveur ONTAP S3 repose sur les capacités de stockage scale-out matures d'ONTAP. Faites évoluer votre cluster ONTAP de manière transparente en étendant vos compartiments S3 pour utiliser les nœuds récemment ajoutés au cluster ONTAP.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">Gestion simple avec ONTAP System Manager</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager est une interface graphique basée sur un navigateur qui vous permet de configurer, gérer et contrôler votre contrôleur de stockage ONTAP sur l'ensemble des sites dispersés à travers le monde dans une seule fenêtre.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">Ce graphique présente l'espace de travail ONTAP System Manager.</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">Vous pouvez configurer et gérer ONTAP S3 avec System Manager et l'interface de ligne de commandes d'ONTAP. Si vous activez S3 et créez des compartiments à l'aide de System Manager, ONTAP fournit des valeurs par défaut de bonnes pratiques pour une configuration simplifiée. Si vous configurez le serveur S3 et les compartiments à partir de l'interface de ligne de commande, vous pouvez toujours les gérer avec System Manager si vous le souhaitez ou vice-versa.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">Lorsque vous créez un compartiment S3 avec System Manager, ONTAP configure un niveau de service de performance par défaut qui est le plus élevé disponible sur votre système. Par exemple, sur un système AFF, le paramètre par défaut est Extreme. Les niveaux de service de performance sont des groupes de règles de QoS adaptatifs prédéfinis. Au lieu d'un des niveaux de service par défaut, vous pouvez définir une « policy group » QoS personnalisée ou aucun « policy group ».</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">Voici quelques groupes de règles de QoS adaptatifs prédéfinis :</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*Extreme.* utilisé pour les applications nécessitant la plus faible latence et les meilleures performances.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*Performance.* utilisée pour les applications avec des besoins de performances et une latence modestes.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*Valeur.* utilisé pour les applications pour lesquelles le débit et la capacité sont plus importants que la latence.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*Personnalisé.* spécifiez une stratégie de qualité de service personnalisée ou aucune règle de qualité de service.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">Si vous sélectionnez *utiliser pour le Tiering*, aucun niveau de service de performances n'est sélectionné et le système essaie de sélectionner un support à faible coût avec des performances optimales pour les données hiérarchisées.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP tente de provisionner ce compartiment sur les niveaux locaux qui comptent les disques les plus appropriés, en satisfaisant le niveau de service choisi. Toutefois, si vous devez spécifier les disques à inclure dans le compartiment, configurez le stockage objet S3 à partir de l'interface de ligne de commandes en spécifiant les niveaux locaux (agrégat). Si vous configurez le serveur S3 à partir de l'interface de ligne de commandes, vous pouvez toujours le gérer avec System Manager.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">Si vous souhaitez spécifier les agrégats utilisés pour les compartiments, vous pouvez uniquement le faire via l'interface de ligne de commande.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform est une plate-forme de diffusion de données à grande échelle qui vous permet d'accéder, de stocker et de gérer facilement les données sous forme de flux continus en temps réel. Conçu par les créateurs d'Apache Kafka à l'origine, ce logiciel étend les avantages de Kafka avec des fonctionnalités haute performance tout en éliminant les tâches de gestion et de surveillance Kafka. Aujourd'hui, plus de 80 % des entreprises classées au Fortune 100 sont alimentées par la technologie de streaming de données, et la plupart d'entre elles utilisent la technique de confluent.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Pourquoi confluent ?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">En intégrant des données historiques et en temps réel dans une seule source centrale de vérité, Confluent facilite la création d'une toute nouvelle catégorie d'applications modernes orientées événements, en bénéficiant d'un pipeline de données universel et en permettant d'exploiter de nouveaux cas d'utilisation avec évolutivité, performances et fiabilité.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">À quoi sert le confluent ?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform vous permet de vous concentrer sur la manière de tirer de la valeur commerciale de vos données plutôt que de vous soucier des mécanismes sous-jacents, tels que le mode de transport ou d'intégration des données entre des systèmes disparates. La plateforme Confluent simplifie la connexion des sources de données à Kafka, créant des applications de streaming, ainsi que la sécurisation, le contrôle et la gestion de votre infrastructure Kafka. Aujourd'hui, la plateforme Fluent est utilisée pour de nombreux cas d'utilisation dans de nombreux secteurs, qu'il s'agisse de services financiers, de vente en canaux et de voitures autonomes, de détection des fraudes, de microservices et de l'IoT.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">La figure suivante montre les composants de la plate-forme de confluent.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">Ce graphique montre les composants de la plate-forme confluent.</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Présentation de la technologie de streaming d'événement confluent</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">Kafka</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Au cœur de la plate-forme de confluent est<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>, la plate-forme de diffusion en continu open source la plus populaire. Voici les fonctionnalités clés de Kafka :</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">Publiez et abonnez-vous à des flux d'enregistrements.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">Stockez les flux d'enregistrements de manière tolérante aux pannes.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">Traiter les flux d'enregistrements.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">La plate-forme confluent prête à l'emploi comprend également le registre de schéma, le proxy REST, un total de plus de 100 connecteurs prédéfinis Kafka et ksqlDB.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Présentation des fonctionnalités d'entreprise de la plate-forme confluent</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent Control Center.* Un système basé sur l'interface utilisateur pour la gestion et le contrôle de Kafka. Il vous permet de gérer facilement Kafka Connect et de créer, modifier et gérer les connexions avec d'autres systèmes.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Confluent pour Kubernetes.* Confluent pour Kubernetes est un opérateur Kubernetes. Les opérateurs Kubernetes étendent les fonctionnalités d'orchestration de Kubernetes en fournissant des fonctionnalités et des exigences uniques pour une application de plateforme spécifique. Pour la plateforme Confluent, cela inclut de simplifier considérablement le processus de déploiement de Kafka sur Kubernetes et d'automatiser les tâches du cycle de vie de l'infrastructure classiques.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Connecteurs Kafka Connect.* les connecteurs utilisent l'API Kafka Connect pour connecter Kafka à d'autres systèmes tels que les bases de données, les magasins de valeur clé, les index de recherche et les systèmes de fichiers. Confluent Hub dispose de connecteurs téléchargeables pour les sources de données et les éviers les plus populaires, y compris les versions entièrement testées et prises en charge de ces connecteurs avec plate-forme confluent. Plus de détails sont disponibles<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*Clusters à auto-équilibrage.* offre un équilibrage de charge automatisé, une détection des pannes et une auto-rétablissement. Il permet également d'ajouter ou de désaffecter des courtiers en fonction des besoins, sans réglage manuel.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* Liaison cluster de confluent.* connecte directement les clusters et met en miroir les sujets d'un cluster à un autre via un pont de liaison. La liaison entre clusters simplifie la configuration des déploiements de clouds hybrides, multiclouds et multiclouds.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*BALANCER de données de confluent.* surveille le nombre de courtiers, la taille des partitions, le nombre de partitions et le nombre de lignes d'attache au sein du cluster. Il vous permet de déplacer des données pour créer une charge de travail homogène dans le cluster, tout en limitant le trafic pour limiter l'impact sur les workloads de production tout en procédant à un rééquilibrage.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*Le réplicateur confluent.* facilite plus que jamais la maintenance de plusieurs clusters Kafka dans de multiples centres de données.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*Stockage à plusieurs niveaux.* fournit des options pour stocker des volumes importants de données Kafka à l'aide de votre fournisseur de cloud favori, ce qui réduit la charge opérationnelle et le coût. Le stockage hiérarchisé permet de conserver les données sur un stockage objet économique et de les faire évoluer uniquement lorsque vous avez besoin de ressources de calcul supplémentaires.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Client JMS confluent.* plate-forme confluent comprend un client compatible JMS pour Kafka. Ce client Kafka met en œuvre l'API standard JMS 1.1, en utilisant les courtiers Kafka comme back-end. Ceci est utile si vous avez des applications héritées utilisant JMS et que vous souhaitez remplacer le courtier de messages JMS existant par Kafka.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Proxy MQTT confluent.* fournit un moyen de publier des données directement sur Kafka à partir de périphériques et passerelles MQTT sans avoir besoin d'un courtier MQTT au milieu.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* Plugins de sécurité confluent.* des plugins de sécurité confluent sont utilisés pour ajouter des capacités de sécurité à divers outils et produits de plate-forme confluent. Actuellement, un plug-in est disponible pour le proxy REST confluent qui permet d'authentifier les demandes entrantes et de propager le principal authentifié aux demandes vers Kafka. Les clients proxy REST prolixes utilisent ainsi les fonctionnalités de sécurité multilocataires du courtier Kafka.</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">Suivant : validation des performances de confluent.</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">Cette page décrit en détail les principaux cas d'utilisation et architectures d'IA, DE ML et de DL.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">Principales utilisations et architectures de l'IA, DU ML et du DL</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">Précédent : récapitulatif des cas d'utilisation.</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">Les principaux champs d'application de l'IA, DU ML et du DL peuvent être divisés en plusieurs sections :</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Les pipelines Spark NLP et l'inférence TensorFlow distribuée</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">La liste suivante contient les bibliothèques Open Source les plus populaires de NLP qui ont été adoptées par la communauté des sciences de la donnée sous différents niveaux de développement :</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">Boîte à outils en langage naturel (NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>. La boîte à outils complète pour toutes les techniques NLP. Elle est maintenue depuis le début des années 2000.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">TextBlob</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>. Une API Python facile à utiliser avec les outils NLP reposant sur NLTK et Pattern.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">Stanford Core NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>. Services et paquets NLP en Java développés par le Stanford NLP Group.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>. La modélisation des sujets pour l'homme a commencé comme un ensemble de scripts Python pour le projet de la Bibliothèque de mathématiques numériques tchèque.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">L'espionnage</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>. Flux de production NLP industriels de bout en bout avec Python et cython avec accélération GPU pour transformateurs.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">Texte rapide</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>. Une bibliothèque libre, légère et open-source de NLP pour l’apprentissage des mariages de mots et la classification des peines créée par le laboratoire de recherche sur l’IA (FAIR) de Facebook.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">Spark NLP est une solution unique et unifiée pour toutes les tâches et exigences de la NLP qui permet un logiciel évolutif, haute performance et haute précision de la NLP pour les cas d'utilisation réels en production. Elle tire parti de l'apprentissage par transfert et met en œuvre les derniers algorithmes et modèles de pointe dans la recherche et dans d'autres secteurs. En raison du manque de soutien total de Spark pour les bibliothèques ci-dessus, Spark NLP a été construit sur le dessus de<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Tirer parti du moteur de traitement de données distribué en mémoire général de Spark en tant que bibliothèque NLP de qualité professionnelle pour les flux de production critiques. Les annoter utilisent des algorithmes basés sur des règles, l'apprentissage machine et TensorFlow pour alimenter l'implémentation de l'apprentissage profond. Cela couvre les tâches NLP courantes, y compris, mais sans s'y limiter, la tokenisation, la lemmatisation, le juguler, le marquage de la partie de la parole, la reconnaissance de l'entité nommée, vérification orthographique et analyse de sentiment.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Les représentations d'encodeur bidirectionnelles des transformateurs (BERT) sont une technique d'apprentissage machine basée sur transformateur pour NLP. Elle a popularisé le concept de préformation et de réglage fin. L'architecture de transformateur de BERT provient de la traduction automatique, qui modélise les dépendances à long terme mieux que les modèles de langage RNN (réseau neuronal récurrent). Il a également introduit la tâche MLM (Modelage du langage masqué), où 15 % aléatoire de tous les jetons sont masqués et le modèle les prédit, ce qui permet une réelle bidirectionnalité.</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">Reuters TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">Banque de PhraseBank</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">Analyse des sentiments pour les nouvelles financières</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">Expliquer le DL du document</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">L'analyse des sentiments financiers est difficile en raison du langage spécialisé et du manque de données étiquetées dans ce domaine.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, Un modèle de langue basé sur une BERT pré-pré-pré-pré-pré, a été adapté au domaine<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>, un corpus financier, et affinée avec des données étiquetées (<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>) pour la classification des sentiments financiers. Les chercheurs ont extrait 4, 500 phrases d'articles de presse avec des termes financiers. Puis 16 experts et maîtres étudiants ayant des antécédents financiers ont qualifié les phrases de positif, neutre et négatif. Nous avons conçu un flux de travail Spark de bout en bout pour analyser le sentiment des transcriptions d'appel des primes d'entreprise du Top 10 NASDAQ de 2016 à 2020 à l'aide de FinBERT et de deux autres pipelines pré-entraînés (<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>) De Spark NLP.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Le moteur de deep learning sous-jacent pour Spark NLP est TensorFlow, une plateforme open source de bout en bout pour le machine learning. Elle permet de créer des modèles facilement, de produire du ML partout et de puissants expérimentations à des fins de recherche. Par conséquent, lors de l'exécution de nos pipelines dans Spark<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> Le mode consiste à exécuter TensorFlow distribué avec des données et une mise en parallèle des modèles sur un nœud maître, plusieurs nœuds workers et un stockage NAS monté sur le cluster.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod a distribué une formation</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">Tr-3969 : Solutions NetApp pour Hadoop</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">La validation principale de Hadoop pour les performances MapReduce est réalisée avec TeraGen, Terasort, TeraValidate et DFSIO (lecture et écriture). Les résultats de la validation TeraGen et Terasort sont présentés dans le<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> Pour les E-Series et dans la section « hiérarchisation du stockage » pour la AFF.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Hovorod sur Spark</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">Selon les demandes des clients, nous considérons que la formation distribuée avec Spark constitue l'un des cas d'utilisation les plus importants. Dans ce document, nous avons utilisé le<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> Pour valider les performances de Spark avec les solutions NetApp de cloud hybride, cloud et sur site à l'aide des contrôleurs de stockage FAS 100 % Flash (AFF) de NetApp, Azure NetApp Files et StorageGRID.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Le package Horovod sur Spark constitue une solution idéale pour Horovod, qui simplifie l'exécution de charges de travail d'entraînement distribuées dans les clusters Spark. Ceci permet une boucle de conception étroite dans laquelle le traitement des données, l'entraînement des modèles et l'évaluation des modèles sont réalisés dans Spark où résident les données d'entraînement et d'inférence.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Vente de magasins de Gaggle Rossmann</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Il existe deux API pour exécuter Horovod sur Spark : une API d'estimateur de haut niveau et une API d'exécution de bas niveau. Bien que les deux utilisent le même mécanisme sous-jacent pour lancer Horovod sur des exécuteurs Spark, l'API Estimator résume le traitement des données, la boucle d'entraînement des modèles, la vérification des modèles, la collecte des métriques et la formation distribuée. Nous avons utilisé les estimateurs Horovod Spark, TensorFlow et Keras pour une préparation des données de bout en bout et un workflow de formation distribué basé sur le<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> la concurrence.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">Scripts Python pour chaque utilisation majeure.</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">Le script<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> se trouve dans la section <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> Il contient trois parties :</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">La première partie effectue diverses étapes de prétraitement des données sur un ensemble initial de fichiers CSV fournis par Kaggle et rassemblés par la communauté. Les données d'entrée sont séparées dans un kit d'entraînement par un<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> un sous-ensemble de données et un jeu de données test.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">La seconde partie définit un modèle DNN (réseau neuronal de deep Keras) avec une fonction d'activation sigmoïde logarithmique et un optimiseur Adam. Elle effectue également une entraînement distribué du modèle à l'aide de Horovod sur Spark.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">La troisième partie effectue des prévisions sur le dataset de test en utilisant le meilleur modèle qui minimise le jeu de validation moyenne d'erreur absolue globale. Il crée ensuite un fichier CSV de sortie.</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">« Apprentissage machine »</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">Voir la section <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> pour divers résultats de comparaison d'exécution.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">L'apprentissage profond multi-utilisateur utilisant Keras pour la prédiction CTR</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">Avec les récentes avancées des plates-formes ET des applications DE ML, une grande attention se porte maintenant sur l'apprentissage à grande échelle. Le taux de clics (CTR) est défini comme le nombre moyen de clics par cent impressions de publicités en ligne (exprimé en pourcentage). Elle est largement adoptée comme indicateur clé dans différents secteurs d'activité et champs d'application, notamment le marketing digital, la vente au détail, l'e-commerce et les fournisseurs de services. Découvrez nos<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> Pour en savoir plus sur les applications CTR et une implémentation complète du workflow d'IA cloud avec Kubernetes, l'ETL de données distribuées et l'entraînement des modèles via DASK et CUDA ML.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte cliquez sur le jeu de données des journaux</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">Dans ce rapport technique, nous avons utilisé une variante du<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (Voir TR-4904) pour l'apprentissage profond distribué multi-travailleurs utilisant Keras pour créer un workflow Spark avec des modèles DCN (Deep et Cross Network), en comparant ses performances en termes de fonction d'erreur de perte de journaux avec un modèle de régression logistique Spark ML de base. Le DCN capture efficacement les interactions de fonctions efficaces avec des degrés délimités, apprend des interactions hautement non linéaires, ne nécessite pas d'ingénierie des fonctions manuelles ni de recherche exhaustive et présente un faible coût de calcul.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Les données des systèmes de recommandation Web sont généralement distinctes et catégoriques, ce qui conduit à un espace important et clairsemé de problèmes pour l'exploration des fonctionnalités. Cela a limité la plupart des systèmes à grande échelle à des modèles linéaires tels que la régression logistique. Cependant, il est essentiel d'identifier les fonctionnalités prédictives fréquentes et d'explorer en même temps des caractéristiques croisées rares ou peu visibles pour faire de bonnes prévisions. Les modèles linéaires sont simples, interprétables et faciles à mettre à l'échelle, mais ils sont limités dans leur puissance expressive.</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">Les caractéristiques transversales, en revanche, ont été montrées significatives dans l'amélioration de l'expressivité des modèles. Malheureusement, il nécessite souvent une ingénierie des fonctionnalités manuelles ou une recherche exhaustive pour identifier ces fonctionnalités. Il est souvent difficile de généraliser les interactions de composants non visibles. L'utilisation d'un réseau neuronal transversal comme DCN évite l'ingénierie des fonctions spécifiques aux tâches en appliquant explicitement le croisement des fonctions de manière automatique. Le réseau transversal se compose de plusieurs couches, où le degré d'interactions le plus élevé est déterminé par la profondeur de la couche. Chaque couche produit des interactions d'ordre plus élevé en fonction de celles existantes et conserve les interactions des couches précédentes.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">Un réseau neuronal de deep learning (DNN) promet de capturer des interactions très complexes entre plusieurs fonctionnalités. Toutefois, par rapport au DCN, il nécessite presque un ordre de grandeur plus de paramètres, est incapable de former explicitement des fonctions transversales et peut ne pas apprendre efficacement certains types d'interactions de fonctions. Le réseau transversal est efficace en termes de mémoire et facile à mettre en œuvre. L'entraînement conjoint des composants Cross et DNN capture efficacement les interactions prédictives des fonctions et fournit des performances de pointe sur le jeu de données Criteo CTR.</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">ml</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">mllib</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">Un modèle DCN commence par une couche d'intégration et de superposition, suivie d'un réseau transversal et d'un réseau profond en parallèle. Elles sont ensuite suivies d'une couche de combinaison finale qui combine les sorties des deux réseaux. Vos données d'entrée peuvent être un vecteur avec des fonctions éparses et denses. Dans Spark, les deux<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> et<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> les bibliothèques contiennent le type<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>. Il est donc important que les utilisateurs établissent une distinction entre les deux et soient conscients lorsqu'ils appellent leurs fonctions et méthodes respectives. Dans les systèmes de recommandation Web tels que la prédiction CTR, les entrées sont surtout des fonctions catégoriques, par exemple<block ref="bf8b858b1d67b8d7c2676d6a7353c3c9" prefix=" " category="inline-code"></block>. Ces fonctions sont souvent codées en tant que vecteurs à chaud, par exemple<block ref="624411787ac52373d7cc41183768999c" prefix=" " category="inline-code"></block>. Codage à chaud (OHE) avec<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> est utile lorsqu'il s'agit de jeux de données du monde réel avec des vocabulaires en constante évolution et en pleine croissance. Nous avons modifié des exemples dans<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> Traiter de gros vocabulaires, créant des vecteurs d'intégration dans la couche d'intégration et de superposition de notre DCN.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo Afficher le jeu de données annonces</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">Le<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> prédit le taux de clics des publicités. Il possède 13 caractéristiques entières et 26 caractéristiques catégoriques dans lesquelles chaque catégorie a une cardinalité élevée. Pour ce jeu de données, une amélioration de 0.001 dans logloperdus est pratiquement significative en raison de la grande taille d'entrée. Une légère amélioration de la précision des prévisions pour une grande base d'utilisateurs peut potentiellement conduire à une augmentation importante du chiffre d'affaires d'une entreprise. Le jeu de données contient 11 Go de journaux utilisateur sur une période de 7 jours, ce qui équivaut à environ 41 millions d'enregistrements. Nous avons utilisé Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> diviser par deux les données à des fins d'entraînement (80 %), de cross-validation (10 %) et les 10 % restants à des fins de test.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN a été mis en œuvre sur TensorFlow avec Keras. Il existe quatre composants principaux pour la mise en œuvre du processus de formation des modèles avec DCN :</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*Traitement et incorporation de données.* les fonctions de valeur réelle sont normalisées en appliquant une transformation de journal. Pour les caractéristiques catégoriques, nous intégrons les fonctions dans les vecteurs denses de dimension 6×(cardinalité de catégorie)1/4. Le fait de concaténer tous les émudages donne un vecteur de dimension 1026.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*Optimisation.* nous avons appliqué l'optimisation stochastique de mini-lot avec l'optimiseur Adam. La taille de batchs a été définie sur 512. La normalisation des lots a été appliquée au réseau profond et la norme de l'attache de gradient a été définie à 100.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">* Régularisation.* nous avons utilisé l'arrêt précoce, comme la régularisation L2 ou la chute n'a pas été trouvée efficace.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*Hyperparamètres.* nous présentons des résultats basés sur une recherche de grille sur le nombre de couches masquées, la taille de couche masquée, le taux d'apprentissage initial et le nombre de couches transversales. Le nombre de couches masquées variait de 2 à 5, avec des tailles de couche cachées comprises entre 32 et 1024. Pour le DCN, le nombre de couches transversales était de 1 à 6. Le taux d'apprentissage initial a été ajusté de 0.0001 à 0.001 par incréments de 0.0001. Toutes les expériences ont appliqué un arrêt précoce à l'étape 150,000 de l'entraînement, au-delà duquel le surajustement a commencé.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">XDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">Int. Auto</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">En plus du DCN, nous avons également testé d'autres modèles de deep learning courants pour la prédiction CTR, notamment<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>,<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>, et<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>.</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">Architectures utilisées pour la validation</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">Nous avons utilisé quatre nœuds workers et un nœud maître avec une paire HA AFF-A800. Tous les membres du cluster étaient connectés via des commutateurs réseau 10GbE.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">Pour cette validation de la solution NetApp Spark, nous avons utilisé trois contrôleurs de stockage différents : E5760, E5724 et AFF-A800. Les contrôleurs de stockage E-Series ont été connectés à cinq nœuds de données avec des connexions SAS de 12 Gbit/s. Le contrôleur de stockage AFF à paire haute disponibilité fournit les volumes NFS exportés via des connexions 10 GbE vers les nœuds workers Hadoop. Les membres du cluster Hadoop ont été connectés via des connexions 10GbE dans les solutions E-Series, AFF et StorageGRID Hadoop.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">Architectures utilisées pour la validation.</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">Suivant : résultats des tests.</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">Cette page décrit les différents domaines dans lesquels cette solution peut être utilisée.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">Récapitulatif du cas d'utilisation</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">Précédente : présentation des solutions NetApp Spark</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">Streaming des données</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark peut traiter le streaming de données en streaming, qui est utilisé pour les processus d'extraction, de transformation et de charge (ETL), l'enrichissement des données, la détection des événements et l'analyse complexe des sessions :</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*Streaming ETL.* les données sont continuellement nettoyées et regroupées avant d'être envoyées dans les datastores. Netflix utilise Kafka et Spark pour créer une solution de surveillance des données et des recommandations de films en ligne en temps réel capable de traiter des milliards d'événements chaque jour à partir de différentes sources de données. Toutefois, le traitement par lot par ETL classique est traité différemment. Ces données sont lues d'abord, puis converties au format de la base de données avant d'être écrites dans la base de données.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*Enrichissement des données.* la diffusion Spark enrichit les données en direct avec des données statiques pour permettre une analyse des données en temps réel. Par exemple, les annonceurs en ligne peuvent fournir des publicités ciblées personnalisées, dirigées par des informations sur le comportement des clients.</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">*Détection d'événement déclencheur.* la diffusion Spark vous permet de détecter et de réagir rapidement à un comportement inhabituel qui pourrait indiquer des problèmes potentiellement graves. Par exemple, les institutions financières utilisent des déclencheurs pour détecter et arrêter les transactions de fraude, et les hôpitaux utilisent des déclencheurs pour détecter les changements sanitaires dangereux détectés dans les paramètres vitaux d’un patient.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*Analyse de session complexe.* la diffusion en continu Spark collecte des événements tels que l'activité de l'utilisateur après s'être connecté à un site Web ou à une application, qui sont ensuite regroupées et analysées. Par exemple, Netflix utilise cette fonctionnalité pour fournir des recommandations de films en temps réel.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link">Tr-4912 : recommandations sur les meilleures pratiques pour le stockage hiérarchisé Kafka fluide avec NetApp</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">Pour obtenir une configuration plus streaming, la vérification Kafka confluent et les tests de performance, consultez la section<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>.</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Le framework intégré Spark vous aide à exécuter des requêtes répétées sur des jeux de données à l'aide de la bibliothèque d'apprentissage machine (MLlib). MLlib est utilisé dans des domaines tels que la mise en grappe, la classification et la réduction de la dimensionnalité pour certaines fonctions communes de Big Data telles que l'intelligence prédictive, la segmentation des clients à des fins de marketing et l'analyse de sentiment. MLlib est utilisé dans la sécurité du réseau pour effectuer des inspections en temps réel des paquets de données pour des indications d'activité malveillante. Elle permet aux fournisseurs de sécurité de découvrir les nouvelles menaces et de garder une longueur d'avance sur les pirates informatiques tout en protégeant leurs clients en temps réel.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">L'apprentissage profond</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow est un framework de deep learning répandu dans le secteur. TensorFlow prend en charge l'entraînement distribué sur un cluster de processeur ou de processeur graphique. Cette formation distribuée permet aux utilisateurs de l'exécuter sur une grande quantité de données comportant des couches profondes.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">Jusqu'à récemment, si nous souhaitions utiliser TensorFlow avec Apache Spark, nous devions effectuer tous les opérations ETL pour TensorFlow sur PySpark, puis écrire les données sur un stockage intermédiaire. Ces données seraient ensuite chargées sur le cluster TensorFlow pour le processus d'entraînement réel. Ce flux de travail exigeait que l'utilisateur conserve deux clusters différents, un pour ETL et un pour l'entraînement distribué de TensorFlow. L'exécution et la maintenance de plusieurs clusters étaient généralement fastidieuses et chronophages.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">Les DataFrames et RDD dans les versions antérieures de Spark ne conviennent pas parfaitement à l'apprentissage profond, en raison de son accès aléatoire limité. La prise en charge native des frameworks de deep learning est ajoutée dans Spark 3.0 avec l'hydrogène projet. Cette approche permet de planifier des opérations non MapReduce sur le cluster Spark.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">Analyse interactive</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark est suffisamment rapide pour effectuer des requêtes exploratoires sans échantillonnage avec des langages de développement autres que Spark, y compris SQL, R et Python. Spark utilise des outils de visualisation pour traiter des données complexes et les visualiser de manière interactive. Spark avec diffusion structurée effectue des requêtes interactives sur des données en direct dans le cadre d'analyses Web qui vous permettent d'exécuter des requêtes interactives sur la session en cours d'un visiteur Web.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">Système de recommandation</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">Au fil des ans, les systèmes de recommandation ont apporté des changements considérables à notre vie, car les entreprises et les consommateurs ont réagi à des changements spectaculaires dans les secteurs du shopping en ligne, du divertissement en ligne et de nombreux autres secteurs. Ces systèmes constituent effectivement l'un des succès les plus évidents liés à l'IA en production. Dans de nombreux cas d'usage pratiques, les systèmes de recommandation sont combinés à l'IA ou aux chatbots de conversation avec un système backend NLP, afin d'obtenir des informations pertinentes et de produire des inférences utiles.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">Aujourd'hui, de nombreux détaillants adoptent des modèles commerciaux plus récents, comme l'achat en ligne et la collecte en magasin, la collecte en ligne, le paiement à l'auto-paiement, la numérisation et l'utilisation, etc. Ces modèles occupent une place de premier plan lors de la pandémie de COVID-19 en rendant les achats plus sûrs et plus pratiques pour les consommateurs. L'IA est cruciale pour ces tendances digitales en pleine expansion, qui sont influencées par le comportement des consommateurs et inversement. Pour répondre à la demande croissante de ses clients, accroître l'expérience de leurs clients, améliorer leur efficacité opérationnelle et augmenter leur chiffre d'affaires, NetApp aide ses clients et entreprises à utiliser des algorithmes de machine learning et de deep learning pour concevoir des systèmes de recommandation plus rapides et plus précis.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">Plusieurs techniques populaires sont utilisées pour formuler des recommandations, notamment le filtrage collaboratif, les systèmes basés sur le contenu, le modèle de recommandation de deep learning (DLRM) et des techniques hybrides. Auparavant, les clients utilisaient PySpark pour mettre en œuvre un filtrage collaboratif afin de créer des systèmes de recommandation. Spark MLlib implémente les moindres carrés alternatifs (ALS) pour le filtrage collaboratif, un algorithme très populaire parmi les entreprises avant la montée de DLRM.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">Le traitement du langage naturel</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">L'IA, rendue possible par le traitement du langage naturel (NLP), est la branche de l'IA qui aide les ordinateurs à communiquer avec les humains. Le NLP est très répandu dans tous les secteurs verticaux et nombreux cas d'utilisation, des assistants intelligents et chatbots aux applications de recherche et de texte prédictif Google. Selon un<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> Prévu, d'ici 2022, 70 % des personnes interagiront quotidiennement avec des plateformes d'IA conversationnelles. Pour une conversation de haute qualité entre un humain et une machine, les réactions doivent être rapides, intelligentes et naturelles.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">Les clients ont besoin d'une grande quantité de données pour traiter et former leurs modèles NLP et ASR (reconnaissance vocale automatique). Elles doivent également déplacer les données de la périphérie au cœur, et jusqu'au cloud, et elles doivent pouvoir inférence en quelques millisecondes afin d'établir une communication naturelle avec les humains. NetApp ai et Apache Spark constituent une combinaison idéale pour le calcul, le stockage, le traitement des données, l'entraînement des modèles, le réglage fin, et de déploiement des applications.</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">L'analyse des sentiments est un domaine d'étude au sein de NLP dans lequel des sentiments positifs, négatifs ou neutres sont extraits du texte. L'analyse de opinion comporte de nombreux cas d'utilisation, allant de la détermination de la performance des employés du centre de support lors de conversations avec les appelants à la prestation de réponses de chatbot automatisées appropriées. Il a également été utilisé pour prédire le cours des actions d’une entreprise sur la base des interactions entre les représentants de l’entreprise et le public au cours des appels trimestriels sur les bénéfices. En outre, l’analyse de sentiment peut être utilisée pour déterminer l’opinion d’un client sur les produits, les services ou l’assistance fournis par la marque.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">le sentiment des informations financières</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">Nous avons utilisé<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> bibliothèque à partir de<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> Pour charger des pipelines pré-entraînés et des représentations d'encodeur bidirectionnelles à partir de modèles Transformers (BERT), y compris<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> et<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>, effectuer la tokenisation, la reconnaissance d'entités nommées, l'entraînement de modèle, l'ajustement et l'analyse de sentiment à grande échelle. Spark NLP est la seule bibliothèque Open Source de NLP en production qui offre des transformateurs de pointe comme BERT, ALBERT, ELECTRA, XLNet, DistillBERT, Roberta, DeBERTa, XLM- Roberta, Longex, ELMO, Encodeur de phrase universel, Google T5, MarianMT et GPT2. La bibliothèque fonctionne non seulement en Python et en R, mais aussi dans l'écosystème JVM (Java, Scala et Kotlin) à grande échelle en étendant en natif Apache Spark.</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">Ensuite, voici les principaux cas d'utilisation d'IA, DE ML et de DL.</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">Précédent : détails de l'architecture de la solution</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID est une plateforme de stockage objet haute performance et économique. Avec le stockage à plusieurs niveaux, la plupart des données que fournit Kafka, qui sont stockées sur le stockage local ou le stockage SAN du courtier, sont déchargées sur le magasin d'objets distant. Cette configuration apporte d'importantes améliorations opérationnelles en réduisant le temps et les coûts nécessaires au rééquilibrage, à l'extension ou à la réduction des clusters ou au remplacement d'un courtier en panne. Le stockage objet joue un rôle important dans la gestion des données qui résident sur le Tier de stockage objet. Il est donc important de choisir le bon stockage objet.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID propose une gestion intelligente et globale des données pilotée par des règles sur une architecture de grid distribuée basée sur des nœuds. Elle simplifie la gestion de pétaoctets de données non structurées et de milliards d'objets grâce à son espace de noms d'objet global universel unique et à des fonctionnalités avancées de gestion des données. Un accès aux objets unique s'étend sur tous les sites et simplifie les architectures haute disponibilité tout en assurant un accès continu aux objets, en cas de panne au niveau du site ou de l'infrastructure.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">La colocation permet de prendre en charge plusieurs applications de cloud et de données d'entreprise non structurées dans un même grid, ce qui améliore le ROI et les utilisations de NetApp StorageGRID. Elle offre la possibilité de créer plusieurs niveaux de services avec des règles de cycle de vie des objets basées sur des métadonnées pour optimiser la durabilité, la protection, la performance et la localisation sur plusieurs sites. Les utilisateurs peuvent adapter les règles de gestion des données, surveiller et appliquer des limites de trafic pour s'adapter sans interruption à l'environnement de données, lorsque leurs exigences changent dans des environnements IT en constante évolution.</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">L'interface graphique de StorageGRID Grid Manager vous permet de configurer, de gérer et de surveiller votre système StorageGRID sur l'ensemble des sites dispersés à travers le monde, dans une seule fenêtre.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">L'interface StorageGRID Grid Manager permet d'effectuer les tâches suivantes :</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">Stratégies de gestion du cycle de vie des informations</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">Politique ILM</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">Règles ILM</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID propose des règles de gestion des données flexibles qui incluent la conservation des copies de réplica de vos objets et l'utilisation de schémas EC (codage d'effacement) comme 2+1 et 4+2 (entre autres) pour stocker vos objets, selon des exigences de performance et de protection des données spécifiques. Les exigences et les charges de travail évoluent au fil du temps. Les règles ILM doivent également évoluer au fil du temps. La modification des règles ILM est une fonction centrale, qui permet aux clients StorageGRID de s'adapter rapidement et facilement à l'évolution permanente de leur environnement. Veuillez vérifier le <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> et <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> configuration dans StorageGRID.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 OU SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID permet d'améliorer les performances en ajoutant des nœuds de stockage, qui peuvent être des machines virtuelles, des serveurs bare Metal ou des appliances dédiées telles que la <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. Lors de nos tests, nous avons dépassé les exigences clés de performance Apache Kafka avec un grid à trois nœuds de taille minimale utilisant l'appliance SGF6024. À mesure que les clients font évoluer leur cluster Kafka avec des courtiers supplémentaires, ils peuvent ajouter davantage de nœuds de stockage pour augmenter la performance et la capacité.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">Équilibreur de charge et configuration de point final</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">Les nœuds d'administration d'StorageGRID fournissent l'interface utilisateur Grid Manager (interface utilisateur) et le terminal d'API REST pour afficher, configurer et gérer votre système StorageGRID, ainsi que des journaux d'audit pour suivre l'activité du système. Pour fournir un terminal S3 hautement disponible pour le stockage hiérarchisé Kafka, nous avons implémenté le équilibreur de charge StorageGRID qui s'exécute comme un service sur les nœuds d'administration et les nœuds de passerelle. En outre, l'équilibreur de charge gère également le trafic local et communique avec le GSLB (Global Server Load Balancing) pour faciliter la reprise après incident.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">Pour améliorer encore la configuration des terminaux, StorageGRID fournit des règles de classification du trafic intégrées au nœud d'administration, vous permet de surveiller le trafic des workloads et d'appliquer diverses limites de qualité de service à vos charges de travail. Les règles de classification du trafic sont appliquées aux terminaux du service StorageGRID Load Balancer pour les nœuds de passerelle et les nœuds d'administration. Ces politiques peuvent faciliter la mise en forme et la surveillance du trafic.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">Classification du trafic à StorageGRID</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID offre des fonctionnalités de QoS intégrées. Les règles de classification du trafic peuvent aider à surveiller différents types de trafic S3 provenant d'une application client. Vous pouvez ensuite créer et appliquer des stratégies pour mettre des limites sur ce trafic en fonction de la bande passante entrée/sortie, du nombre de demandes simultanées de lecture/écriture ou du taux de demande de lecture/écriture.</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka est un framework conçu par un bus logiciel qui utilise le traitement en flux écrit dans Java et Scala. Elle vise à fournir une plate-forme unifiée haut débit à faible latence pour la gestion des flux de données en temps réel. Kafka peut se connecter à un système externe pour l'exportation et l'importation de données via Kafka Connect. Ce système fournit les flux Kafka, une bibliothèque de traitement de flux Java. Kafka utilise un protocole TCP binaire optimisé pour son efficacité et s'appuie sur une abstraction « jeu de messages » qui regroupe naturellement les messages ensemble pour réduire la surcharge liée au réseau. Cela permet d'effectuer des opérations sur disque séquentielles plus volumineuses, des paquets réseau plus volumineux et des blocs de mémoire contigus. Kafka peut ainsi transformer un flux d'écritures de messages aléatoires en rafales en écritures linéaires. La figure suivante illustre le flux de données de base d'Apache Kafka.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka stocke les messages clés provenant d'un nombre arbitraire de processus appelés producteurs. Les données peuvent être partitionnées en différentes partitions dans différentes rubriques. Dans une partition, les messages sont strictement ordonnés par leur décalage (la position d'un message dans une partition) et indexés et stockés avec un horodatage. D'autres processus appelés consommateurs peuvent lire des messages à partir de partitions. Pour le traitement par flux, Kafka propose l'API stream qui permet d'écrire les applications Java qui utilisent les données depuis Kafka et écrivent les résultats sur Kafka. Apache Kafka fonctionne également avec les systèmes de traitement de flux externes comme Apache Apex, Apache Flink, Apache Spark, Apache Storm et Apache NiFi.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka s'exécute sur un cluster composé d'un ou de plusieurs serveurs (appelés courtiers), et les partitions de tous les sujets sont distribuées sur les nœuds du cluster. En outre, les partitions sont répliquées sur plusieurs courtiers. Cette architecture permet à Kafka de fournir un flux de messages volumineux tolérant aux pannes et lui a permis de remplacer certains des systèmes de messagerie traditionnels comme JMS (Java message Service), AMQP (Advanced message Queuing Protocol), etc. Depuis la version 0.11.0.0, Kafka propose les écritures transactionnelles qui fournissent un traitement exact du flux à l'aide de l'API stream.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka prend en charge deux types de sujets : classiques et compactés. Les rubriques régulières peuvent être configurées avec une durée de conservation ou une limite d'espace. Si certains enregistrements sont plus anciens que le temps de rétention spécifié ou si la limite d'espace est dépassée pour une partition, Kafka est autorisée à supprimer les anciennes données dans l'espace de stockage disponible. Par défaut, les sujets sont configurés avec une durée de conservation de 7 jours, mais il est également possible de stocker des données indéfiniment. Pour les sujets compactés, les enregistrements n'expirent pas en fonction des limites de temps ou d'espace. Au lieu de cela, Kafka traite les messages plus récents comme des mises à jour de messages plus anciens avec la même clé et garantit de ne jamais supprimer le message le plus récent par clé. Les utilisateurs peuvent entièrement supprimer des messages en écrivant un message appelé tombstone avec la valeur NULL pour une clé spécifique.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Fournit cinq API principales à Kafka :</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*Producer API.* permet à une application de publier des flux d'enregistrements.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*Consumer API.* permet à une application de s'abonner aux rubriques et de traiter les flux d'enregistrements.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*API de connecteur.* exécute les API de producteur et de consommateur réutilisables qui peuvent lier les rubriques aux applications existantes.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*API de flux* cette API convertit les flux d'entrée en sortie et produit le résultat.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*Admin API.* utilisé pour gérer les sujets Kafka, les courtiers et les autres objets Kafka.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">Les API grand public et producteur s'appuient sur le protocole de messagerie Kafka et proposent une implémentation de référence pour les clients consommateurs et producteurs Kafka en Java. Le protocole de messagerie sous-jacent est un protocole binaire que les développeurs peuvent utiliser pour écrire leurs propres clients client ou producteurs dans n'importe quel langage de programmation. Ceci déverrouille Kafka de l'écosystème Java Virtual machine (JVM). Une liste des clients non Java disponibles est conservée dans le wiki Apache Kafka.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Cas d'utilisation d'Apache Kafka</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka est le plus populaire pour la messagerie, le suivi des activités du site Web, les metrics, l'agrégation de journaux, le traitement du flux, approvisionnement des événements et consignation des enregistrements.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka a amélioré le débit, le partitionnement intégré, la réplication et la tolérance aux pannes, ce qui en fait une solution idéale pour les applications de traitement de messages à grande échelle.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka peut reconstruire les activités d'un utilisateur (vues de pages, recherches) dans un pipeline de suivi comme un ensemble de flux de publication-abonnement en temps réel.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka est souvent utilisé pour les données de surveillance opérationnelle. Cela implique d'agréger des statistiques à partir d'applications distribuées pour produire des flux centralisés de données opérationnelles.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">Beaucoup de gens utilisent Kafka comme solution de remplacement d'agrégation de journaux. L'agrégation de journaux collecte généralement les fichiers journaux physiques hors des serveurs et les place dans un emplacement central (par exemple, un serveur de fichiers ou HDFS) pour le traitement. Kafka extrait les détails des fichiers et assure un abstraction plus fluide des données du journal ou d'événements sous forme de flux de messages. Cela permet un traitement à faible latence et une prise en charge simplifiée de plusieurs sources de données et de la consommation des données distribuées.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">De nombreux utilisateurs du traitement des données Kafka traitent les données de pipelines de traitement comme plusieurs étapes. Ces données brutes sont consommées à partir de sujets Kafka, puis sont agrégées, enrichies ou transformées en nouveaux sujets afin de favoriser la consommation ou le traitement du suivi. Par exemple, un pipeline de traitement pour recommander des articles de nouvelles peut ramper le contenu de l'article à partir des flux RSS et le publier dans un thème "articles". Un traitement plus poussé peut normaliser ou dédupliquer ce contenu et publier le contenu de l'article nettoyé vers un nouveau sujet, et une étape de traitement finale peut tenter de recommander ce contenu aux utilisateurs. Ces pipelines de traitement créent des graphiques de flux de données en temps réel sur la base de sujets individuels.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">Le sourd d'événement est un style de conception d'application pour lequel les changements d'état sont consignés sous forme d'une séquence d'enregistrements ordonnée à l'heure. La prise en charge de Kafka pour les journaux stockés les plus volumineux en fait un excellent back-end pour une application intégrée dans ce style.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka peut servir de journal externe destiné à un système distribué. Ce journal aide à la réplication des données entre les nœuds et agit comme un mécanisme de resynchronisation pour les nœuds défaillants afin de restaurer leurs données. La fonctionnalité de compaction des journaux dans Kafka vous aide à prendre en charge ce cas d'utilisation.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">La plateforme Confluent est une plateforme prête pour l'entreprise qui complète Kafka avec les capacités avancées conçues pour accélérer le développement et la connectivité des applications, permettre les transformations par le traitement du flux, simplifier les opérations à grande échelle et répondre aux exigences architecturales strictes. Conçu par les créateurs d'Apache Kafka à l'origine, ce logiciel étend les avantages de Kafka avec des fonctionnalités haute performance tout en éliminant les tâches de gestion et de surveillance Kafka. Aujourd'hui, plus de 80 % des entreprises classées au Fortune 100 sont équipées de technologies de streaming de données, et la plupart d'entre elles utilisent la technique de confluent.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform vous permet de vous concentrer sur la manière de tirer de la valeur commerciale de vos données plutôt que de vous soucier des mécanismes sous-jacents, tels que le mode de transport ou d'intégration des données entre des systèmes disparates. La plateforme Confluent simplifie la connexion des sources de données à Kafka, créant des applications de streaming, ainsi que la sécurisation, le contrôle et la gestion de votre infrastructure Kafka. Aujourd'hui, la plateforme parler couramment utilisée pour de nombreux cas d'utilisation dans de nombreux secteurs, qu'il s'agisse des services financiers, de la vente en canaux multiples, des voitures autonomes, de la détection des fraudes, Les microservices et l'IoT.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">La figure suivante montre les composants confluent de la plateforme Kafka.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Présentation de la technologie de diffusion d'événements de Confluent</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Au cœur de la plate-forme de confluent est<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>, la plate-forme de streaming distribuée open-source la plus populaire. Les capacités clés de Kafka sont les suivantes :</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Présentation des fonctionnalités d'entreprise de la plate-forme confluent</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent Control Center.* Un système à interface graphique pour la gestion et le contrôle de Kafka. Il vous permet de gérer facilement Kafka Connect et de créer, modifier et gérer les connexions avec d'autres systèmes.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Connecteurs confluent à Kafka.* les connecteurs utilisent l'API Kafka Connect pour connecter Kafka à d'autres systèmes tels que les bases de données, les magasins de valeur clé, les index de recherche et les systèmes de fichiers. Confluent Hub dispose de connecteurs téléchargeables pour les sources de données et les éviers les plus populaires, y compris les versions entièrement testées et prises en charge de ces connecteurs avec plate-forme confluent. Plus de détails sont disponibles<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*Clusters à auto-équilibrage.* offre un équilibrage de charge automatisé, une détection des pannes et une auto-rétablissement. Il permet d'ajouter ou de désaffecter des courtiers en fonction des besoins, sans réglage manuel.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*BALANCER de données de confluent.* surveille le nombre de courtiers, la taille des partitions, le nombre de partitions et le nombre de lignes d'attache au sein du cluster. Il vous permet de déplacer des données pour créer une charge de travail homogène dans le cluster, tout en limitant le trafic pour limiter l'impact sur les workloads de production tout en procédant à un rééquilibrage.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">Suivant : vérification confluent.</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">La solution de transfert de données pour l'IA repose sur les besoins des utilisateurs en matière de traitement des données Hadoop à partir d'opérations d'IA. NetApp déplace les données de HDFS vers NFS à l'aide de NIPAM. Dans un cas d'utilisation, le client devait déplacer les données vers NFS sur site et un autre client devait déplacer les données de Windows Azure Storage Blob vers Cloud Volumes Service pour traiter les données des instances cloud GPU dans le cloud.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">Solution de transfert de données pour l'IA</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">Précédent : solution de Data Mover.</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">Le schéma suivant illustre les détails de la solution de transfert de données.</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Les étapes suivantes sont requises pour créer la solution de transfert de données :</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">Le SAN ONTAP fournit HDFS, et NAS fournit le volume NFS via NIPAM au cluster du data Lake de production.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">Les données du client sont dans HDFS et NFS. Les données NFS peuvent être des données de production à partir d'autres applications utilisées pour l'analytique Big Data et les opérations d'IA.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">La technologie NetApp FlexClone crée un clone du volume NFS de production et le provisionne sur site vers le cluster d'IA.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">Les données d'une LUN SAN HDFS sont copiées dans un volume NFS avec NIPAM et l'<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande. NIPAM utilise la bande passante de plusieurs interfaces réseau pour transférer des données. Ce processus réduit le temps de copie des données afin de pouvoir transférer davantage de données.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">Les deux volumes NFS sont provisionnés sur le cluster d'IA pour les opérations d'IA.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">Pour traiter les données NFS sur site avec des GPU dans le cloud, les volumes NFS sont mis en miroir vers NetApp Private Storage (NPS) avec la technologie NetApp SnapMirror et montés sur les fournisseurs de services cloud pour les GPU.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">Le client souhaite traiter des données dans des services EC2/EMR, HDInsight ou DataProc dans des GPU provenant de fournisseurs de services cloud. Le mécanisme de déplacement des données Hadoop déplace les données des services Hadoop vers les services Cloud volumes avec NIPAM et le<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> commande.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Les données Cloud Volumes Service sont provisionnées à l'IA via le protocole NFS.les données traitées via l'IA peuvent être envoyées sur un emplacement sur site à des fins d'analytique Big Data, en plus du cluster NVIDIA via NIPAM, SnapMirror et NPS.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">Dans ce scénario, le client dispose de données volumineuses dans le système NAS à un emplacement distant, requises pour le traitement d'IA sur le contrôleur de stockage NetApp sur site. Dans ce scénario, il est préférable d'utiliser l'outil de migration XCP pour migrer les données plus rapidement.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">Le cas d'utilisation hybride peut utiliser Cloud Sync pour migrer les données locales des systèmes NFS, CIFS et S3 vers le cloud, et inversement pour le traitement de l'IA à l'aide de processeurs graphiques tels que ceux d'un cluster NVIDIA. Cloud Sync et l'outil de migration XCP sont utilisés pour la migration des données NFS vers ONTAP NFS de NetApp.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">Suivant : GPFS vers NetApp ONTAP NFS.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">Nous avons utilisé les scripts Terasort et TeraValidate de l'outil de test TeraGen pour mesurer la validation des performances Spark avec les configurations E5760, E5724 et AFF-A800. En outre, trois cas d'utilisation majeurs ont été testés, les pipelines Spark NLP et l'entraînement TensorFlow distribué, la formation Horovod distribuée et l'apprentissage profond multi-travailleur à l'aide de Keras pour la prédiction par CTR avec DeepFM.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">Résultats des tests</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">Précédent : principales utilisations et architectures de l'IA, DU ML et du DL.</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">Nous avons utilisé les scripts Terasort et TeraValidate de l'outil de test TeraGen pour mesurer la validation des performances Spark avec les configurations E5760, E5724 et AFF-A800. En outre, trois cas d'utilisation majeurs ont été testés : les pipelines Spark NLP et l'entraînement TensorFlow distribué, la formation Horovod distribuée et l'apprentissage profond multi-travailleur à l'aide de Keras pour la prédiction par CTR avec DeepFM.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">Pour la validation des environnements E-Series et StorageGRID, nous avons utilisé le facteur de réplication Hadoop 2. Pour la validation AFF, nous n'utilisons qu'une seule source de données.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">Le tableau suivant répertorie la configuration matérielle pour la validation des performances Spark.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">Type</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Nœuds workers Hadoop</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">Type de disque</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">Disques par nœud</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">Contrôleur de stockage</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">Paire haute disponibilité unique</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">Une seule paire HA</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">Le tableau suivant répertorie la configuration logicielle requise.</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">Environnement d'exécution OpenJDK</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">Serveur virtuel OpenJDK 64 bits</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">Étincelle</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">Analyse du sentiment financier</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">SDK NVIDIA Riva</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Cadre Tao</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">Nous avons publié<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>, Dans lequel un pipeline d'IA conversationnel de bout en bout a été créé à l'aide du<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, Stockage AFF et système NVIDIA DGX. Le pipeline exécute le traitement du signal audio par lots, la reconnaissance vocale automatique (ASR), l'apprentissage par transfert et l'analyse de sentiment en utilisant le kit DataOps,<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>, et le<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>. Élargissement de l'utilisation de l'analyse des sentiments à l'industrie des services financiers, nous avons conçu un workflow SparkNLP, chargé de trois modèles BERT pour diverses tâches du NLP, telles que la reconnaissance des entités nommées et obtenu un sentiment de phrase pour les 10 meilleures entreprises du NASDAQ appels trimestriels sur les bénéfices.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">Le script suivant<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> Utilise le modèle FinBERT pour traiter les transcriptions dans HDFS et produire des comptages positifs, neutres et négatifs, comme le montre le tableau suivant :</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">Le tableau ci-dessous répertorie les résultats de l'analyse du sentiment au niveau des phrases pour les 10 premières entreprises du NASDAQ de 2016 à 2020.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">Le nombre et le pourcentage de sentiments</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">Toutes les 10 entreprises</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AIRBUS</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">Comptes positifs</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">Compte neutre</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">Comptes négatifs</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">Décomptes sans catégorie</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(nombre total)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">En termes de pourcentages, la plupart des phrases prononcées par les PDG et les DAF sont factuelles et portent donc un sentiment neutre. Lors d'un appel sur les gains, les analystes posent des questions qui peuvent transmettre un sentiment positif ou négatif. Il est intéressant d'examiner de manière quantitative la façon dont le sentiment négatif ou positif affecte le cours des actions le même jour ou le jour suivant de la négociation.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">Le tableau ci-dessous répertorie les 10 premières entreprises du NASDAQ, exprimées en pourcentage, au niveau des phrases.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">Pourcentage de sentiment</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">Positif</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13 %</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06 %</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69 %</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24 %</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07 %</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08 %</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44 %</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25 %</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23 %</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">Neutre</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17 %</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02 %</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82 %</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87 %</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42 %</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50 %</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65 %</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77 %</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44 %</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">Négatif</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43 %</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92 %</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49 %</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52 %</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51 %</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42 %</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91 %</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96 %</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33 %</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">Sans catégorie</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27 %</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37 %</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01 %</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">En termes d'exécution du flux de travail, nous avons constaté une nette amélioration de 4,6 fois par rapport à<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> Le mode vers un environnement distribué dans HDFS et une amélioration encore de 0.14 % avec NFS.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">Comme le montre la figure suivante, le parallélisme des données et des modèles a amélioré le traitement des données et la vitesse d'inférence des modèles TensorFlow distribués. L'emplacement des données dans NFS a permis une exécution légèrement supérieure, car le goulot d'étranglement du flux de travail correspond au téléchargement des modèles pré-entraînés. Si nous augmentons la taille des jeux de données de transcription, l'avantage du protocole NFS est plus évident.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">L'analyse des sentiments NLP Spark est un processus d'exécution de bout en bout.</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Formation distribuée avec la performance Horovod</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">“Scripts Python pour chaque cas d’utilisation majeur”</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">La commande suivante a produit des informations d'exécution et un fichier journal dans notre cluster Spark à l'aide d'un seul<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> nœud avec 160 exécuteurs avec chacun un noyau. La mémoire de l'exécuteur était limitée à 5 Go pour éviter les erreurs de mémoire insuffisante. Voir la section <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> pour obtenir plus de détails sur le traitement des données, l'entraînement du modèle et le calcul de la précision du modèle dans<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>.</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">Le temps d'exécution résultant avec dix séries de tests d'entraînement était le suivant :</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">Il fallait plus de 43 minutes pour traiter les données d'entrée, entraîner un modèle DNN, calculer la précision et produire des points de contrôle TensorFlow et un fichier CSV pour les résultats de prédiction. Nous avons limité le nombre de tests d'entraînement à 10, qui dans la pratique est souvent réglé à 100 pour assurer une précision satisfaisante du modèle. La durée d'entraînement évolue généralement de manière linéaire avec le nombre de séries de tests.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">Nous avons ensuite utilisé les quatre nœuds workers disponibles dans le cluster et exécuté le même script dans<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> Mode avec données dans HDFS :</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">Le temps d'exécution obtenu a été amélioré comme suit :</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">Avec le modèle et le parallélisme des données de Horovod dans Spark, nous avons vu une vitesse d'exécution de 5,29x<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> contre<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> mode avec dix séries de tests d'entraînement. Ceci est illustré dans la figure suivante avec les légendes<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> et<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>. L'entraînement du modèle DNN sous-jacent peut être accéléré au moyen de processeurs graphiques, le cas échéant. Nous prévoyons de mener ces tests et de publier les résultats dans un futur rapport technique.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">Notre prochain test a comparé les temps d'exécution avec les données d'entrée résidant dans NFS et HDFS. Le volume NFS du AFF A800 a été monté sur<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> Sur les cinq nœuds (un maître, quatre travailleurs) de notre cluster Spark Nous avons exécuté une commande similaire à celle des tests précédents avec<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> Paramètre maintenant pointant vers le montage NFS :</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">Le temps d'exécution avec NFS obtenu est le suivant :</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">Il y a eu une accélération supplémentaire de 1,43 fois, comme le montre la figure suivante. Par conséquent, avec un système de stockage 100 % Flash NetApp connecté à leur cluster, les clients profitent des avantages du transfert et de la distribution rapides des données pour les workflows Horovod Spark, avec une vitesse de 7,5 fois supérieure à celle d'un seul nœud.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Exécution du workflow Horovod Spark</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">Modèles de deep learning pour les performances de prévision CTR</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">Pour les systèmes de recommandation conçus pour optimiser le CTR, vous devez apprendre les interactions de fonctionnalités sophistiquées derrière les comportements utilisateur qui peuvent être calculées mathématiquement de bas en haut de gamme. Les interactions de type faible et élevé avec les fonctionnalités doivent être tout aussi importantes pour un bon modèle d'apprentissage profond, sans biasing vers l'un ou l'autre. Le Deep Factorisation machine (DeepFM), un réseau neuronal basé sur la factorisation, combine les machines d'automatisation à des fins de recommandation et d'apprentissage profond afin d'apprendre les fonctionnalités dans une nouvelle architecture de réseaux neuronaux.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">Modèles larges et profonds</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">Bien que les machines de factorisation conventionnelles utilisent des interactions de composants pairées en tant que produit interne de vecteurs latents entre les fonctionnalités et permettent théoriquement de capturer des informations de gros ordre, en pratique, les professionnels de l'apprentissage machine n'utilisent généralement que des interactions de fonctionnalités de second ordre du fait de la complexité élevée des calculs et du stockage. Des variantes de réseau neuronal profondes comme celle de Google<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> en revanche, elle apprend des interactions de fonctionnalités sophistiquées dans une structure de réseau hybride en combinant un modèle à large linéaire et un modèle profond.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">Il existe deux entrées pour ce modèle large et profond, l'une pour le modèle large sous-jacent et l'autre pour le plus profond, dont la dernière partie nécessite toujours une ingénierie de fonctionnalité experte et rend ainsi la technique moins généralisable pour d'autres domaines. Contrairement au modèle large et profond, DeepFM peut être efficacement formé avec des fonctions brutes sans aucune technique de fonction car sa grande partie et sa pièce profonde partagent la même entrée et le même vecteur d'intégration.</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">“Scripts Python pour chaque cas d’utilisation majeur.”</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">Nous avons d'abord traité le Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11 Go) dans un fichier CSV nommé<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Stocké dans un montage NFS<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> à l'aide de<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> dans la section <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> Dans ce script, la fonction<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> effectue plusieurs méthodes de chaîne pour supprimer les onglets et les insérer<block ref="f89bb99ea60d9e9cbbc95ce1a8f1a63a" prefix=" " category="inline-code"></block> comme séparateur et<block ref="918d67b3695a9c52a0e182a621fc33da" prefix=" " category="inline-code"></block> en tant que réseau. Notez que vous n'avez besoin que de traiter l'original<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> une fois, de sorte que le bloc de code soit affiché comme commentaires.</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">Pour les tests suivants sur les différents modèles d'apprentissage profond, nous avons utilisé<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> comme fichier d'entrée. Lors des tests suivants, le fichier CSV d'entrée a été lu dans un Spark DataFrame avec un schéma contenant un champ de<block ref="cdb10f764735165c687209f811432621" prefix=" " category="inline-code"></block>, composants denses entiers<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>, et des caractéristiques parsemées<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>. Les éléments suivants<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> La commande prend dans un CSV d'entrée, forme des modèles DeepFM avec une répartition à 20 % pour la validation croisée, et sélectionne le meilleur modèle après dix séries de tests d'entraînement pour calculer la précision de prédiction sur le jeu de tests :</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">Notez que depuis le fichier de données<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> Est supérieur à 11 Go, vous devez définir une quantité suffisante<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> supérieure à la taille du jeu de données pour éviter toute erreur.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Flèche Apache</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">Dans le ci-dessus<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> configuration que nous avons également activée<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>, Qui convertit un Spark DataFrame en un Pandas DataFrame avec le<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> méthode.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">Après la division aléatoire, le dataset d'entraînement contient plus de 36 rangées et des échantillons de 9 millions dans le dataset de test :</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">Ce rapport technique étant axé sur les tests CPU sans utiliser de GPU, il est impératif de construire TensorFlow avec des indicateurs de compilateur appropriés. Cette étape évite d'appeler des bibliothèques à accélération graphique et tire pleinement parti des instructions AVX (Advanced Vector Extensions) et AVX2 de TensorFlow. Ces fonctionnalités sont conçues pour les calculs algébriques linéaires tels que l'ajout vectorisé, les multiproduits matriciels dans un entraînement DNN d'avance ou de contre-propagation. L'instruction FMA (Multiply Add) avec AVX2 utilisant des registres à virgule flottante 256 bits est idéale pour les types de code entier et de données, ce qui permet d'obtenir une vitesse de 2 fois plus élevée. Pour le code FP et les types de données, AVX2 atteint 8 % de vitesse supérieure à AVX.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">Pour créer TensorFlow à partir d'une source, NetApp vous recommande d'utiliser<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>. Pour notre environnement, nous avons exécuté les commandes suivantes dans l'invite du shell pour l'installation<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block>, Et Bazel.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">Vous devez activer GCC 5 ou version ultérieure pour utiliser les fonctions C++17 pendant le processus de création, qui est fourni par RHEL avec la bibliothèque de collections logicielles (SCL). Les commandes suivantes s'installent<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> Et GCC 11.2.1 sur notre cluster RHEL 7.9 :</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">article</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">Notez que les deux dernières commandes sont en cours d'activation<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>, qui utilise<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1). Assurez-vous également que votre<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> La version est supérieure à 1.8.3 (fournie avec RHEL 7.9). Se reporter à ceci<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> pour mise à jour<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> à 2.24.1.</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">“Scripts Python pour chaque cas d’utilisation majeur,”</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">Nous supposons que vous avez déjà cloné le dernier référentiel TensorFlow maître. Créez ensuite un<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> répertoire avec un<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> Fichier pour créer TensorFlow à partir de la source avec AVX, AVX2 et FMA. Exécutez le<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> Et spécifiez l'emplacement binaire Python correct.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> Est désactivé pour nos tests car nous n'avons pas utilisé de GPU. A<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> le fichier est généré en fonction de vos paramètres. De plus, nous avons modifié le fichier et l'ensemble<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> Pour activer la prise en charge de HDFS. Reportez-vous à la section<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> dans la section <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> pour obtenir une liste complète des paramètres et des indicateurs.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">Après avoir créé TensorFlow avec les indicateurs appropriés, exécutez le script suivant pour traiter le jeu de données Criteo Display Ads, former un modèle DeepFM et calculer la zone sous la courbe caractéristique d'exploitation du récepteur (ROC CASC) à partir des notes de prédiction.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">Après dix tests d'entraînement, nous avons obtenu le score AUC sur le jeu de données de test :</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">De la même manière que dans les précédents cas d'utilisation, nous avons comparé le temps d'exécution du flux de production Spark avec des données résidant sur différents emplacements. La figure suivante montre une comparaison des prédictions CTR d'apprentissage profond pour le temps d'exécution des workflows Spark.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Comparaison des prévisions de CTR d'apprentissage profond pour le temps d'exécution des workflows Spark</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">Ensuite, solution cloud hybride.</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">Nous avons réalisé des tests de stockage sur plusieurs niveaux avec cinq ou huit nœuds de courtage lors d'une charge de travail exigeante en produits, avec une paire haute disponibilité AFF A900 sur un contrôleur de stockage NetApp. Selon nos tests, le temps d'exécution et les résultats en termes de performances ont été dimensionnés en conséquence, avec le nombre de nœuds courtiers, jusqu'à ce que l'utilisation des ressources AFF A900 atteigne cent pour cent. La configuration du contrôleur de stockage ONTAP nécessite au moins une paire haute disponibilité.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">Tests de performance avec le générateur de charges de travail produisant la consommation</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">Précédent : validation des performances confluentes.</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">Les performances de l'opération de récupération S3 ont augmenté de façon linéaire en fonction du nombre de nœuds courtiers en confluent. Le contrôleur de stockage ONTAP prend en charge jusqu'à 12 paires HA dans un déploiement unique.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">Le graphique suivant montre le trafic de Tiering S3 combiné avec cinq ou huit nœuds de courtage. Nous avons optimisé les performances d'une seule paire haute disponibilité AFF A900.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">Ce graphique présente le trafic associé au Tiering S3 avec cinq ou huit nœuds de courtage.</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">Le graphique suivant montre le débit Kafka à environ 31,74 Gbit/s.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">Ce graphique montre le débit Kafka à environ 31,74 Gbit/s.</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">Nous avons également observé un débit similaire dans le contrôleur de stockage ONTAP<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> rapport.</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">Ensuite : recommandations sur les bonnes pratiques en matière de performances.</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">Cette utilisation repose sur un client de ce domaine qui doit sauvegarder ses données d'analytique cloud dans son data Center sur site.</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">Précédent : cas d'utilisation 1 : sauvegarde des données Hadoop.</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">Ce cas d'utilisation est basé sur un client de radiodiffusion qui doit sauvegarder les données d'analytique cloud vers son data Center sur site, comme l'illustre la figure ci-dessous.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">Dans ce scénario, les données de capteurs de l'IoT sont ingérées sur le cloud et analysées à l'aide d'un cluster Apache Spark open source dans AWS. Une nécessité consiste à sauvegarder les données traitées depuis le cloud vers une infrastructure sur site.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">L'activation de la protection des données ne doit pas affecter les performances du cluster Spark/Hadoop de production dans le cloud.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">Les données de Cloud Sensor doivent être déplacées et protégées sur site de manière efficace et sécurisée.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">Flexibilité du transfert des données depuis le cloud vers un environnement sur site dans des conditions différentes, telles que sur demande, instantanément et pendant les faibles temps de chargement du cluster.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">Le client utilise AWS Elastic Block Store (EBS) pour le stockage HDFS du cluster Spark afin de recevoir et d'ingérer les données provenant de capteurs distants via Kafka. Par conséquent, le stockage HDFS agit comme source des données de sauvegarde.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">Pour y répondre, NetApp ONTAP Cloud est déployé dans AWS, et un partage NFS est créé pour servir de cible de sauvegarde pour le cluster Spark/Hadoop.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">Une fois le partage NFS créé, le module d'analytique sur place permet de copier les données du stockage HDFS EBS vers le partage NFS ONTAP. Une fois que les données sont stockées dans le système NFS dans ONTAP Cloud, la technologie SnapMirror peut être utilisée pour mettre en miroir les données du cloud vers du stockage sur site selon les besoins, de manière sécurisée et efficace.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">Cette image présente la sauvegarde et la reprise d'activité entre le cloud et la solution sur site.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">Suivant : cas d'utilisation 3 - activation de DevTest sur les données Hadoop existantes.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">Cette section décrit les personnes susceptibles d'être intéressées par le contenu de cette solution.</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">L'univers de l'analytique et de la science des données touche plusieurs disciplines au NIVEAU DE L'INFORMATIQUE et des activités :</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">Un ingénieur DevOps doit disposer des outils nécessaires pour intégrer les nouvelles applications d'IA et DE ML dans son pipeline d'intégration et de livraison continues.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">Les administrateurs et architectes cloud doivent être en mesure de configurer et de gérer des ressources de cloud hybride.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">Les utilisateurs professionnels veulent avoir accès à des applications d'analytique, d'IA, DE ML et de DL.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">Dans ce rapport technique, nous explique comment NetApp AFF, E-Series, StorageGRID, NFS direct, Apache Spark Horovod et Keras aident chacun de ces rôles à apporter de la valeur aux entreprises.</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">Suivant : technologie de la solution.</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">Ce document décrit les bonnes pratiques relatives à l'utilisation de Kafka sur un contrôleur de stockage NetApp.</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka est une plateforme de streaming aux événements distribuée par la communauté qui prend en charge des milliards d'événements par jour. Initialement conçu comme une file d'attente de messagerie, Kafka repose sur l'abstraction d'un journal de validation distribué. Depuis sa création et l'open source par LinkedIn en 2011, Kafka a évolué depuis la file d'attente des messages vers une plateforme complète de streaming d'événements. Confluent assure la distribution d'Apache Kafka avec la plateforme confluent. La plateforme Confluent complète Kafka avec des fonctions communautaires et commerciales supplémentaires conçues pour améliorer l'expérience de streaming tant des opérateurs que des développeurs en production à grande échelle.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">Ce document présente les meilleures pratiques pour l'utilisation du stockage hiérarchisé de niveau confluent sur une offre de stockage objet NetApp en fournissant le contenu suivant :</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">Vérification couramment assurée avec le stockage objet NetApp : NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">Tests des performances du stockage à plusieurs niveaux</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">Instructions sur les meilleures pratiques pour parler couramment les systèmes de stockage NetApp</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Pourquoi le stockage à plusieurs niveaux confluent ?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Cet article par confluent</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent est devenu la plateforme de streaming en temps réel par défaut pour de nombreuses applications, en particulier pour le Big Data, l'analytique et les charges de travail de streaming. Le stockage à plusieurs niveaux permet aux utilisateurs de séparer les ressources de calcul du stockage dans la plateforme confluent. Cette solution rend le stockage des données plus économique, vous permet de stocker des volumes presque infinis de données et de faire évoluer les charges de travail à la demande (ou en réduisant). Elle simplifie également les tâches administratives telles que le rééquilibrage des données et des locataires. Les systèmes de stockage compatibles S3 peuvent tirer parti de toutes ces capacités pour démocratiser les données avec tous les événements. L'ingénierie des données est ainsi inutile. Pour plus d'informations sur la raison pour laquelle vous devez utiliser le stockage à plusieurs niveaux pour Kafka, vérifiez <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">Pourquoi choisir NetApp StorageGRID pour le stockage hiérarchisé ?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID est une plateforme de stockage objet leader du marché, StorageGRID est une solution de stockage objet Software-defined qui prend en charge les API objet standard telles qu'Amazon simple Storage Service (S3). StorageGRID stocke et gère des volumes massifs de données non structurées pour un stockage objet sécurisé et durable. Vous placez vos contenus au bon endroit, au bon moment, dans le Tier de stockage adéquat, afin d'optimiser les workflows et de réduire les coûts du contenu enrichi distribué à l'échelle mondiale.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">Le plus grand atout concurrentiel de StorageGRID est son moteur de règles de gestion du cycle de vie de l'information (ILM) qui permet une gestion du cycle de vie des données pilotée par les règles (policy). Le moteur de règles peut utiliser les métadonnées pour gérer la façon dont les données sont stockées tout au long de leur durée de vie. Il optimise alors la performance et optimise automatiquement les coûts et la durabilité à mesure que les données vieillissent.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Activation du stockage à plusieurs niveaux confluent</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">L'idée de base d'un stockage hiérarchisé est de séparer les tâches du stockage des données du traitement des données. Cette séparation facilite l'évolutivité indépendante du niveau de stockage et du Tier de traitement des données.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Une solution de stockage à plusieurs niveaux pour confluent doit contenir deux facteurs. Tout d'abord, ils doivent contourner ou éviter les propriétés communes de disponibilité et de cohérence du magasin d'objets, comme les incohérences dans les opérations DE LISTE et l'indisponibilité occasionnelle d'objets. Deuxièmement, il doit traiter correctement l'interaction entre le stockage à plusieurs niveaux et le modèle de réplication et de tolérance aux pannes de Kafka, y compris la possibilité pour les dirigeants zombies de continuer à classer les plages de décalage. Le stockage objet NetApp fournit à la fois une disponibilité cohérente des objets et des modèles de haute disponibilité qui rendent le stockage fatigué disponible dans les plages de décalage de Tier. Le stockage objet NetApp procure une disponibilité cohérente des objets et un modèle de haute disponibilité pour que le stockage en fatigue soit disponible dans les plages de décalage de Tier.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">Le stockage à plusieurs niveaux vous permet d'utiliser des plateformes haute performance pour les lectures et les écritures à faible latence à proximité de l'arrière de vos données de streaming. Vous pouvez également utiliser des magasins d'objets plus économiques et évolutifs comme NetApp StorageGRID pour les lectures historiques à haut débit. Nous disposons également d'une solution technique pour Spark avec le contrôleur de stockage netapp et découvrez comment dans ce document les détails. La figure suivante montre comment Kafka s'intègre dans un pipeline analytique en temps réel.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">La figure suivante décrit le positionnement de NetApp StorageGRID comme le Tier de stockage objet couramment utilisé par Kafka.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">Ensuite : détails de l'architecture de la solution.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">Ce rapport technique a utilisé les références suivantes :</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Architecture et composants d'Apache Spark</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Cas d'utilisation d'Apache Spark</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Les défis d'Apache</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Deep et Cross Network pour les annonces cliquez sur les prédictions</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ETL de diffusion en continu</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Solutions NetApp E-Series pour Hadoop</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">Analyse des sentiments des communications avec NetApp ai</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">Kit d'outils DataOps</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">Cette section décrit la nature et les composants d'Apache Spark et leur contribution à cette solution.</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">Précédent : audience cible.</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark est un framework de programmation célèbre qui permet de rédiger des applications Hadoop directement avec le système Hadoop Distributed File System (HDFS). Spark est prête pour la production et prend en charge le traitement du streaming de données, et elle est plus rapide que MapReduce. Spark propose une mise en cache des données en mémoire configurable pour une itération efficace, et le shell Spark est interactif pour l'apprentissage et l'exploration des données. Avec Spark, vous pouvez créer des applications en Python, Scala ou Java. Les applications SPARK consistent en un ou plusieurs travaux qui ont une ou plusieurs tâches.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">Chaque application Spark est dotée d'un tournevis à bougie. En mode YARN-client, le pilote s'exécute localement sur le client. En mode YARN-Cluster, le pilote s'exécute dans le cluster du maître d'application. En mode cluster, l'application continue à fonctionner même si le client se déconnecte.</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">Il existe trois gestionnaires de cluster :</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*Autonome.* ce gestionnaire fait partie de Spark, ce qui facilite l'installation d'un cluster.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos.* il s'agit d'un gestionnaire de cluster général qui exécute également MapReduce et d'autres applications.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*HADOOP YARN.* il s'agit d'un gestionnaire de ressources dans Hadoop 3.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">Le jeu de données distribué résilient (RDD) est le composant principal de Spark. RDD recrée les données perdues et manquantes des données stockées dans la mémoire du cluster et stocke les données initiales provenant d'un fichier ou créées par programmation. Les RDD sont créés à partir de fichiers, de données en mémoire ou d'un autre RDD. La programmation des étincelles effectue deux opérations : la transformation et les actions. Transformation crée un nouveau RDD basé sur un RDD existant. Les actions renvoient une valeur à partir d'un RDD.</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">Les transformations et les actions s'appliquent également aux ensembles de données Spark et aux DataFrames. Un jeu de données est un ensemble distribué de données qui offre les avantages des RDD (fort typage, utilisation des fonctions lambda) avec les avantages du moteur d'exécution optimisé de Spark SQL. Un jeu de données peut être construit à partir d'objets JVM, puis manipulé à l'aide de transformations fonctionnelles (MAP, plantMap, filtre, etc.). Un DataFrame est un jeu de données organisé en colonnes nommées. Il est conceptuellement équivalent à une table dans une base de données relationnelle ou à une trame de données dans R/Python. DataFrames peut être construit à partir d'un large éventail de sources, telles que des fichiers de données structurés, des tables dans Hive/HBase, des bases de données externes sur site ou dans le cloud, ou des disques durs virtuels existants.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Les applications Spark incluent un ou plusieurs travaux Spark. Les travaux exécutent des tâches dans des exécuteurs et les exécuteurs exécutent des conteneurs DE FILS. Chaque exécuteur s’exécute dans un seul conteneur et des exécuteurs existent tout au long de la durée de vie d’une application. Un exécuteur est corrigé après le démarrage de l'application et LE FIL ne redimensionne pas le conteneur déjà alloué. Un exécuteur peut exécuter des tâches simultanément sur des données en mémoire.</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">Ensuite : présentation des solutions NetApp Spark</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">Ce document est consacré à l'architecture Apache Spark, aux utilisations client et au portefeuille de solutions de stockage NetApp dans le domaine de l'analytique Big Data et de l'intelligence artificielle. Nous présentons également les résultats de plusieurs tests basés sur des outils standard d'IA, de machine learning et de deep learning utilisés par rapport à un système Hadoop classique, afin de choisir la solution Spark appropriée.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">Tr-4570 : Solutions de stockage NetApp pour Apache Spark : architecture, cas d'utilisation et résultats des performances</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">Ce document est consacré à l'architecture Apache Spark, aux utilisations client et au portefeuille de solutions de stockage NetApp consacré à l'analytique Big Data et à l'intelligence artificielle (IA). Nous avons également présenté les résultats de plusieurs tests à l'aide des outils standard de l'IA, du machine learning (ML) et du deep learning (DL) par rapport à un système Hadoop standard qui vous permet de choisir la solution Spark adaptée. Il vous faut tout d'abord une architecture Spark, les composants appropriés et deux modes de déploiement (cluster et client).</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">Ce document présente également des cas d'utilisation pour résoudre les problèmes de configuration. Il présente également la gamme de solutions de stockage NetApp qui traite de l'analytique Big Data, de l'IA, DU ML et du DL avec Spark. Nous terminons ensuite avec les résultats des tests effectués à partir des cas d'utilisation propres à Spark et de la gamme de solutions NetApp Spark.</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">Cette section se concentre sur les défis clients liés à l'analytique Big Data et à l'IA/AM/AP dans des secteurs en croissance de données tels que le commerce, le marketing digital, la banque, la fabrication discrète, la fabrication des processus, américain et à ses services professionnels.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">Performances imprévisibles</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">Les déploiements Hadoop classiques utilisent généralement du matériel ordinaire. Pour optimiser les performances, vous devez configurer le réseau, le système d'exploitation, le cluster Hadoop, les composants de l'écosystème tels que Spark et le matériel. Même si vous ajustez chaque couche, il peut être difficile d'atteindre les niveaux de performance souhaités, car Hadoop fonctionne sur du matériel générique qui n'a pas été conçu pour assurer de hautes performances dans votre environnement.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">Pannes de nœuds et de supports</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">Même dans des conditions normales, le matériel de base est susceptible de subir des défaillances. Si un disque d'un nœud de données tombe en panne, le maître Hadoop considère par défaut que ce nœud est défectueux. Il copie ensuite les données spécifiques de ce nœud sur le réseau, des réplicas à un nœud en bon état. Ce processus ralentit les paquets réseau pour toutes les tâches Hadoop. Le cluster doit ensuite recopier les données et supprimer les données sur-répliquées lorsque le nœud défectueux revient à un état sain.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Dépendance vis-à-vis d'un fournisseur Hadoop</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Les distributeurs Hadoop disposent de leur propre distribution Hadoop avec leurs propres versions, qui dépendent des clients de ces distributions. Toutefois, de nombreux clients ont besoin d'une prise en charge pour les analyses en mémoire qui n'lient pas le client à des distributions Hadoop spécifiques. Ils ont besoin de la liberté de changer de distribution tout en bénéficiant de l'analytique.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">Manque de support pour plus d'une langue</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">Les clients ont souvent besoin d'un support pour plusieurs langues en plus des programmes MapReduce Java pour exécuter leurs tâches. Les options telles que SQL et les scripts offrent davantage de flexibilité pour obtenir les réponses, davantage d'options pour organiser et récupérer les données, et accélèrent le déplacement des données dans une structure analytique.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">Difficulté d'utilisation</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Pendant quelques temps, certains se plaignent du fait que Hadoop est difficile à utiliser. Même si Hadoop est devenu plus simple et plus puissant à chaque nouvelle version, cette critique a persisté. Hadoop exige de comprendre les modèles de programmation Java et MapReduce, ce qui représente un véritable défi pour les administrateurs de base de données et les équipes qui disposent de compétences classiques en matière de script.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">Structures et outils complexes</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">Les équipes chargées de l'IA sont confrontées à plusieurs défis. Même avec des connaissances avancées en science des données, les outils et les frameworks pour différents écosystèmes et applications de déploiement ne se traduisent pas toujours par une traduction unique. Une plate-forme de data science doit s'intégrer en toute transparence aux plateformes Big Data correspondantes intégrées sur Spark et offrir la facilité de déplacement des données, des modèles réutilisables, un code prêt à l'emploi et des outils qui prennent en charge les meilleures pratiques en matière de prototypage, de validation, de gestion des versions, de partage, de réutilisation, et de déploiement rapide des modèles en production.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">Pourquoi choisir NetApp ?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp peut améliorer votre expérience Spark de l'une des manières suivantes :</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">L'accès direct NetApp NFS (voir la figure ci-dessous) permet aux clients d'exécuter des tâches d'analytique Big Data sur leurs données NFSv3 ou NFSv4 existantes ou nouvellement sollicitées sans déplacer ou copier les données. Elle empêche plusieurs copies de données et n'a plus besoin de synchroniser les données avec une source.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">Optimisation du stockage et réduction de la réplication des serveurs. Par exemple, la solution Hadoop de NetApp E-Series nécessite deux à trois réplicas des données et la solution FAS Hadoop requiert une source de données, mais aucune réplication ou copie de données. Les solutions de stockage NetApp génèrent également moins de trafic serveur à serveur.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">Amélioration des tâches Hadoop et du comportement du cluster en cas de panne de disque ou de nœud.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">De meilleures performances d'ingestion des données.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">Autres configurations Apache Spark</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">Dans le secteur financier et de la santé par exemple, ces transferts de données doivent se conformer à des obligations légales, une tâche ardue. Dans ce scénario, l'accès direct NetApp NFS analyse les données financières et de santé à partir de leur emplacement d'origine. L'autre avantage clé est que l'accès direct NetApp NFS simplifie la protection des données Hadoop grâce aux commandes Hadoop natives et à l'activation des workflows de protection des données avec la gamme complète de solutions NetApp de gestion des données.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">L'accès direct NetApp NFS propose deux types d'options de déploiement pour les clusters Hadoop/Spark :</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">Par défaut, les clusters Hadoop ou Spark utilisent le système HDFS (Hadoop Distributed File System) pour le stockage des données et le système de fichiers par défaut. NetApp NFS direct peut remplacer le système HDFS par défaut par un stockage NFS comme système de fichiers par défaut, permettant ainsi une analytique directe sur les données NFS.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">Dans une autre option de déploiement, l'accès direct NetApp NFS prend en charge la configuration de NFS en tant que stockage supplémentaire et HDFS dans un cluster Hadoop ou Spark unique. Dans ce cas, le client peut partager des données via les exports NFS et y accéder depuis le même cluster, ainsi que des données HDFS.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">Les principaux avantages de l'accès direct NetApp NFS sont les suivants :</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">L'analyse des données depuis leur emplacement actuel empêche toute tâche fastidieuse de transférer des données analytiques vers une infrastructure Hadoop telle que HDFS.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">Réduction du nombre de répliques de trois à un.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">Les utilisateurs peuvent découpler les ressources de calcul et de stockage afin de les faire évoluer de façon indépendante.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">Protection des données grâce aux fonctionnalités avancées de gestion d'ONTAP.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Certification avec la plateforme de données Hortonworks.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">Déploiements d'analytique hybride.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">Réduction des délais de sauvegarde grâce à la fonctionnalité multithread dynamique.</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">Voir<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Pour la sauvegarde de données Hadoop, la sauvegarde et la reprise d'activité depuis le cloud vers les systèmes sur site, ce qui permet le DevTest sur les données Hadoop existantes, la protection des données et la connectivité multicloud, et l'accélération des workloads d'analytique.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">Les sections suivantes décrivent les fonctionnalités de stockage importantes pour les clients Spark.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">Hiérarchisation du stockage</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">La hiérarchisation du stockage Hadoop permet de stocker des fichiers de différents types de stockage conformément à une règle de stockage. Les types de stockage sont notamment<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block>,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block>,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block>,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block>, et<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>.</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">La figure suivante montre les performances des solutions NetApp pour un SSD Hadoop.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">Temps de tri de 1 To de données.</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">Tr-3969 solution NetApp E-Series pour Hadoop</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">La configuration NL-SAS de base utilisait huit nœuds de calcul et 96 disques NL-SAS. Cette configuration a généré 1 To de données en 4 minutes et 38 secondes. Voir<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> pour plus d'informations sur le cluster et la configuration du stockage.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">Grâce à TeraGen, la configuration SSD a généré 1 To de données 15,6 fois plus vite que la configuration NL-SAS. De plus, la configuration SSD utilisait deux fois moins de nœuds de calcul et deux fois moins de disques (24 disques SSD au total). En fonction de la durée d'exécution des tâches, elle était presque deux fois plus rapide que la configuration NL-SAS.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">Évolutivité des performances - évolutivité horizontale</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">Pour augmenter la puissance de calcul d'un cluster Hadoop dans une solution AFF, il est possible d'ajouter des nœuds de données avec un nombre approprié de contrôleurs de stockage. NetApp recommande de démarrer avec quatre nœuds de données par baie de contrôleur de stockage, puis d'augmenter le nombre de huit nœuds de données par contrôleur de stockage, en fonction des caractéristiques des charges de travail.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF et FAS sont parfaits pour l'analytique sur place. Vous pouvez ajouter des gestionnaires de nœuds et, sans interrompre l'activité, un contrôleur de stockage à la demande sans interrompre l'activité. Nous proposons des fonctionnalités riches avec AFF et FAS, notamment la prise en charge des supports NVMe, l'efficacité garantie, la réduction des données, la qualité de service, l'analytique prédictive, tiering, réplication, déploiement dans le cloud et sécurité. Pour aider les clients à satisfaire leurs besoins, NetApp propose des fonctionnalités telles que l'analytique des systèmes de fichiers, les quotas et l'équilibrage de la charge intégrée sans frais de licence supplémentaires. NetApp fournit de meilleures performances que ses concurrents en termes de nombre de tâches simultanées, de latence inférieure ou d'opérations simplifiées, et un débit par seconde supérieur à celui de ses concurrents. De plus, NetApp Cloud Volumes ONTAP s'exécute sur les trois principaux fournisseurs cloud.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">Évolutivité des performances - évolutivité verticale</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">Les fonctionnalités scale-up permettent d'ajouter des disques aux systèmes AFF, FAS et E-Series lorsque vous avez besoin de capacité de stockage supplémentaire. Avec Cloud Volumes ONTAP, l'évolutivité du stockage jusqu'au niveau des po est deux facteurs : Tiering des données peu utilisées vers un stockage objet à partir d'un stockage bloc et pile des licences Cloud Volumes ONTAP sans calcul supplémentaire.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">Protocoles multiples</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">Les systèmes NetApp prennent en charge la plupart des protocoles pour les déploiements Hadoop, notamment SAS, iSCSI, FCP, InfiniBand, Et NFS.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">Solutions opérationnelles et prises en charge</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MAPR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">certification</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">en tant que partenaire</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">Les solutions Hadoop décrites dans ce document sont prises en charge par NetApp. Ces solutions sont également certifiées avec les principaux distributeurs Hadoop. Pour plus d'informations, reportez-vous à la section<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> site, le<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> Et le Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> et<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> distants.</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">Suivant : public cible.</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">Précédent : de MapR-FS sur ONTAP NFS.</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">Meilleures pratiques NetApp pour les modules d'analytique sur place</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup Volume Guide des meilleures pratiques et de mise en œuvre</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">Version 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">Janvier 2022</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">Déplacez directement les données de HDFS et de MapR-FS vers NFS à l'aide de NetApp XCP.</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">Janvier 2020</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">XCP inclus comme Data Mover par défaut. Ajout de MapR-FS sur NFS et GPFS sur le transfert de données NFS.</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">Novembre 2018</block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp propose une solution simple et évolutive pour Splunk SmartStore qui optimise les performances et la résilience, tout en offrant un coût total de possession exceptionnel.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">Alors que les clients prennent conscience de la puissance et de la facilité d'utilisation de l'analytique Splunk, ils veulent naturellement indexer un volume de données croissant. À mesure que les volumes de données augmentent, l'infrastructure de calcul et de stockage est nécessaire pour y répondre.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">Hiérarchisation intelligente et réduction des coûts</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">Précédent : avantages de cette solution.</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">Alors que les clients prennent conscience de la puissance et de la facilité d'utilisation de l'analytique Splunk, ils veulent naturellement indexer un volume de données croissant. À mesure que les volumes de données augmentent, l'infrastructure de calcul et de stockage est nécessaire pour y répondre. Dans la mesure où les données plus anciennes sont référencées moins souvent, la consommation du même volume de ressources de calcul et du stockage primaire coûteux devient de plus en plus inefficace. Pour fonctionner à grande échelle, les clients tirent parti du déplacement des données fortement sollicitées vers un Tier plus économique, libérant ainsi le calcul et le stockage primaire pour les données fortement sollicitées.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore avec StorageGRID offre aux entreprises une solution évolutive, performante et économique. SmartStore étant conscient des données, il évalue automatiquement les modèles d'accès aux données afin de déterminer quelles données doivent être accessibles pour les analyses en temps réel (données fortement sollicitées) et quelles données doivent résider dans un stockage à long terme moins coûteux (données chaudes). SmartStore utilise l'API AWS S3 standard de manière dynamique et intelligente, et place les données dans le stockage S3 fourni par StorageGRID. L'architecture scale-out flexible de StorageGRID permet au niveau de données utiles d'augmenter à moindre coût en fonction des besoins. L'architecture basée sur des nœuds de StorageGRID assure une réponse optimale aux besoins en termes de performance et de coûts.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">L'image suivante illustre le Tiering Splunk et StorageGRID.</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">La combinaison leader du secteur Splunk SmartStore avec NetApp StorageGRID offre les avantages d'une architecture dissociée grâce à une solution complète.</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">Ensuite : présentation de la solution.</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">Cette section présente un récapitulatif des utilisations et des solutions proposées par NetApp pour répondre à différents besoins de protection de données Hadoop.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">Précédent : cas d'utilisation 5 - accélération des charges de travail analytiques.</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">Cette section présente un récapitulatif des utilisations et des solutions proposées par NetApp pour répondre à différents besoins de protection de données Hadoop. Grâce à la Data Fabric optimisée par NetApp, les clients peuvent :</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">Choisissez les solutions de protection des données adaptées en tirant parti des fonctionnalités avancées de gestion des données de NetApp et en intégrant les flux de travail natifs Hadoop.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Réduire la durée des fenêtres de sauvegarde des clusters Hadoop de près de 70 %.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Éliminez les effets des sauvegardes de clusters Hadoop sur les performances.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">Protégez les données multicloud et assurez l'accès aux données provenant de différents fournisseurs cloud simultanément à une seule source d'analytique.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">Création de copies de clusters Hadoop rapides et compactes à l'aide de la technologie FlexClone</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">Pour en savoir plus sur les informations fournies dans ce document, consultez ces documents et/ou sites web :</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">Solutions NetApp d'analytique Big Data</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">Charge de travail Apache Spark avec le stockage NetApp</block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Solutions de stockage NetApp pour Apache Spark</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">Apache Hadoop sur l'environnement Data Fabric optimisé par NetApp</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">Remerciements</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, Ingénieur commercial, ventes pour le district ANZ Victoria District, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, responsable du développement commercial, NetApp</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, Directeur MPSG, NetApp</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, Ingénieur système, ANZ Victoria District se, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">Janvier 2018</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">Mise à jour avec le cas d'utilisation n° 5 : accélération de la charge de travail analytique</block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">Le data Center d'entreprise moderne est un cloud hybride qui connecte plusieurs environnements d'infrastructures distribuées par le biais d'un plan de gestion continue des données avec un modèle d'exploitation cohérent, sur site et/ou dans plusieurs clouds publics. Pour profiter pleinement d'un cloud hybride, vous devez pouvoir déplacer les données en toute transparence entre vos environnements sur site et multicloud sans avoir à convertir les données ou à remanier l'application.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">Solution cloud hybride</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">Précédent : résultats des tests.</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">Nous avons indiqué qu'ils commencent leur transition vers le cloud hybride, soit en déplaçant le stockage secondaire vers le cloud pour des utilisations telles que la protection des données, soit en déplaçant les workloads moins stratégiques comme le développement d'applications et le DevOps vers le cloud. Elles passent par la suite à des charges de travail plus stratégiques. L'hébergement web et de contenu, le DevOps et le développement d'applications, les bases de données, l'analytique et les applications conteneurisées font partie des workloads de cloud hybride les plus répandus. La complexité, le coût et les risques liés aux projets d'IA des entreprises ont toujours entravé l'adoption de l'IA, de l'étape expérimentale à la production.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">Avec une solution de cloud hybride NetApp, les clients bénéficient d'outils intégrés de sécurité, de gouvernance des données et de conformité avec un seul panneau de commande pour la gestion des données et des workflows dans les environnements distribués, tout en optimisant le coût total de possession en fonction de leur consommation. La figure suivante est un exemple de solution proposée par un partenaire de services clouds chargé d'offrir une connectivité multicloud pour les données d'analytique Big Data des clients.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">Exemple de solution d'un partenaire de services clouds.</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">Dans ce scénario, les données IoT reçues dans AWS de différentes sources sont stockées dans un emplacement central dans NetApp Private Storage (NPS). Le stockage NPS est connecté aux clusters Spark ou Hadoop situés dans AWS et Azure, ce qui permet aux applications d'analytique Big Data exécutées dans plusieurs clouds d'accéder aux mêmes données. Voici les principaux défis et exigences de cette utilisation :</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">Les données doivent être reçues de différentes sources, telles que les environnements sur site et cloud, par le biais de différents capteurs et concentrateurs.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">La solution doit être efficace et économique.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">Le principal défi consiste à concevoir une solution économique et efficace qui offre des services d'analytique hybride entre les différents environnements sur site et cloud.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">Notre solution de protection des données et de connectivité multicloud résout le problème des applications d'analytique cloud de plusieurs hyperscalers. Comme illustré dans la figure ci-dessus, les données provenant des capteurs sont transmises et ingérées sur le cluster AWS Spark via Kafka. Les données sont stockées dans un partage NFS hébergé sur NPS, situé en dehors du fournisseur cloud au sein d'un data Center Equinix.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">Étant donné que NetApp NPS est connecté à Amazon AWS et Microsoft Azure via respectivement les connexions Direct Connect et Express route, les clients peuvent utiliser le module d'analytique sur place pour accéder aux données à partir de clusters d'analytique Amazon et AWS. Par conséquent, car les systèmes de stockage sur site et NPS exécutent le logiciel ONTAP,<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> Permet de mettre en miroir les données NPS dans le cluster sur site pour une analytique de cloud hybride entre les environnements sur site et clouds multiples.</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">Pour optimiser les performances, NetApp recommande généralement d'utiliser plusieurs interfaces réseau et des connexions directes ou des routes express pour accéder aux données à partir des instances cloud. Nous avons d'autres solutions de transfert de données, notamment<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> et<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> Aider les clients à concevoir des clusters Spark dans le cloud hybride intégrant la cohérence applicative, sécurisés et économiques.</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">Suivant : scripts Python pour chaque cas d'utilisation majeur.</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">Journalisation des modifications récentes apportées à la documentation sur les solutions NetApp</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">Journal des modifications des solutions NetApp</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">Modifications récentes de la documentation sur les solutions NetApp Les modifications les plus récentes sont répertoriées en premier.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">Toutes les modifications</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">*Date*</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">*Zone de solution*</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">*Description du changement*</block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">10/25/2022</block>
  <block id="80d05b7bca341d02b41c7f6cb32ad23b" category="cell">Ajout d'un lien vers le docuemntation VMware pour FSX ONTAP en tant que datastore NFS</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">Ajout d'une référence sur le blog pour la configuration du cloud hybride avec FSX ONTAP et VMC sur AWS SDDC utilisant VMware HCX</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">09/30/2022</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">Solution ajoutée pour la migration des charges de travail vers le datastore FSxN à l'aide de VMware HCX</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">09/29/2022</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">Solution ajoutée pour migrer des charges de travail vers le datastore ANF à l'aide de VMware HCX</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">09/14/2022</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">Ajout de liens vers les calculateurs de TCO et les simulateurs pour FSX/VMC et ANF/AVS</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">Ajout de l'option supplémentaire de datastore NFS pour AWS/VMC</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">08/25/2022</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">Base de données</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">Ajout de blog : modernisez votre exploitation de bases de données Oracle dans le cloud hybride avec le stockage Amazon FSX</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">L'IA</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">Nouvelle solution : NVIDIA ai Enterprise avec NetApp et VMware</block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">08/23/2022</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">Mise à jour de la dernière disponibilité de région pour toutes les options supplémentaires de datastore NFS</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">08/05/2022</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">Ajout des informations « redémarrer requis » pour les paramètres VMware ESXi et ONTAP recommandés</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">07/28/2022</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">Ajout de la solution de reprise après incident avec SnapCenter et Veeam pour AWS/VMC (stockage connecté invité)</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">07/21/2022</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">Ajout de la solution de reprise après incident avec CVO et JetStream pour AVS (stockage connecté à l'invité)</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">06/29/2022</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">Ajout du WP-7357 : déploiement de base de données Oracle sur les meilleures pratiques EC2/FSX</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">06/16/2022</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">Ajout du guide de conception NVIDIA DGX SuperPOD avec NetApp</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">06/10/2022</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">Ajout de la présentation AVS avec ANF native datastore et reprise après incident avec JetStream</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">06/07/2022</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">Mise à jour de la prise en charge de la région AVS pour correspondre aux annonces / support de présentation publique</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">Analytique des données</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Lien ajouté vers la solution NetApp EF600 avec Splunk Enterprise</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">06/02/2022</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">Ajout de la liste de disponibilité des datastores NFS pour l'environnement multicloud hybride NetApp avec VMware</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">05/20/2022</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">Nouveaux guides de conception et de déploiement BeeGFS pour SuperPOD</block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">04/01/2022</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">Contenu organisé du multicloud hybride avec les solutions VMware : pages d'accueil pour chaque hyperscaler et inclusion du contenu de la solution (cas d'utilisation) disponible</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">03/29/2022</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">Ajout d'un nouveau rapport technique : le DevOps avec NetApp Astra</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">03/08/2022</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">Ajout d'une nouvelle vidéo de démonstration : accélération du développement de logiciels avec Astra Control et la technologie NetApp FlexClone</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">03/01/2022</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">Ajout de nouvelles sections à NVA-1160: Installation d'Astra Control Center via OperatorHub et Ansible</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">02/02/2022</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">Généralités</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">Création de pages d'accueil pour mieux organiser le contenu pour l'IA et l'analytique moderne</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">01/22/2022</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">Ajout de TR : déplacement des données avec les workflows E-Series et BeeGFS pour l'IA et l'analytique</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">12/21/2021</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">Création de pages d'accueil pour mieux organiser le contenu pour la virtualisation et le multicloud hybride avec VMware</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">Ajout d'une nouvelle vidéo de démonstration : exploitez NetApp Astra Control pour réaliser des analyses post-mortem et restaurer votre application dans NVA-1160</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">12/06/2021</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">Création d'un environnement multicloud hybride avec du contenu VMware pour l'environnement de virtualisation et des options de stockage connecté à l'invité</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">11/15/2021</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">Ajout d'une nouvelle vidéo de démonstration : protection des données dans le pipeline ci/CD avec Astra Control dans NVA-1160</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">Analytique moderne</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">Nouveau contenu : meilleures pratiques pour Kafka fluide</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">11/02/2021</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">Automatisation</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">10/29/2021</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">Nouveau contenu : TR-4657 - Solutions de données de cloud hybride NetApp : Spark et Hadoop</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Protection automatisée des données pour les bases de données Oracle</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">10/26/2021</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">Ajout d'une section de blog pour les applications d'entreprise et les bases de données dans la vignette des solutions NetApp. Ajout de deux blogs aux blogs de base de données.</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">10/18/2021</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">Tr-4908 - Solutions de base de données dans le cloud hybride avec SnapCenter</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">10/14/2021</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">Ajout des parties 1-4 de la série de blogs NetApp avec VMware VCF</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">10/04/2021</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">Ajout d'une nouvelle vidéo de démonstration : migration des workloads à l'aide d'Astra Control Center vers NVA-1160</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">09/23/2021</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">Migration des données</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">Nouveau contenu : meilleures pratiques de NetApp pour NetApp XCP</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">09/21/2021</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">Nouveau contenu ou ONTAP pour les administrateurs VMware vSphere, automatisation VMware vSphere</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">09/09/2021</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">Ajout de l'intégration de l'équilibreur de charge F5 BIG-IP avec OpenShift dans NVA-1160</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">08/05/2021</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Intégration d'une nouvelle technologie à NVA-1160 - NetApp Astra Control Center sur Red Hat OpenShift</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">07/21/2021</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">Déploiement automatisé d'Oracle19c pour ONTAP sur NFS</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">07/02/2021</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">Tr-4897 - SQL Server sur Azure NetApp Files : vue du déploiement réel</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">06/16/2021</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">Ajout d'une nouvelle vidéo de démonstration : installation d'OpenShift Virtualization : Red Hat OpenShift avec NetApp</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">Ajout d'une nouvelle vidéo de démonstration, déploiement d'une machine virtuelle avec OpenShift Virtualization : Red Hat OpenShift avec NetAppp</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">06/14/2021</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Ajout de la solution : Microsoft SQL Server sur Azure NetApp Files</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">06/11/2021</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">Ajout d'une nouvelle vidéo de démonstration : migration des workloads à l'aide d'Astra Trident et de SnapMirror vers NVA-1160</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">06/09/2021</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">Ajout d'un nouveau cas d'utilisation à NVA-1160 - Advanced Cluster Management pour Kubernetes sur Red Hat OpenShift avec NetApp</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">05/28/2021</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">Ajout d'un nouveau cas d'utilisation dans NVA-1160 - OpenShift Virtualization with NetApp ONTAP</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">05/27/2021</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">Ajout d'un nouveau cas d'utilisation à NVA-1160- Colocation avec NetApp ONTAP</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">05/26/2021</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">NVA-1160 - Red Hat OpenShift avec NetApp</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">05/25/2021</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">Ajout d'un blog : installation de NetApp Trident sur Red Hat OpenShift – Comment résoudre le problème de Docker : « toomanyRequests » !</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">05/19/2021</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">Lien ajouté vers les solutions FlexPod</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">Solution ai Control plane convertie du PDF au HTML</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">05/17/2021</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">Ajout de la vignette Commentaires sur la solution à la page principale</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">05/11/2021</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">Déploiement automatisé d'Oracle 19c pour ONTAP sur NFS</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">05/10/2021</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">Nouvelle vidéo : comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 3</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">05/06/2021</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Base de données Oracle</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">Ajout d'un lien vers les bases de données RAC Oracle 19c sous FlexPod datacenter avec Cisco UCS et NetApp AFF A800 over FC</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">05/05/2021</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">Ajout de la vidéo sur l'automatisation et la NVA FlexPod (1155)</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">05/03/2021</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">Virtualisation des postes de travail</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">Ajout d'un lien vers les solutions de virtualisation des postes de travail FlexPod</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">04/30/2021</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">Vidéo : comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 2</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">04/26/2021</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">Blog ajouté : utiliser VMware Tanzu avec ONTAP pour accélérer votre transition vers Kubernetes</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">04/06/2021</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">Ajout de « à propos de ce référentiel »</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">03/31/2021</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Ajout du rapport TR-4886 - inférence d'IA à la périphérie : NetApp ONTAP avec Lenovo ThinkSystem solution Design</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">03/29/2021</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NVA-1157 - charge de travail Apache Spark avec la solution de stockage NetApp</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">03/23/2021</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">Vidéo : comment utiliser vvols avec NetApp et VMware Tanzu Basic, partie 1</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">03/09/2021</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">Ajout de contenu E-Series ; contenu par catégorie</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">03/04/2021</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">Nouveau contenu : commencer à utiliser l'automatisation des solutions NetApp</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">02/18/2021</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">Ajout du rapport TR-4597 : VMware vSphere pour ONTAP</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">02/16/2021</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">Ajout d'étapes de déploiement automatisées pour l'inférence d'IA en périphérie</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">02/03/2021</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">SAP</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">Ajout d'une page d'accueil pour l'ensemble du contenu SAP et SAP HANA</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">02/01/2021</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">VDI avec NetApp VDS, contenu ajouté aux nœuds GPU</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">01/06/2021</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">Nouvelle solution : NetApp ONTAP ai avec des systèmes NVIDIA DGX A100 et des switchs Ethernet Mellanox Spectrum (conception et déploiement)</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">12/22/2020</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">Version initiale du référentiel de solutions NetApp</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">IA/analytique</block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">Multicloud hybride</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">Applications d'entreprise et bases de données</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">Référentiel de solutions SAP</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">Pour en savoir plus sur les mises à jour SAP et SAP HANA, consultez le contenu « Historique des mises à jour » présent pour chacune des solutions de la <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">Protection et migration des données</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">Configurer les informations d'identification.</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">Créer des types d'informations d'identification. Pour les solutions impliquant ONTAP, vous devez configurer le type d'informations d'identification pour qu'il corresponde aux entrées de nom d'utilisateur et de mot de passe.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Accédez à Administration → types d'informations d'identification, puis cliquez sur Ajouter.</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">Collez le contenu suivant dans la configuration d'entrée :</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Collez le contenu suivant dans Configuration d'injecteur, puis cliquez sur Enregistrer :</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">Créer des informations d'identification pour ONTAP</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Accédez à Ressources → informations d'identification, puis cliquez sur Ajouter.</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">Entrez le nom et les informations d'organisation des informations d'identification ONTAP</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">Sélectionnez le type d'informations d'identification créé à l'étape précédente.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">Sous Détails du type, entrez le nom d'utilisateur et le mot de passe de vos clusters source et destination.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">Cliquez sur Save</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Créez des informations d'identification pour Oracle</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Entrez le nom et les détails de l'organisation pour Oracle</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">Sélectionnez le type d'informations d'identification de la machine.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">Sous Détails du type, entrez le nom d'utilisateur et le mot de passe des hôtes Oracle.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">Sélectionnez la méthode d'escalade des privilèges appropriée et saisissez le nom d'utilisateur et le mot de passe.</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">Répétez le processus si nécessaire pour une autre information d'identification pour l'hôte dr_oracle.</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">Configuration de ONTAP et CVO</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">*Configurer et lancer le modèle de travail.*</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">Créez le modèle de travail.</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">Entrez le nom Configuration ONTAP/CVO</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">Sélectionnez le type de travail ; Exécuter configure le système en fonction d'un manuel de vente.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Sélectionnez l'inventaire, le projet, le PlayBook et les identifiants correspondant au PlayBook.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">Sélectionnez le manuel de vente ontap_setup.yml pour un environnement sur site ou sélectionnez cvo_setup.yml pour la réplication vers une instance CVO.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">Collez les variables globales copiées à partir de l'étape 4 dans le champ variables du modèle sous l'onglet YAML.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">Nous utiliserons ce modèle et le copierons pour les autres manuels de vente.</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">Connectez-vous au site de support NetApp et téléchargez la dernière version de NetApp Astra Control Center. Une licence associée à votre compte NetApp est requise. Après avoir téléchargé le fichier tarball, transférez-le sur le poste de travail d'administration.</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Site d'inscription à Astra</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Pour commencer avec une licence d'essai d'Astra Control, visitez le<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">Déballez la boule tar et remplacez le répertoire de travail par le dossier obtenu.</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">Avant de commencer l'installation, poussez les images du centre de contrôle Astra vers un registre d'images.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Vous pouvez choisir de le faire avec Docker ou Podman ; les instructions pour les deux sont fournies dans cette étape.</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">Exportez le FQDN du Registre avec le nom de l'organisation/espace de noms/projet comme variable d'environnement 'regiant'.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">Connectez-vous au registre.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">Si vous utilisez<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utilisateur doit se connecter au registre privé, puis utiliser un jeton au lieu du mot de passe -<block ref="7d7ac4e834205786dd5590244b8666d4" prefix=" " category="inline-code"></block>.</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">Vous pouvez également créer un compte de service, attribuer un rôle d'éditeur de registre et/ou de visualiseur de registre (selon que vous avez besoin d'un accès Push/Pull) et vous connecter au registre à l'aide du jeton du compte de service.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">Créez un fichier de script shell et collez le contenu suivant dans celui-ci.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">Si vous utilisez des certificats non approuvés pour votre registre, modifiez le script de shell et utilisez-le<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> pour la commande push podman<block ref="0860f2134645f92280f543681a4900f8" prefix=" " category="inline-code"></block>.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">Rendre le fichier exécutable.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">Exécutez le script de shell.</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">Si vous utilisez<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utilisateur doit se connecter au registre privé, puis utiliser un jeton au lieu du mot de passe -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">Ensuite, chargez les certificats TLS du registre d'images sur les nœuds OpenShift. Pour ce faire, créez une config map dans l'espace de noms openshift-config à l'aide des certificats TLS et installez-la sur la configuration d'images du cluster pour que le certificat soit fiable.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">Si vous utilisez un registre interne OpenShift avec des certificats TLS par défaut de l'opérateur d'entrée portant une route, vous devez suivre l'étape précédente pour corriger le nom d'hôte de la route. Pour extraire les certificats de l'opérateur Ingress, vous pouvez utiliser la commande<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Créer un espace de noms<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Pour la pose de l'opérateur du centre de commande Astra.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">Créez un secret avec des informations d'identification pour vous connecter au registre d'images dans<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> espace de noms.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Modifiez le CR du conducteur du centre de contrôle Astra<block ref="29815934e812e1cfba6cc38eff0d17d3" prefix=" " category="inline-code"></block>, Qui est un ensemble de ressources que le Centre de contrôle Astra déploie. Dans la demande de modification de l'opérateur, recherchez la définition de déploiement pour<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> Et entrez le FQDN de votre registre avec le nom d'organisation tel qu'il a été donné lors de l'envoi des images au Registre (dans cet exemple,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>) en remplaçant le texte<block ref="e7fbb61ffc587682a801796b46db408a" prefix=" " category="inline-code"></block> et fournir le nom du secret que nous venons de créer dans<block ref="0d9b54b29da54379cca6b8782b9faae5" prefix=" " category="inline-code"></block> section. Vérifier les autres détails de l'opérateur, enregistrer et fermer.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">Créer l'opérateur en exécutant la commande suivante.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">Créez un espace de noms dédié pour installer toutes les ressources Astra Control Center.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">Créez le secret pour accéder au registre d'images dans cet espace de noms.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Modifiez le fichier CRD de l'Astra Control Center<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> Saisissez le nom de domaine complet, les détails du registre d'images, l'adresse e-mail de l'administrateur et d'autres détails.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">Créez le CRD du centre de contrôle Astra dans l'espace de noms créé pour celui-ci.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">Le fichier précédent<block ref="14eaa229cb5cb8abd16cee04a7cdc20c" prefix=" " category="inline-code"></block> Est la version minimale du CRD du centre de contrôle Astra. Si vous souhaitez créer le CRD avec plus de contrôle, comme définir un storageclass autre que la valeur par défaut pour la création de PVC ou fournir des détails SMTP pour les notifications de courrier électronique, vous pouvez modifier le fichier<block ref="70b058e54d2bda749060070a7f9c4e5c" prefix=" " category="inline-code"></block>, Entrez les détails nécessaires et utilisez-les pour créer le CRD.</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">Planification du manuel de réplication des fichiers binaires et des bases de données</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">Copier le modèle de travail créé précédemment.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">Recherchez le modèle d'installation ONTAP/CVO et, à l'extrême droite, cliquez sur Copy Template</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">Cliquez sur Modifier le modèle dans le modèle copié et changez le nom en Manuel de réplication de base de données et binaire.</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">Conserver les mêmes inventaires, projets, identifiants pour le modèle.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">Sélectionnez ora_Replication_cg.yml comme PlayBook à exécuter.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">Les variables resteront les mêmes, mais l'IP du cluster CVO devra être définie dans la variable dst_cluster_ip.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">Planifier le modèle de travail.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">Cliquez sur le modèle de manuel de réplication de base de données et binaire, puis cliquez sur programmes dans le jeu d'options supérieur.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">Cliquez sur Ajouter, ajouter un planning de noms pour la réplication binaire et de base de données, choisissez la date/l'heure de début au début de l'heure, choisissez votre fuseau horaire local et la fréquence d'exécution. La fréquence d'exécution sera souvent mise à jour de la réplication SnapMirror.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">Un planning distinct sera créé pour la réplication du volume de journaux afin de pouvoir le répliquer à une fréquence plus élevée.</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">Créer des types d'informations d'identification. Pour les solutions impliquant ONTAP, vous devez configurer le type d'identifiants pour qu'il corresponde aux entrées de nom d'utilisateur et de mot de passe. Nous ajouterons également des entrées pour Cloud Central et AWS.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Collez le contenu suivant dans Configuration d'injecteur et cliquez sur Enregistrer :</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">Créez des justificatifs pour ONTAP/CVO/AWS</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">Sous Type Details, entrez le nom d'utilisateur et le mot de passe de vos clusters source et CVO, Cloud Central/Manager, AWS Access/Secret Key et Cloud Central Refresh Token.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Créer des informations d'identification pour Oracle (Source)</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Entrez le nom et les détails de l'organisation de l'hôte Oracle</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Créez des informations d'identification pour la destination Oracle</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">Entrez le nom et les détails de l'organisation pour l'hôte Oracle de reprise sur incident</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">Sous Détails de type, entrez le nom d'utilisateur (utilisateur ec2 ou si vous l'avez modifié par défaut) et la clé privée SSH</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">Sélectionnez la méthode d'escalade des privilèges correcte (sudo) et entrez le nom d'utilisateur et le mot de passe si nécessaire.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">Avant de commencer l'installation, poussez les images du centre de contrôle Astra vers un registre d'images. Vous pouvez choisir de le faire avec Docker ou Podman, les instructions pour les deux sont fournies dans cette étape.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">Podman</block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">Si vous utilisez des certificats non approuvés pour votre registre, modifiez le script de shell et utilisez-le<block ref="0f5007fcae9fe13c2bbe7c6669b72178" prefix=" " category="inline-code"></block> pour la commande push podman<block ref="fec4f991fbdc39b7083cbf10fdc5cd9d" prefix=" " category="inline-code"></block>.</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">Lorsque vous utilisez des registres d'images privés qui ne sont pas de confiance publique, chargez les certificats TLS du registre d'images sur les nœuds OpenShift. Pour ce faire, créez une config map dans l'espace de noms openshift-config à l'aide des certificats TLS et installez-la sur la configuration d'images du cluster pour que le certificat soit fiable.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Créer un espace de noms<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Pour Astra Control Center.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">Connectez-vous à la console IUG de Red Hat OpenShift avec un accès cluster-admin.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">Sélectionnez Administrateur dans la liste déroulante perspective.</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Accédez à Operators &gt; OperatorHub et recherchez Astra.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">Sélectionnez<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> mosaïque et clic<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">Carreau de l'opérateur ACC</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">Sur l'écran installer l'opérateur, acceptez tous les paramètres par défaut et cliquez sur<block ref="349838fb1d851d3e2014b9fe39203275" prefix=" " category="inline-code"></block>.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">Détails de l'utilisateur ACC</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">Attendre la fin de l'installation par l'opérateur.</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">L'opérateur ACC attend la pose</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">Une fois l'installation de l'opérateur réussie, cliquez sur<block ref="6423332325de5a7100cc070ffad7a372" prefix=" " category="inline-code"></block>.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">Installation de l'ACC terminée</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">Cliquez ensuite sur<block ref="43f8527e733785e2ca7a92853d30e4f7" prefix=" " category="inline-code"></block> Dans la mosaïque Astra Control Center du conducteur.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">Créer une instance ACC</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Remplissez le<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> et cliquez sur<block ref="686e697538050e4664636337cc3b834f" prefix=" " category="inline-code"></block>.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">Vous pouvez modifier le nom de l'instance du Centre de contrôle Astra.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">Vous pouvez éventuellement activer ou désactiver Auto support. Il est recommandé de conserver la fonctionnalité Auto support.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Saisissez le nom de domaine complet pour Astra Control Center.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Accédez à la version du Centre de contrôle Astra ; la dernière est affichée par défaut.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Entrez un nom de compte pour le centre de contrôle Astra et des détails d'administrateur tels que le prénom, le nom et l'adresse e-mail.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">Entrez la règle de récupération du volume. La valeur par défaut est conservation.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">Dans le Registre d'images, entrez le FQDN de votre registre ainsi que le nom d'organisation tel qu'il a été donné lors de l'envoi des images au Registre (dans cet exemple,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>)</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">Si vous utilisez un registre qui nécessite une authentification, entrez le nom secret dans la section Registre d'images.</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Configurez les options d'échelle pour les limites de ressources Astra Control Center.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">Entrez le nom de la classe de stockage si vous souhaitez placer des ESV sur une classe de stockage non-défaut.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">Définissez les préférences de gestion de CRD.</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">Planification du manuel de réplication des journaux</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">Cliquez sur Modifier le modèle dans le modèle copié et modifiez le nom en Manuel de réplication des journaux.</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">Sélectionnez ora_Replication_logs.yml comme PlayBook à exécuter.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Cliquez sur le modèle de manuel de réplication des journaux, puis sur programmes dans le jeu d'options supérieur.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">Cliquez sur Ajouter, Ajouter un planning de noms pour la réplication de journaux, choisissez la date/l'heure de début au début de l'heure, choisissez votre fuseau horaire local et la fréquence d'exécution. La fréquence d'exécution sera souvent mise à jour de la réplication SnapMirror.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">Il est recommandé de définir le programme du journal à mettre à jour toutes les heures pour garantir la récupération de la dernière mise à jour horaire.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="doc">REVENDEURS</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="doc">Config VARS hôte</block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="doc">Plateformes NetApp</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">Les entreprises se tournent de plus en plus vers les pratiques DevOps pour créer de nouveaux produits, réduire les cycles de lancement et ajouter rapidement de nouvelles fonctionnalités. En raison de leur nature inné et agile, les conteneurs et les microservices ont un rôle essentiel dans l'accompagnement des pratiques DevOps. Cependant, la pratique du DevOps à l'échelle de production dans un environnement d'entreprise présente ses propres défis et impose certaines exigences à l'infrastructure sous-jacente, notamment :</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">Haute disponibilité à tous les niveaux de la pile</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">Simplicité des procédures de déploiement</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">Des opérations et des mises à niveau non disruptives</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">Une infrastructure programmable et basée sur des API pour suivre le rythme de l'agilité des microservices</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">Colocation avec garanties de performances</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">La possibilité d'exécuter simultanément des workloads virtualisés et conteneurisés</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">La possibilité de faire évoluer indépendamment l'infrastructure en fonction des besoins des workloads</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform est une plateforme Kubernetes d'entreprise entièrement prise en charge. Red Hat apporte plusieurs améliorations à l'open source Kubernetes afin de fournir une plateforme applicative avec tous les composants entièrement intégrés pour créer, déployer et gérer des applications conteneurisées.</block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">Pour en savoir plus, rendez-vous sur le site Web OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp propose plusieurs systèmes de stockage parfaitement adaptés aux data centers d'entreprise et aux déploiements de cloud hybride. Le portefeuille NetApp inclut des systèmes de stockage NetApp ONTAP, NetApp Element et E-Series, tous capables d'assurer un stockage persistant pour les applications conteneurisées.</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">Pour plus d'informations, rendez-vous sur le site Web de NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, déployés dans un environnement sur site et optimisés par la technologie de protection des données NetApp de confiance.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">Pour plus d'informations, rendez-vous sur le site Web NetApp Astra<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes telles que {k8s_distribution_name}.</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">Pour en savoir plus, rendez-vous sur le site Web Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp propose plusieurs plateformes de stockage compatibles avec Astra Trident et Astra Control pour le provisionnement, la protection et la gestion des données pour les applications conteneurisées.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">Les systèmes AFF et FAS exécutent NetApp ONTAP et fournissent aussi bien le stockage en mode fichier (NFS) que en mode bloc (iSCSI).</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP et ONTAP Select offrent les mêmes avantages, respectivement, dans le cloud et dans l'espace virtuel.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service (AWS/GCP) et Azure NetApp Files proposent un stockage basé sur des fichiers dans le cloud.</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">Les systèmes de stockage NetApp Element couvrent des cas d'utilisation de type bloc (iSCSI) dans un environnement hautement évolutif.</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">Chaque système de stockage du portefeuille NetApp simplifie la gestion et le déplacement des données entre les sites sur site et le cloud, de sorte que vos données sont là où sont vos applications.</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">Les pages suivantes contiennent des informations supplémentaires sur les systèmes de stockage NetApp validés dans la solution {solution_name} :</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="fcda5b98e8c212807dc088477e802757" category="inline-link-macro">NetApp Element</block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="9d312703c40c2d87b835076063682d59" category="paragraph">NetApp ONTAP est un puissant outil de gestion du stockage. Il inclut des fonctionnalités telles qu'une interface graphique intuitive, des API REST avec intégration de l'automatisation, des analyses prédictives et des actions correctives informées par IA, des mises à niveau matérielles sans interruption et des importations intersystèmes de stockage.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">Site Web NetApp ONTAP</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">Pour en savoir plus sur la baie de stockage NetApp ONTAP, consultez la<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP offre les fonctionnalités suivantes :</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">Système de stockage unifié avec accès et gestion simultanés aux données de NFS, CIFS, iSCSI, FC, FCoE, Et les protocoles FC-NVMe.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">Différents modèles de déploiement incluent des configurations matérielles sur site 100 % Flash, hybrides et 100 % HDD, des plateformes de stockage basées sur des VM sur un hyperviseur pris en charge comme ONTAP Select, et dans le cloud comme Cloud Volumes ONTAP.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">Amélioration de l'efficacité du stockage des données sur les systèmes ONTAP avec la prise en charge du Tiering automatique des données, de la compression des données à la volée, de la déduplication et de la compaction.</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">Stockage basé sur la charge de travail, contrôlé par QoS.</block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">Intégration transparente dans un cloud public pour le Tiering et la protection des données. ONTAP fournit également des fonctionnalités robustes de protection des données qui le distinguent dans tous les environnements :</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">*Copies NetApp Snapshot.* sauvegarde instantanée rapide des données en utilisant un espace disque minimal, sans impact supplémentaire sur les performances.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">*NetApp SnapMirror.* miroir les copies Snapshot des données d'un système de stockage à un autre. ONTAP prend également en charge la mise en miroir des données vers d'autres plateformes physiques et des services clouds natifs.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">*SnapLock de NetApp.* pour une administration efficace des données non réinscriptibles, en les écrivant sur des volumes spéciaux qui ne peuvent pas être écrasés ou effacés pour une période déterminée.</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">*NetApp SnapVault.* sauvegarde les données de plusieurs systèmes de stockage sur une copie Snapshot centrale qui sert de sauvegarde à tous les systèmes désignés.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">*NetApp SyncMirror.* permet la mise en miroir des données en temps réel au niveau RAID sur deux plexes différents de disques connectés physiquement au même contrôleur.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">*NetApp SnapRestore* permet une restauration rapide des données sauvegardées à la demande à partir de copies Snapshot.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">*NetApp FlexClone.* assure le provisionnement instantané d'une copie lisible et inscriptible d'un volume NetApp à partir d'une copie Snapshot.</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">Pour plus d'informations sur ONTAP, consultez le<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">NetApp ONTAP est disponible sur site, virtualisé ou dans le cloud.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp offre des AFF plateformes de stockage FAS (100 % Flash) et scale-out, sur mesure et dotées d'une faible latence, d'une protection des données intégrée et d'une prise en charge multiprotocole.</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">Ces deux systèmes sont optimisés par le logiciel de gestion des données NetApp ONTAP, le logiciel de gestion des données le plus avancé du secteur pour une gestion du stockage simplifiée, extrêmement disponible et intégrée au cloud qui répond aux besoins de Data Fabric en matière de rapidité, d'efficacité et de sécurité.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">Pour en savoir plus sur les plateformes NetApp AFF/FAS, cliquez<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select est un déploiement Software-defined de NetApp ONTAP qui peut être déployé sur un hyperviseur de votre environnement. Installée sur VMware vSphere ou KVM, cette solution offre toutes les fonctionnalités et l'expérience d'un système matériel ONTAP.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">Pour plus d'informations sur ONTAP Select, cliquez sur<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="section-title">Cloud Volumes ONTAP</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP est une version cloud de NetApp ONTAP qui peut être déployée dans un certain nombre de clouds publics, notamment Amazon AWS, Microsoft Azure et Google Cloud.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Pour plus d'informations sur Cloud Volumes ONTAP, cliquez sur<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp propose plusieurs produits pour orchestrer, gérer, protéger et migrer les applications conteneurisées avec état et leurs données.</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Control propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état optimisés par la technologie de protection des données NetApp. Astra Control Service est disponible pour la prise en charge des workloads avec état dans les déploiements Kubernetes cloud natifs. Le centre de contrôle Astra permet de prendre en charge les workloads avec état dans les déploiements sur site de plateformes Kubernetes d'entreprise telles que {k8s_distribution_name}. Pour en savoir plus, rendez-vous sur le site Web NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes telles que {k8s_distribution_name}. Pour en savoir plus, rendez-vous sur le site Web Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les produits NetApp validés pour les applications et la gestion du stockage persistant dans la solution {solution_name} :</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="inline-link-macro">NetApp Astra Control Center</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, déployés dans un environnement sur site et optimisé par les technologies NetApp de protection des données.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">Le centre de contrôle NetApp Astra peut être installé sur un cluster {k8s_distribution_name} sur lequel l'orchestrateur de stockage Astra Trident est déployé et configuré avec des classes de stockage et des systèmes back-end de stockage vers des systèmes de stockage NetApp ONTAP.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">ce document ici</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Pour en savoir plus sur Astra Trident, rendez-vous sur <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>.</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">Dans un environnement connecté au cloud, Astra Control Center utilise Cloud Insights pour fournir des fonctionnalités avancées de surveillance et de télémétrie. En l'absence de connexion Cloud Insights, un contrôle limité et une télémétrie (sept jours de metrics) sont disponibles et exportés vers les outils de contrôle natifs Kubernetes (Prometheus et Grafana) via des terminaux ouverts.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Le centre de contrôle Astra est entièrement intégré à l'écosystème NetApp AutoSupport et Active IQ qui fournit un soutien aux utilisateurs, fournit des conseils pour la résolution de problèmes et affiche des statistiques d'utilisation.</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">En plus de la version payante d'Astra Control Center, une licence d'évaluation de 90 jours est également disponible. La version d'évaluation est prise en charge par e-mail et dans le Channel Slack de la communauté. Les clients ont accès à ces ressources, à d'autres articles de la base de connaissances et à de la documentation disponibles dans le tableau de bord de support des produits.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Site Web d'Astra</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Pour en savoir plus sur la gamme Astra, consultez le <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes telles que {k8s_distribution_name}. Trident fonctionne avec l'ensemble de la gamme de solutions de stockage NetApp, notamment les systèmes de stockage NetApp ONTAP et Element, et prend également en charge les connexions NFS et iSCSI. Trident accélère le workflow DevOps en permettant aux utilisateurs d'approvisionner et de gérer le stockage à partir de leurs systèmes de stockage NetApp, sans intervention de l'administrateur de stockage.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">Un administrateur peut configurer plusieurs systèmes de stockage back-end en fonction des besoins des projets et des modèles de système de stockage. Ces fonctionnalités permettent notamment la compression, des types de disques spécifiques ou des niveaux de QoS garantissant un certain niveau de performance. Une fois définis, ces systèmes back-end peuvent être utilisés par les développeurs dans leurs projets pour créer des demandes de volume persistant et connecter le stockage persistant à la demande dans leurs conteneurs.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident a un cycle de développement rapide et, comme Kubernetes, est lancé quatre fois par an.</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">La dernière version d'Astra Trident est disponible en avril 22.04, en avril 2022. Une matrice de prise en charge pour quelle version de Trident a été testée avec laquelle une distribution Kubernetes est disponible<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">Depuis la version 20.04, l'opérateur Trident effectue la configuration de Trident. L'opérateur facilite les déploiements à grande échelle et offre un support supplémentaire, notamment l'auto-rétablissement des pods déployés dans le cadre de l'installation de Trident.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">Avec la version 21.01, un graphique Helm a été disponible pour faciliter l'installation de l'opérateur Trident.</block>
  <block id="662609908ab8e0f372d83dea3511370b" category="inline-link">procédure</block>
  <block id="8575c02ec176b0f64904bcbd79e81cba" category="list-text">Pour déployer Astra Control Center, vous devez disposer d'un ordinateur Ubuntu/RHEL avec Ansible. Suivez ceci<block ref="c1972c5d94c51919767b49f6cefbf6ba" category="inline-link-rx"></block> Pour Ubuntu et ceci<block ref="c4dab530b5bf152ded398881b8308451" category="inline-link-rx"></block> Pour RHEL.</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Clonez le référentiel GitHub qui héberge le contenu Ansible.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">Connectez-vous au site de support NetApp et téléchargez la dernière version de NetApp Astra Control Center. Une licence associée à votre compte NetApp est requise. Après avoir téléchargé le tarball, transférez-le sur le poste de travail.</block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Créez ou obtenez le fichier kubeconfig avec un accès administrateur au cluster {k8s_usercluster_name} sur lequel le centre de contrôle Astra doit être installé.</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">Définissez le répertoire sur<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">Modifiez le<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> classez les variables et remplissez-les avec les informations requises.</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">Utilisez le PlayBook pour déployer le centre de contrôle Astra. Le PlayBook requiert des privilèges root pour certaines configurations.</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">Exécutez la commande suivante pour exécuter le PlayBook si l'utilisateur exécutant le PlayBook est root ou a configuré un sudo sans mot de passe.</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">Si l'accès sudo basé sur un mot de passe est configuré, exécutez la commande suivante pour exécuter le PlayBook, puis saisissez le mot de passe sudo.</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">Cliquez sur Modifier le modèle dans le modèle copié et modifiez le nom en Manuel de restauration et de récupération.</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">Sélectionnez ora_Recovery.yml comme manuel de vente à exécuter.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">Ce PlayBook ne sera pas exécuté tant que vous n'êtes pas prêt à restaurer votre base de données sur le site distant.</block>
  <block id="f1fc5bef6accc6d1fab4ab73142df7f3" category="list-text">Pour déployer Astra Control Center sur un playbooks Ansible, vous devez utiliser un ordinateur Ubuntu/RHEL avec Ansible installé. Suivre la procédure<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Pour Ubuntu et la procédure<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Pour RHEL.</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">Connectez-vous au site de support NetApp et téléchargez la dernière version de NetApp Astra Control Center. Une licence associée à votre compte NetApp est requise. Après avoir téléchargé le tarball, transférez-le sur le poste de travail.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">Remplacez le répertoire par na_astra_control_suite.</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">Modifiez le<block ref="014d194d817c312b5ce910e74b4d3836" prefix=" " category="inline-code"></block> et remplissez les variables avec les informations requises.</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">Si l'utilisateur exécutant le PlayBook est root ou a configuré un sudo sans mot de passe, exécutez la commande suivante pour exécuter le PlayBook.</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">Si l'accès sudo basé sur un mot de passe est configuré, exécutez la commande suivante pour exécuter le PlayBook, puis saisissez le mot de passe sudo.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="doc">Validation de l'installation d'Oracle</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">Cela répertoriera les processus oracle si l'installation est terminée comme prévu et si la base de données oracle a démarré</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost ~]$ sqlplus / as sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le jeu Mai 6 12:52:51 2021 version 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. Tous droits réservés.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">Connecté à : Oracle Database 19c Enterprise Edition version 19.0.0.0.0 - production version 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">SQL&gt;</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">SQL&gt; sélectionnez nom, log_mode à partir de v$database; NAME LOG_MODE --------- ----------- JOURNAL D'ARCHIVAGE CDB2</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">SQL&gt; affiche les pdb</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">SQL&gt; col svrname form a30 SQL&gt; col dirname form a30 SQL&gt; sélectionnez svrname, dirname, nfsversion de v$dnfs_servers ;</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME DIRNAME NFSVERSION -------------------------------------- ------------------------- --------------- 172.21.126.200 /rhelora03_u02 NFSv4.0 172.21.126.200 /rhelora03_u03 NFSv4.0 172.21.126.200 /rhelora03_u01 NFSv4.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[oracle@localhost ~]$ sqlplus système@//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le jeu Mai 6 13:19:57 2021 version 19.8.0.0.0</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">Entrez le mot de passe : heure de la dernière connexion réussie : mercredi 05 2021 17 mai 11:11 -04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">SQL&gt; show user USER user est "SYSTEM" SQL&gt; show con_name CON_NAME CDB2_PDB1</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">Où obtenir de l'aide ?</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">La communauté NetApp solution Automation prend en charge le Channel Slack</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">Si vous avez besoin d'aide avec la boîte à outils, veuillez vous joindre à la <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> et recherchez le canal solution-automation pour poser vos questions ou vos questions.</block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">Cette solution est conçue dans un environnement de cloud hybride pour prendre en charge les bases de données de production sur site pouvant atteindre l'ensemble des clouds publics populaires pour les opérations de développement/test et de reprise d'activité.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">Conditions requises pour le SnapCenter</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">Précédent : architecture de solutions.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">Cette solution prend en charge toutes les bases de données actuellement prises en charge par SnapCenter, bien que seules les bases de données Oracle et SQL Server soient démontrées ici. Cette solution est validée pour les charges de travail de base de données virtualisées, bien que les charges de travail sans système d'exploitation soient également prises en charge.</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">Nous supposons que les serveurs de base de données de production sont hébergés sur site et que les volumes BDD sont présentés aux hôtes BDD à partir d'un cluster de stockage ONTAP. Le logiciel SnapCenter est installé sur site pour la sauvegarde des bases de données et la réplication des données dans le cloud. Un contrôleur Ansible est recommandé, mais pas nécessaire pour l'automatisation du déploiement de bases de données ou la synchronisation de la configuration des bases de données et des noyaux du système d'exploitation avec une instance de reprise d'activité en attente ou des instances de développement/test dans le cloud public.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">De production</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">*Sur place*</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">Toutes les bases de données et versions prises en charge par SnapCenter</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 ou version ultérieure</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 ou version ultérieure</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">Cluster ONTAP 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">LIFs intercluster configurées</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">Connectivité sur site vers un VPC dans le cloud (VPN, interconnexion, etc.)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">Ports réseau ouverts - ssh 22 - tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">*Cloud - AWS*</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Connecteur Cloud Manager</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">Correspondance des instances EC2 du système d'exploitation de base de données avec sur site</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">*Cloud - Azure*</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">Correspondance des serveurs virtuels Azure du système d'exploitation de base de données sur site</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">*Cloud - GCP*</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">Mise en correspondance des instances de DB OS Google Compute Engine avec sur site</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">Suivant : configuration des prérequis.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">Cette page décrit la méthode automatisée de déploiement d'Oracle19c sur le stockage ONTAP NetApp.</block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">Les entreprises automatisent leur environnement pour gagner en efficacité, accélérer les déploiements et réduire les efforts manuels. Les outils de gestion de la configuration comme Ansible sont utilisés pour rationaliser les opérations des bases de données d'entreprise. Avec cette solution, nous vous montrerons comment utiliser Ansible pour automatiser la protection des données d'Oracle avec NetApp ONTAP. Grâce à la possibilité pour les administrateurs du stockage, les administrateurs système et les administrateurs de bases de données de configurer la réplication des données de manière cohérente et rapide vers un data Center hors site ou un cloud public, vous bénéficiez des avantages suivants :</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">Éliminez les complexités de la conception et les erreurs humaines, et mettez en œuvre un déploiement cohérent et des meilleures pratiques reproductibles</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">Diminuer le temps de configuration de la réplication intercluster, de l'instanciation CVO et de la restauration des bases de données Oracle</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">Augmentez la productivité des administrateurs de bases de données, des systèmes et des administrateurs du stockage</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">Assure le flux de travail de restauration de base de données pour faciliter le test d'un scénario de reprise après incident.</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp fournit aux clients des modules et des rôles Ansible validés pour accélérer le déploiement, la configuration et la gestion du cycle de vie de votre environnement de base de données Oracle. Cette solution fournit des instructions et un code de PlayBook Ansible pour vous aider à :</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">Réplication sur site à site</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">Création des lifs intercluster sur la source et la destination</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">Établir le cluster et le peering de vServers</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Créer et initialiser SnapMirror des volumes Oracle</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Créez un planning de réplication via AWX/Tower pour les binaires, les bases de données et les journaux Oracle</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">Restaurez la base de données Oracle sur le volume de destination et connectez-la en ligne</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">Sur site vers CVO dans AWS</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">Créer un connecteur AWS</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">Créez l'instance CVO dans AWS</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Ajoutez un cluster sur site à Cloud Manager</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">Création des lifs intercluster sur la source</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">Pour en savoir plus ou pour commencer, consultez les vidéos de présentation ci-dessous.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">Déploiements AWX/Tower</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">Partie 1: À définir</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="list-text">vidéo</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">Partie 2: À déterminer</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">ici pour commencer à utiliser la solution</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">Lorsque vous êtes prêt, cliquez sur <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">Les solutions NetApp pour bases de données d'entreprise constituent un ensemble de fonctionnalités stratégiques et technologiques qui démontrent les fonctionnalités du stockage NetApp dans les principales bases de données d'entreprise.</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">Solutions NetApp pour bases de données d'entreprise</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">Ce document traite du déploiement en temps réel d'un groupe de disponibilité Microsoft SQL Server Always On Availability (AOAG) sur Azure NetApp Files exploitant des machines virtuelles Azure.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">Tr-4897 : SQL Server sur Azure NetApp Files - vue du déploiement réel</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">Les services IT sont confrontés à des changements constants. Selon Gartner, près de 75 % des bases de données auront besoin d'un stockage cloud d'ici 2022. En tant que système de gestion de base de données relationnelle (SGBDR) de premier plan, Microsoft SQL Server est la solution de choix pour les applications et les organisations Windows conçues pour la plate-forme et qui utilisent SQL Server pour tout, de la planification des ressources d'entreprise (ERP) à l'analytique en passant par la gestion de contenu. SQL Server a permis de révolutionner la manière dont les entreprises gèrent des jeux de données massifs et exploitent leurs applications pour répondre aux besoins en termes de performances de schéma et de requêtes.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">La plupart des départements IT adoptent une approche axée sur le cloud. Les clients qui ont entamé une phase de transformation évaluent leur paysage IT actuel, puis migrent leurs workloads de bases de données vers le cloud d'après un exercice d'évaluation et de découverte. Certains facteurs justifient la migration vers le cloud : l'élasticité/le bursting, la sortie du data Center, la consolidation du data Center, les scénarios de fin de vie, les fusions, des acquisitions, etc. Les raisons de la migration peuvent varier en fonction de chaque entreprise et de leurs priorités business. Lors de votre transition vers le cloud, il est primordial de choisir le bon stockage cloud pour exploiter toute la puissance du déploiement cloud des bases de données SQL Server.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">Cas d'utilisation</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">La migration de l'environnement SQL Server vers Azure et l'intégration de SQL Server avec le vaste éventail de fonctionnalités PaaS (plateforme en tant que service) d'Azure, telles que Azure Data Factory, Azure IoT Hub et Azure machine learning génèrent une valeur commerciale considérable pour soutenir la transformation digitale. En adoptant le cloud, les entités commerciales respectives peuvent se concentrer sur la productivité et fournir de nouvelles fonctionnalités et améliorations plus rapidement (cas d'utilisation du DevTest) qu'en se reposant sur le modèle CapEx ou sur le cloud privé classique. Ce document traite du déploiement en temps réel d'un groupe de disponibilité Microsoft SQL Server Always On Availability (AOAG) sur Azure NetApp Files exploitant des machines virtuelles Azure.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files fournit un stockage de grande qualité avec des partages de fichiers disponibles en continu. Les partages disponibles en continu sont requis par les bases de données de production SQL Server sur le partage de fichiers SMB afin de s'assurer que le nœud a toujours accès au stockage de la base de données, notamment lors de scénarios de perturbations tels que les mises à niveau ou les défaillances du contrôleur. Les partages de fichiers disponibles en permanence permettent d'éviter la réplication des données entre les nœuds de stockage. Azure NetApp Files utilise l'évolutivité scale-out SMB 3.0, les pointeurs permanents et le basculement transparent pour prendre en charge la continuité de l'activité en cas d'interruptions planifiées ou non, y compris de nombreuses tâches administratives.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">Lors de la planification de migrations clouds, il est recommandé d'évaluer systématiquement la meilleure approche à utiliser. L'approche la plus courante et la plus simple pour la migration d'applications est le réhébergement (aussi appelé lift and shift). L'exemple de scénario fourni dans ce document utilise la méthode de réhébergement. SQL Server sur serveurs virtuels Azure avec Azure NetApp Files vous permet d'utiliser des versions complètes de SQL Server dans le cloud sans avoir à gérer votre matériel sur site. En outre, les machines virtuelles SQL Server simplifient vos coûts de licence lorsque vous payez à l'utilisation, et vous offrent plus de souplesse et d'capacités de bursting pour les scénarios de développement, de test et de mise à jour immobilière.</block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">Certaines conditions préalables doivent être configurées à la fois sur site et dans le cloud avant d'exécuter des workloads de base de données de cloud hybride. La section suivante fournit un résumé de ce processus de haut niveau et les liens suivants fournissent des informations supplémentaires sur la configuration du système nécessaire.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">Configuration des prérequis</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">Précédent : exigences relatives aux solutions.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="list-text">Installation et configuration de SnapCenter</block>
  <block id="df3fb602185c77a88bab186791d02636" category="list-text">Configuration du stockage du serveur de bases de données sur site</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="list-text">Licences requises</block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="list-text">Mise en réseau et sécurité</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">Identifiant NetApp Cloud Central</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">Accès au réseau à partir d'un navigateur Web vers plusieurs noeuds finaux</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">Emplacement réseau d'un connecteur</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">Les autorisations du fournisseur cloud</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">Mise en réseau pour des services individuels</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">Remarques importantes :</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Où déployer Cloud Manager Connector ?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Architecture et dimensionnement de Cloud volumes ONTAP</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">Un seul nœud ou une haute disponibilité ?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">Vous trouverez des informations supplémentaires sur les liens suivants :</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">Sur site</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">Cloud public</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">Suivant : conditions préalables sur site.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">Les entreprises automatisent leur environnement pour gagner en efficacité, accélérer les déploiements et réduire les efforts manuels. Les outils de gestion de la configuration comme Ansible sont utilisés pour rationaliser les opérations des bases de données d'entreprise. Dans cette solution, nous vous montrerons comment utiliser Ansible pour automatiser le provisionnement et la configuration d'Oracle 19c avec NetApp ONTAP. En permettant aux administrateurs du stockage, aux administrateurs système et aux administrateurs de bases de données de déployer de façon cohérente et rapide un nouveau stockage, de configurer des serveurs de base de données et d'installer le logiciel Oracle 19c, vous bénéficiez des avantages suivants :</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">Réduction du temps de provisionnement du stockage, de la configuration des hôtes de base de données et d'installation d'Oracle</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">Permettre l'évolutivité du stockage et des bases de données en toute simplicité</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Créer et configurer le stockage ONTAP NFS pour Oracle Database</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">Installez Oracle 19c sur RedHat Enterprise Linux 7/8 ou Oracle Linux 7/8</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">Configuration d'Oracle 19c sur un système de stockage NFS ONTAP</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">Partie 1 : mise en route, exigences, détails d'automatisation et configuration initiale AWX/Tour</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">Partie 2 : variables et exécution du manuel de vente</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">Déploiement de l'interface de ligne de</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">Partie 1 : mise en route, exigences, détails d'automatisation et configuration de l'hôte Ansible Control</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">Mitch Blackburn, Pat Sinthusan, NetApp</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">Ce guide des meilleures pratiques a pour objectif d'aider les administrateurs du stockage et des bases de données à déployer correctement Microsoft SQL Server sur un système de stockage NetApp EF-Series.</block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">Tr-4794 : bases de données Oracle sur la gamme EF-Series NetApp</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn, Ebin Kadavy, NetApp</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">Le document TR-4794 a pour objectif d'aider les administrateurs du stockage et des bases de données à déployer Oracle sur un système de stockage NetApp EF-Series.</block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">Tr-3633 : bases de données Oracle sur ONTAP</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">Jeffrey Steiner, NetApp</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">Consulter le <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> Pour déterminer si l'environnement, les configurations et les versions spécifiés dans le TR-3633 sont pris en charge par votre environnement.</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Architectures de solution avec Azure NetApp Files</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="list-text">Avantages liés au déploiement de Azure NetApp Files pour SQL Server</block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">Guide de déploiement SQL Server sur Azure à l'aide de Azure NetApp Files</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Tolérance aux pannes, haute disponibilité et résilience avec Azure NetApp Files</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">Que vous souhaitiez cibler un cloud 100 % cloud ou un cloud hybride avec des bases de données étendues, Azure NetApp Files offre d'excellentes options pour déployer et gérer les charges de travail de base de données tout en réduisant le coût total de possession en rendant les données requises de manière transparente pour la couche applicative.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">Ce document contient des recommandations pour la planification, la conception, l'optimisation et l'évolutivité des déploiements Microsoft SQL Server avec Azure NetApp Files, qui peuvent varier considérablement d'une implémentation à l'autre. Les détails techniques de l'implémentation et les exigences métier détermineront la solution à adopter pour chaque projet.</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">Vous pouvez maintenant utiliser Azure NetApp Files pour héberger la base de données et le témoin de partage de fichiers pour le cluster SQL Server.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">Vous pouvez accélérer les temps de réponse des applications et assurer une disponibilité de 99.9999 % pour accéder aux données SQL Server où et quand vous en avez besoin.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">Vous pouvez simplifier la complexité globale du déploiement de SQL Server et de la gestion continue, telles que l'entrelacement raid, avec un redimensionnement simple et instantané.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">Ses fonctionnalités intelligentes vous permettent de déployer des bases de données SQL Server en quelques minutes et d'accélérer leurs cycles de développement.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Si Azure Cloud est la destination incontournable, Azure NetApp Files est la solution de stockage idéale pour optimiser le déploiement.</block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Avant d'installer Cloud Manager Connector et Cloud Volumes ONTAP et de configurer SnapMirror, nous devons préparer notre environnement cloud. Cette page décrit le travail à effectuer, ainsi que les considérations relatives au déploiement de Cloud Volumes ONTAP.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">Conditions préalables au cloud public</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">Précédent : conditions préalables sur site.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Liste de contrôle des conditions préalables au déploiement de Cloud Manager et de Cloud Volumes ONTAP</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">Emplacement réseau d'un connecteur</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">documentation cloud</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">Pour en savoir plus sur ce dont vous avez besoin pour démarrer, consultez le site<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">Considérations</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">1. Qu'est-ce qu'un connecteur Cloud Manager ?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">Dans la plupart des cas, un administrateur de compte Cloud Central doit déployer un connecteur dans votre réseau cloud ou sur site. Ce connecteur permet à Cloud Manager de gérer les ressources et les processus au sein de votre environnement de cloud public.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">Pour plus d'informations sur les connecteurs, visitez notre<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2. Dimensionnement et architecture de Cloud Volumes ONTAP</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Lors du déploiement de Cloud Volumes ONTAP, vous avez le choix entre un package prédéfini ou la création de votre propre configuration. Bon nombre de ces valeurs peuvent être modifiées ultérieurement, sans interrompre l'activité, mais certaines décisions clés doivent être prises avant le déploiement, en fonction des charges de travail à déployer dans le cloud.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">Outil de dimensionnement CVO</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">Chaque fournisseur de cloud propose différentes options de déploiement et chaque workload dispose de ses propres propriétés. NetApp a une<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> cela peut aider à dimensionner correctement les déploiements en fonction de la capacité et des performances, mais il a été conçu autour de certains concepts de base qui méritent d'être pris en compte :</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">Capacité requise</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">Capacité réseau de la machine virtuelle du cloud</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">Les caractéristiques de performances du stockage cloud</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">L'essentiel est de planifier une configuration qui non seulement répond aux besoins actuels en termes de capacité et de performances, mais qui étudie également la croissance future. Ce chiffre est généralement appelé marge de capacité et marge de performance.</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">Si vous souhaitez des informations complémentaires, lisez la documentation sur la planification correcte<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, et<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3. Un seul nœud ou haute disponibilité ?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">Dans tous les clouds, il est possible de déployer Cloud volumes ONTAP dans un seul nœud ou dans une paire haute disponibilité en cluster avec deux nœuds. Selon le cas de figure, vous pouvez déployer un nœud unique pour réduire les coûts ou une paire haute disponibilité pour améliorer la disponibilité et la redondance.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">Pour une reprise après incident ou l'exécution de systèmes de stockage temporaires pour le développement et le test, des nœuds uniques sont courants, car l'impact d'une panne d'infrastructure soudaine ou d'un zone est moindre. Toutefois, pour toutes les utilisations de production, et lorsque les données ne se trouvent que dans un seul emplacement ou que le dataset doit avoir plus de redondance et de disponibilité, la haute disponibilité est recommandée.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">Pour plus d'informations sur l'architecture de la version haute disponibilité de chaque Cloud, consultez la documentation pour<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> et<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">Présentation de mise en route.</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">Cette section fournit des informations sur les facteurs à prendre en compte lors de la migration de la base de données Oracle sur site vers l'instance AWS EC2 et le stockage FSX.</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">Migration de base de données sur site vers un cloud public</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">Précédent : gestion de la base de données.</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">La migration de bases de données constitue un défi de taille. La migration d'une base de données Oracle sur site vers le cloud ne fait pas exception.</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">Les sections suivantes présentent des facteurs clés à prendre en compte lors de la migration des bases de données Oracle vers le cloud public AWS avec la plateforme de stockage FSX et de calcul EC2 AWS.</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">Le stockage ONTAP est disponible sur site</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">Créez une instance EC2 de calcul cible correspondant à l'instance sur site.</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">Provisionner des volumes de base de données de taille équivalente à partir de la console FSX.</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">Montez les volumes de base de données FSX sur l'instance EC2.</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">Configurer la réplication SnapMirror entre les volumes de base de données sur site et les volumes de base de données FSX cible. La synchronisation initiale peut prendre un certain temps pour déplacer les données source principales, mais les mises à jour incrémentielles suivantes sont bien plus rapides.</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">Brisez les volumes en miroir, exécutez la restauration Oracle sur la cible et créez la base de données pour le service.</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">Pointez les applications vers la base de données Oracle dans le cloud.</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">Le stockage ONTAP n'est pas disponible sur site</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">Si la base de données Oracle sur site est hébergée sur un système de stockage tiers autre que ONTAP, la migration de base de données est basée sur la restauration d'une copie de sauvegarde de base de données Oracle. Vous devez lire le journal d'archivage pour le mettre à jour avant de basculer.</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3 peut être utilisé comme emplacement de stockage intermédiaire pour le déplacement et la migration des bases de données. Reportez-vous aux étapes de haut niveau suivantes pour cette méthode :</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">Provisionnement d'une nouvelle instance EC2 de correspondance comparable à celle de l'instance sur site</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">Provisionnez des volumes de base de données égaux à partir du stockage FSX et montez les volumes sur l'instance EC2.</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">Créer une copie de sauvegarde Oracle au niveau du disque.</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">Déplacez la copie de sauvegarde vers le stockage AWS S3.</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">Recréez le fichier de contrôle Oracle, restaurez et restaurez la base de données en extrayant les données et le journal d'archivage à partir du stockage S3.</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">Synchronisez la base de données Oracle cible avec la base de données source sur site.</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">Lors du basculement, arrêtez l'application et la base de données Oracle source. Copiez les derniers journaux d'archivage et appliquez-les à la base de données Oracle cible pour la mettre à jour.</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">Démarrez la base de données cible pour l'accès des utilisateurs.</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">Redirection de l'application vers la base de données cible pour terminer le basculement.</block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">Cette section décrit en détail la gestion d'AWS RDS Custom pour les bases de données Oracle via l'interface utilisateur d'SnapCenter en complément de l'interface de console AWS RDS.</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">Précédent : procédures de déploiement.</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">En plus de la console de gestion AWS EC2 et FSX, le nœud de contrôle Ansible et l'outil d'interface utilisateur SnapCenter sont déployés pour la gestion de la base de données dans cet environnement Oracle.</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Un nœud de contrôle Ansible peut être utilisé pour gérer la configuration de l'environnement Oracle avec des mises à jour parallèles qui permettent de synchroniser les instances principales et de secours pour les mises à jour du noyau ou des correctifs. Les fonctionnalités de basculement, de resynchronisation et de restauration peuvent être automatisées avec le kit d'automatisation NetApp pour archiver rapidement la restauration et la disponibilité des applications avec Ansible. Certaines tâches reproductibles de gestion de base de données peuvent être exécutées à l'aide d'un PlayBook pour réduire les erreurs humaines.</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">Présentation du plug-in SnapCenter pour bases de données Oracle</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">L'outil de l'interface utilisateur SnapCenter peut effectuer une sauvegarde Snapshot de base de données, une restauration instantanée, le clonage des bases de données, etc. Avec le plug-in SnapCenter pour bases de données Oracle. Pour plus d'informations sur les fonctionnalités du plug-in Oracle, consultez le <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>.</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">Les sections suivantes expliquent comment les principales fonctions de gestion de base de données Oracle sont exécutées grâce à l'interface utilisateur d'SnapCenter :</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">Sauvegardes Snapshot de bases de données</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">Restauration instantanée des bases de données</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">Création d'un clone de base de données</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">Le clonage de bases de données crée une réplique d'une base de données primaire sur un hôte EC2 distinct pour la restauration des données en cas d'erreur ou de corruption de données logiques. Les clones peuvent également être utilisés pour le test d'applications, le débogage, la validation des correctifs, etc.</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">Prise d'un instantané</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">Une base de données Oracle EC2/FSX est régulièrement sauvegardée à des intervalles configurés par l'utilisateur. L'utilisateur peut également effectuer une sauvegarde Snapshot complète à tout moment. Cela s'applique à la fois aux sauvegardes Snapshot de bases de données complètes et aux sauvegardes Snapshot de journaux d'archive uniquement.</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">Prise d'un instantané complet de la base de données</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">Un instantané complet de la base de données inclut tous les fichiers Oracle, y compris les fichiers de données, les fichiers de contrôle et les fichiers journaux d'archivage.</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">Connectez-vous à l'interface utilisateur SnapCenter et cliquez sur Ressources dans le menu gauche. Dans la liste déroulante vue, passez à la vue Groupe de ressources.</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">Cliquez sur le nom de la ressource de sauvegarde complète, puis sur l'icône Sauvegarder maintenant pour lancer une sauvegarde supplémentaire.</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">Cliquez sur Sauvegarder, puis confirmez la sauvegarde pour lancer une sauvegarde complète de la base de données.</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">Dans la vue Ressources de la base de données, ouvrez la page de sauvegarde gérée de la base de données pour vérifier que la sauvegarde unique a bien été effectuée. Une sauvegarde complète de la base de données crée deux snapshots : un pour le volume de données et un pour le volume du journal.</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">Prise d'un instantané du journal d'archivage</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">Un instantané du journal d'archivage est uniquement pris pour le volume du journal d'archivage Oracle.</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">Connectez-vous à l'interface utilisateur SnapCenter et cliquez sur l'onglet Ressources dans la barre de menus située à gauche. Dans la liste déroulante vue, passez à la vue Groupe de ressources.</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">Cliquez sur le nom de la ressource de sauvegarde du journal, puis sur l'icône Sauvegarder maintenant pour lancer une sauvegarde supplémentaire des journaux d'archivage.</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">Cliquez sur Sauvegarder, puis confirmez la sauvegarde pour lancer une sauvegarde du journal d'archivage.</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">Dans la vue Ressources de la base de données, ouvrez la page de sauvegarde gérée de la base de données pour vérifier que la sauvegarde du journal d'archivage unique a bien été effectuée. Une sauvegarde du journal d'archivage crée un snapshot pour le volume du journal.</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">Restauration à un point dans le temps</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">La restauration basée sur SnapCenter à un point dans le temps est exécutée sur le même hôte d'instance EC2. Procédez comme suit pour effectuer la restauration :</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">Dans l'onglet Ressources SnapCenter &gt; vue base de données, cliquez sur le nom de la base de données pour ouvrir la sauvegarde de la base de données.</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">Sélectionnez la copie de sauvegarde de la base de données et le point dans le temps souhaité pour la restauration. Marquez également le numéro SCN correspondant au point dans le temps. La restauration ponctuelle peut être effectuée à l'aide de l'heure ou du SCN.</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">Mettez en surbrillance l'instantané du volume du journal et cliquez sur le bouton Monter pour monter le volume.</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">Sélectionnez l'instance EC2 principale pour monter le volume du journal.</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">Vérifiez que le travail de montage s'est terminé correctement. Vérifiez également sur l'hôte de l'instance EC2 pour voir le volume du journal monté et le chemin du point de montage.</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">Copiez les journaux d'archivage du volume du journal monté dans le répertoire du journal d'archivage en cours.</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">Revenez à l'onglet ressource SnapCenter &gt; page de sauvegarde de la base de données, mettez en surbrillance la copie Snapshot de données, puis cliquez sur le bouton Restaurer pour lancer le flux de travail de restauration de la base de données.</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">Vérifiez tous les fichiers de données et modifiez l'état de la base de données si nécessaire pour la restauration et la restauration, puis cliquez sur Next.</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">Choisissez une étendue de récupération à l'aide de SCN ou de Time. Plutôt que de copier les journaux d'archive montés dans le répertoire de journaux actuel comme indiqué à l'étape 6, le chemin du journal d'archivage monté peut être répertorié dans « spécifier des emplacements de fichiers journaux d'archive externes » pour la restauration.</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">Spécifiez un prescripteur facultatif à exécuter si nécessaire.</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">Spécifiez un script de post-script facultatif à exécuter si nécessaire. Vérifiez la base de données ouverte après la récupération.</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">Indiquez un serveur SMTP et une adresse e-mail si une notification de travail est nécessaire.</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">Restaurez le récapitulatif du travail. Cliquez sur Terminer pour lancer la tâche de restauration.</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">Valider la restauration à partir de SnapCenter.</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">Valider la restauration à partir de l'hôte de l'instance EC2.</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">Pour démonter le volume du journal de restauration, inversez les étapes de l'étape 4.</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">Création d'un clone de base de données</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">La section suivante explique comment utiliser le workflow de clonage SnapCenter pour créer un clone de base de données à partir d'une base de données primaire vers une instance EC2 de secours.</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">Effectuer une sauvegarde instantanée complète de la base de données primaire à partir de SnapCenter en utilisant le groupe de ressources de sauvegarde complet.</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">Dans l'onglet ressource SnapCenter &gt; vue base de données, ouvrez la page gestion des sauvegardes de la base de données principale à partir de laquelle la réplique doit être créée.</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">Montez le snapshot du volume de journal effectué à l'étape 4 sur l'hôte de l'instance EC2 de secours.</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">Mettez en surbrillance la copie snapshot à cloner pour la réplique, puis cliquez sur le bouton Cloner pour lancer la procédure de clonage.</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">Modifiez le nom de la copie du réplica afin qu'il soit différent du nom de la base de données principale. Cliquez sur Suivant.</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">Remplacez l'hôte clone par l'hôte EC2 de secours, acceptez la dénomination par défaut et cliquez sur Next (Suivant).</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Modifiez vos paramètres Oracle Home pour qu'ils correspondent à ceux configurés pour l'hôte du serveur Oracle cible, puis cliquez sur Next (Suivant).</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">Spécifiez un point de récupération à l'aide du temps ou du SCN et du chemin du journal d'archivage monté.</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">Si nécessaire, envoyez les paramètres de messagerie SMTP.</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">Clonez le récapitulatif des tâches, puis cliquez sur Terminer pour lancer la tâche de clonage.</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">Validez le clone de réplica en consultant le journal des travaux de clonage.</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">La base de données clonée est enregistrée immédiatement dans SnapCenter.</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Désactivez le mode de journal d'archivage Oracle. Connectez-vous à l'instance EC2 en tant qu'utilisateur oracle et exécutez la commande suivante :</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">Au lieu de créer des copies de sauvegarde Oracle primaires, un clone peut aussi être créé à partir de copies de sauvegarde secondaires répliquées sur un cluster FSX cible, avec les mêmes procédures.</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">Basculement HAUTE DISPONIBILITÉ vers la veille et la resynchronisation</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">Le cluster haute disponibilité de secours d'Oracle offre une haute disponibilité en cas de défaillance sur le site primaire, au niveau de la couche de calcul ou de la couche de stockage. L'un des principaux avantages de la solution est qu'un utilisateur peut tester et valider l'infrastructure à tout moment ou à toute fréquence. Le basculement peut être simulé par l'utilisateur ou déclenché par une défaillance réelle. Les processus de basculement sont identiques et peuvent être automatisés afin de restaurer rapidement les applications.</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">Consultez la liste suivante des procédures de basculement :</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">Pour effectuer une simulation de basculement, exécutez une sauvegarde de snapshot de journal pour vider les dernières transactions du site de secours, comme indiqué dans la section <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>. Dans le cas d'un basculement déclenché par une défaillance réelle, les dernières données récupérables sont répliquées vers le site de secours avec la dernière sauvegarde planifiée du volume des journaux.</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">Faire un break de SnapMirror entre le cluster principal et le cluster FSX de secours.</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">Montez les volumes de base de données de secours répliqués sur l'hôte d'instance EC2 de secours.</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">Rééditez le binaire Oracle si le binaire Oracle répliqué est utilisé pour la restauration Oracle.</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">Restaurez la base de données Oracle de secours vers le dernier journal d'archivage disponible.</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">Ouvrez la base de données Oracle de secours pour l'accès des applications et des utilisateurs.</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">Dans le cas d'une panne réelle du site primaire, la base de données Oracle de secours joue désormais le rôle de nouveau site principal et les volumes de base de données peuvent être utilisés pour reconstruire le site primaire en panne comme un nouveau site de secours avec la méthode SnapMirror inverse.</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">Pour une simulation d'échec du site primaire pour le test ou la validation, arrêtez la base de données Oracle de secours après avoir terminé les exercices de test. Démontez ensuite les volumes de base de données de secours de l'hôte de l'instance EC2 de secours et synchronisez la réplication du site primaire vers le site de secours.</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">Ces procédures peuvent être exécutées à l'aide du kit d'automatisation de NetApp disponible au téléchargement sur le site GitHub public de NetApp.</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">Lisez attentivement les instructions de README avant de tenter de configurer et de tester le basculement.</block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">Suivant : migration de base de données.</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">Cette section fournit des détails sur la validation des performances et les résultats du banc d'essai d'essai d'une charge de travail OLTP simulée par SwingBench.</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">Validation des performances et résultats du banc d'essai</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">Précédent : gestion de la base de données Oracle.</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">L'objectif de cette validation de performance n'est pas de définir de marque. Au contraire, si vous suivez les procédures de déploiement et les meilleures pratiques comme décrit dans la présente documentation, vous pouvez vous attendre à des metrics de performances similaires issus de votre déploiement de bases de données Oracle sur un cloud public.</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Nous avons utilisé un module SOE (SwingBench Sales Order Entry) pour simuler une charge de travail de type OLTP. Nous avons également appliqué la charge de travail à une base de données Oracle déployée sur une instance M5 EC2 avec des volumes de stockage FSX sur le protocole NFS. Le profil d'E/S Swingbanal SOE par défaut est proche d'un fractionnement en lecture/écriture 80/20, proche d'un profil de charge de travail Oracle OLTP réel.</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">La charge de travail est augmentée en augmentant le nombre d'utilisateurs simultanés du côté client qui effectuent la saisie des commandes de vente, la navigation, les requêtes d'inventaire, etc. Les nombres testés étaient de 8, 16, 32, 64 et 128 utilisateurs simultanés. L'algorithme utilisé par SwingBench est lourd du côté serveur pour pousser des volumes de transaction raisonnables et tester les limites du serveur Oracle. Nous avons observé qu'avec 2 128 utilisateurs simultanés, le taux d'utilisation du CPU de l'instance EC2 a atteint environ 80 à 90 % de la capacité.</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">Les sections suivantes fournissent des détails sur la configuration et les résultats des tests.</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">Configuration de l'environnement de test</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">Nous avons déployé une instance EC2 M5 avec 8 vCPU, 32 Go de RAM et 10 Gps de bande passante réseau.</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">Stockage FSX</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">Nous avons créé trois volumes de base de données et monté les volumes avec NFS sur une instance EC2 comme suit :</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/U01 - binaire Oracle</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/U02 - fichiers de données Oracle, fichier de contrôle</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/U03 - fichiers journaux Oracle, fichier de contrôle</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">Nous avons conservé deux copies d'un fichier de contrôle stratégique pour assurer la redondance.</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">Le système de fichiers FSX est configuré avec une capacité de 80,000 IOPS et un débit d'E/S de 2 GiBps.</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Configuration Oracle</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Nous avons installé Oracle version 19c avec le correctif 19.8 RU. DNFS était activé sur le serveur.</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">La base de données a été déployée en tant que base de données conteneurisée avec trois BDD. Nous avons utilisé une instance de PDB pour les tests de performances. La figure suivante montre le dimensionnement du stockage Oracle sur les points de montage NFS.</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Configuration SwingBench</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">Nous avons déployé SwingBench 2.6 (la dernière version) sur un hôte Windows avec 8 vCPU et 32 Go de RAM. Nous avons utilisé le module de test SOE plsql version 2 pour le banc d'essai. Le profil de charge par défaut fournit un ratio de lecture/écriture 80/20 pour simuler la charge de travail transactionnelle OLTP réelle.</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">Le facteur d'échelle de schéma que nous avons utilisé était 50, ce qui a fourni une charge initiale de données de 160G et 30G d'allocation temporaire de l'espace. À cette échelle, le schéma SOE a fourni 1000 entrepôts et 50 millions de clients pour la simulation du traitement des commandes en ligne.</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">La capture d'écran suivante montre le profil de charge de travail et les mesures d'exécution transactionnelle typiques de l'interface utilisateur Windows Swingbanon.</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">Comme le montre ce graphique, le niveau de transaction a été maintenu au même niveau tout au long de l'exécution du test.</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">Analyse des résultats des tests</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">Nous avons recueilli les résultats SwingBench pour chaque essai et obtenu les rapports Oracle AWR correspondants pour l'analyse des performances.</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">Pour l'utilisateur final, nous avons étudié des mesures clés, telles que le volume de transactions et le temps de réponse des utilisateurs. Les deux indicateurs montrent le nombre de transactions que les utilisateurs peuvent exécuter à partir du système de saisie des commandes en fonction du nombre d'utilisateurs connectés simultanément au système, ainsi que la rapidité avec laquelle les utilisateurs peuvent effectuer des transactions et recevoir des réponses après leur saisie de la commande.</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">À partir du serveur Oracle, nous avons analysé le rapport Oracle AWR pour déterminer les principaux événements d'attente susceptibles de ralentir les transactions des utilisateurs. Les 10 principaux événements d'attente Oracle ont indiqué que, lors des tests de transactions simulés d'un banc d'essai, le serveur Oracle est principalement lié aux E/S avec jusqu'à 50 à 60 % du temps consacré par les bases de données<block ref="235591872ecf336383513d22098a1fa0" prefix=" " category="inline-code"></block>.<block ref="a249b22faad82bdea2a0930347b9e5ac" prefix=" " category="inline-code"></block> Est également un facteur important car les validations de transactions entraînent le vidage des E/S du journal depuis le cache tampon vers le fichier journal sur le disque, bien qu'il soit un facteur plus faible au niveau du pourcentage temps-base de données.</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">Nous avons saisi le volume de transaction utilisateur, le temps de réponse utilisateur et les événements d'attente Oracle en tête par rapport au nombre d'utilisateurs simultanés lors de l'exécution d'une transaction. Les résultats sont présentés ci-dessous :</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">Ces résultats indiquent que nous pouvons augmenter en continu les volumes de transactions des utilisateurs avec un nombre croissant d'utilisateurs simultanés, tout en maintenant une faible latence d'E/S et un temps de réponse utilisateur, ce qui est approprié pour une application Oracle.</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">La latence d'E/S et le temps de réponse des utilisateurs ont commencé à augmenter quand on atteint 128 utilisateurs simultanés. Cela est dû au fait que l'instance EC2 approche de la capacité totale des serveurs, comme illustré dans le schéma suivant :</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">De même, le schéma suivant montre les IOPS et le débit FSX correspondants, tout en remplissant les volumes de transaction utilisateur au moment opportun.</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Facteurs à prendre en compte pour le déploiement de bases de données Oracle</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">Nous n'avons pas atteint la capacité de stockage FSX provisionnée en IOPS ou en débit lorsque l'instance EC2 de serveur Oracle est devenue le facteur limitant. Par conséquent, vous devez dimensionner correctement la capacité de calcul et de stockage en fonction du volume de transaction au niveau de l'application utilisateur, comme nous le présentons dans la section <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">Optimisez les opérations et exploitez tout le potentiel de vos données, sur site ou dans le cloud.</block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">Solutions de base de données de cloud hybride avec workflow de reprise après incident SnapCenter</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">Flux de travail de reprise après incident</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">Précédent : flux de travail pour les phases de développement/test bursting dans le cloud.</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">Les entreprises ont adopté le cloud public comme ressource et destination viables pour la reprise après incident. SnapCenter rend ce processus aussi transparent que possible. Ce workflow de reprise d'activité est très similaire au workflow de clonage, mais la restauration de base de données s'exécute via le dernier journal disponible répliqué dans le cloud afin de restaurer toutes les transactions d'entreprise possibles. Toutefois, des étapes supplémentaires de préconfiguration et de post-configuration sont propres à la reprise sur incident.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">Clonez une base de données de production Oracle sur site dans le cloud pour la reprise après incident</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">Pour vérifier que la restauration des clones s'exécute via le dernier journal disponible, nous avons créé une petite table de test et inséré une ligne. Les données de test seront récupérées après une récupération complète du dernier journal disponible.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">Connectez-vous à SnapCenter en tant qu'ID utilisateur de gestion de base de données pour Oracle. Accédez à l'onglet Ressources, qui affiche les bases de données Oracle protégées par SnapCenter.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Sélectionnez le groupe de ressources du journal Oracle et cliquez sur Sauvegarder maintenant pour exécuter manuellement une sauvegarde du journal Oracle afin de vider la dernière transaction vers la destination dans le cloud. Dans un scénario de reprise d'activité réel, la dernière transaction récupérable dépend de la fréquence de réplication du volume des journaux de base de données vers le cloud, qui dépend à son tour de la politique RTO ou RPO de l'entreprise.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">En cas de reprise d'activité, SnapMirror asynchrone perd les données qui n'ont pas été effectuées vers la destination cloud dans l'intervalle de sauvegarde du journal de base de données. Il est possible de programmer des sauvegardes plus fréquentes des journaux pour limiter les pertes de données. Cependant, la fréquence de sauvegarde des journaux est limitée, techniquement réalisable.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">Sélectionnez la dernière sauvegarde du journal sur la ou les sauvegarde(s) miroir secondaire et montez la sauvegarde du journal.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">Sélectionnez la dernière sauvegarde complète de la base de données et cliquez sur Cloner pour lancer le flux de travail de clonage.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">Sélectionnez un ID unique de base de données de clone sur l'hôte.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">Provisionnez un volume de journalisation et montez-le sur le serveur de reprise après incident cible pour la zone de restauration Flash Oracle et les journaux en ligne.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">La procédure de clonage Oracle ne crée pas de volume de journaux qui doit être provisionné sur le serveur de reprise après incident avant le clonage.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">Sélectionnez l'hôte et l'emplacement du clone cible pour placer les fichiers de données, les fichiers de contrôle et les journaux de reprise.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">Sélectionnez les informations d'identification du clone. Renseignez les détails de la configuration initiale d'Oracle sur le serveur cible.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">Spécifiez les scripts à exécuter avant le clonage. Les paramètres de la base de données peuvent être ajustés si nécessaire.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">Sélectionnez jusqu'à Annuler comme option de restauration pour que la restauration s'exécute dans tous les journaux d'archivage disponibles pour récupérer la dernière transaction répliquée vers l'emplacement du cloud secondaire.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">Configurez le serveur SMTP pour la notification par e-mail si nécessaire.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">Récapitulatif sur le clone de DR.</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">Les bases de données clonées sont enregistrées avec SnapCenter immédiatement après la fin du clonage, puis sont disponibles pour la protection de sauvegarde.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Validation et configuration des clones après reprise après incident pour Oracle</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">Valider la dernière transaction de test qui a été vidée, répliquée et restaurée sur le site de DR dans le cloud.</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">Configurer la zone de récupération flash.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">Configurez le programme d'écoute Oracle pour l'accès des utilisateurs.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">Séparer le volume cloné du volume source répliqué</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">La réplication inverse du cloud sur site, puis reconstruisez le serveur de base de données sur site en panne.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">Le fractionnement des clones peut entraîner une utilisation temporaire de l'espace de stockage qui dépasse de loin la normale. Cependant, après la reconstruction du serveur de bases de données sur site, vous pouvez libérer de l'espace supplémentaire.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">Clonez une base de données de production SQL sur site dans le cloud pour la reprise après incident</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">De la même façon, pour vérifier que la restauration des clones SQL a été exécutée par le dernier journal disponible, nous avons créé une petite table de tests et inséré une ligne. Les données de test seront récupérées après une récupération complète du dernier journal disponible.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">Connectez-vous à SnapCenter avec un ID utilisateur de gestion de base de données pour SQL Server. Accédez à l'onglet Ressources, qui affiche le groupe de ressources de protection SQL Server.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">Exécutez manuellement une sauvegarde de journal pour vider la dernière transaction à répliquer sur un stockage secondaire dans le cloud public.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">Sélectionnez la dernière sauvegarde complète SQL Server du clone.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">Définissez le paramètre de clonage comme le serveur de clonage, l'instance de clonage, le nom du clone et l'option de montage. L'emplacement de stockage secondaire où le clonage est effectué est rempli automatiquement.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">Sélectionnez toutes les sauvegardes de journaux à appliquer.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">Spécifiez tous les scripts facultatifs à exécuter avant ou après le clonage.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">Spécifiez un serveur SMTP si vous souhaitez recevoir une notification par e-mail.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">Récapitulatif sur le clone de DR. Les bases de données clonées sont immédiatement enregistrées auprès de SnapCenter et disponibles pour la protection des sauvegardes.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">Validation et configuration des clones après reprise après incident pour SQL</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">Surveillez l'état des tâches de clonage.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">Vérifier que la dernière transaction a été répliquée et restaurée avec l'ensemble des clones et des restaurations des fichiers journaux</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">Configurez un nouveau répertoire journal SnapCenter sur le serveur DR pour la sauvegarde des journaux SQL Server.</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">La communauté NetApp solution Automation prend en charge le Channel Slack</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">Si vous avez besoin d'aide pour cette solution et ces cas d'utilisation, rejoignez le <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> et recherchez le canal solution-automation pour poser vos questions ou vos questions.</block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">Cette section décrit le processus de déploiement de Cloud Manager et de Cloud Volumes ONTAP dans AWS.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">Mise en route du cloud public AWS</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">Précédente : mise en route sur site.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">Cloud public AWS</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">Pour simplifier l'suivi, nous avons créé ce document en nous basant sur le déploiement dans AWS. Cependant, ce processus est très similaire pour Azure et GCP.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">1. Contrôle avant vol</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">Avant le déploiement, s'assurer que l'infrastructure permet le déploiement à l'étape suivante. Ceci inclut les éléments suivants :</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">Compte AWS</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">VPC dans votre région</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">Sous-réseau avec accès à l'Internet public</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">Autorisations permettant d'ajouter des rôles IAM à votre compte AWS</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">Une clé secrète et une clé d'accès pour votre utilisateur AWS</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2. Étapes de déploiement de Cloud Manager et de Cloud Volumes ONTAP dans AWS</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">Documentation cloud NetApp</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">De nombreuses méthodes de déploiement de Cloud Manager et de Cloud Volumes ONTAP sont disponibles. Cette méthode est la plus simple, mais requiert la plupart des autorisations. Si cette méthode n'est pas adaptée à votre environnement AWS, consultez le<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Déployez Cloud Manager Connector</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">Accédez à<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> et connectez-vous ou inscrivez-vous.</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">Une fois connecté, vous devez être redirigé vers la toile.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">Cliquez sur Add Working Environment (Ajouter un environnement de travail) et choisissez Cloud Volumes ONTAP in AWS. Vous pouvez également choisir de déployer un système à un seul nœud ou une paire haute disponibilité. J'ai choisi de déployer une paire haute disponibilité.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">Si aucun connecteur n'a été créé, une fenêtre contextuelle s'affiche vous demandant de créer un connecteur.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">Cliquez sur Oui, puis choisissez AWS.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">Page règles NetApp</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">Saisissez votre clé secrète et votre clé d'accès. Assurez-vous que votre utilisateur dispose des autorisations appropriées indiquées sur le<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">Attribuez un nom au connecteur et utilisez un rôle prédéfini comme décrit sur le<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> Vous pouvez également demander à Cloud Manager de créer le rôle dont vous avez besoin.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">Fournissez les informations de mise en réseau nécessaires au déploiement du connecteur. Vérifiez que l'accès Internet sortant est activé par :</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">En donnant au connecteur une adresse IP publique</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">Donner au connecteur un proxy pour fonctionner</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">Donner au connecteur une route vers l'Internet public par le biais d'une passerelle Internet</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">Établir une communication avec le connecteur via SSH, HTTP et HTTPS en fournissant un groupe de sécurité ou en créant un nouveau groupe de sécurité. J'ai activé l'accès au connecteur à partir de mon adresse IP uniquement.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">Vérifiez les informations de la page de résumé et cliquez sur Ajouter pour déployer le connecteur.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">Le connecteur se déploie à présent à l'aide d'une pile de formation de nuages. Vous pouvez contrôler sa progression depuis Cloud Manager ou via AWS.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">Une fois le déploiement terminé, une page de réussite s'affiche.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Déployez Cloud Volumes ONTAP</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">Sélectionnez AWS et le type de déploiement selon vos besoins.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">Si aucun abonnement n'a été attribué et que vous souhaitez acheter avec PAYGO, choisissez Modifier les informations d'identification.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">Choisissez Ajouter un abonnement.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">Choisissez le type de contrat auquel vous souhaitez vous abonner. J'ai choisi le paiement à l'utilisation.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">Vous êtes redirigé vers AWS ; sélectionnez Continuer pour vous inscrire.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">Vous allez être redirigé vers NetApp Cloud Central. Si vous êtes déjà abonné et que vous n'êtes pas redirigé, cliquez ici.</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">Vous êtes redirigé vers Cloud Central, où vous devez nommer votre abonnement et l'attribuer à votre compte Cloud Central.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">Une fois réussi, une page de coche s'affiche. Revenez à l'onglet Cloud Manager.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">L'abonnement s'affiche désormais dans Cloud Central. Cliquez sur appliquer pour continuer.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">Saisissez les détails de l'environnement de travail, notamment :</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">Nom du cluster</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">Mot de passe du cluster</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">Balises AWS (en option)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">Page d'accueil de NetApp Cloud</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">Choisissez les services supplémentaires que vous souhaitez déployer. Pour en savoir plus sur ces services, rendez-vous sur la<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">Choisissez si vous souhaitez le déployer dans plusieurs zones de disponibilité (trois sous-réseaux, chacun dans une zone AZ différente) ou dans une seule zone de disponibilité. J'ai choisi plusieurs AZS.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">Choisissez la région, le VPC et le groupe de sécurité dans lequel le cluster doit être déployé. Dans cette section, vous affectez également les zones de disponibilité par nœud (et médiateur) ainsi que les sous-réseaux qu'ils occupent.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">Choisissez les méthodes de connexion pour les nœuds et le médiateur.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">Le médiateur requiert la communication avec les API AWS. Une adresse IP publique n'est pas requise tant que les API sont accessibles après le déploiement de l'instance EC2 médiateur.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">Documentation cloud NetApp</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">Les adresses IP flottantes sont utilisées pour permettre l'accès aux différentes adresses IP utilisées par Cloud Volumes ONTAP, y compris la gestion du cluster et le traitement des adresses IP. Ces adresses doivent être déjà routables sur votre réseau et ajoutées aux tables d'acheminement dans votre environnement AWS. Ils sont nécessaires pour activer des adresses IP cohérentes pour une paire haute disponibilité lors du basculement. Vous trouverez plus d'informations sur les adresses IP flottantes dans le<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">Sélectionnez les tables de routage auxquelles les adresses IP flottantes sont ajoutées. Ces tables de routage sont utilisées par les clients pour communiquer avec Cloud Volumes ONTAP.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">Elles peuvent choisir d'activer le chiffrement géré par AWS ou le KMS AWS pour chiffrer la racine ONTAP, le démarrage et les disques de données.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">Choisissez votre modèle de licence. Si vous ne savez pas quel choix choisir, contactez votre représentant NetApp.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">Sélectionnez la configuration la mieux adaptée à votre utilisation. Cela est lié aux considérations de dimensionnement décrites dans la page des prérequis.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">Créer un volume (facultatif) Cette opération n'est pas requise, car les étapes suivantes utilisent SnapMirror, qui crée les volumes pour nous.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">Vérifiez les sélections effectuées et cochez les cases pour vérifier que Cloud Manager déploie des ressources dans votre environnement AWS. Une fois terminé, cliquez sur Go.</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">Le processus de déploiement commence maintenant par Cloud Volumes ONTAP. Cloud Manager utilise les API AWS et les piles de formation cloud pour déployer Cloud Volumes ONTAP. Il configure ensuite le système selon vos spécifications, vous offrant ainsi un système prêt à l'emploi qu'il est possible d'utiliser instantanément. La durée de ce processus varie en fonction des sélections effectuées.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">Vous pouvez contrôler la progression en accédant à la chronologie.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">La chronologie représente un audit de toutes les actions effectuées dans Cloud Manager. Vous pouvez afficher tous les appels d'API effectués par Cloud Manager lors de la configuration sur AWS et sur le cluster ONTAP. Elle peut également être utilisée efficacement pour résoudre tous les problèmes auxquels vous êtes confronté.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">Une fois le déploiement terminé, le cluster CVO s'affiche dans Canvas, pour lequel la capacité actuelle est de. Le cluster ONTAP à l'état actuel est entièrement configuré pour offrir une véritable expérience prête à l'emploi.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">Configurez SnapMirror sur site vers le cloud</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">Dès lors que vous disposez d'un système ONTAP source et d'un système ONTAP de destination déployés, vous pouvez répliquer des volumes contenant des données de base de données dans le cloud.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">Matrice de compatibilité SnapMirror</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">Pour obtenir un guide sur les versions ONTAP compatibles avec SnapMirror, reportez-vous à la<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">Cliquez sur le système ONTAP source (sur site) et faites-le glisser vers la destination, sélectionnez réplication &gt; Activer ou sélectionnez réplication &gt; Menu &gt; répliquer.</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">Sélectionnez Activer.</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">Ou Options.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">Répliquer.</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">Si vous n'avez pas effectué de glisser-déposer, choisissez le cluster de destination vers lequel effectuer la réplication.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">Choisissez le volume que vous souhaitez répliquer. Nous avons répliqué les données et tous les volumes des journaux.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">Choisissez le type de disque de destination et la règle de hiérarchisation. Pour la reprise après incident, nous recommandons l'utilisation d'un disque SSD comme type de disque et pour maintenir le Tiering des données. Le Tiering des données procède au Tiering des données en miroir dans un stockage objet à faible coût et vous permet d'économiser de l'argent sur des disques locaux. Lorsque vous rompez la relation ou que vous clonez le volume, les données utilisent le stockage local rapide.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">Sélectionnez le nom du volume de destination : nous avons choisi<block ref="47456946fa180c1578446a0fa28fca75" prefix=" " category="inline-code"></block>.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">Sélectionnez la vitesse de transfert maximale pour la réplication. Cela vous permet d'économiser de la bande passante si vous disposez d'une connexion à faible bande passante au cloud, par exemple un VPN.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">Définissez la règle de réplication. Nous avons choisi un miroir, qui prend le jeu de données le plus récent et le réplique dans le volume de destination. Vous pouvez également choisir une politique différente en fonction de vos besoins.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">Choisissez la planification du déclenchement de la réplication. NetApp recommande de définir une planification « journalière » pour le volume de données et une planification « horaire » pour les volumes de journaux, même si cela peut être modifié en fonction des besoins.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">Vérifier les informations saisies, cliquer sur Go pour déclencher l'homologue du cluster et l'homologue SVM (si c'est votre première réplication entre les deux clusters), puis mettre en œuvre et initialiser la relation SnapMirror.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">Poursuivez ce processus pour les volumes de données et de journaux.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">Pour vérifier toutes vos relations, accédez à l'onglet réplication dans Cloud Manager. Vous pouvez ici gérer vos relations et connaître leur statut.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">Une fois tous les volumes répliqués, vous êtes dans un état stable et prêt à passer aux flux de travail de reprise après incident et de développement/test.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">3. Déployez l'instance de calcul EC2 pour les workloads de bases de données</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">Type d'instance EC2</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS a préconfiguré des instances de calcul EC2 pour diverses charges de travail. Le choix du type d'instance détermine le nombre de cœurs de processeur, la capacité de mémoire, le type de stockage et la capacité, ainsi que la performance du réseau. Pour ces cas d'usage, à l'exception de la partition OS, le stockage principal permettant l'exécution de la charge de travail de la base de données est alloué à partir de CVO ou du moteur de stockage FSX ONTAP. Par conséquent, les principaux facteurs à prendre en compte sont le choix des cœurs de processeur, de la mémoire et du niveau de performance du réseau. Les types d'instances AWS EC2 classiques sont disponibles ici :<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">Dimensionnement de l'instance de calcul</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">Sélectionnez le type d'instance approprié en fonction de la charge de travail requise. Les facteurs à prendre en compte incluent le nombre de transactions commerciales à prendre en charge, le nombre d'utilisateurs simultanés, le dimensionnement des jeux de données, etc.</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">Le déploiement d'instances EC2 peut être lancé via le tableau de bord EC2. Les procédures de déploiement précises dépassent le cadre de cette solution. Voir<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Configuration de l'instance Linux pour le workload Oracle</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">Cette section contient des étapes de configuration supplémentaires après le déploiement d'une instance EC2 Linux.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">Ajoutez une instance de secours Oracle au serveur DNS pour la résolution de nom dans le domaine de gestion SnapCenter.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">Ajoutez un ID utilisateur de gestion Linux en tant que identifiants SnapCenter OS avec des autorisations sudo sans mot de passe. Activez l'ID avec l'authentification par mot de passe SSH sur l'instance EC2. (Par défaut, l'authentification par mot de passe SSH et le sudo sans mot de passe sont désactivés sur les instances EC2.)</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">Configurez l'installation Oracle pour qu'elle corresponde à l'installation Oracle sur site, par exemple les correctifs du système d'exploitation, les versions et correctifs d'Oracle, etc.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Déploiement automatisé Oracle 19c</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">Les rôles d'automatisation de la base de données NetApp Ansible peuvent être utilisés pour configurer les instances EC2 pour le développement/test des bases de données et la reprise après incident. Le code d'automatisation peut être téléchargé sur le site GitHub public de NetApp :<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. L'objectif est d'installer et de configurer une pile logicielle de base de données sur une instance EC2 afin qu'elle corresponde aux configurations du système d'exploitation et de la base de données sur site.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">Configuration de l'instance Windows pour la charge de travail SQL Server</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">Cette section répertorie d'autres étapes de configuration après le déploiement initial d'une instance de Windows EC2.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">Récupérez le mot de passe administrateur Windows pour vous connecter à une instance via RDP.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Désactivez le pare-feu Windows, rejoignez l'hôte dans le domaine SnapCenter de Windows et ajoutez l'instance au serveur DNS pour la résolution du nom.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">Provisionnez un volume log SnapCenter pour stocker les fichiers log de SQL Server.</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Configurez iSCSI sur l'hôte Windows pour monter le volume et formater le lecteur de disque.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">Automatisation NetApp</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">Là encore, une grande partie des tâches précédentes peuvent être automatisées avec la solution d'automatisation NetApp pour SQL Server. Consultez le site GitHub public d'automatisation NetApp pour connaître les nouveaux rôles et solutions publiés :<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">Ensuite, les workflows de développement/test bursting dans le cloud.</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">Le schéma d'architecture suivant illustre un déploiement de base de données Oracle hautement disponible sur une instance AWS EC2 avec le service de stockage FSX. Il est possible de mettre en place un schéma de déploiement similaire, à la différence de celui mis en veille dans une autre région, pour la reprise après incident.</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">Le stockage de base de données Oracle sur des volumes FSX, en revanche, est déployé avec la console FSX d'AWS ou l'interface de ligne de commande. Les volumes binaires, de données ou de journaux Oracle sont ensuite présentés et montés sur un hôte Linux d'instance EC2. Chaque volume de données ou de journaux peut disposer de plusieurs LUN allouées en fonction du protocole de stockage sous-jacent utilisé.</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter fournit des flux de production pour la restauration instantanée des bases de données Oracle ou pour le clonage des bases de données dans les zones primaires ou de secours, si nécessaire. Grâce à l'interface utilisateur de SnapCenter, vous pouvez configurer la sauvegarde et la réplication de la base de données Oracle sur le stockage FSX de secours pour assurer une haute disponibilité ou la reprise après incident en fonction de vos objectifs RTO ou RPO.</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">La solution offre un autre processus qui offre des capacités similaires à celles disponibles dans le déploiement d'Oracle RAC et de Data Guard.</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">Suivant : procédures de déploiement.</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">Cette page décrit la protection automatisée des données d'Oracle19c sur le stockage ONTAP NetApp.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">Procédure de déploiement étape par étape</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">Protection des données Oracle AWX/Tower</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">Créez l'inventaire, le groupe, les hôtes et les informations d'identification de votre environnement</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">Cette section décrit la configuration des inventaires, des groupes, des hôtes et des identifiants d'accès dans AWX/Ansible Tower qui préparent l'environnement à l'utilisation des solutions automatisées NetApp.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Accédez à Ressources → inventaires → Ajouter, puis cliquez sur Ajouter un inventaire.</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">Indiquez le nom et les détails de l'organisation, puis cliquez sur Enregistrer.</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">Sur la page inventaires, cliquez sur l'inventaire créé.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Accédez au sous-menu groupes et cliquez sur Ajouter.</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">Indiquez le nom oracle de votre premier groupe et cliquez sur Enregistrer.</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">Répétez le processus pour un second groupe appelé dr_oracle.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">Sélectionnez le groupe oracle créé, accédez au sous-menu hôtes et cliquez sur Ajouter un nouvel hôte.</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">Indiquez l'adresse IP de gestion de l'hôte Oracle source, puis cliquez sur Enregistrer.</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">Ce processus doit être répété pour le groupe dr_oracle et ajouter l'adresse IP/nom d'hôte de gestion de l'hôte DR/destination Oracle.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">Les instructions ci-dessous pour créer les types d'identifiants d'identifiants pour une certification sur site avec ONTAP ou CVO pour AWS sont décrites ci-dessous.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">Sur site</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">Créer un projet</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Accédez à Ressources → projets, puis cliquez sur Ajouter.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">Sélectionnez Git dans le champ Type d'informations d'identification du contrôle source.</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">entrez <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> Comme URL de contrôle de source.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">Il peut être nécessaire de synchroniser le projet de temps en temps lorsque le code source change.</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">Configurer les variables globales</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">Les variables définies dans cette section s'appliquent à tous les hôtes Oracle, bases de données et cluster ONTAP.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">Saisissez les paramètres spécifiques à votre environnement dans le formulaire intégré Global variables ou var.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">Les éléments en bleu doivent être modifiés pour correspondre à votre environnement.</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">Manuels de vente automatisation</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">Il y a quatre manuels de vente distincts qui doivent être exécutés.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">PlayBook pour la configuration de votre environnement, sur site ou Cloud volumes ONTAP.</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Manuel de vente pour la réplication de fichiers binaires et de bases de données Oracle selon un calendrier</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">Manuel de vente pour la réplication des journaux Oracle selon un planning</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">Manuel de vente pour la récupération de votre base de données sur un hôte de destination</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">Configuration d'ONTAP/CVO</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">Réplication pour volumes binaires et de base de données</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">Réplication pour les volumes de journaux</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">Restaurez et récupérez la base de données</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Récupération de la base de données Oracle</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">Les volumes de données des bases de données Oracle de production sur site sont protégés via la réplication NetApp SnapMirror vers un cluster ONTAP redondant dans un data Center secondaire ou vers Cloud Volume ONTAP dans un cloud public. Dans un environnement de reprise après incident entièrement configuré, les instances de calcul de restauration dans le data Center secondaire ou dans le cloud public sont de secours et prêtes à restaurer la base de données de production en cas d'incident. Les instances de calcul de secours sont maintenues synchronisées avec les instances sur site en exécutant des mises à jour paraellel sur le patch du noyau du système d'exploitation ou la mise à niveau en parallèle.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">Dans cette solution démontrée, le volume binaire Oracle est répliqué sur la cible et monté sur l'instance cible pour créer la pile logicielle Oracle. Cette approche de restauration d'Oracle a un avantage sur une nouvelle installation d'Oracle à la dernière minute lorsqu'un incident s'est produit. Cela garantit que l'installation d'Oracle est parfaitement synchronisée avec les niveaux de patch et d'installation du logiciel de production sur site, etc. Cependant, cela peut avoir ou non des implications de licence logicielle supplémentaires pour le volume binaire Oracle répliqué sur le site de reprise, selon la structure des licences logicielles avec Oracle. Il est recommandé à l'utilisateur de vérifier avec son personnel chargé des licences logicielles afin d'évaluer les exigences de licence Oracle potentielles avant de décider d'utiliser la même approche.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">L'hôte Oracle de secours au niveau de la destination est configuré avec les configurations prérequis d'Oracle.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">Les SnapMirrors sont rompus et les volumes sont créés pour être inscriptibles et montés sur l'hôte Oracle de secours.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">Le module de récupération Oracle effectue les tâches suivantes pour la récupération et le démarrage d'Oracle sur le site de reprise après le montage de tous les volumes de base de données sur l'instance de calcul de secours.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">Synchronisez le fichier de contrôle : nous avons déployé des fichiers de contrôle Oracle dupliqués sur un volume de base de données différent afin de protéger le fichier de contrôle de base de données stratégique. L'une est sur le volume de données et l'autre sur le volume du journal. Les volumes de données et de journaux sont répliqués à une fréquence différente, mais ils sont désynchronisés au moment de la restauration.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Rééditer le binaire Oracle : comme le binaire Oracle est transféré vers un nouvel hôte, il faut un rélien.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Restaurer base de données Oracle : le mécanisme de récupération récupère le dernier numéro de modification du système dans le dernier journal archivé disponible dans le volume du journal Oracle à partir du fichier de contrôle et récupère la base de données Oracle pour récupérer toutes les transactions commerciales qui ont pu être répliquées vers le site de reprise après incident au moment de la défaillance. La base de données est ensuite démarrée dans une nouvelle incarnation pour effectuer des connexions utilisateur et une transaction commerciale sur le site de reprise.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">Avant d'exécuter le manuel de récupération, assurez-vous d'avoir bien les éléments suivants : assurez-vous de les copier sur /etc/oratab et /etc/oraInst.loc de l'hôte Oracle source vers l'hôte de destination</block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">Les tâches décrites dans cette section doivent être effectuées sur site pour préparer l'environnement de workloads de base de données de cloud hybride SnapCenter.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">Conditions préalables sur site</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">Précédent : configuration des prérequis.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">Pour préparer l'environnement de workload de base de données de cloud hybride SnapCenter, les tâches suivantes doivent être réalisées sur site.</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">L'outil NetApp SnapCenter est une application Windows qui s'exécute généralement dans un environnement de domaine Windows, mais aussi dans un déploiement de groupe de travail. Elle est basée sur une architecture multiniveaux, incluant un serveur de gestion centralisée (le serveur SnapCenter) et un plug-in SnapCenter sur les hôtes du serveur de base de données pour les charges de travail de la base de données. Voici quelques éléments à prendre en compte pour le déploiement du cloud hybride.</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">*Déploiement d'instance unique ou de haute disponibilité.* le déploiement de haute disponibilité fournit une redondance en cas de défaillance d'un serveur d'instance SnapCenter unique.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">*Résolution du nom.* le DNS doit être configuré sur le serveur SnapCenter pour résoudre tous les hôtes de base de données ainsi que sur le SVM de stockage pour la recherche avant et arrière. Le serveur DNS doit également être configuré sur des serveurs de base de données pour résoudre le serveur SnapCenter et la SVM de stockage pour la recherche avant et arrière.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">*Configuration du contrôle d'accès basé sur les rôles (RBAC).* pour les charges de travail de bases de données mixtes, vous pouvez utiliser RBAC pour isoler la responsabilité de gestion de différentes plates-formes de bases de données telles qu'une base de données admin pour Oracle ou un administrateur pour SQL Server. Les autorisations nécessaires doivent être accordées à l'utilisateur DB admin.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">*Activer la stratégie de sauvegarde basée sur des stratégies.* pour renforcer la cohérence et la fiabilité des sauvegardes.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">*Ouvrez les ports réseau nécessaires sur le pare-feu.* pour que le serveur SnapCenter sur site communique avec les agents installés sur l'hôte DB cloud.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">*Les ports doivent être ouverts pour permettre le trafic SnapMirror entre le cloud sur site et le cloud public.* le serveur SnapCenter utilise ONTAP SnapMirror pour répliquer les sauvegardes Snapshot sur site vers les SVM de stockage Cloud volumes ONTAP.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">Workflow d'installation de SnapCenter</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">Après avoir soigneusement étudié et planifié la pré-installation, cliquez sur ce bouton <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> Pour plus d'informations sur l'installation et la configuration de SnapCenter.</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">Les performances du stockage jouent un rôle important dans les performances globales des bases de données et des applications. Une disposition de stockage bien conçue peut non seulement améliorer les performances de la base de données, mais aussi faciliter la gestion de la sauvegarde et de la restauration de la base de données. Plusieurs facteurs doivent être pris en compte lors de la définition de l'organisation du stockage, notamment la taille de la base de données, le taux de modification attendu des données pour la base de données et la fréquence avec laquelle vous effectuez des sauvegardes.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">En reliant directement des LUN de stockage à la machine virtuelle invitée par NFS ou iSCSI pour les charges de travail de bases de données virtualisées, vous bénéficiez généralement de performances supérieures à celles du stockage alloué via VMDK. NetApp recommande l'organisation de stockage d'une importante base de données SQL Server sur les LUN décrits dans la figure suivante.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">La figure suivante présente l'organisation de stockage recommandée par NetApp pour les bases de données SQL Server de petite ou moyenne taille sur des LUN.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">Le répertoire des journaux est dédié à SnapCenter pour effectuer une synthèse du journal des transactions pour la récupération de la base de données. Pour une base de données très volumineuse, plusieurs LUN peuvent être allouées à un volume pour améliorer les performances.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Pour les charges de travail de bases de données Oracle, SnapCenter prend en charge les environnements de bases de données bénéficiant d'un stockage ONTAP monté sur l'hôte en tant que périphériques physiques ou virtuels. Vous pouvez héberger toute la base de données sur un ou plusieurs périphériques de stockage en fonction du caractère stratégique de l'environnement. Généralement, les clients isolent les fichiers de données sur un système de stockage dédié de tous les autres fichiers comme les fichiers de contrôle, les fichiers de reprise et les fichiers journaux d'archivage. Cela permet aux administrateurs de restaurer rapidement (ONTAP Single-File SnapRestore) ou de cloner une grande base de données stratégique (de plusieurs pétaoctets) à l'aide de la technologie Snapshot en quelques secondes à quelques minutes.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">Pour optimiser la latence, un volume de stockage dédié doit être déployé sur différents types de fichiers Oracle afin d'optimiser la latence. Pour une grande base de données, plusieurs LUN (NetApp recommande jusqu'à huit) par volume doivent être alloués aux fichiers de données.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">Pour les bases de données Oracle plus petites, SnapCenter prend en charge les dispositions de stockage partagé dans lesquelles vous pouvez héberger plusieurs bases de données ou faire partie d'une base de données sur le même volume de stockage ou LUN. Par exemple, vous pouvez héberger des fichiers de données pour toutes les bases de données d'un groupe de disques + DATA ASM ou d'un groupe de volumes. Le reste des fichiers (fichiers de reprise, journaux d'archivage et fichiers de contrôle) peut être hébergé sur un autre groupe de disques ou groupe de volumes dédié (LVM). Un tel scénario de déploiement est illustré ci-dessous.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Pour faciliter la relocalisation des bases de données Oracle, le binaire Oracle doit être installé sur un LUN distinct inclus dans la stratégie de sauvegarde régulière. Cela permet de garantir que, dans le cas du transfert de la base de données vers un nouvel hôte serveur, la pile Oracle peut être démarrée pour la restauration sans problèmes potentiels dus à un binaire Oracle désynchronisé.</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter est un logiciel sous licence de NetApp. Elle est généralement incluse dans une licence ONTAP sur site. Cependant, pour le déploiement d'un cloud hybride, une licence cloud pour SnapCenter doit également ajouter CVO à SnapCenter comme destination de réplication des données cible. Veuillez consulter les liens ci-dessous pour en savoir plus sur la licence standard basée sur la capacité SnapCenter :</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">Licences standard basées sur la capacité SnapCenter</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">Dans le cas d'une base de données de production sur site nécessitant une stabilité accrue dans le cloud pour les opérations de développement/test et de reprise d'activité, la mise en réseau et la sécurité sont des facteurs essentiels à prendre en compte lors de la configuration de l'environnement et de la connexion au cloud public à partir d'un data Center sur site.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">Les clouds publics utilisent généralement un cloud privé virtuel (VPC) pour isoler différents utilisateurs au sein d'une plateforme de cloud public. Au sein d'un VPC individuel, la sécurité est contrôlée à l'aide de mesures telles que des groupes de sécurité configurables en fonction des besoins des utilisateurs pour le verrouillage d'un VPC.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">La connectivité entre le data Center sur site et le VPC peut être sécurisée via un tunnel VPN. Sur la passerelle VPN, la sécurité peut être renforcée à l'aide de règles NAT et de pare-feu qui bloquent les tentatives d'établissement de connexions réseau à partir d'hôtes sur Internet vers des hôtes à l'intérieur du data Center de l'entreprise.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">Pour les considérations relatives au réseau et à la sécurité, consultez les règles Cloud volumes ONTAP entrantes et sortantes pour votre cloud public :</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">Règles du groupe de sécurité pour CVO - AWS</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">Règles du groupe de sécurité pour CVO - Azure</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">Règles de pare-feu pour CVO - GCP</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Utilisation de l'automatisation Ansible pour la synchronisation facultative des instances de BDD entre l'environnement sur site et le cloud</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">Pour simplifier la gestion d'un environnement de base de données de cloud hybride, NetApp vous recommande vivement, mais ne vous demande pas de déployer un contrôleur Ansible afin d'automatiser certaines tâches de gestion, comme le maintien des instances de calcul sur site et dans le cloud en mode synchrone. Cela est particulièrement important, car une instance de calcul désynchronisée dans le cloud peut entraîner l'erreur de la base de données récupérée dans le cloud en raison de l'absence de packages du noyau et d'autres problèmes.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">La fonctionnalité d'automatisation d'un contrôleur Ansible peut également être utilisée pour étendre SnapCenter à certaines tâches, comme l'interruption de l'instance SnapMirror pour activer la copie de données de reprise après incident en production.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">Configuration du contrôleur Red Hat/CentOS Ansible</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Configuration du contrôleur Ansible Ubuntu/Debian</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">Suivez ces instructions pour configurer votre nœud de contrôle Ansible pour les machines RedHat ou CentOS : <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. Suivez ces instructions pour configurer votre nœud de contrôle Ansible pour les machines Ubuntu ou Debian : <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">Suivant : cloud public.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">Tr-4250 : SAP avec Oracle sous UNIX et NFS avec NetApp clustered Data ONTAP et SnapManager pour SAP 3.4</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">Nils Bauer, NetApp</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">Le rapport TR-4250 décrit les défis que pose la conception de solutions de stockage pour prendre en charge les produits de la suite d'affaires SAP à l'aide d'une base de données Oracle. L'objectif principal de ce document est de faire face aux défis posés par la conception, le déploiement, l'exploitation et la gestion de l'infrastructure de stockage par les dirigeants et LES responsables IT qui utilisent la dernière génération de solutions SAP. Les recommandations contenues dans ce document sont génériques, elles ne sont pas spécifiques à une application SAP ou à la taille et à la portée de l'implémentation SAP. Dans le rapport TR-4250, nous partons du principe que le lecteur connaît les technologies et le fonctionnement des produits NetApp et SAP. Le rapport TR-4250 a été développé sur la base des interactions du personnel technique de NetApp, SAP, Oracle et de nos clients.</block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155 : bases de données Oracle 19c RAC sur FlexPod Datacenter avec Cisco UCS et NetApp AFF A800 over FC - Guide de conception et de déploiement</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">Allen Cao, NetApp</block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">Cette page décrit la méthode automatisée de déploiement de la protection des données Oracle sur un système de stockage NetApp ONTAP.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">Pour commencer</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">Cette solution a été conçue pour être exécutée dans un environnement AWX/Tower.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/Tour</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">Pour les environnements AWX/Tower, vous êtes guidé par la création d'un inventaire de votre cluster de gestion ONTAP et de votre serveur Oracle (IP et noms d'hôtes), la création d'identifiants, la configuration d'un projet qui extrait le code Ansible de NetApp Automation Github et du modèle de tâche qui lance l'automatisation.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">La solution a été conçue pour s'exécuter dans un scénario de cloud privé (sur site vers sur site) et de cloud hybride (Cloud Volumes ONTAP de l'environnement sur site vers le cloud public [CVO])</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">Remplissez les variables spécifiques à votre environnement et copiez-les et collez-les dans les champs Vars supplémentaires de votre modèle de travail.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">Une fois que les rva supplémentaires ont été ajoutés à votre modèle de poste, vous pouvez lancer l'automatisation.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">L'automatisation est définie sur à exécuter trois phases (Configuration, Replication Schedule pour les binaires Oracle, Database, Logs et Replication Schedule uniquement pour les journaux), et une autre phase pour restaurer la base de données sur un site de reprise.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">Recueillir les conditions requises pour les déploiements de Cloud volumes ONTAP et de connecteur</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">Pour obtenir des instructions détaillées pour obtenir les clés et les jetons nécessaires à la protection des données CVO, rendez-vous sur <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">&lt;strong=« big » dans votre infrastructure sur site&lt;/strong&gt; &lt;strong&gt;&lt;/strong&gt;</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">*Environnement Ansible*</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v.2.10 et supérieur</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Bibliothèques Python - netapp-lib - xmltodict - jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">*ONTAP*</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP version 9.8 +</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">Deux agrégats de données</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS vlan et ifgrp créés</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">*Serveur(s) Oracle*</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">Interfaces réseau pour les systèmes de gestion NFS, publics et en option</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">Environnement Oracle existant sous source et système d'exploitation Linux équivalent sur le site de reprise (site de reprise d'activité ou cloud public)</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">&lt;Strong=« big » pour CVO&lt;/strong&gt;</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Définissez l'espace d'échange approprié sur l'instance Oracle EC2, par défaut certaines instances EC2 sont déployées avec 0 swap</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">*Cloud Manager/AWS*</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">Accès AWS/clé secrète</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">Compte NetApp Cloud Manager</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">Jeton d'actualisation de NetApp Cloud Manager</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">Détails de l'automatisation</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">Ce déploiement automatisé est conçu avec un PlayBook Ansible unique composé de trois rôles distincts. Les rôles sont pour les configurations ONTAP, Linux et Oracle. Le tableau suivant décrit les tâches en cours d'automatisation.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">Manuel de vente</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">Tâches</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">*ontap_setup*</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">Vérification préalable de l'environnement ONTAP</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">Création de LIFs intercluster sur le cluster source (FACULTATIF)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">Création de LIFs intercluster sur le cluster destination (FACULTATIF)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">Création de Cluster et de SVM peering</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">Création de SnapMirror de destination et initialisation des volumes Oracle désignés</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">*ora_replication_cg*</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">Activez le mode de sauvegarde pour chaque base de données dans /etc/oratab</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Copie Snapshot des volumes binaires et de base de données Oracle</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror mis à jour</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">Désactivez le mode de sauvegarde pour chaque base de données dans /etc/oratab</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">*ora_replication_log*</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">Changer le journal courant de chaque base de données dans /etc/oratab</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Copie Snapshot du volume du journal Oracle</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">*ora_recovery*</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">Interrompre SnapMirror</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">Activez NFS et créez une Junction path pour les volumes Oracle sur le point de destination</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">Configurer l'hôte Oracle de reprise après incident</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Monter et vérifier les volumes Oracle</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Récupérez et démarrez la base de données Oracle</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">*cvo_setup*</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">Pré-contrôle de l'environnement</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">Configuration AWS/AWS Access Key ID/Secret Key/Default Region</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">Création d'un rôle AWS</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">Création de l'instance NetApp Cloud Manager Connector dans AWS</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">Création de l'instance Cloud Volumes ONTAP (CVO) dans AWS</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">Ajoutez le cluster ONTAP source sur site à NetApp Cloud Manager</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">Activez NFS et créez le Junction path pour les volumes Oracle sur le CVO de destination</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">Paramètres par défaut</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">Pour simplifier l'automatisation, nous avons préréglé de nombreux paramètres Oracle requis avec des valeurs par défaut. Il n'est généralement pas nécessaire de modifier les paramètres par défaut pour la plupart des déploiements. Un utilisateur plus avancé peut modifier les paramètres par défaut avec précaution. Les paramètres par défaut se trouvent dans chaque dossier de rôle, sous le répertoire par défaut.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">Licence</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">Vous devez lire les informations de licence comme indiqué dans le référentiel Github. En accédant, téléchargeant, installant ou utilisant le contenu de ce référentiel, vous acceptez les conditions de la licence prévue <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">Notez qu'il existe certaines restrictions quant à la production et/ou au partage de tout dérivé avec le contenu de ce référentiel. Assurez-vous de lire les conditions du <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> avant d'utiliser le contenu. Si vous n'acceptez pas toutes les conditions, n'accédez pas, ne téléchargez pas ou n'utilisez pas le contenu de ce référentiel.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">Ici pour consulter les procédures détaillées de l'AWX/Tour</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">Lorsque vous êtes prêt, cliquez sur <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">Cette section couvre le déploiement en temps réel d'un environnement de base de données SQL dans une configuration AOAG à l'aide d'un volume SMB Azure NetApp Files.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">Conception de référence de haut niveau en temps réel</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">Nombre de nœuds : 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">Nombre de bases de données : 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">Nombre de groupes de disponibilité : 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">Conservation des sauvegardes : 7 jours</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">Archivage des sauvegardes : 365 jours</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Le déploiement de la solution FCI avec SQL Server sur des machines virtuelles Azure avec un partage Azure NetApp Files offre un modèle économique, avec une seule copie des données. Cette solution peut empêcher les problèmes d'opération d'ajout de fichiers si le chemin d'accès au fichier diffère de la réplique secondaire.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">L'image suivante montre les bases de données d'AOAG réparties sur les nœuds.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Disposition des données</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">Les fichiers de base de données utilisateur (.mdf) et les fichiers journaux de transactions de base de données utilisateur (.ldf) avec tempdb sont stockés sur le même volume. Le niveau de service est Ultra.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">La configuration se compose de quatre nœuds et de quatre groupes AG. Les 21 bases de données (qui font partie de Dynamic AX, SharePoint, RDS connection broker et services d'indexation) sont stockées sur les volumes Azure NetApp Files. Les bases de données sont équilibrées entre les nœuds AOAG pour utiliser efficacement les ressources sur les nœuds. Quatre instances D32 v3 sont ajoutées dans le WSFC, qui participe à la configuration AOAG. Ces quatre nœuds sont provisionnés dans le réseau virtuel Azure et ne sont pas transférés depuis une infrastructure sur site.</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">Si les journaux exigent des performances et un débit plus élevés en fonction de la nature de l'application et des requêtes exécutées, les fichiers de base de données peuvent être placés au niveau de service Premium et les journaux peuvent être stockés au niveau de service Ultra.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">Si les fichiers tempdb ont été placés sur Azure NetApp Files, le volume Azure NetApp Files doit être séparé des fichiers de base de données utilisateur. Voici un exemple de distribution des fichiers de base de données dans AOAG.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">Pour conserver les avantages de la protection des données basée sur les copies Snapshot, NetApp recommande de ne pas combiner les données et les données journaux dans le même volume.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">Une opération d'ajout de fichier effectuée sur le réplica principal peut échouer sur les bases de données secondaires si le chemin d'accès au fichier d'une base de données secondaire diffère du chemin d'accès à la base de données principale correspondante. Cela peut se produire si le chemin du partage est différent sur les nœuds principaux et secondaires (en raison de comptes d'ordinateur différents). Cet échec peut entraîner la suspension des bases de données secondaires. Si le modèle de croissance ou de performance ne peut pas être prévu et que l'on prévoit d'ajouter des fichiers plus tard, un cluster de basculement SQL Server avec Azure NetApp Files est acceptable. Dans la plupart des déploiements, Azure NetApp Files répond aux exigences de performance.</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">Il existe plusieurs façons de migrer une base de données utilisateur SQL Server sur site vers SQL Server sur une machine virtuelle Azure. La migration peut être en ligne ou hors ligne. Les options choisies dépendent de la version de SQL Server, des exigences de l'entreprise et des contrats de niveau de service définis au sein de l'organisation. Pour réduire les temps d'indisponibilité lors du processus de migration de la base de données, NetApp recommande d'utiliser l'option AlwaysOn ou l'option de réplication transactionnelle. S'il n'est pas possible d'utiliser ces méthodes, vous pouvez migrer la base de données manuellement.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">L'approche la plus simple et la plus testée pour déplacer des bases de données sur plusieurs machines est la sauvegarde et la restauration. En principe, vous pouvez commencer par une sauvegarde de base de données suivie d'une copie de sauvegarde de la base de données dans Azure. Vous pouvez alors restaurer la base de données. Pour optimiser les performances de transfert de données, migrez les fichiers de base de données vers la machine virtuelle Azure à l'aide d'un fichier de sauvegarde compressé. La conception générale mentionnée dans ce document fait appel à l'approche de sauvegarde du stockage de fichiers Azure avec synchronisation de fichiers Azure, puis effectue la restauration vers Azure NetApp Files.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure Migrate peut être utilisé pour détecter, évaluer et migrer les charges de travail SQL Server.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">Pour effectuer une migration, procédez comme suit :</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">Configurez la connectivité en fonction de vos besoins.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">Effectuez une sauvegarde complète de la base de données vers un emplacement de partage de fichiers sur site.</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Copiez les fichiers de sauvegarde sur un partage de fichiers Azure avec le fichier de synchronisation Azure.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">Provisionnez la machine virtuelle avec la version souhaitée de SQL Server.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">Copiez les fichiers de sauvegarde sur la machine virtuelle à l'aide de<block ref="12cba3ee81cf4a793796a51b6327c678" prefix=" " category="inline-code"></block> commande à partir d'une invite de commande.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">Restaurez l'ensemble des bases de données sur SQL Server sur des machines virtuelles Azure.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">La restauration de 21 bases de données a nécessité environ 9 heures. Cette approche est spécifique à ce scénario. Toutefois, d'autres techniques de migration répertoriées ci-dessous peuvent être utilisées en fonction de votre situation et de vos exigences.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">Pour déplacer les données d'un serveur SQL sur site vers Azure NetApp Files, vous avez le choix entre plusieurs autres options de migration :</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">Détachez les fichiers de données et de journaux, copiez-les dans le stockage Azure Blob, puis reliez-les à SQL Server dans la machine virtuelle Azure avec un partage de fichiers ANF monté à partir de l'URL.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Assistant d'ajout d'un réplica Azure</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Si vous utilisez toujours un déploiement de groupe de disponibilité sur site, utilisez le<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> Pour créer une réplique dans Azure, puis effectuer un basculement.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">réplication transactionnelle</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">Utilisez SQL Server<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Pour configurer l'instance Azure SQL Server en tant qu'abonné, désactivez la réplication et pointez les utilisateurs vers l'instance de base de données Azure.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Expédiez le disque dur à l'aide du service d'importation/exportation de Windows.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">Sauvegarde et restauration</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">La sauvegarde et la restauration sont un aspect important de tout déploiement de SQL Server. Il est obligatoire d'avoir le filet de sécurité approprié pour récupérer rapidement de divers scénarios de défaillance et de perte de données en conjonction avec des solutions haute disponibilité comme AOAG. L'outil de sauvegarde de base de données SQL Server, Azure Backup (streaming) ou tout outil de sauvegarde tiers tel que CommVault peuvent être utilisés pour effectuer une sauvegarde cohérente entre les applications,</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">Outil SCSQLAPI</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">La technologie Snapshot de Azure NetApp Files vous permet de créer facilement une copie instantanée des bases de données utilisateur, sans affecter les performances ni l'utilisation du réseau. Cette technologie vous permet également de restaurer une copie Snapshot sur un nouveau volume ou de rétablir rapidement l'état antérieur à la création de cette copie à l'aide de la fonction de restauration de volume. Le processus Azure NetApp Files Snapshot est très rapide et efficace, ce qui permet de réaliser plusieurs sauvegardes par jour, contrairement aux sauvegardes en streaming proposées par les sauvegardes Azure. En permettant d'effectuer plusieurs copies Snapshot au cours d'une journée, les délais de RPO et de RTO peuvent être considérablement réduits. Pour ajouter de la cohérence applicative afin que les données soient intactes et correctement vidées sur le disque avant la copie Snapshot, utilisez l'outil de mise au repos de la base de données SQL Server <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; Pour accéder à ce lien, vous devez disposer des identifiants de connexion SSO NetApp.) Cet outil peut être exécuté à partir de PowerShell, qui arrête la base de données SQL Server et peut ensuite effectuer la copie Snapshot de stockage cohérente au niveau des applications pour les sauvegardes.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">*Notes : *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">L'outil SCSQLAPI ne prend en charge que les versions 2016 et 2017 de SQL Server.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">L'outil SCSQLAPI ne fonctionne qu'avec une base de données à la fois.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">Isolez les fichiers de chaque base de données en les plaçant dans un volume Azure NetApp Files distinct.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Sauvegarde Azure</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">En raison des vastes limites de l'API SCSQL,<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> Utilisé pour la protection des données afin de répondre aux exigences des contrats de niveau de service. Il offre une sauvegarde en flux de SQL Server exécutée sur des machines virtuelles Azure et Azure NetApp Files. Azure Backup permet un RPO de 15 minutes avec des sauvegardes fréquentes de journaux et une restauration jusqu'à une seconde.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">Contrôle</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files est intégré à Azure Monitor pour les données de séries chronologiques et fournit des metrics du stockage alloué, de l'utilisation réelle du stockage, des IOPS du volume, du débit, des octets de lecture du disque/s en écriture de disques en octets/seconde, en lectures/s de disque et en écritures/s de disque, ainsi que la latence associée. Ces données peuvent être utilisées pour identifier les goulots d'étranglement avec des alertes et effectuer des vérifications de l'état pour vérifier que votre déploiement SQL Server s'exécute dans une configuration optimale.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">Dans ce HLD, ScienceLogic permet de surveiller Azure NetApp Files en exposant les mesures à l'aide du principal de service approprié. L'image suivante est un exemple de l'option métrique de Azure NetApp Files.</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">DevTest utilisant des clones épais</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Avec Azure NetApp Files, vous pouvez créer des copies instantanées des bases de données pour tester les fonctionnalités qui doivent être implémentées en utilisant la structure et le contenu de la base de données en cours pendant les cycles de développement des applications, afin d'utiliser les outils d'extraction et de manipulation des données lors du remplissage des entrepôts de données, ou de récupérer les données qui ont été supprimées ou modifiées par erreur. Ce processus n'implique pas la copie des données à partir des conteneurs Azure Blob, ce qui en fait une méthode très efficace. Une fois le volume restauré, il peut être utilisé pour les opérations de lecture/écriture, ce qui réduit considérablement la validation et le délai de mise sur le marché. Ceci doit être utilisé en association avec SCSQLAPI pour assurer la cohérence des applications. Cette approche fournit une autre technique d'optimisation continue des coûts avec Azure NetApp Files en exploitant l'option Restaurer vers un nouveau volume.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">Le volume créé à partir de la copie Snapshot à l'aide de l'option Restaurer un nouveau volume consomme la capacité du pool de capacité.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">Pour éviter des coûts supplémentaires (si le pool de capacité doit être augmenté), vous pouvez supprimer les volumes clonés à l'aide de l'interface de ligne de commandes REST ou Azure.</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">Options de stockage hybride</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">Bien que NetApp recommande d'utiliser le même stockage pour tous les nœuds des groupes de disponibilité SQL Server, plusieurs options de stockage peuvent être utilisées dans certains scénarios. Ce scénario est possible pour Azure NetApp Files dans lequel un nœud d'AOAG est connecté à un partage de fichiers SMB Azure NetApp Files et le second nœud est connecté à un disque Azure Premium. Dans ces cas, assurez-vous que le partage SMB de Azure NetApp Files contient la copie principale des bases de données utilisateur et que le disque Premium est utilisé comme copie secondaire.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">Dans de tels déploiements, pour éviter tout problème de basculement, assurez-vous que la disponibilité continue est activée sur le volume SMB. Sans attribut disponible en continu, la base de données peut échouer si une maintenance en arrière-plan est effectuée au niveau de la couche de stockage.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">Conservez la copie principale de la base de données sur le partage de fichiers SMB de Azure NetApp Files.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">Continuité de l'activité</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">La reprise après incident s'effectue généralement après coup dans n'importe quel déploiement. Cependant, la reprise sur incident doit être abordée lors de la phase initiale de conception et de déploiement afin d'éviter tout impact sur votre activité. Avec Azure NetApp Files, la fonctionnalité de réplication interrégion (CRR) permet de répliquer les données de volume au niveau des blocs vers la région appariée pour gérer toute panne régionale inattendue. Le volume de destination CRR peut être utilisé pour les opérations de lecture, ce qui en fait le candidat idéal aux simulations de reprise après incident. De plus, la destination CRR peut être affectée avec le niveau de service le plus bas (par exemple, Standard) afin de réduire le coût total de possession global. En cas de basculement, la réplication peut être interrompue, afin de prendre en charge les opérations de lecture/écriture du volume respectif. De plus, le niveau de service du volume peut être modifié à l'aide de la fonctionnalité de niveau de service dynamique, afin de réduire considérablement les coûts de reprise après incident. Il s'agit d'une autre fonctionnalité unique d'Azure NetApp Files avec la réplication de blocs dans Azure.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">Archivage de copies Snapshot à long terme</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">Copie Azure</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">De nombreuses entreprises doivent obligatoirement appliquer la conservation à long terme des données Snapshot à partir des fichiers de base de données. Bien que ce processus ne soit pas utilisé dans ce HLD, il peut être facilement réalisé à l'aide d'un script de batch simple utilisant<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> Pour copier le répertoire de snapshots dans le conteneur Azure Blob. Le script de batch peut être déclenché en fonction d'un planning spécifique à l'aide de tâches planifiées. Le processus est simple : il comprend les étapes suivantes :</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">Téléchargez le fichier exécutable AzCopy V10. L'installation n'est rien, car il s'agit d'un<block ref="98e83379d45538379c2ac4e47c3be81d" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">Autoriser AzCopy en utilisant un jeton SAS au niveau du conteneur avec les autorisations appropriées.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">Une fois que AzCopy est autorisé, le transfert des données commence.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">Dans les fichiers de traitement par lot, assurez-vous d'échapper aux % de caractères qui apparaissent dans les jetons SAS. Pour ce faire, ajoutez un % de caractère supplémentaire à côté de % de caractères existants dans la chaîne de jeton SAS.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">Transfert sécurisé requis</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">Le<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> La définition d'un compte de stockage détermine si la connexion à un compte de stockage est sécurisée avec transport Layer Security (TLS). Ce paramètre est activé par défaut. L'exemple de script de traitement par lot suivant copie de façon récursive les données du répertoire de copie Snapshot vers un conteneur Blob désigné :</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">L'exemple cmd suivant est exécuté dans PowerShell :</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Une fonctionnalité de sauvegarde similaire pour la conservation à long terme sera bientôt disponible dans Azure NetApp Files.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">Le script de batch peut être utilisé dans tout scénario nécessitant la copie de données dans le conteneur Blob d'une région quelconque.</block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">Optimisation des coûts</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">Avec la transformation des volumes et l'évolution dynamique du niveau de service, qui est totalement transparente pour la base de données, Azure NetApp Files permet une optimisation continue des coûts dans Azure. Cette fonctionnalité est largement utilisée dans ce HLD pour éviter le sur-provisionnement du stockage supplémentaire pour gérer les pics de charge de travail.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">Le redimensionnement du volume peut être facilement effectué en créant une fonction Azure conjointement aux journaux d'alertes Azure.</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen, NetApp</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">Tr-4467 fournit à nos clients et partenaires des pratiques d'excellence pour le déploiement de clustered NetApp Data ONTAP sur la prise en charge des solutions SAP Business Suite exécutées dans un environnement Microsoft SQL Server sur Windows.</block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">L'agilité du cloud public, le retour sur investissement et les économies constituent des propositions de valeur significatives pour les entreprises d'adopter le cloud public en vue de développer et de tester les applications de base de données. Il n'y a pas de meilleur outil que SnapCenter pour faire de cela une réalité en urgence. SnapCenter peut non seulement protéger votre base de données de production sur site, mais aussi cloner rapidement une copie pour le développement d'applications ou les tests de code dans le cloud public, tout en consommant très peu d'espace de stockage supplémentaire. Vous trouverez ci-après des détails sur les processus étape par étape à l'aide de l'outil.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">Workflow de développement/test bursting vers le cloud</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">Précédente : mise en route avec le cloud public AWS.</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">L'agilité du cloud public, le retour sur investissement et les économies générées sont toutes des propositions de valeur pertinentes pour les entreprises qui adoptent le cloud public pour les efforts de développement et de test des applications de bases de données. SnapCenter est le meilleur outil pour faire de cette vision une réalité. SnapCenter peut non seulement protéger votre base de données de production sur site, mais aussi cloner rapidement une copie pour le développement d'applications ou les tests de code dans le cloud public, tout en consommant très peu d'espace de stockage supplémentaire. Vous trouverez ci-après des détails sur les processus étape par étape d'utilisation de cet outil.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">Cloner une base de données Oracle à des fins de développement et de test à partir d'une sauvegarde snapshot répliquée</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Connectez-vous à SnapCenter avec un ID utilisateur de gestion de base de données pour Oracle. Accédez à l'onglet Ressources, qui affiche les bases de données Oracle protégées par SnapCenter.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">Cliquez sur le nom de la base de données sur site prévue pour la topologie de sauvegarde et la vue détaillée. Si un emplacement répliqué secondaire est activé, les sauvegardes miroir liées s'affichent.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">Basculez vers la vue sauvegardes en miroir en cliquant sur sauvegardes en miroir. La ou les sauvegardes du miroir secondaire s'affichent alors.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">Choisissez une copie de sauvegarde de base de données secondaire en miroir à cloner et déterminez un point de récupération par heure et numéro de modification du système ou par SCN. Généralement, le point de restauration doit faire l'objet d'une sauvegarde complète de la base de données ou d'un SCN à cloner. Une fois qu'un point de récupération a été déterminé, la sauvegarde du fichier journal requis doit être montée pour la restauration. La sauvegarde du fichier journal doit être montée sur le serveur de base de données cible sur lequel la base de données clone doit être hébergée.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">Si l'élagage des journaux est activé et que le point de restauration est étendu au-delà de la dernière taille des journaux, il peut être nécessaire de monter plusieurs sauvegardes des journaux d'archives.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">Mettez en surbrillance la copie de sauvegarde complète de la base de données à cloner, puis cliquez sur le bouton clone pour démarrer le workflow du clone de base de données.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">Choisissez un SID de base de données de clonage approprié pour une base de données de conteneur complète ou un clone CDB.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">Sélectionnez l'hôte de clone cible dans le cloud. Les répertoires des fichiers de données, des fichiers de contrôle et des journaux de reprise sont créés par le workflow de clonage.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">Le nom d'identification aucun est utilisé pour l'authentification basée sur le système d'exploitation, ce qui rend le port de base de données non pertinent. Remplissez le répertoire Oracle Home, Oracle OS User et Oracle OS Group approprié tel qu'il est configuré dans le serveur de base de données clone cible.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">Spécifiez les scripts à exécuter avant l'opération de clonage. Plus important encore, le paramètre d'instance de base de données peut être ajusté ou défini ici.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">Spécifiez le point de récupération par date et heure ou par SCN. Jusqu'à ce que Annuler récupère la base de données jusqu'aux journaux d'archivage disponibles. Spécifiez l'emplacement du journal d'archivage externe à partir de l'hôte cible sur lequel le volume du journal d'archivage est monté. Si le propriétaire Oracle du serveur cible est différent du serveur de production sur site, vérifiez que le répertoire du journal d'archivage est lisible par le propriétaire Oracle du serveur cible.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">Configurez le serveur SMTP pour la notification par e-mail si vous le souhaitez.</block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">Récapitulatif du clonage.</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">Après le clonage, vous devez vérifier que la base de données clonée est opérationnelle. Certaines tâches supplémentaires, telles que le démarrage de l'écouteur ou la désactivation du mode d'archivage du journal DB, peuvent être effectuées sur la base de données de développement/test.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">Cloner une base de données SQL à des fins de développement et de test à partir d'une sauvegarde Snapshot répliquée</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">Connectez-vous à SnapCenter avec un ID utilisateur de gestion de base de données pour SQL Server. Accédez à l'onglet Ressources, qui affiche les bases de données utilisateur SQL Server protégées par SnapCenter et une instance SQL de secours cible dans le cloud public.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">Cliquez sur le nom de base de données utilisateur SQL Server sur site prévu pour la topologie des sauvegardes et la vue détaillée. Si un emplacement répliqué secondaire est activé, les sauvegardes miroir liées s'affichent.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">Basculer vers la vue sauvegardes mises en miroir en cliquant sur sauvegardes mises en miroir. Les sauvegardes de miroir secondaire sont alors affichées. Étant donné que SnapCenter sauvegarde le journal de transactions SQL Server sur un disque dédié à la restauration, seules les sauvegardes complètes de la base de données sont affichées ici.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">Choisissez une copie de sauvegarde, puis cliquez sur le bouton Cloner pour lancer le flux de travail Cloner à partir de la sauvegarde.</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">Sélectionnez un serveur cloud comme serveur de clonage cible, nom d'instance de clone et nom de base de données clone. Choisissez un point de montage à affectation automatique ou un chemin de point de montage défini par l'utilisateur.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">Déterminez un point de restauration par heure de sauvegarde du journal ou par date et heure spécifiques.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">Spécifiez les scripts facultatifs à exécuter avant et après l'opération de clonage.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">Configurez un serveur SMTP si vous souhaitez recevoir une notification par e-mail.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">Synthèse des clones.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">Surveillez l'état du travail et vérifiez que la base de données utilisateur prévue a été associée à une instance SQL cible dans le serveur clone du cloud.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">Configuration post-clonage</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">Une base de données de production Oracle sur site est généralement exécutée en mode d'archivage des journaux. Ce mode n'est pas nécessaire pour une base de données de développement ou de test. Pour désactiver le mode d'archivage des journaux, connectez-vous à la base de données Oracle sous sysdba, exécutez une commande de changement du mode de journalisation et démarrez la base de données pour accéder à.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Configurez un écouteur Oracle ou enregistrez la base de données nouvellement clonée avec un écouteur existant pour accéder à l'utilisateur.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">Pour SQL Server, passez du mode de journal complet à facile afin que le fichier journal de développement/test SQL Server puisse être facilement réduit lorsqu'il remplit le volume de journal.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">Actualiser la base de données de clonage</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">Déposez les bases de données clonées et nettoyez l'environnement de serveur Cloud DB. Suivez ensuite les procédures précédentes pour cloner une nouvelle base de données avec des données récentes. Le clonage d'une nouvelle base de données ne prend que quelques minutes.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">Actualiser un clone</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">Arrêtez la base de données clone, exécutez une commande de mise à jour du clone à l'aide de l'interface de ligne de commandes. Pour plus d'informations, consultez la documentation SnapCenter suivante : <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">Si vous avez besoin d'aide pour utiliser cette solution, rejoignez la <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> et recherchez le canal solution-automation pour poser vos questions ou vos questions.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">Suivant : workflow de reprise sur incident.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">L'outil NetApp SnapCenter utilise le contrôle d'accès basé sur des rôles (RBAC) pour gérer l'accès aux ressources utilisateur et les autorisations, et l'installation d'SnapCenter crée des rôles préremplis. Vous pouvez également créer des rôles personnalisés en fonction de vos besoins ou de vos applications.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">Pour commencer sur site</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">Précédent : présentation de la mise en route.</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">1. Configurer l'utilisateur administrateur de la base de données dans SnapCenter</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">L'outil NetApp SnapCenter utilise le contrôle d'accès basé sur des rôles (RBAC) pour gérer l'accès aux ressources utilisateur et les autorisations. De plus, l'installation de SnapCenter crée des rôles préremplis. Vous pouvez également créer des rôles personnalisés en fonction de vos besoins ou de vos applications. Il est judicieux de disposer d'un ID utilisateur d'administration dédié pour chaque plateforme de base de données prise en charge par SnapCenter pour la sauvegarde, la restauration de bases de données et/ou la reprise après incident. Vous pouvez également utiliser un ID unique pour gérer toutes les bases de données. Dans nos tests de cas et notre démonstration, nous avons créé un utilisateur administratif dédié respectivement à Oracle et à SQL Server.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">Certaines ressources SnapCenter ne peuvent être provisionnées que avec le rôle SnapCenter. Les ressources peuvent ensuite être attribuées à d'autres ID d'utilisateur pour l'accès.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">Dans un environnement SnapCenter sur site préinstallé et configuré, les tâches suivantes peuvent déjà avoir été effectuées. Si ce n'est pas le cas, procédez comme suit pour créer un utilisateur administrateur de base de données :</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Ajoutez l'utilisateur admin à Windows Active Directory.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID attribué avec le rôle SnapCenterAdmin.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">Accédez à l'onglet accès sous Paramètres et utilisateurs, puis cliquez sur Ajouter pour ajouter un nouvel utilisateur. Le nouvel ID utilisateur est lié à l'utilisateur admin créé dans Windows Active Directory à l'étape 1. . Attribuez le rôle approprié à l'utilisateur selon les besoins. Affectez des ressources à l'utilisateur administrateur, le cas échéant.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2. Conditions préalables à l'installation du plug-in SnapCenter</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter effectue des sauvegardes, des restaurations, des clones et d'autres fonctions à l'aide d'un agent de plug-in exécuté sur les hôtes de base de données. Il se connecte à l'hôte et à la base de données via les informations d'identification configurées sous l'onglet Paramètres et informations d'identification pour l'installation du plug-in et d'autres fonctions de gestion. Il existe des conditions de privilège spécifiques en fonction du type d'hôte cible, tel que Linux ou Windows, ainsi que du type de base de données.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">Les informations d'identification des hôtes DB doivent être configurées avant l'installation du plug-in SnapCenter. En général, vous souhaitez utiliser un compte d'utilisateur administrateur sur l'hôte DB comme informations d'identification de connexion hôte pour l'installation du plug-in. Vous pouvez également attribuer le même ID utilisateur pour l'accès à la base de données à l'aide de l'authentification basée sur le système d'exploitation. En revanche, vous pouvez également utiliser l'authentification de base de données avec différents ID d'utilisateur de base de données pour l'accès à la gestion de base de données. Si vous décidez d'utiliser l'authentification basée sur le système d'exploitation, l'ID utilisateur admin du système d'exploitation doit disposer d'un accès DB. Pour l'installation de SQL Server sous domaine Windows, un compte d'administrateur de domaine peut être utilisé pour gérer tous les serveurs SQL du domaine.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">Hôte Windows pour SQL Server :</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">Si vous utilisez des informations d'identification Windows pour l'authentification, vous devez configurer vos informations d'identification avant d'installer des plug-ins.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">Si vous utilisez une instance SQL Server pour l'authentification, vous devez ajouter les informations d'identification après avoir installé des plug-ins.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">Si vous avez activé l'authentification SQL lors de la configuration des informations d'identification, l'instance ou la base de données découverte s'affiche avec une icône de verrouillage rouge. Si l'icône de verrouillage apparaît, vous devez spécifier les informations d'identification de l'instance ou de la base de données pour pouvoir ajouter l'instance ou la base de données à un groupe de ressources.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">Vous devez affecter ces informations d'identification à un utilisateur RBAC sans accès sysadmin lorsque les conditions suivantes sont remplies :</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">Les informations d'identification sont affectées à une instance SQL.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">L'instance ou l'hôte SQL est affecté à un utilisateur RBAC.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">L'utilisateur administrateur de BD RBAC doit disposer à la fois du groupe de ressources et des privilèges de sauvegarde.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Hôte UNIX pour Oracle :</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">Vous devez avoir activé la connexion SSH par mot de passe pour l'utilisateur root ou non-root en modifiant sshd.conf et en redémarrant le service sshd. L'authentification SSH basée sur le mot de passe sur une instance AWS est désactivée par défaut.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">Configurez les privilèges sudo pour que l'utilisateur non-root installe et démarre le processus de plug-in. Après avoir installé le plug-in, les processus s'exécutent en tant qu'utilisateur root efficace.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">Créez des informations d'identification avec le mode d'authentification Linux pour l'utilisateur d'installation.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Vous devez installer Java 1.8.x (64 bits) sur votre hôte Linux.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">L'installation du plug-in de base de données Oracle installe également le plug-in SnapCenter pour Unix.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3. Installation du plug-in hôte SnapCenter</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">Avant de tenter d'installer des plug-ins SnapCenter sur des instances de serveur BDD cloud, assurez-vous que toutes les étapes de configuration sont terminées, comme indiqué dans la section cloud appropriée pour le déploiement de l'instance de calcul.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">Les étapes suivantes illustrent la manière dont un hôte de base de données est ajouté à SnapCenter pendant qu'un plug-in SnapCenter est installé sur l'hôte. La procédure s'applique à l'ajout d'hôtes sur site et d'hôtes cloud. La démonstration suivante ajoute un hôte Windows ou Linux résidant dans AWS.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">Configurez les paramètres globaux de SnapCenter VMware</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">Accédez à Paramètres &gt; Paramètres globaux. Sous Paramètres de l'hyperviseur, sélectionnez « les machines virtuelles ont des disques iSCSI à connexion directe ou NFS pour tous les hôtes », puis cliquez sur mettre à jour.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">Ajoutez l'hôte Windows et l'installation du plug-in sur l'hôte</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">Connectez-vous à SnapCenter avec un ID utilisateur doté des privilèges SnapCenterAdmin.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">Cliquez sur l'onglet hôtes dans le menu de gauche, puis cliquez sur Ajouter pour ouvrir le flux de travail Ajouter hôte.</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">Choisissez Windows pour le type d'hôte ; le nom d'hôte peut être un nom d'hôte ou une adresse IP. Le nom d'hôte doit être résolu à l'adresse IP d'hôte correcte de l'hôte SnapCenter. Choisissez les informations d'identification de l'hôte créées à l'étape 2. Choisissez Microsoft Windows et Microsoft SQL Server comme modules d'extension à installer.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Une fois le plug-in installé sur un hôte Windows, son état global s'affiche sous la forme "configurer le répertoire du journal".</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">Cliquez sur le nom d'hôte pour ouvrir la configuration du répertoire du journal de SQL Server.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">Cliquez sur « configurer le répertoire du journal » pour ouvrir « configurer le plug-in pour SQL Server ».</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">Cliquez sur Parcourir pour découvrir le stockage NetApp afin de définir un répertoire de journaux ; SnapCenter utilise ce répertoire de journaux pour restaurer les fichiers journaux de transactions du serveur SQL. Cliquez ensuite sur Enregistrer.</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">Pour que le stockage NetApp provisionné sur un hôte de base de données soit découvert, le stockage (sur site ou CVO) doit être ajouté à SnapCenter, comme illustré à l'étape 6 pour CVO.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">Une fois le répertoire du journal configuré, l'état global du plug-in hôte Windows est défini sur en cours d'exécution.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">Pour attribuer l'hôte à l'ID utilisateur de gestion de base de données, accédez à l'onglet accès sous Paramètres et utilisateurs, cliquez sur l'ID utilisateur de gestion de base de données (dans notre cas, l'ID utilisateur de gestion de base de données à affecter à l'hôte), puis cliquez sur Enregistrer pour terminer l'affectation de ressources hôte.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Ajoutez l'hôte Unix et l'installation du plug-in sur l'hôte</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">Cliquez sur l'onglet hôtes dans le menu de gauche, puis cliquez sur Ajouter pour ouvrir le flux de travail Ajouter hôte.</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">Choisissez Linux comme Type d'hôte. Le nom d'hôte peut être soit le nom d'hôte, soit une adresse IP. Cependant, le nom d'hôte doit être résolu pour corriger l'adresse IP de l'hôte SnapCenter. Choisissez les informations d'identification de l'hôte créées à l'étape 2. Les informations d'identification de l'hôte nécessitent des privilèges sudo. Vérifiez Oracle Database en tant que plug-in à installer, qui installe à la fois les plug-ins hôtes Oracle et Linux.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">Cliquez sur plus d'options et sélectionnez « Ignorer les vérifications de préinstallation ». Vous êtes invité à confirmer l'omission de la vérification de préinstallation. Cliquez sur Oui, puis sur Enregistrer.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">Cliquez sur soumettre pour démarrer l'installation du plug-in. Vous êtes invité à confirmer l'empreinte digitale comme indiqué ci-dessous.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter effectue la validation et l'enregistrement des hôtes, puis le plug-in est installé sur l'hôte Linux. L'état passe de installation du plug-in à exécution.</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">Affectez l'hôte nouvellement ajouté à l'ID utilisateur de gestion de base de données approprié (dans notre cas, oradba).</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4. Découverte de ressources de base de données</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">Une fois l'installation du plug-in réussie, les ressources de la base de données sur l'hôte peuvent être immédiatement découvertes. Cliquez sur l'onglet Ressources dans le menu de gauche. Selon le type de plate-forme de base de données, un certain nombre de vues sont disponibles, comme la base de données, le groupe de ressources, etc. Vous devrez peut-être cliquer sur l'onglet Actualiser les ressources si les ressources de l'hôte ne sont pas découvertes et affichées.</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">Lorsque la base de données est initialement découverte, l'état global est indiqué comme « non protégé ». La capture d'écran précédente montre qu'une base de données Oracle n'est pas encore protégée par une règle de sauvegarde.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">Lorsqu'une configuration ou une stratégie de sauvegarde est configurée et qu'une sauvegarde a été exécutée, l'état général de la base de données affiche l'état de sauvegarde « sauvegarde réussie » et l'horodatage de la dernière sauvegarde. La capture d'écran suivante montre l'état de sauvegarde d'une base de données utilisateur SQL Server.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">Si les informations d'identification d'accès à la base de données ne sont pas correctement configurées, un bouton de verrouillage rouge indique que la base de données n'est pas accessible. Par exemple, si les informations d'identification Windows ne disposent pas d'un accès sysadmin à une instance de base de données, les informations d'identification de la base de données doivent être reconfigurées pour déverrouiller le verrou rouge.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Une fois que les informations d'identification appropriées sont configurées soit au niveau de Windows, soit au niveau de la base de données, le verrou rouge disparaît et les informations de type de serveur SQL sont rassemblées et vérifiées.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">5. Configuration de la réplication des volumes de peering de cluster de stockage et de BDD</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">Pour protéger vos données de base de données sur site à l'aide d'un cloud public comme destination cible, les volumes de base de données du cluster ONTAP sur site sont répliqués dans Cloud volumes CVO à l'aide de la technologie NetApp SnapMirror. Les volumes cibles répliqués peuvent ensuite être clonés pour LE DÉVELOPPEMENT/opérations ou la reprise après incident. Les étapes de haut niveau suivantes vous permettent de configurer le peering de clusters et la réplication des volumes de la base de données.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">Configurer les LIF intercluster pour le peering de cluster sur le cluster sur site et sur l'instance du cluster CVO. Cette étape peut être réalisée avec ONTAP System Manager. Un déploiement CVO par défaut est configuré automatiquement pour les LIF inter-cluster.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">Cluster sur site :</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">Cluster CVO cible :</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">Mise en route - Cloud public AWS</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">Lorsque les LIF intercluster sont configurées, le peering de clusters et la réplication des volumes peuvent être configurés en utilisant le glisser-déposer dans NetApp Cloud Manager. Voir <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> pour plus d'informations.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">Vous pouvez également effectuer la réplication de volume de peering de clusters et de bases de données à l'aide de ONTAP System Manager, comme suit :</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">Connectez-vous à ONTAP System Manager. Naviguez jusqu'à Cluster &gt; Paramètres et cliquez sur Peer Cluster pour configurer le cluster peering avec l'instance CVO dans le cloud.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">Accédez à l'onglet volumes. Sélectionnez le volume de la base de données à répliquer et cliquez sur protéger.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">Définissez la règle de protection sur asynchrone. Sélectionner le cluster de destination et le SVM de stockage.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">Vérifier que le volume est synchronisé entre la source et la cible et que la relation de réplication fonctionne correctement.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">6. Ajouter le SVM de stockage de base de données CVO à SnapCenter</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">Cliquez sur l'onglet Storage System dans le menu, puis sur New pour ajouter un SVM de stockage CVO qui héberge les volumes de base de données cible répliqués dans SnapCenter. Saisissez l'IP de gestion de cluster dans le champ Storage System, puis saisissez le nom d'utilisateur et le mot de passe appropriés.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">Cliquez sur plus d'options pour ouvrir d'autres options de configuration de stockage. Dans le champ plate-forme, sélectionnez Cloud Volumes ONTAP, cochez secondaire, puis cliquez sur Enregistrer.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">Attribuez les systèmes de stockage aux ID d'utilisateur de gestion de la base de données SnapCenter, comme indiqué dans la <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">7. Configurer la politique de sauvegarde de la base de données dans SnapCenter</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">Les procédures suivantes montrent comment créer une stratégie de sauvegarde complète de base de données ou de fichiers journaux. La stratégie peut ensuite être mise en œuvre pour protéger les ressources des bases de données. L'objectif de point de récupération (RPO) ou l'objectif de délai de restauration (RTO) détermine la fréquence des sauvegardes de bases de données et/ou de journaux.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Créez une stratégie de sauvegarde complète de la base de données pour Oracle</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">Connectez-vous à SnapCenter en tant qu'ID utilisateur de gestion de base de données, cliquez sur Paramètres, puis sur stratégies.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">Cliquez sur Nouveau pour lancer un nouveau workflow de création de stratégie de sauvegarde ou choisir une stratégie existante pour la modification.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">Sélectionnez le type de sauvegarde et la fréquence de planification.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">Définissez le paramètre de conservation de sauvegarde. Cet objectif définit le nombre de copies de sauvegarde complètes à conserver dans une base de données.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">Sélectionnez les options de réplication secondaires pour envoyer les sauvegardes de snapshots primaires locaux à répliquer vers un emplacement secondaire dans le cloud.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">Spécifiez tout script facultatif à exécuter avant et après l'exécution d'une sauvegarde.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">Exécutez la vérification des sauvegardes si nécessaire.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">Récapitulatif.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Créez une stratégie de sauvegarde du journal de base de données pour Oracle</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID utilisateur de gestion de base de données, cliquez sur Paramètres, puis sur stratégies.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">Cliquez sur Nouveau pour lancer un nouveau workflow de création de stratégie de sauvegarde ou choisissez une stratégie existante à modifier.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">Définissez la période de conservation du journal.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">Répliquez la réplication dans un emplacement secondaire dans le cloud public.</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">Spécifiez tous les scripts facultatifs à exécuter avant et après la sauvegarde du journal.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">Spécifiez tous les scripts de vérification de sauvegarde.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">Créez une stratégie de sauvegarde complète de la base de données pour SQL</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">Définissez l'option de sauvegarde et la fréquence de planification. Pour SQL Server configuré avec un groupe de disponibilité, il est possible de définir une réplique de sauvegarde préférée.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">Définissez la période de conservation des sauvegardes.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">Intégrez la réplication de copie de sauvegarde à un emplacement secondaire dans le cloud.</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">Spécifiez tous les scripts facultatifs à exécuter avant ou après une procédure de sauvegarde.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">Spécifiez les options d'exécution de la vérification de sauvegarde.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">Créez une stratégie de sauvegarde du journal de base de données pour SQL.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID utilisateur de gestion de base de données, cliquez sur Paramètres &gt; règles, puis sur Nouveau pour lancer un nouveau workflow de création de règles.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">Définissez l'option de sauvegarde du journal et la fréquence de planification. Pour SQL Server configuré avec un groupe de disponibilité, une réplique de sauvegarde préférée peut être définie.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">La stratégie de sauvegarde des données de SQL Server définit la rétention de la sauvegarde des journaux ; acceptez les valeurs par défaut ici.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">Réplication de sauvegardes de journaux sur un stockage secondaire dans le cloud.</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">8. Mettre en œuvre une politique de sauvegarde pour protéger la base de données</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter utilise un groupe de ressources pour sauvegarder une base de données dans un groupe logique de ressources de bases de données, par exemple plusieurs bases de données hébergées sur un serveur, une base de données partageant les mêmes volumes de stockage, plusieurs bases de données prenant en charge une application professionnelle, etc. La protection d'une base de données unique crée un groupe de ressources lui-même. Les procédures suivantes montrent comment mettre en œuvre une stratégie de sauvegarde créée à la section 7 pour protéger les bases de données Oracle et SQL Server.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Créez un groupe de ressources pour la sauvegarde complète d'Oracle</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID utilisateur de gestion de base de données et accédez à l'onglet Ressources. Dans la liste déroulante Affichage, choisissez base de données ou Groupe de ressources pour lancer le flux de travail de création de groupe de ressources.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">Indiquez un nom et des balises pour le groupe de ressources. Vous pouvez définir un format de nommage pour la copie Snapshot et contourner la destination redondante du journal d'archivage si elle est configurée.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">Ajoutez des ressources de base de données au groupe de ressources.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">Sélectionnez une stratégie de sauvegarde complète créée dans la section 7 dans la liste déroulante.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">Cliquez sur le signe (+) pour configurer le programme de sauvegarde souhaité.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Cliquez sur Charger les localisateurs pour charger le volume source et le volume de destination.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Créez un groupe de ressources pour la sauvegarde du journal d'Oracle</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">Sélectionnez une stratégie de sauvegarde de journal créée dans la section 7 dans la liste déroulante.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">Cliquez sur le signe (+) pour configurer le programme de sauvegarde souhaité.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">Si la vérification de sauvegarde est configurée, elle s'affiche ici.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">Configurez un serveur SMTP pour la notification par e-mail si vous le souhaitez.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">Créez un groupe de ressources pour la sauvegarde complète de SQL Server</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID utilisateur de gestion de base de données et accédez à l'onglet Ressources. Dans la liste déroulante Affichage, choisissez une base de données ou un groupe de ressources pour lancer le flux de travail de création de groupe de ressources. Indiquez un nom et des balises pour le groupe de ressources. Vous pouvez définir un format d'attribution de nom à la copie Snapshot.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">Sélectionnez les ressources de base de données à sauvegarder.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">Sélectionnez une stratégie de sauvegarde SQL complète créée dans la section 7.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">Ajoutez la durée exacte des sauvegardes ainsi que la fréquence.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">Choisissez le serveur de vérification pour la sauvegarde sur secondaire si la vérification de sauvegarde doit être effectuée. Cliquez sur Charger le localisateur pour renseigner l'emplacement de stockage secondaire.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">Créez un groupe de ressources pour la sauvegarde des journaux de SQL Server</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">Connectez-vous à SnapCenter à l'aide d'un ID utilisateur de gestion de base de données et accédez à l'onglet Ressources. Dans la liste déroulante Affichage, choisissez une base de données ou un groupe de ressources pour lancer le flux de travail de création de groupe de ressources. Indiquez le nom et les balises du groupe de ressources. Vous pouvez définir un format d'attribution de nom à la copie Snapshot.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">Sélectionnez une stratégie de sauvegarde du journal SQL créée à la section 7.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">Ajoutez la synchronisation exacte pour la sauvegarde ainsi que la fréquence.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">Choisissez le serveur de vérification pour la sauvegarde sur secondaire si la vérification de sauvegarde doit être effectuée. Cliquez sur le localisateur de charge pour renseigner l'emplacement de stockage secondaire.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9. Valider la sauvegarde</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">Une fois que des groupes de ressources de sauvegarde de base de données sont créés pour protéger les ressources de base de données, les tâches de sauvegarde s'exécutent en fonction du planning prédéfini. Vérifiez l'état d'exécution du travail sous l'onglet moniteur.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">Accédez à l'onglet Ressources, cliquez sur le nom de la base de données pour afficher les détails de la sauvegarde de la base de données, et basculez entre les copies locales et les copies miroir pour vérifier que les sauvegardes Snapshot sont répliquées dans un emplacement secondaire du cloud public.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">À ce stade, les copies de sauvegarde de base de données dans le cloud sont prêtes à cloner pour exécuter des processus de développement/test ou pour la reprise après incident en cas de panne principale.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">Ensuite, mise en route du cloud public AWS.</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">Cette solution a été conçue pour être exécutée dans un environnement AWX/Tower ou via l'interface de ligne de commande sur un hôte de contrôle Ansible.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">Le modèle de travail est exécuté en trois phases en spécifiant des balises pour ontap_config, linux_config et oracle_config.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">CLI via l'hôte de contrôle Ansible</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">Cliquez ici pour RHEL 7/8 ou CentOS 7/8</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Ici pour Ubuntu/Debian</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Pour configurer l'hôte Linux de sorte qu'il puisse être utilisé comme hôte de contrôle Ansible<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>, ou<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Une fois l'hôte de contrôle Ansible configuré, vous pouvez cloner le référentiel Ansible Automation.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">Modifiez le fichier hosts avec les adresses IP et/ou les noms d'hôte de votre cluster de gestion ONTAP et les adresses IP de gestion du serveur Oracle.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">Remplissez les variables spécifiques à votre environnement, puis copiez-les et collez-les dans le<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">Chaque hôte Oracle dispose d'un fichier de variables identifié par son nom d'hôte qui contient des variables spécifiques à l'hôte.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">Une fois tous les fichiers variables terminés, vous pouvez exécuter le PlayBook en trois phases en spécifiant des balises pour<block ref="0aadb2735557202c6ab978c489e2b6e9" prefix=" " category="inline-code"></block>,<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block>, et<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block>.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">Hôte AWX/Tower ou Linux pour être l'hôte de contrôle Ansible</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP version 9.3 - 9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Fichiers d'installation Oracle sur les serveurs Oracle</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">Rôle</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">*ontap_config*</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Création d'un SVM basé sur NFS pour Oracle</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">Création de l'export-policy</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Création de volumes pour Oracle</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">Création des LIFs NFS</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">*linux_config*</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">Création de points de montage et montage de volumes NFS</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">Vérifiez les montages NFS</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">Configuration propre à l'OS</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Créez des répertoires Oracle</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">Configurer les huppages</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">Désactivez SELinux et le démon de pare-feu</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">Activer et démarrer le service chronyd</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">augmenter la limite stricte du descripteur de fichier</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">Créez le fichier de session PAM.d</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">*oracle_config*</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Installation du logiciel Oracle</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Créer un écouteur Oracle</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Créez des bases de données Oracle</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Configuration de l'environnement Oracle</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">Enregistrer l'état PDB</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">Activer le mode d'archivage de l'instance</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">Activez le client dNFS</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">Activez le démarrage et l'arrêt automatiques de la base de données entre les redémarrages du système d'exploitation</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">Pour simplifier l'automatisation, nous avons préréglé de nombreux paramètres de déploiement Oracle avec des valeurs par défaut. Il n'est généralement pas nécessaire de modifier les paramètres par défaut pour la plupart des déploiements. Un utilisateur plus avancé peut modifier les paramètres par défaut avec précaution. Les paramètres par défaut se trouvent dans chaque dossier de rôle, sous le répertoire par défaut.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">Instructions de déploiement</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">Avant de commencer, téléchargez les fichiers d'installation et de correctif Oracle suivants et placez-les dans le<block ref="d66a510d21988f96fd9c018f6843c729" prefix=" " category="inline-code"></block> Répertoire avec accès en lecture, en écriture et en exécution pour tous les utilisateurs sur chaque serveur de base de données à déployer. Les tâches d'automatisation recherchent les fichiers d'installation nommés dans ce répertoire particulier pour l'installation et la configuration d'Oracle.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">Ici pour les procédures de déploiement AWX/Tower détaillées</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">Ici pour le déploiement de CLI</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">Lorsque vous êtes prêt, cliquez sur <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> ou <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">Déploiement AWX/Tower Oracle 19c Database</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">1. Créez l'inventaire, le groupe, les hôtes et les informations d'identification de votre environnement</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">S'il existe des variables d'inventaire, collez-les dans le champ variables.</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">Indiquez le nom du groupe pour ONTAP, collez les variables du groupe (le cas échéant) et cliquez sur Enregistrer.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Répétez le processus pour un autre groupe pour Oracle.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">Sélectionnez le groupe ONTAP créé, accédez au sous-menu hôtes et cliquez sur Ajouter un nouvel hôte.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">Indiquez l'adresse IP de gestion de cluster ONTAP, collez les variables hôte (le cas échéant), puis cliquez sur Enregistrer.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Ce processus doit être répété pour le groupe Oracle et l'adresse IP/nom d'hôte(s) de gestion du ou des hôtes Oracle.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">Créer des types d'informations d'identification. Pour les solutions impliquant ONTAP, vous devez configurer le type d'informations d'identification pour qu'il corresponde aux entrées de nom d'utilisateur et de mot de passe.</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">Collez le contenu suivant dans la configuration d'injecteur :</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">Entrez le nom et les détails de l'organisation de ONTAP.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">Sélectionnez le type d'informations d'identification personnalisé que vous avez créé pour ONTAP.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">Sous Type Details, entrez le nom d'utilisateur, le mot de passe et le mot de passe vsadmin_password.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">Cliquez sur Retour aux informations d'identification et cliquez sur Ajouter.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Entrez le nom et les détails de l'organisation pour Oracle.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">2. Créez un projet</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">entrez <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> Comme URL de contrôle de source.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">3. Configurer Oracle Host_var</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">Les variables définies dans cette section sont appliquées à chaque serveur et base de données Oracle.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">Entrez les paramètres spécifiques à votre environnement dans le formulaire variables ou host_var intégrés suivant.</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">Remplissez toutes les variables dans les champs bleus.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">Une fois les variables entrées, cliquez sur le bouton Copier du formulaire pour copier toutes les variables à transférer vers AWX ou Tour.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">Revenez à AWX ou Tower et accédez à Ressources → hosts, puis sélectionnez et ouvrez la page de configuration du serveur Oracle.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">Sous l'onglet Détails, cliquez sur Modifier et collez les variables copiées de l'étape 1 dans le champ variables de l'onglet YAML.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">Répétez ce processus pour tous les serveurs Oracle supplémentaires du système.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">4. Configurer les variables globales</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">Remplissez toutes les variables dans les champs bleus.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">Une fois les variables entrées, cliquez sur le bouton Copier du formulaire pour copier toutes les variables à transférer vers AWX ou Tour dans le modèle de travail suivant.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">5. Configurez et lancez le modèle de travail.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">Entrez le nom et la description</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">Sélectionnez le type de travail ; Exécuter configure le système en fonction d'un manuel de vente et vérifier effectue une exécution sèche d'un manuel de vente sans configurer réellement le système.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">Sélectionnez All_PlayBook.yml comme PlayBook par défaut à exécuter.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">Cochez la case demander au lancement dans le champ balises de travail.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">Lorsque vous y êtes invité lors du lancement pour les balises de travail, saisissez configuration_requise. Vous devrez peut-être cliquer sur la ligne Créer une balise de travail sous configuration_exigences pour entrer la balise de travail.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">configuration_exigences vous garantit que vous disposez des bibliothèques appropriées pour exécuter les autres rôles.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">Cliquez sur Suivant, puis sur lancer pour lancer le travail.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">Cliquez sur Affichage → travaux pour contrôler la sortie et la progression du travail.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">Lorsque vous y êtes invité au lancement pour les balises de tâche, saisissez ontap_config. Vous devrez peut-être cliquer sur la ligne Create Job Tag située juste en dessous d'ontap_config pour entrer la balise de travail.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">Cliquez sur Affichage → travaux pour contrôler la sortie et la progression du travail</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">Une fois le rôle ontap_config terminé, exécutez de nouveau le processus pour linux_config.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">Sélectionnez le modèle souhaité, puis cliquez sur lancer.</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Lorsque vous êtes invité à lancer le type de balises de travail dans linux_config, vous devrez peut-être sélectionner la ligne Créer une « balise de travail » juste en dessous de linux_config pour entrer la balise de travail.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">Sélectionnez Affichage → travaux pour contrôler la sortie et la progression du travail.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Une fois le rôle linux_config terminé, relancez le processus pour oracle_config.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">Accédez à Ressources → modèles.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">Lorsque vous êtes invité à lancer pour les balises de travail, tapez oracle_config. Vous devrez peut-être sélectionner la ligne Créer une balise de travail juste en dessous d'oracle_config pour entrer la balise de travail.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">6. Déployer des bases de données supplémentaires sur le même hôte Oracle</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">La partie Oracle du PlayBook crée une base de données de conteneur Oracle unique sur un serveur Oracle par exécution. Pour créer des bases de données de conteneurs supplémentaires sur le même serveur, procédez comme suit.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">Réviser les variables Host_var.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">Retournez à l'étape 2 - configurer Oracle Host_var.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Remplacez le SID Oracle par une chaîne de nom différente.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">Définissez le port d'écoute sur un numéro différent.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">Remplacez le port EM Express par un autre numéro si vous installez EM Express.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">Copiez et collez les variables hôte révisées dans le champ variables hôte Oracle de l'onglet Détails de la configuration hôte.</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">Lancez le modèle de travail de déploiement avec uniquement la balise oracle_config.</block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">Ce livre blanc fournit des contours et des validations d'une solution pour la haute disponibilité et la reprise après incident des bases de données RDS d'Oracle personnalisées à AWS, en exploitant le service de stockage AWS FSX dans un déploiement de zones de disponibilité multiples.</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">Allen Cao, Niyaz Mohamed, Jeffrey Steiner, NetApp</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">De nombreuses bases de données Oracle d'entreprise stratégiques sont toujours hébergées sur site, et de nombreuses entreprises cherchent à migrer ces bases de données Oracle vers un cloud public. Souvent, ces bases de données Oracle sont axées sur les applications et requièrent donc des configurations spécifiques à l'utilisateur, une fonctionnalité qui n'offre pas de nombreuses offres de cloud public « base de données en tant que service ». Par conséquent, l'environnement actuel de la base de données nécessite une solution de base de données Oracle basée sur le cloud public, conçue à partir d'un service de calcul et de stockage évolutif haute performance capable de répondre à des besoins uniques. Les instances de calcul AWS EC2 et le service de stockage AWS FSX peuvent être les pièces manquantes dans ce puzzle que vous pouvez exploiter pour créer et migrer vos workloads stratégiques de base de données Oracle vers un cloud public.</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon Elastic Compute Cloud (Amazon EC2) est un service Web qui fournit une capacité de calcul sécurisée et redimensionnable dans le cloud. Il est conçu pour faciliter le cloud computing à l'échelle du Web pour les entreprises. L'interface simple de service en ligne Amazon EC2 vous permet d'obtenir et de configurer la capacité en cas de conflits minimes. Il vous offre un contrôle total de vos ressources informatiques et vous permet d'utiliser l'environnement informatique éprouvé d'Amazon.</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">Amazon FSX pour ONTAP est un service de stockage AWS qui utilise un stockage de niveau bloc et fichier NetApp ONTAP de pointe, exposant les protocoles NFS, SMB et iSCSI. Grâce à un tel moteur de stockage, il n'a jamais été aussi simple de transférer des applications de base de données Oracle stratégiques vers AWS avec des temps de réponse inférieurs à la milliseconde, un débit de plusieurs Gbit/s et plus de 100,000 000 IOPS par instance de base de données. Mieux encore, le service de stockage FSX est doté d'une fonctionnalité de réplication native qui vous permet de migrer facilement votre base de données Oracle sur site vers AWS ou de répliquer votre base de données Oracle stratégique vers une zone de disponibilité AWS secondaire pour la haute disponibilité ou la reprise après incident.</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">L'objectif de cette documentation est de fournir des processus, des procédures et des conseils détaillés sur les meilleures pratiques pour déployer et configurer une base de données Oracle avec un stockage FSX et une instance EC2 offrant des performances similaires à celles d'un système sur site. NetApp propose également un kit d'automatisation qui automatise la plupart des tâches nécessaires au déploiement, à la configuration et à la gestion de votre workload de base de données Oracle dans le cloud public AWS.</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">Ensuite, architecture des solutions.</block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">Déploiement de la base de données Oracle 19c par CLI</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">Section mise en route et conditions</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">Cette section décrit les étapes requises pour préparer et déployer Oracle19c Database avec l'interface de ligne de commande. Vérifiez que vous avez passé en revue le <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> et préparez votre environnement en conséquence.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Téléchargez Oracle19c repo</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">Modifiez le fichier hosts</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">Avant le déploiement, procédez comme suit :</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">Modifiez le répertoire na_oracle19c_Deploy du fichier hosts.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">Sous [ONTAP], modifiez l'adresse IP en votre IP de gestion de cluster.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">Sous le groupe [oracle], ajoutez les noms des hôtes oracle. Le nom d'hôte doit être résolu à son adresse IP via DNS ou le fichier hosts, ou il doit être spécifié dans l'hôte.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">Une fois ces étapes terminées, enregistrez les modifications.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">L'exemple suivant illustre un fichier hôte :</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">Cet exemple exécute le PlayBook et déploie oracle 19c sur deux serveurs BDD oracle simultanément. Vous pouvez également effectuer des tests avec un seul serveur de base de données. Dans ce cas, il vous suffit de configurer un fichier de variable hôte.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">Le manuel de vente s'exécute de la même façon, quel que soit le nombre d'hôtes et de bases de données Oracle que vous déployez.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">Modifiez le fichier host_name.yml sous Host_var</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">Chaque hôte Oracle a son fichier de variable hôte identifié par son nom d'hôte qui contient des variables spécifiques à l'hôte. Vous pouvez spécifier un nom quelconque pour votre hôte. Modifiez et copiez le<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> Dans la section Config VARS hôte et collez-la dans votre choix<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">Modifiez le fichier var.yml</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">Le<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> Le fichier consolide toutes les variables spécifiques à l'environnement (ONTAP, Linux ou Oracle) pour le déploiement Oracle.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">Modifiez et copiez les variables de la section VARS et collez ces variables dans votre<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">Exécutez le manuel de vente</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">Après avoir rempli les conditions préalables requises à l'environnement et copié les variables dans<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> et<block ref="97513b66e909abfd622924972387a816" prefix=" " category="inline-code"></block>, vous êtes maintenant prêt à déployer les manuels de vente.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">vous devez modifier &lt;username&gt; pour l'adapter à votre environnement.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">Déployer des bases de données supplémentaires sur le même hôte Oracle</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">La partie Oracle du PlayBook crée une base de données de conteneur Oracle unique sur un serveur Oracle par exécution. Pour créer une base de données de conteneurs supplémentaire sur le même serveur, procédez comme suit :</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">Réviser les variables Host_var.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">Revenir à l'étape 3 - Modifier le<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> dossier sous<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">Si vous avez installé EM Express, remplacez le port EM Express par un autre numéro.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">Copiez et collez les variables hôte révisées dans le fichier de variable hôte Oracle sous<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block>.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">Exécutez le PlayBook avec le<block ref="b656a5ae2d7a83cf0ead9c81fb96ec17" prefix=" " category="inline-code"></block> marquez comme indiqué ci-dessus dans <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">Cette section présente un récapitulatif des tâches à accomplir pour répondre aux exigences préalables requises, comme indiqué dans la section précédente. La section suivante énumère les tâches générales, à la fois pour les opérations sur site et dans le cloud public. Les processus et procédures détaillés sont accessibles en cliquant sur les liens correspondants.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">Présentation de mise en route</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">Conditions préalables : conditions requises pour le cloud public.</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">Configurer l'utilisateur admin de la base de données dans SnapCenter</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">Conditions préalables à l'installation du plug-in SnapCenter</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">Installation du plug-in hôte SnapCenter</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">Découverte de ressources DE BASE DE DONNÉES</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">Configuration de la réplication du volume de peering de clusters et de BDD</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">Ajouter le SVM de stockage de base de données CVO à SnapCenter</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">Configurez la stratégie de sauvegarde de la base de données dans SnapCenter</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">Mise en œuvre d'une stratégie de sauvegarde pour protéger la base de données</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">Validation de la sauvegarde</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">Contrôle avant vol</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">Étapes de déploiement de Cloud Manager et de Cloud Volumes ONTAP dans AWS</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">Déployez l'instance de calcul EC2 pour les workloads de base de données</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">Cliquez sur les liens suivants pour plus d'informations :</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">Cloud public - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">Cette solution fournit aux clients et aux équipes terrain de NetApp des instructions et des conseils pour configurer, exploiter et migrer des bases de données vers un environnement de cloud hybride à l'aide de l'outil graphique de NetApp SnapCenter et CVO pour le service de stockage de NetApp dans des clouds publics.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">Tr-4908 : Présentation des solutions de base de données dans le cloud hybride avec SnapCenter</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">Alan Cao, Felix Melligan, NetApp</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">Cette solution fournit aux clients et aux équipes terrain de NetApp des instructions et des conseils pour configurer, exploiter et migrer les bases de données vers un environnement de cloud hybride à l'aide de l'outil graphique de NetApp SnapCenter et du service de stockage CVO pour les clouds publics pour les utilisations suivantes :</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">Les opérations de développement et de test des bases de données dans le cloud hybride</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">Reprise après incident des bases de données dans le cloud hybride</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">Aujourd'hui, de nombreuses bases de données d'entreprise résident toujours dans les data centers privés pour des raisons de performance, de sécurité et/ou autres. Cette solution de base de données de cloud hybride permet aux entreprises d'exploiter leurs bases de données principales sur site, tout en utilisant un cloud public pour les opérations des bases de données de développement/test, ainsi que pour la reprise après incident afin de réduire les coûts de licence et d'exploitation.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">De nombreuses bases de données d'entreprise, comme Oracle, SQL Server, SAP HANA, etc., vos coûts de licence et d'exploitation sont élevés. De nombreux clients paient une licence unique et les coûts de support annuels en fonction du nombre de cœurs de calcul dans leur environnement de base de données, que les cœurs soient utilisés pour le développement, les tests, la production ou la reprise après incident. Il est possible que certains de ces environnements ne soient pas pleinement utilisés tout au long du cycle de vie des applications.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">Ces solutions permettent aux clients de réduire le nombre de cœurs pouvant être concédants en déplaçant dans le cloud leurs environnements de base de données dédiés au développement, au test ou à la reprise après incident. Grâce à l'évolutivité du cloud public, la redondance, la haute disponibilité et un modèle de facturation basé sur la consommation, les économies réalisées en termes de licence et d'exploitation peuvent être importantes, sans sacrifier la disponibilité ou la facilité d'utilisation des applications.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">Outre les économies potentielles en termes de licences pour les bases de données, le modèle de licence CVO basé sur la capacité de NetApp permet aux clients d'économiser les coûts de stockage par Go, tout en leur permettant de gérer de façon optimale les bases de données qui ne sont pas disponibles dans les services de stockage de la concurrence. Le tableau suivant montre une comparaison des coûts de stockage des services de stockage les plus courants disponibles dans le cloud public.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">Cette solution montre que, grâce à l'outil logiciel avec interface graphique SnapCenter et à la technologie NetApp SnapMirror, les opérations de base de données de cloud hybride peuvent être facilement configurées, mises en œuvre et exploitées.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">Les vidéos suivantes présentent SnapCenter en action :</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">Sauvegarde d'une base de données Oracle sur un cloud hybride avec SnapCenter</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter : clonez DES OPÉRATIONS DE DÉVELOPPEMENT/TEST dans AWS Cloud pour une base de données Oracle</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">Bien que les illustrations de ce document montrent Cloud volumes ONTAP comme instance de stockage cible dans le cloud public, la solution est également entièrement validée pour la nouvelle version du moteur de stockage FSX ONTAP pour AWS.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">Pour tester vous-même la solution et ses cas d'utilisation, un laboratoire NetApp sur demande SL10680 peut être demandé via le lien suivant : https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD : AWS - NW, SnapCenter (Onsite)^.</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">Cette section fournit des informations sur les facteurs à prendre en compte lors du déploiement de la base de données Oracle sur l'instance AWS EC2 et le stockage FSX.</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Facteurs à prendre en compte pour le déploiement de bases de données Oracle</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">Précédent : architecture de la solution.</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">Un cloud public offre de nombreuses options de calcul et de stockage. L'utilisation d'un type d'instance de calcul et d'un moteur de stockage appropriés est un bon point de départ pour le déploiement des bases de données. Vous devez également sélectionner des configurations de calcul et de stockage optimisées pour les bases de données Oracle.</block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">Les sections suivantes décrivent les principaux facteurs à prendre en compte lors du déploiement d'une base de données Oracle dans un cloud public AWS sur une instance EC2 avec un stockage FSX.</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">Performances des VM</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">Il est important de choisir la bonne taille de machine virtuelle pour obtenir des performances optimales d'une base de données relationnelle dans le cloud public. Pour de meilleures performances, NetApp recommande l'utilisation d'une instance EC2 de la série M5 pour le déploiement Oracle, optimisée pour les charges de travail de la base de données. Le même type d'instance est également utilisé pour alimenter une instance RDS pour Oracle par AWS.</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">Choisissez la combinaison de CPU virtuels et de RAM appropriée en fonction des caractéristiques de la charge de travail.</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">Ajoutez de l'espace d'échange à une machine virtuelle. Le déploiement de l'instance EC2 par défaut ne crée pas d'espace d'échange, ce qui n'est pas optimal pour une base de données.</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">Disposition du stockage et paramètres</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">NetApp recommande l'infrastructure de stockage suivante :</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">Pour le stockage NFS, la disposition des volumes recommandée est de trois volumes : un pour le binaire Oracle, un pour les données Oracle et un fichier de contrôle dupliqué, et un pour le journal actif Oracle, le journal archivé et le fichier de contrôle.</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">Pour le stockage iSCSI, la disposition des volumes recommandée est de trois volumes : un pour le binaire Oracle, un pour les données Oracle et un fichier de contrôle dupliqué, et un pour le journal actif Oracle, le journal archivé et le fichier de contrôle. Cependant, chaque volume de données et de journaux doit idéalement contenir quatre LUN. Les LUN sont idéalement équilibrées sur les nœuds de cluster haute disponibilité.</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">Pour les IOPS et le débit du stockage, vous pouvez choisir le seuil de provisionnement des IOPS et du débit pour le cluster de stockage FSX. Ces paramètres peuvent être ajustés à la volée à tout moment.</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">La valeur d'IOPS automatique est de trois IOPS par Gio de capacité de stockage allouée ou définie par l'utilisateur (jusqu'à 80,000).</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">Le niveau de débit est incrémenté comme suit : 128, 256, 512, 1024, 2045 Mbit/s.</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">Vérifiez le <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> Documentation lors du dimensionnement du débit et des opérations d'entrée/sortie par seconde</block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">Configuration NFS</block>
  <block id="b6e1b7fd7aad364a8ad758d8ae8ba50d" category="paragraph">Linux, le système d'exploitation le plus courant, comprend des fonctionnalités NFS natives. Oracle propose le client NFS direct (dNFS) intégré en mode natif dans Oracle. Oracle a pris en charge NFSv3 pendant plus de 20 ans, et NFSv4 est pris en charge par Oracle 12.1.0.2 et versions ultérieures. Le déploiement automatisé d'Oracle à l'aide du kit d'automatisation NetApp configure automatiquement dNFS sur NFSv3.</block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">Autres facteurs à prendre en compte :</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">Les tables d'emplacements TCP correspondent à l'équivalent NFS de la profondeur de la file d'attente HBA (Host-bus-adapter). Ces tableaux contrôlent le nombre d'opérations NFS qui peuvent être en attente à la fois. La valeur par défaut est généralement 16, un chiffre bien trop faible pour assurer des performances optimales. Le problème inverse se produit sur les noyaux Linux plus récents : la limite de la table des emplacements TCP augmente automatiquement par envoi de demandes, jusqu'à atteindre le niveau de saturation du serveur NFS.</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">Pour des performances optimales, ajustez les paramètres du noyau qui contrôlent les tables d'emplacements TCP sur 128.</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">Le tableau suivant présente les options de montage NFS recommandées pour Linux NFSv3 : instance unique.</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">Avant d'utiliser dNFS, vérifiez que les correctifs décrits dans Oracle Doc 1495104.1 sont installés. À partir d'Oracle 12c, dNFS prend en charge NFS v3, NFS V4 et NFS v4.1. Conformément à la politique de support de NetApp, les versions 3 et 4 sont prises en charge pour tous les clients. Cependant, au moment de la rédaction de ce rapport, NFS v4.1 n'était pas pris en charge pour une utilisation avec Oracle dNFS.</block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">Comme indiqué dans l'architecture de la solution, la haute disponibilité est basée sur la réplication au niveau du stockage. Ainsi, la start-up et la disponibilité d'Oracle dépendent de la rapidité à laquelle le calcul et le stockage peuvent être rétablis et rétablis. Voir les facteurs clés suivants :</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">Préparez une instance de calcul de secours et synchronisée avec le stockage primaire via la mise à jour parallèle Ansible vers les deux hôtes.</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">Répliquez le volume binaire à partir du volume primaire à des fins de veille, de sorte que vous n'ayez pas besoin d'installer Oracle à la dernière minute et de déterminer ce qui doit être installé et corrigé.</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">La fréquence de réplication détermine la rapidité de restauration de la base de données Oracle pour assurer la disponibilité du service. Il existe un compromis entre la fréquence de réplication et la consommation du stockage.</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">Exploitez l'automatisation pour rendre la restauration et le basculement en veille rapides et exempts d'erreurs humaines. À ce propos, NetApp propose un kit d'automatisation.</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">Cette section décrit les procédures de déploiement de la base de données personnalisée Oracle RDS avec un système de stockage FSX.</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">Déploiement d'une instance Linux EC2 pour Oracle via la console EC2</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">Si vous découvrez AWS, vous devez d'abord configurer un environnement AWS. L'onglet de documentation de la page d'accueil du site Web AWS propose des liens d'instructions EC2 pour le déploiement d'une instance Linux EC2 qui peut être utilisée pour héberger votre base de données Oracle via la console AWS EC2. La section suivante récapitule ces étapes. Pour plus d'informations, consultez la documentation spécifique à AWS EC2.</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">Configuration de l'environnement AWS EC2</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">Vous devez créer un compte AWS pour provisionner les ressources nécessaires à l'exécution de votre environnement Oracle sur les services EC2 et FSX. La documentation AWS suivante fournit les informations nécessaires :</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Configuration pour utiliser Amazon EC2</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">Principaux sujets :</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">S'inscrire à AWS.</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">Créer une paire de clés.</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">Créez un groupe de sécurité.</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">Activation de plusieurs zones de disponibilité dans les attributs de compte AWS</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">Pour une configuration Oracle haute disponibilité comme indiqué dans le diagramme de l'architecture, vous devez activer au moins quatre zones de disponibilité d'une région. Il est également possible de définir des zones de disponibilité dans différentes régions afin de déterminer les distances requises pour la reprise après incident.</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">Création et connexion à une instance EC2 pour héberger la base de données Oracle</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Commencez à utiliser les instances Amazon EC2 Linux</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">Voir le tutoriel <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> pour bénéficier de procédures de déploiement détaillées et de meilleures pratiques.</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">Présentation.</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">Prérequis.</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">Étape 1 : lancez une instance.</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">Étape 2 : connexion à votre instance.</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">Étape 3 : nettoyez votre instance.</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">Les captures d'écran suivantes illustrent le déploiement d'une instance Linux de type m5 avec la console EC2 pour l'exécution d'Oracle.</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">Dans le tableau de bord EC2, cliquez sur le bouton jaune lancer l'instance pour démarrer le workflow de déploiement de l'instance EC2.</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">À l'étape 1, sélectionnez « Red Hat Enterprise Linux 8 (HVM), SSD Volume Type - ami-0b0af3577f5e3532 (x86 64 bits) / ami-01fc429821bf1f4b4 (ARM 64 bits) ».</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">À l'étape 2, sélectionnez un type d'instance m5 avec l'allocation de processeur et de mémoire appropriée en fonction de la charge de travail de votre base de données Oracle. Cliquez sur « Suivant : configurer les détails de l'instance ».</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">À l'étape 3, choisissez le VPC et le sous-réseau dans lesquels l'instance doit être placée et activez l'affectation IP publique. Cliquez sur Next : Add Storage.</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">À l'étape 4, allouez suffisamment d'espace pour le disque racine. Vous aurez peut-être besoin de l'espace nécessaire pour ajouter un échange. Par défaut, l'instance EC2 attribue un espace d'échange nul, ce qui n'est pas optimal pour l'exécution d'Oracle.</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">À l'étape 5, ajoutez une balise pour l'identification de l'instance si nécessaire.</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">À l'étape 6, sélectionnez un groupe de sécurité existant ou créez-en un avec la stratégie entrante et sortante souhaitée pour l'instance.</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">À l'étape 7, vérifiez le résumé de la configuration de l'instance, puis cliquez sur lancer pour démarrer le déploiement de l'instance. Vous êtes invité à créer une paire de clés ou à sélectionner une paire de clés pour accéder à l'instance.</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">Connectez-vous à l'instance EC2 à l'aide d'une paire de clés SSH. Modifiez le nom de votre clé et l'adresse IP de votre instance si nécessaire.</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">Vous devez créer deux instances EC2 en tant que serveurs primaires et de secours Oracle dans leur zone de disponibilité désignée comme indiqué dans le schéma d'architecture.</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Provisionner FSX pour les systèmes de fichiers ONTAP pour le stockage de bases de données Oracle</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">Le déploiement d'instances EC2 alloue un volume racine EBS à l'OS. FSX pour systèmes de fichiers ONTAP fournit des volumes de stockage de base de données Oracle, y compris les volumes binaires, de données et de journaux Oracle. Les volumes NFS de stockage FSX peuvent être provisionnés depuis la console AWS FSX ou depuis l'installation Oracle, et l'automatisation de la configuration qui alloue les volumes à la configuration de l'utilisateur dans un fichier de paramètres d'automatisation.</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="section-title">Création de FSX pour les systèmes de fichiers ONTAP</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">Gestion de FSX pour les systèmes de fichiers ONTAP</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">Renvoi à cette documentation<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> Pour la création de FSX pour les systèmes de fichiers ONTAP.</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">Principaux éléments à prendre en compte :</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">Capacité de stockage SSD. 1024 Gio, maximum 192 Tio.</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">IOPS SSD provisionnées. Selon les exigences des charges de travail, un maximum de 80,000 SSD par système de fichiers.</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">Capacité de débit.</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">Définissez le mot de passe administrateur fsxadmin/vsadmin. Requis pour l'automatisation de la configuration FSX.</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">Sauvegarde et maintenance. Désactiver les sauvegardes quotidiennes automatiques ; la sauvegarde du stockage de base de données est exécutée via la planification SnapCenter.</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">Récupérez l'adresse IP de gestion SVM ainsi que les adresses d'accès spécifiques aux protocoles à partir de la page de détails des SVM. Requis pour l'automatisation de la configuration FSX.</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">Reportez-vous aux procédures étape par étape suivantes pour configurer un cluster FSX haute disponibilité principal ou de secours.</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">Dans la console FSX, cliquez sur Créer un système de fichiers pour démarrer le flux de travail de provisionnement FSX.</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">Sélectionnez Amazon FSX pour NetApp ONTAP. Cliquez ensuite sur Suivant.</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">Sélectionnez création standard et, dans Détails du système de fichiers, nommez votre système de fichiers, Multi-AZ HA. Choisissez entre IOPS automatiques ou provisionnées par l'utilisateur, selon les charges de travail de votre base de données (jusqu'à 80,000 000 IOPS) SSD. Le stockage FSX est fourni avec une mise en cache NVMe jusqu'à 2 Tio au niveau du backend, afin de fournir des IOPS encore plus élevées.</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">Dans la section réseau et sécurité, sélectionnez le VPC, le groupe de sécurité et les sous-réseaux. Ils doivent être créés avant le déploiement FSX. En fonction du rôle du cluster FSX (primaire ou de secours), placez les nœuds de stockage FSX dans les zones appropriées.</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">Dans la section sécurité et cryptage, acceptez la valeur par défaut et saisissez le mot de passe fsxadmin.</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">Entrer le nom du SVM et le mot de passe vsadmin.</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">Laissez la configuration de volume vide ; vous n'avez pas besoin de créer de volume à ce stade.</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Consultez la page Résumé et cliquez sur Créer un système de fichiers pour terminer la mise à disposition du système de fichiers FSX.</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Provisionnement de volumes de base de données pour les bases de données Oracle</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">Gestion de FSX pour les volumes ONTAP - création d'un volume</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">Voir <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> pour plus d'informations.</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">Dimensionnement approprié des volumes de base de données</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">Désactivation de la règle de hiérarchisation des pools de capacité pour la configuration des performances</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">Activation d'Oracle dNFS pour les volumes de stockage NFS.</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">Configuration de chemins d'accès multiples pour les volumes de stockage iSCSI</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">Créer un volume de base de données à partir de la console FSX</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">À partir de la console AWS FSX, vous pouvez créer trois volumes pour le stockage de fichiers de base de données Oracle : un pour le binaire Oracle, un pour les données Oracle et un pour le journal Oracle. Assurez-vous que la dénomination des volumes correspond au nom de l'hôte Oracle (défini dans le fichier hosts du kit d'automatisation) pour identifier correctement. Dans cet exemple, nous utilisons db1 comme nom d'hôte Oracle EC2 au lieu d'un nom d'hôte standard basé sur l'adresse IP pour une instance EC2.</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">La création de LUN iSCSI n'est actuellement pas prise en charge par la console FSX. Pour déployer les LUN iSCSI pour Oracle, les volumes et les LUN peuvent être créés à l'aide de l'automatisation pour ONTAP avec le kit d'automatisation NetApp.</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">Installez et configurez Oracle sur une instance EC2 avec des volumes de base de données FSX</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">L'équipe d'automatisation NetApp propose un kit d'automatisation qui permet d'exécuter l'installation et la configuration d'Oracle sur les instances EC2 en fonction des meilleures pratiques. La version actuelle du kit d'automatisation prend en charge Oracle 19c sur NFS avec le correctif 19.8 RU par défaut. Le kit d'automatisation peut être facilement adapté pour d'autres correctifs RU si nécessaire.</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">Préparez un contrôleur Ansible pour exécuter l'automatisation</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">Suivre les instructions de la section «<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>« Pour provisionner une petite instance Linux EC2 afin d'exécuter le contrôleur Ansible. Au lieu d'utiliser RedHat, Amazon Linux t2.large avec 2 vCPU et 8 Go de RAM doit suffire.</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">Kit d'automatisation du déploiement NetApp Oracle</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">Connectez-vous à l'instance de contrôleur EC2 Ansible provisionnée à partir de l'étape 1 en tant qu'utilisateur ec2 et à partir du répertoire de base utilisateur ec2, exécutez la<block ref="aebfab4ae394171a00d2e86fff2ff38b" prefix=" " category="inline-code"></block> commande permettant de cloner une copie du code d'automatisation.</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">Exécuter le déploiement automatisé d'Oracle 19c à l'aide du kit d'automatisation</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">Voir ces instructions détaillées <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> Pour déployer Oracle 19c avec automatisation de l'interface de ligne de commande. Il existe une modification de la syntaxe de commande pour l'exécution de PlayBook, car vous utilisez une paire de clés SSH à la place d'un mot de passe pour l'authentification d'accès aux hôtes. La liste suivante fournit un récapitulatif de haut niveau :</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">Par défaut, une instance EC2 utilise une paire de clés SSH pour l'authentification des accès. À partir des répertoires racine d'automatisation du contrôleur Ansible<block ref="4a1bfa90833e8fe6c82ca6f61f31d147" prefix=" " category="inline-code"></block>, et<block ref="a1d1fcb426260f0fdb7febffa690e21c" prefix=" " category="inline-code"></block>, Faites une copie de la clé SSH<block ref="956c187b3d0c7dcff5b113900e032874" prefix=" " category="inline-code"></block> Pour l'hôte Oracle déployé à l'étape «<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>."</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">Connectez-vous à l'hôte DB de l'instance EC2 en tant qu'utilisateur ec2 et installez la bibliothèque python3.</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">Comment allouer de la mémoire pour qu'elle fonctionne en tant qu'espace d'échange dans une instance Amazon EC2 en utilisant un fichier d'échange ?</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">Créez un espace de permutation de 16 Go à partir du lecteur de disque racine. Par défaut, une instance EC2 crée un espace d'échange nul. Suivez cette documentation AWS : <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>.</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Revenez au contrôleur Ansible <block ref="e97a9e3bee0cbfb89ba75f3695725fba" prefix="(" category="inline-code"></block>), et exécuter le manuel de vente pré-clone avec les exigences appropriées et<block ref="7ee7ce51db32cbf806a0c21c648f4c2b" prefix=" " category="inline-code"></block> balises.</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">Passez à l'<block ref="127b3ddd6eac38dd05a00b88b9348ff5" prefix=" " category="inline-code"></block> Lisez le fichier README et remplissez le répertoire global<block ref="5257c59f933f1208afadab7dd8ef3fe6" prefix=" " category="inline-code"></block> fichier avec les paramètres globaux pertinents.</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">Remplissez le<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> fichier avec les paramètres pertinents dans le<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Exécutez le PlayBook pour Linux, et appuyez sur entrée lorsque vous y êtes invité pour le mot de passe vsadmin.</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Exécutez le manuel de vente pour Oracle et appuyez sur entrée lorsque vous y êtes invité pour le mot de passe vsadmin.</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">Modifiez le bit d'autorisation du fichier de clé SSH sur 400 si nécessaire. Modifiez l'hôte Oracle <block ref="e15cba2a55d1c830968665125de5abf6" prefix="(" category="inline-code"></block> dans le<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> File) adresse IP de l'adresse publique de votre instance EC2.</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">Configuration de SnapMirror entre le cluster principal et le cluster FSX HA de secours</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">Pour une haute disponibilité et une reprise après incident, vous pouvez configurer la réplication SnapMirror entre le cluster de stockage principal et le cluster de stockage FSX en veille. À la différence d'autres services de stockage cloud, FSX permet à l'utilisateur de contrôler et de gérer la réplication du stockage à la fréquence souhaitée et au débit de réplication. Il permet également aux utilisateurs de tester la haute disponibilité/reprise sur incident sans aucune incidence sur la disponibilité.</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">Les étapes suivantes expliquent comment configurer la réplication entre un cluster de stockage principal et un cluster de stockage FSX de secours.</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">Configuration du peering de cluster principal et de secours. Connectez-vous au cluster principal en tant qu'utilisateur fsxadmin et exécutez la commande suivante. Ce processus de création réciproque exécute la commande create sur le cluster principal et le cluster standby. Remplacement<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> avec le nom approprié pour votre environnement.</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">Configurer le SVM peering entre le cluster principal et le cluster de secours. Connectez-vous au cluster principal en tant qu'utilisateur vsadmin et exécutez la commande suivante. Remplacement<block ref="f826cd2f4a01fe594ea3f06fc8e9a764" prefix=" " category="inline-code"></block>,<block ref="73483be5a30a2604d22183209c74149e" prefix=" " category="inline-code"></block>,<block ref="33c864f25bec561bad1458ab06ec3177" prefix=" " category="inline-code"></block> avec les noms appropriés pour votre environnement.</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">Vérifier que le cluster et les &amp; Vserver Peerings sont correctement configurés.</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">Créez des volumes NFS cibles au niveau du cluster FSX de secours pour chaque volume source au niveau du cluster FSX primaire. Remplacez le nom du volume selon les besoins de votre environnement.</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">Vous pouvez également créer des volumes et des LUN iSCSI pour le binaire Oracle, les données Oracle et le journal Oracle si le protocole iSCSI est utilisé pour l'accès aux données. Laissez environ 10 % d'espace libre sur les volumes pour les snapshots.</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">Vol create -volume dr_db1_log -agrégat aggr1 -size 250G -state online -policy default -unix-permissions ---rwxr-xr-x -type RW</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">Pour les LUN iSCSI, créez un mappage pour l'initiateur hôte Oracle pour chaque LUN, en utilisant la LUN binaire comme exemple. Remplacez le groupe initiateur par un nom adapté à votre environnement et augmentez l'ID de lun pour chaque LUN supplémentaire.</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">Créer une relation SnapMirror entre les volumes de base de données primaire et de secours. Remplacez le nom de SVM approprié pour votre environnement.s</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">Cette configuration de SnapMirror peut être automatisée à l'aide d'un kit d'automatisation NetApp pour les volumes de base de données NFS. Le kit est disponible en téléchargement sur le site GitHub public de NetApp.</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">Lisez attentivement les instructions du système README avant de tenter un test de configuration et de basculement.</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">La réplication du binaire Oracle du cluster principal vers un cluster de secours peut avoir des implications sur la licence Oracle. Contactez votre représentant en licence Oracle pour plus de précisions. L'alternative est que Oracle soit installé et configuré au moment de la récupération et du basculement.</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">Déploiement de SnapCenter</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">Installation de SnapCenter</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">Installation du serveur SnapCenter</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">Suivre <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> Pour installer SnapCenter Server. Cette documentation explique comment installer un serveur SnapCenter autonome. Une version SaaS d'SnapCenter est en cours de révision et est disponible prochainement. Si besoin, contactez votre représentant NetApp pour connaître la disponibilité.</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">Configurez le plug-in SnapCenter pour l'hôte EC2 Oracle</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">Après l'installation automatisée de SnapCenter, connectez-vous à SnapCenter en tant qu'utilisateur administratif de l'hôte Windows sur lequel le serveur SnapCenter est installé.</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">Dans le menu de gauche, cliquez sur Paramètres, puis sur Credential et sur Nouveau pour ajouter les informations d'identification de l'utilisateur ec2 pour l'installation du plug-in SnapCenter.</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">Réinitialise le mot de passe de l'utilisateur ec2 et active l'authentification SSH par mot de passe en modifiant le<block ref="07b421e5f5e0300b1a0fd6cc22745306" prefix=" " category="inline-code"></block> Fichier sur l'hôte de l'instance EC2.</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">Vérifiez que la case « utiliser les privilèges de sudo » est cochée. Il vous suffit de réinitialiser le mot de passe de l'utilisateur ec2 à l'étape précédente.</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">Ajoutez le nom du serveur SnapCenter et l'adresse IP au fichier hôte de l'instance EC2 pour la résolution du nom.</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">Sur l'hôte Windows du serveur SnapCenter, ajoutez l'adresse IP de l'hôte d'instance EC2 au fichier hôte Windows<block ref="803976de87f6862821bd3c4d94e0ff2b" prefix=" " category="inline-code"></block>.</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">Dans le menu de gauche, sélectionnez hôtes &gt; hôtes gérés, puis cliquez sur Ajouter pour ajouter l'hôte d'instance EC2 à SnapCenter.</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">Vérifiez la base de données Oracle et, avant de soumettre, cliquez sur autres options.</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">Cochez Ignorer les vérifications de préinstallation. Confirmez que vous n'avez pas ignoré les vérifications de préinstallation, puis cliquez sur soumettre après l'enregistrement.</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">Vous êtes invité à confirmer l'empreinte digitale, puis à cliquer sur confirmer et soumettre.</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">Une fois la configuration du plug-in réussie, l'état global de l'hôte géré s'affiche comme étant en cours d'exécution.</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Configurer la règle de sauvegarde pour la base de données Oracle</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">Reportez-vous à cette section <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Pour plus d'informations sur la configuration de la stratégie de sauvegarde de la base de données Oracle.</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">Généralement, vous devez créer une stratégie pour la sauvegarde complète de la base de données Oracle avec snapshot et une règle pour la sauvegarde snapshot de type archive-journal-seulement d'Oracle.</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">Vous pouvez activer l'élagage des journaux d'archive Oracle dans la stratégie de sauvegarde pour contrôler l'espace de journalisation et d'archivage. Cochez la case « mettre à jour SnapMirror après avoir créé une copie Snapshot locale » dans « Sélectionner l'option de réplication secondaire », car vous devez répliquer vers un emplacement en veille pour la haute disponibilité ou la reprise après incident.</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Configurer la sauvegarde et la planification de la base de données Oracle</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">La sauvegarde de base de données dans SnapCenter peut être configurée par l'utilisateur et peut être configurée individuellement ou en tant que groupe dans un groupe de ressources. L'intervalle de sauvegarde dépend des objectifs RTO et RPO. NetApp recommande d'exécuter une sauvegarde complète de base de données toutes les quelques heures et d'archiver la sauvegarde des journaux à une fréquence plus élevée (par exemple 10-15 minutes) pour une restauration rapide.</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">Reportez-vous à la section Oracle du <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> pour obtenir des processus détaillés étape par étape pour la mise en œuvre de la stratégie de sauvegarde créée dans la section <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> et pour la planification des tâches de sauvegarde.</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">L'image suivante fournit un exemple de groupes de ressources configurés pour sauvegarder une base de données Oracle.</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">Suivant : gestion de la base de données.</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">Cette section décrit une architecture cloud hybride typique pour les opérations de développement/test et de reprise après incident.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">Le schéma d'architecture suivant illustre la mise en œuvre standard du fonctionnement des bases de données d'entreprise dans un cloud hybride pour les opérations de développement/test et de reprise après incident.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">Dans des opérations business normales, les volumes synchronisés des bases de données dans le cloud peuvent être clonés et montés sur des instances de bases de données de développement/test pour le développement ou les tests d'applications. En cas de défaillance, les volumes de base de données synchronisés dans le cloud peuvent ensuite être activés pour la reprise d'activité.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">Ensuite, les exigences des solutions.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">Cette section décrit les différents points à prendre en compte lorsque Azure NetApp Files avec SQL Server est dans le cloud.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">Facteurs à prendre en compte</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">optimisé pour la mémoire</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">Il est important de choisir la bonne taille de machine virtuelle pour obtenir des performances optimales d'une base de données relationnelle dans le cloud public. Microsoft recommande de continuer à utiliser les mêmes options d'ajustement des performances de base de données que celles applicables à SQL Server dans des environnements de serveurs sur site. Utiliser<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> Tailles des machines virtuelles pour optimiser les performances des charges de travail SQL Server. Collectez les données de performances du déploiement existant pour identifier l'utilisation de la mémoire RAM et de l'UC tout en choisissant les instances appropriées. La plupart des déploiements choisissent une série D, E ou M.</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">Pour optimiser les performances des charges de travail SQL Server, utilisez des tailles de machines virtuelles optimisées par la mémoire.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp et Microsoft recommandent d'identifier les exigences en termes de performances de stockage avant de choisir le type d'instance avec le ratio mémoire/VCORE approprié. Cette fonctionnalité permet également de sélectionner un type d'instance inférieur avec la bande passante réseau appropriée pour dépasser les limites en termes de débit de stockage de la machine virtuelle.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">Redondance des machines virtuelles</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">ensemble de disponibilité</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">zones de disponibilité</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">Pour augmenter la redondance et la haute disponibilité, les machines virtuelles SQL Server doivent être identiques<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> ou différent<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Lorsque vous créez des VM Azure, vous devez choisir entre configurer des ensembles de disponibilité et des zones de disponibilité ; une VM Azure ne peut pas participer aux deux.</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">Pour la haute disponibilité, la configuration DE SQL Server AOAG ou toujours sur l'instance de cluster de basculement (FCI) est la meilleure option. Pour AOAG, cela implique plusieurs instances de SQL Server sur des machines virtuelles Azure sur un réseau virtuel. Si une haute disponibilité est requise au niveau de la base de données, envisagez de configurer les groupes de disponibilité SQL Server.</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server peut être déployé avec un partage de fichiers SMB comme option de stockage. À partir de SQL Server 2012, les bases de données système (master, model, msdb ou tempdb), En outre, les bases de données utilisateur peuvent être installées avec le serveur de fichiers Server message Block (SMB) en tant qu'option de stockage. Cela s'applique à SQL Server autonome et à SQL Server FCI.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">Le stockage de partage de fichiers pour les bases de données SQL Server doit prendre en charge la propriété disponible en continu. Cela permet un accès ininterrompu aux données de partage de fichiers.</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files fournit un stockage de fichiers haute performance pour répondre à toutes les charges de travail exigeantes et réduit le coût total de possession SQL Server par rapport aux solutions de stockage bloc. Avec le stockage en mode bloc, les machines virtuelles ont imposé des limites en termes d'E/S et de bande passante pour les opérations sur disques ; les seules limites en bande passante réseau sont appliquées à Azure NetApp Files. En d'autres termes, aucune limite d'E/S au niveau des VM n'est appliquée à la Azure NetApp Files. Sans ces limites d'E/S, SQL Server exécuté sur des machines virtuelles plus petites connectées à Azure NetApp Files peut exécuter aussi bien que SQL Server sur des machines virtuelles plus importantes. Azure NetApp Files réduit les coûts de déploiement de SQL Server en réduisant les coûts de licence du calcul et des logiciels. Pour obtenir une analyse détaillée des coûts et des performances lors du déploiement de Azure NetApp Files pour SQL Server, consultez le<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">Azure NetApp Files for SQL Server offre les avantages suivants :</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Azure NetApp Files permet d'utiliser des instances plus petites, ce qui réduit les coûts de calcul.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">Azure NetApp Files réduit également les coûts de licence logicielle, ce qui diminue le TCO global.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">La modification des volumes et la fonctionnalité de niveau de service dynamique permettent d'optimiser les coûts en s'dimensionnant pour des charges de travail prévisibles et en évitant le surprovisionnement.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">Pour augmenter la redondance et la haute disponibilité, les machines virtuelles SQL Server doivent être identiques<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> ou dans un autre<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Tenez compte des exigences de chemin de fichier si des fichiers de données définis par l'utilisateur sont nécessaires ; dans ce cas, sélectionnez FCI SQL sur AOAG SQL.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">\\ANFSMB-b4ca.anf.test\SQLDB et \\ANFSMB-b4ca.anf.test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">Le chemin UNC suivant est pris en charge :<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">Le chemin UNC de bouclage n'est pas pris en charge.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">Pour le dimensionnement, utilisez les données historiques de votre environnement sur site. Pour les charges de travail OLTP, faites correspondre les IOPS cibles aux exigences de performance en utilisant des charges de travail aux heures moyennes et de pointe, ainsi que les compteurs de performances en lecture/s des disques et en écriture/sec. Pour les charges de travail d'entrepôt de données et de création de rapports, faites correspondre le débit cible en utilisant des charges de travail aux heures moyennes et de pointe, ainsi que les octets en lecture/s et les octets d'écriture sur disque/s. Les valeurs moyennes peuvent être utilisées conjointement avec les fonctions de reformatage de volume.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">Créer des partages disponibles en continu</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">Créer un partage disponible en continu</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Créer des partages disponibles en continu via le portail Azure ou l'interface de ligne de commande Azure Dans le portail, sélectionnez l'option Activer la propriété disponibilité continue. Pour l'interface de ligne de commande Azure, spécifiez le partage en tant que partage disponible en continu à l'aide de la<block ref="0be8c8a92e4fe4621be30aa11942bc4d" prefix=" " category="inline-code"></block> option définie sur<block ref="91da4c74e2fced40755d4d3997af3488" prefix=" " category="inline-code"></block>. Pour en savoir plus sur la création d'un nouveau volume à disponibilité continue, voir<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">Activez la disponibilité sans interruption pour le volume SMB comme illustré dans l'image suivante.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">Si un compte de domaine non administrateur est utilisé, assurez-vous que le compte dispose du privilège de sécurité requis.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">Définissez les autorisations appropriées au niveau du partage et les autorisations appropriées au niveau du fichier.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">Conversion des volumes SMB existants pour utiliser la disponibilité continue</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">Une propriété disponible en continu ne peut pas être activée sur les volumes SMB existants. Utilisez la technologie NetApp Snapshot pour convertir un volume existant en partage disponible en continu. Pour plus d'informations, voir<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files prend en charge trois niveaux de services : standard (16 Mbit/s par téraoctet), Premium (64 Mbit/s par téraoctet) et Ultra (128 Mbit/s par téraoctet). Pour optimiser les performances de la charge de travail de la base de données, il est important de provisionner une taille de volume appropriée. Avec Azure NetApp Files, la performance du volume et la limite de débit reposent sur une combinaison des facteurs suivants :</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">Validation des performances</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">Outil de banc d'essai du stockage SQL Server (SB)</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">Comme pour tout déploiement, le test des machines virtuelles et du stockage est crucial. Pour la validation du stockage, des outils tels que HammerDB, Apploader, le<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>, Ou tout script personnalisé ou FIO avec le mélange de lecture/écriture approprié doit être utilisé. N'oubliez pas cependant que la plupart des charges de travail SQL Server, y compris les charges de travail OLTP occupées, sont proches de 80 à 90 % en lecture et de 10 à 20 % en écriture.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">Pour démontrer les performances, un test rapide a été effectué sur un volume en utilisant des niveaux de service premium. Dans ce test, la taille du volume a été augmentée de 100 Go à 2 To à la volée sans interrompre l'accès aux applications et sans aucune migration de données.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">Voici un autre exemple de test des performances en temps réel avec HammerDB effectué pour le déploiement décrit dans ce livre blanc. Pour ce test, nous avons utilisé une petite instance avec huit CPU virtuels, un disque SSD premium de 500 Go et un volume Azure NetApp Files SMB de 500 Go. HammerDB a été configuré avec 80 entrepôts et 8 utilisateurs.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">Le graphique suivant montre que Azure NetApp Files a pu fournir 2,6 fois le nombre de transactions par minute à une latence 4 fois plus faible en utilisant un volume de taille comparable (500 Go).</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">Un test supplémentaire a été réalisé en redimensionnant une instance plus grande avec des CPU virtuels 32 x et un volume Azure NetApp Files 16 To. Le nombre de transactions par minute a augmenté, avec une latence uniforme d'un millième de seconde. HammerDB a été configuré avec 80 entrepôts et 64 utilisateurs pour ce test.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files permet le redimensionnement transparent et sans interruption des volumes. Il est possible de modifier les niveaux de service sans temps d'indisponibilité et sans impact sur les applications. Cette fonctionnalité est unique et permet une gestion dynamique des coûts qui évite d'avoir à dimensionner la base de données avec des mesures de pointe. Vous pouvez utiliser des charges de travail avec état stable, ce qui vous évite des coûts initiaux. La réorganisation du volume et le changement dynamique au niveau des services vous permettent d'ajuster à la demande la bande passante et le niveau de services des volumes Azure NetApp Files sans interrompre les E/S tout en maintenant l'accès aux données.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">Les offres PaaS Azure, telles que LogicApp ou les fonctions, peuvent être utilisées pour redimensionner facilement le volume en fonction d'un déclencheur de règle d'alerte ou de bande Web spécifique afin de répondre aux demandes des workloads tout en gérant dynamiquement les coûts.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">Prenons l'exemple d'une base de données qui nécessite 250 Mbit/s pour un fonctionnement stable. Cependant, elle nécessite également un débit maximal de 400 Mbit/s. Dans ce cas, le déploiement doit être effectué avec un volume de 4 To conforme au niveau de service Premium afin de répondre aux exigences de performances stables. Pour gérer les pics de charge de travail, il est possible d'augmenter la taille du volume à l'aide des fonctions Azure de jusqu'à 7 To pour une période donnée, puis de réduire la taille du volume afin d'exploiter le déploiement de façon économique. Cette configuration évite le sur-provisionnement du stockage.</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">À propos de ce référentiel</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">Brève présentation du référentiel de solutions NetApp, où trouver des solutions spécifiques et comment utiliser ce référentiel</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">Navigation dans le référentiel</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">La navigation dans le référentiel est gérée par la barre latérale principale qui est présentée sur le côté gauche de la page. Les solutions sont classées dans des domaines techniques de plus haut niveau considérés comme des « tours technologiques » pour les solutions NetApp.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Vue d'ensemble de Technology Towers</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">*Section*</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">*Page d'accueil de contenu*</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">Ensemble de solutions basées sur l'IA. La page d'accueil dédiée à l'IA propose du contenu fréquemment présenté dans des « mosaïques » de contenu spécifiques.</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">Contenu d'IA</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">Ensemble de solutions modernes d'analytique de données (par exemple Splunk SmartStore, Apache Spark, etc.). La page d'accueil Modern Data Analytics propose du contenu très répandu dans des « mosaïques » de contenu spécifiques.</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">Contenu moderne d'analytique des données</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">Définit NetApp dans un modèle multicloud hybride, notamment les options VMware dans le cloud public et de stockage NetApp dans chacun des hyperscalers. La page d'accueil du multicloud hybride propose du contenu très répandu dans les vignettes spécifiques au contenu.</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">Multicloud hybride avec contenu VMware</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">Ensemble de solutions de virtualisation clés, y compris la virtualisation de postes de travail La page d'accueil de la virtualisation propose du contenu très répandu dans les « mosaïques » de contenu spécifique.</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">Contenu de la virtualisation</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">Collection de solutions basées sur des conteneurs. La page d'accueil de la virtualisation propose du contenu très répandu dans les « mosaïques » de contenu spécifique.</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">Contenu des conteneurs</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">Applications métier et bases de données</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">Un ensemble d'applications d'entreprise et de solutions de base de données. La page d'accueil SAP et SAP HANA propose oparmi les contenus présentés dans des « tiles » spécifiques. Les solutions de base de données Oracle et SQL Server sont également traitées dans cette section.</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">Contenu SAP et SAP HANA</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="cell">Migration et protection des données</block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">Collecte de solutions de migration, de protection et de sécurité des données.</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Présentation de la mise en route de l'automatisation de la solution avec Red Hat Ansible.</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Journal des modifications</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">journal des modifications</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">Toutes les modifications majeures apportées au référentiel (nouvelles solutions, mises à jour majeures, nouvelles vidéos/démos, etc.) sont suivies dans le <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>.</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">Commentaires</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">Veuillez l'utiliser <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> pour demander des modifications au contenu ou fournir des commentaires sur celui-ci. Veuillez être aussi précis que possible pour vous assurer que vos commentaires sont pris en compte de manière appropriée.</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">Les derniers ajouts à la documentation sur les solutions Cloud hybride, virtualisation des postes de travail et conteneurs</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">Nouveautés en matière de solutions de Cloud hybride, de virtualisation des postes de travail et de conteneurs</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">Présentation de la documentation la plus récente sur les solutions et solutions de clouds hybrides, de virtualisation de postes de travail et de conteneurs.</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">*Cloud hybride / privé*</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">*Virtualisation*</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">VMware vSphere pour ONTAP</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">*Virtualisation des postes de travail*</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">VDI cloud hybride avec NetApp Virtual Desktop Service (VDS)</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">*Conteneurs*</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">Le DevOps avec NetApp Astra</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">Vidéo : accélérez le développement logiciel avec Astra Control et la technologie NetApp FlexClone</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Installation automatisée d'Astra Control Center via Ansible</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">Vidéo : exploitez le contrôle NetApp Astra pour effectuer une analyse post-mortem et restaurer votre application</block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">Vidéo : protection des données dans le pipeline ci/CD avec Astra Control</block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">Vidéo : migration des workloads avec Astra Control Center - Red Hat OpenShift avec NetApp</block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">NetApp Astra Control Center sur Red Hat OpenShift</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">Vidéo : migration des workloads avec Astra Trident et SnapMirror - Red Hat OpenShift avec NetApp</block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="inline-link-macro">Solution NetApp de gestion avancée des clusters pour Kubernetes sur Red Hat OpenShift</block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">Red Hat OpenShift Virtualization avec NetApp ONTAP</block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">Vidéo : installation d'OpenShift Virtualization - Red Hat OpenShift avec NetApp</block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">Vidéo : déploiement d'un ordinateur virtuel avec OpenShift Virtualization - Red Hat OpenShift avec NetApp</block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">Colocation sur Red Hat OpenShift avec NetApp ONTAP</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NVA-1160 - Red Hat OpenShift avec NetApp</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">Anthos sur un système bare Metal avec NetApp</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">Vidéos et démonstrations : Red Hat OpenShift avec NetApp</block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">La vidéo suivante présente certaines des fonctionnalités documentées dans ce document :</block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="list-text"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="list-text"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="list-text"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="list-text"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="list-text"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="list-text"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">Vidéo : NetApp HCI pour Red Hat OpenShift sur le déploiement de la virtualisation Red Hat</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">Suivant : informations complémentaires Red Hat OpenShift avec NetApp.</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">Informations complémentaires : Red Hat OpenShift avec NetApp</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">Pour en savoir plus sur les informations fournies dans ce document, consultez les sites web suivants :</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">Documentation NetApp</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Documentation Trident d'Astra</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">Documentation NetApp Astra Control Center</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Documentation Red Hat OpenShift</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Documentation Red Hat OpenStack Platform</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Documentation Red Hat Virtualization</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">Documentation VMware vSphere</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">Possibilité d'exécuter simultanément des workloads virtualisés et conteneurisés</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">Possibilité de faire évoluer indépendamment l'infrastructure en fonction des besoins des workloads</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">Pour en savoir plus, rendez-vous sur le site web d'OpenShift<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">Pour en savoir plus, rendez-vous sur le site Web de NetApp<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, déployé dans un environnement sur site et optimisé par la technologie de protection des données NetApp de confiance.</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">NetApp propose plusieurs plateformes de stockage compatibles avec Astra Trident et Astra Control afin de provisionner, de protéger et de gérer les données pour les applications conteneurisées.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">Les systèmes de stockage NetApp Element fournissent des cas d'utilisation basés sur les blocs (iSCSI) dans un environnement hautement évolutif.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">Chaque système de stockage du portefeuille NetApp simplifie la gestion et le déplacement des données entre les sites sur site et le cloud, ce qui vous permet d'assurer que vos données sont là où sont vos applications.</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">Intégration transparente avec le cloud public pour le Tiering et la protection des données. ONTAP fournit également des fonctionnalités robustes de protection des données qui le distinguent dans tous les environnements :</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">Ces deux systèmes sont optimisés par le logiciel de gestion des données NetApp ONTAP, le logiciel de gestion des données le plus avancé du secteur pour une gestion du stockage simplifiée, intégrée au cloud et hautement disponible. Il offre la vitesse, l'efficacité et la sécurité dont votre environnement Data Fabric a besoin.</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select est un déploiement Software-defined de NetApp ONTAP qui peut être déployé sur un hyperviseur de votre environnement. Installée sur VMware vSphere ou KVM, cette solution permet de bénéficier de toutes les fonctionnalités et de l'expérience d'un système matériel ONTAP.</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP est une version de NetApp ONTAP déployée dans le cloud et qui peut être déployée dans plusieurs clouds publics, notamment Amazon AWS, Microsoft Azure et Google Cloud.</block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">NetApp propose plusieurs produits pour orchestrer, gérer, protéger et migrer les applications conteneurisées avec état et leurs données.</block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">NetApp Astra Control propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, optimisés par la technologie de protection des données NetApp. Astra Control Service est disponible pour la prise en charge des workloads avec état dans les déploiements Kubernetes cloud natifs. Le centre de contrôle Astra permet de prendre en charge les workloads avec état dans les déploiements sur site de plateformes Kubernetes d'entreprise telles que {k8s_distribution_name}. Pour en savoir plus, rendez-vous sur le site Web NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">Dans un environnement connecté au cloud, Astra Control Center utilise Cloud Insights pour fournir des fonctionnalités avancées de surveillance et de télémétrie. En l'absence de connexion Cloud Insights, un contrôle limité et une télémétrie (valeurs de metrics de 7 jours) sont disponibles et exportés vers les outils de contrôle natifs Kubernetes (Prometheus et Grafana) via des terminaux ouverts.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">En plus de la version payante d'Astra Control Center, une licence d'évaluation de 90 jours est disponible. La version d'évaluation est prise en charge par e-mail et par la communauté (Channel Slack). Les clients ont accès à ces articles, ainsi qu'à d'autres articles de la base de connaissances, et à la documentation disponible dans le tableau de bord de support des produits.</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes telles que {k8s_distribution_name}. Trident fonctionne avec l'ensemble de la gamme de solutions de stockage NetApp, notamment les systèmes de stockage NetApp ONTAP et Element, et prend également en charge les connexions NFS et iSCSI. Trident accélère le workflow DevOps en permettant aux utilisateurs d'approvisionner et de gérer le stockage à partir de leurs systèmes de stockage NetApp, sans intervention de l'administrateur de stockage.</block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident a un cycle de développement rapide, et comme Kubernetes, est lancé quatre fois par an.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">Depuis la version 20.04, l'opérateur Trident effectue la configuration de Trident. L'opérateur facilite les déploiements à grande échelle et offre un support supplémentaire, notamment l'auto-rétablissement des pods déployés dans le cadre de l'installation de Trident.</block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">Fonctionnalités : gestion avancée des clusters pour Kubernetes sur Red Hat OpenShift avec NetApp</block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">Observabilité</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">La solution Advanced Cluster Management pour Kubernetes fournit un moyen de surveiller les nœuds, les pods, les applications et les workloads dans l'ensemble des clusters.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">Naviguez jusqu'à observer les environnements &gt; Présentation.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">Page d'accueil observabilité</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">Tous les pods et les charges de travail dans tous les clusters sont surveillés et triés en fonction de différents filtres. Cliquez sur Pods pour afficher les données correspondantes.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">Observer les afficheurs</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">Tous les nœuds des clusters sont surveillés et analysés en fonction de divers points de données. Cliquez sur nœuds pour obtenir plus d'informations sur les détails correspondants.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">Observez les nœuds</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">Tous les clusters sont surveillés et organisés en fonction de différents paramètres et ressources de cluster. Cliquez sur clusters pour afficher les détails du cluster.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">Observer les clusters</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">Suivant : fonctionnalités - Créer des ressources.</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">Configuration d'une colocation sur Red Hat OpenShift avec NetApp</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">Évolutivité : ajout de projets</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">Dans une configuration mutualisée, l'ajout de nouveaux projets avec des ressources de stockage nécessite une configuration supplémentaire pour garantir que la colocation n'est pas respectée. Pour ajouter d'autres projets dans un cluster mutualisé, effectuez les opérations suivantes :</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">Connectez-vous au cluster NetApp ONTAP en tant qu'administrateur du stockage.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">Accédez à<block ref="ba7ff8660fabd8daa8e7fbd0c74dd990" prefix=" " category="inline-code"></block> et cliquez sur<block ref="ec211f7c20af43e742bf2570c3cb84f9" prefix=" " category="inline-code"></block>. Créez un nouveau SVM dédié au projet-3. Créer également un compte vsadmin pour gérer le SVM et ses ressources</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">Créer des SVM pour l'évolutivité</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Connectez-vous au cluster Red Hat OpenShift en tant qu'administrateur de cluster.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">Créer un nouveau projet.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">Assurez-vous que le groupe d'utilisateurs du projet Project-3 est créé sur IDP et synchronisé avec le cluster OpenShift.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">Créer le rôle de développeur du projet-3.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">La définition de rôle fournie dans cette section n'est qu'un exemple. Le rôle de développeur doit être défini en fonction des exigences de l'utilisateur final.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">Créer RoleBinding pour les développeurs dans projet-3 liant le rôle développeur-projet-3 au groupe correspondant (ocp-project-3) dans projet-3.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Connectez-vous au cluster Red Hat OpenShift en tant qu'administrateur du stockage</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Créer un système back-end Trident et le mapper sur le SVM dédié au projet-3. NetApp recommande d'utiliser le compte vsadmin du SVM afin de connecter le backend au SVM au lieu d'utiliser l'administrateur du cluster ONTAP</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">Nous utilisons le pilote ontap-nas dans cet exemple. Utilisez le pilote approprié pour créer le back-end en fonction du cas d'utilisation.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">Nous partons du principe que Trident est installé dans le projet trident.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">Créez la classe de stockage pour Project-3 et configurez-la pour qu'elle utilise les pools de stockage du système back-end dédié au projet-3.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">Créer un Resourcequota pour limiter les ressources dans le projet-3 demandant du stockage de storageclasses dédié à d'autres projets.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">Patch des ResourceQuotas dans d'autres projets pour limiter les ressources de ces projets à l'accès au stockage depuis le storageclass dédié au projet-3.</block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">Selon l'utilisation, les conteneurs et les machines virtuelles peuvent servir de plateformes optimales pour différents types d'applications. Par conséquent, de nombreuses entreprises exécutent certaines de leurs workloads sur des conteneurs et certaines sur des VM. Les entreprises doivent souvent relever des challenges supplémentaires : la gestion de plateformes distinctes : un hyperviseur pour les machines virtuelles et un orchestrateur de conteneur pour les applications.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">Pour relever ce défi, Red Hat a lancé OpenShift Virtualization (anciennement appelé Container Native Virtualization) à partir de la version 4.6 d'OpenShift. La fonction de virtualisation OpenShift vous permet d'exécuter et de gérer les machines virtuelles avec des conteneurs sur la même installation OpenShift Container Platform. Elle offre une fonctionnalité de gestion hybride permettant d'automatiser le déploiement et la gestion des machines virtuelles par l'intermédiaire des opérateurs. Outre la création de VM dans OpenShift, Red Hat prend également en charge l'importation de VM à partir de VMware vSphere, Red Hat Virtualization et Red Hat OpenStack Platform.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">Virtualisation OpenShift</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">Certaines fonctionnalités comme la migration de VM en direct, le clonage de disques de VM, les snapshots de VM, etc. Sont également prises en charge par OpenShift Virtualization avec l'aide d'Astra Trident, avec le soutien de NetApp ONTAP. Des exemples de chacun de ces flux de travail sont présentés plus loin dans ce document dans leurs sections respectives.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Pour en savoir plus sur Red Hat OpenShift Virtualization, consultez la documentation<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">Suivant : conditions préalables au déploiement.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">Ce document de référence assure la validation du déploiement de la solution Red Hat OpenShift, déployée via IPI (installer provisionnés Infrastructure) dans plusieurs environnements de data Center différents, comme validé par NetApp. Il détaille également l'intégration du stockage avec les systèmes de stockage NetApp grâce à l'orchestrateur de stockage Astra Trident pour la gestion du stockage persistant et à NetApp Astra Control Center pour la gestion et la protection des applications avec état. Enfin, un certain nombre de validations de solutions et d'utilisations réelles sont explorées et documentées.</block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">Créer des ressources sur plusieurs clusters</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">La gestion avancée des clusters pour Kubernetes permet aux utilisateurs de créer des ressources sur un ou plusieurs clusters gérés simultanément à partir de la console. Par exemple, si vous disposez de clusters OpenShift sur différents sites et que ONTAP vous souhaitez provisionner des PVC sur les deux sites, vous pouvez cliquer sur le signe (+) de la barre d'onglets. Sélectionnez ensuite les clusters sur lesquels vous souhaitez créer la demande de volume persistant, collez la ressource YAML, puis cliquez sur Créer.</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">Créer des ressources</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">Les solutions de conteneurs NetApp sont validées pour les déploiements de nombreux orchestrateurs de conteneurs basés sur Kubernetes et leur intégration avec les systèmes et les logiciels de gestion du stockage NetApp.</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">Solutions de conteneur NetApp</block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">Installation d'OpenShift Virtualization : Red Hat OpenShift avec NetApp</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">Suivant : informations complémentaires Red Hat OpenShift avec NetApp</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">Déploiement d'un ordinateur virtuel avec OpenShift Virtualization : Red Hat OpenShift avec NetApp</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="summary">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Red Hat OpenShift.</block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Présentation d'Astra Trident</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge, y compris Red Hat OpenShift, pour les conteneurs et les distributions Kubernetes. Trident fonctionne avec l'ensemble de la gamme de solutions de stockage NetApp, notamment les systèmes de stockage NetApp ONTAP et Element, et prend également en charge les connexions NFS et iSCSI. Trident accélère le workflow DevOps en permettant aux utilisateurs d'approvisionner et de gérer le stockage à partir de leurs systèmes de stockage NetApp, sans intervention de l'administrateur de stockage.</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">La dernière version d'Astra Trident est 22.01 publiée en janvier 2022. Une matrice de prise en charge pour quelle version de Trident a été testée avec laquelle une distribution Kubernetes est disponible<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Téléchargez Astra Trident</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">Pour installer Trident sur le cluster utilisateur déployé et provisionner un volume persistant, procédez comme suit :</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">Téléchargez l'archive d'installation sur la station de travail d'administration et extrayez son contenu. La version actuelle de Trident est la version 22.01, que vous pouvez télécharger<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">Extrayez l'installation de Trident du bundle téléchargé.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Installer l'opérateur Trident avec Helm</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">Définissez tout d'abord l'emplacement du cluster utilisateur<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Fichier en tant que variable d'environnement pour que vous n'ayez pas à le référencer, car Trident n'a pas d'option pour transmettre ce fichier.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Lancer la commande Helm pour installer l'opérateur Trident à partir du tarball dans le répertoire Helm lors de la création du namespace trident dans le cluster utilisateur.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">Vous pouvez vérifier que Trident est correctement installé en vérifiant les pods qui s'exécutent dans l'espace de noms ou en utilisant le binaire tridentctl pour vérifier la version installée.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">Dans certains cas, il est possible que les environnements client nécessitent la personnalisation du déploiement Trident. Dans ce cas, il est également possible d'installer manuellement l'opérateur Trident et de mettre à jour les manifestes inclus pour personnaliser le déploiement.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Installez manuellement l'opérateur Trident</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">Commencez par définir l'emplacement du cluster utilisateur<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Fichier en tant que variable d'environnement pour que vous n'ayez pas à le référencer, car Trident n'a pas d'option pour transmettre ce fichier.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">Le<block ref="c84ef67352bb6783ff2881f9f2821c2a" prefix=" " category="inline-code"></block> le répertoire contient des manifestes pour définir toutes les ressources requises. À l'aide des manifestes appropriés, créer le<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block> définition de ressource personnalisée.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Si aucun n'existe, créez un espace de nom Trident dans le cluster à l'aide du manifeste fourni.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">Créez les ressources requises pour le déploiement par un opérateur Trident, par exemple un<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block> pour l'opérateur, un<block ref="d7d354d0f9d0780e168c895c92a32c24" prefix=" " category="inline-code"></block> et<block ref="e866afd8290d5c73cda6260e04e6eef0" prefix=" " category="inline-code"></block> à la<block ref="5c24ffd6438853b537bd99b3fccd3340" prefix=" " category="inline-code"></block>, un dédié<block ref="316707d12484dd3afede08839dee49bc" prefix=" " category="inline-code"></block>, ou l'opérateur lui-même.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">Vous pouvez vérifier l'état de l'opérateur après son déploiement à l'aide des commandes suivantes :</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">Une fois l'opérateur déployé, nous pouvons maintenant l'utiliser pour installer Trident. Cela nécessite la création d'un<block ref="ae61bf6af1a7406b62c72a4bef1ab62d" prefix=" " category="inline-code"></block>.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">Préparez les nœuds workers pour le stockage</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">La plupart des distributions Kubernetes sont fournies avec des packages et des utilitaires permettant de monter les systèmes back-end NFS installés par défaut, y compris Red Hat OpenShift.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">Cependant, pour NFSv3, il n'existe aucun mécanisme pour négocier la simultanéité entre le client et le serveur. Par conséquent, le nombre maximal d'entrées de la table d'emplacements sunrpc côté client doit être synchronisé manuellement avec la valeur prise en charge sur le serveur pour assurer les meilleures performances de la connexion NFS sans que le serveur n'ait à diminuer la taille de la fenêtre de la connexion.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">Pour ONTAP, le nombre maximal d'entrées de la table des emplacements sunrpc pris en charge est de 128, c'est-à-dire que ONTAP peut traiter 128 requêtes NFS simultanées à la fois. Cependant, par défaut, Red Hat CoreOS/Red Hat Enterprise Linux possède au maximum 65,536 entrées de table sunrpc par connexion. Nous devons définir cette valeur sur 128 et cela peut être fait à l'aide de l'opérateur de configuration machine (MCO) d'OpenShift.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">Pour modifier le nombre maximal d'entrées de la table d'emplacements sunrpc dans les nœuds de travail OpenShift, procédez comme suit :</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">Connectez-vous à la console Web OCP et accédez à Compute &gt; machine configurations. Cliquez sur Créer une configuration de machine. Copiez et collez le fichier YAML, puis cliquez sur Créer.</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">Une fois le MCO créé, la configuration doit être appliquée à tous les nœuds workers et redémarrée un par un. Le processus prend entre 20 et 30 minutes environ. Vérifiez si la configuration de la machine est appliquée à l'aide de<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> et assurez-vous que le pool de configuration de la machine pour les employés est mis à jour.</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">Pour préparer les nœuds workers afin de permettre le mappage des volumes de stockage en mode bloc via le protocole iSCSI, vous devez installer les packages nécessaires pour prendre en charge cette fonctionnalité.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">Dans Red Hat OpenShift, ces opérations sont gérées via l'application d'un MCO (opérateur de configuration de machine) à votre cluster après son déploiement.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">Pour configurer les nœuds workers pour exécuter des services iSCSI, procédez comme suit :</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">Lorsque vous n'utilisez pas les chemins d'accès multiples :</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">Lorsque vous utilisez les chemins d'accès multiples :</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">Une fois la configuration créée, il faut environ 20 à 30 minutes pour appliquer la configuration aux nœuds worker et les recharger. Vérifiez si la configuration de la machine est appliquée à l'aide de<block ref="1b2628e311828c98f0307b49309b67ee" prefix=" " category="inline-code"></block> et assurez-vous que le pool de configuration de la machine pour les employés est mis à jour. Vous pouvez également vous connecter aux nœuds workers pour vérifier que le service iscsid est en cours d'exécution (et que le service multipathd est exécuté en cas d'utilisation de chemins d'accès multiples).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">Il est également possible de confirmer que la MachineConfig a été appliquée avec succès et que les services ont été lancés comme prévu en exécutant le<block ref="5c237bbde25a8cf47cdca465191a6c1d" prefix=" " category="inline-code"></block> commande avec les indicateurs appropriés.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">Création de systèmes back-end de stockage</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Une fois l'installation d'Astra Trident Operator, vous devez configurer le système back-end pour la plateforme de stockage NetApp spécifique que vous utilisez. Suivre les liens ci-dessous pour poursuivre l'installation et la configuration d'Astra Trident.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">ISCSI NetApp ONTAP</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">ISCSI NetApp Element</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">Ensuite, validation/utilisation de la solution : Red Hat OpenShift avec NetApp.</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">Cette section décrit les options d'équilibrage de charge pour les utilisateurs qui souhaitent personnaliser leur déploiement Red Hat OpenShift avec NetApp.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">Exploration des options d'équilibreur de charge avec Red Hat OpenShift avec NetApp</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">Dans la plupart des cas, Red Hat OpenShift met les applications à la disposition du monde extérieur via des routes. Un service est exposé en lui donnant un nom d'hôte accessible en externe. La route définie et les points de terminaison identifiés par son service peuvent être utilisés par un routeur OpenShift pour fournir cette connectivité nommée aux clients externes.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">Cependant, dans certains cas, les applications nécessitent le déploiement et la configuration d'équilibreurs de charge personnalisés pour exposer les services appropriés. Il s'agit notamment du centre de contrôle NetApp Astra, Pour répondre à ce besoin, nous avons évalué un certain nombre d'options d'équilibrage de charge personnalisé. Leur installation et leur configuration sont décrites dans cette section.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les options de équilibreur de charge validées dans la solution Red Hat OpenShift avec NetApp :</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">MetalLB</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">Ensuite, dossiers de validation/d'utilisation de la solution : Red Hat OpenShift avec NetApp.</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">Pour plus d'informations sur ONTAP, consultez le<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">Ensuite, présentation des intégrations de stockage NetApp</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="doc">OpenShift sur bare Metal</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">OpenShift sur bare Metal permet un déploiement automatisé de OpenShift Container Platform sur des serveurs génériques.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">OpenShift sur bare Metal est similaire aux déploiements virtuels d'OpenShift. Ce système facilite le déploiement, accélère le provisionnement et permet l'évolutivité des clusters OpenShift, tout en supportant des workloads virtualisés pour les applications qui ne sont pas prêtes pour les conteneurs. En déployant sur un serveur bare Metal, vous n'avez pas à gérer l'environnement d'hyperviseur hôte sans frais supplémentaires, en plus de l'environnement OpenShift. En le déployant directement sur des serveurs bare Metal, vous pouvez également réduire les limitations de la surcharge physique liées au partage des ressources entre l'hôte et l'environnement OpenShift.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">OpenShift sur bare Metal offre les fonctionnalités suivantes :</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">*Déploiement IPI ou programme d'installation assisté.* avec un cluster OpenShift déployé par IPI (installer Provisionable Infrastructure) sur des serveurs bare Metal, les clients peuvent déployer un environnement OpenShift hautement polyvalent et facilement évolutif, directement sur des serveurs génériques, sans avoir à gérer une couche d'hyperviseur.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">*Conception de cluster compacte.* pour minimiser les besoins matériels, OpenShift sur bare Metal permet aux utilisateurs de déployer des clusters de seulement 3 nœuds, en permettant aux nœuds de plan de contrôle OpenShift d'agir également comme nœuds workers et conteneurs hôtes.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">*Virtualisation OpenShift.* OpenShift peut exécuter des machines virtuelles dans des conteneurs à l'aide d'OpenShift Virtualization. Cette virtualisation native de conteneur exécute l'hyperviseur KVM dans un conteneur, et connecte les volumes persistants pour le stockage des machines virtuelles.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">*Infrastructure optimisée pour l'IA/ML*.* déployez des applications comme Kubeflow pour les applications de machine learning en intégrant des nœuds workers basés sur les processeurs graphiques à votre environnement OpenShift et en tirant parti d'OpenShift Advanced Scheduling.</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">Conception du réseau</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">La solution Red Hat OpenShift sur NetApp utilise deux switchs de données pour assurer la connectivité des données primaires à 25 Gbit/s. Il utilise également deux commutateurs de gestion qui fournissent une connectivité à 1 Gbit/s pour la gestion intrabande des nœuds de stockage et la gestion hors bande pour la fonctionnalité IPMI.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">Pour le déploiement d'IPI sans système d'exploitation OpenShift, vous devez créer un nœud de provisionnement, une machine Red Hat Enterprise Linux 8 qui doit disposer d'interfaces réseau connectées à des réseaux distincts.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">*Provisioning Network.* ce réseau est utilisé pour démarrer les nœuds bare-Metal et installer les images et les paquets nécessaires pour déployer le cluster OpenShift.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">*Réseau bare-Metal.* ce réseau est utilisé pour la communication publique du cluster après son déploiement.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">Dans le cadre de la configuration du nœud de provisionnement, le client crée des interfaces de pont qui permettent au trafic de s'acheminer correctement sur le nœud lui-même et sur la machine virtuelle de démarrage provisionnée pour le déploiement. Une fois le cluster déployé, l'API et les adresses VIP d'entrée sont migrées du nœud bootstrap vers le cluster récemment déployé.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">Les images suivantes illustrent l'environnement au cours du déploiement IPI et une fois le déploiement terminé.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">Exigences VLAN</block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">La solution Red Hat OpenShift avec NetApp est conçue pour séparer de façon logique le trafic réseau à différents fins, à l'aide de réseaux locaux virtuels (VLAN).</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">ID VLAN</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">Réseau de gestion hors bande</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">Gestion pour les nœuds bare Metal et IPMI</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">Réseau sans système d'exploitation</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">Un seul cluster est disponible pour les services OpenShift</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">Réseau de provisionnement</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">Réseau pour l'amorçage PXE et l'installation de nœuds bare Metal via IPI</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">Bien que chacun de ces réseaux soit virtuellement séparé par des VLAN, chaque port physique doit être configuré en mode d'accès avec le VLAN principal affecté, car il n'existe aucun moyen de transmettre une balise VLAN au cours d'une séquence de démarrage PXE.</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">Ressources de prise en charge de l'infrastructure réseau</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">L'infrastructure suivante doit être en place avant le déploiement de la plateforme de conteneurs OpenShift :</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">Au moins un serveur DNS qui fournit une résolution complète du nom d'hôte accessible à partir du réseau de gestion intrabande et du réseau de VM.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">Au moins un serveur NTP accessible depuis le réseau de gestion intrabande et le réseau de VM.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(Facultatif) connectivité Internet sortante pour le réseau de gestion intrabande et le réseau VM.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">Ensuite, présentation du stockage NetApp.</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">Configuration ONTAP iSCSI de NetApp</block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">Pour activer l'intégration de Trident avec le système de stockage NetApp ONTAP, il faut créer un back-end permettant la communication avec le système de stockage.</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">Des exemples de fichiers backend sont disponibles dans l'archive d'installation téléchargée dans le<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> hiérarchie des dossiers. Pour les systèmes NetApp ONTAP servant iSCSI, copiez le<block ref="684351d8ace6c8daa15d6a5ec881647e" prefix=" " category="inline-code"></block> dans votre répertoire de travail et modifiez le fichier.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">Modifiez les valeurs LIF, dataLIF, svm, nom d'utilisateur et mot de passe dans ce fichier.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">Lorsque ce fichier backend est en place, exécutez la commande suivante pour créer votre premier back-end.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">Lorsque le back-end est créé, vous devez ensuite créer une classe de stockage. Tout comme pour le back-end, il existe un exemple de fichier de classe de stockage qui peut être modifié pour l'environnement disponible dans le dossier des échantillons-entrées. Copiez-le dans le répertoire de travail et apportez les modifications nécessaires pour refléter le back-end créé.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">La seule modification à effectuer dans ce fichier consiste à définir le<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> valeur du nom du pilote de stockage du back-end nouvellement créé. Notez également la valeur nom-champ, qui doit être référencée ultérieurement.</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">Il y a un champ facultatif appelé<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> qui est défini dans ce fichier. Dans les systèmes back-end iSCSI, cette valeur peut être définie sur un type de système de fichiers Linux spécifique (XFS, ext4, etc.) ou peut être supprimée pour permettre à OpenShift de décider du système de fichiers à utiliser.</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">Exécutez le<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> pour créer la classe de stockage.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">Une fois la classe de stockage créée, vous devez ensuite créer la première demande de volume persistant. Il y a un échantillon<block ref="a46b72c0e3ff39640d78567a663da1aa" prefix=" " category="inline-code"></block> fichier qui peut être utilisé pour effectuer cette action également située dans les entrées d'échantillons.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">La seule modification à effectuer dans ce fichier est de s'assurer que<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> le champ correspond à celui que vous venez de créer. La définition du volume persistant peut être personnalisée davantage selon les besoins de la charge de travail à provisionner.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">Créez le PVC en émettant le<block ref="fb024832e51eb5f6da9113a745f1eb59" prefix=" " category="inline-code"></block> commande. La création peut prendre un certain temps en fonction de la taille du volume de sauvegarde en cours de création, de sorte que vous pouvez regarder le processus au fur et à mesure qu'il se termine.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">Ensuite : validation et utilisation de la solution.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">N'importe quelle solution mutualisée permet à aucun utilisateur d'accéder à davantage de ressources du cluster que nécessaire. Ainsi, l'ensemble des ressources à configurer dans le cadre de la configuration de colocation est divisé entre l'administrateur cluster, l'administrateur stockage et les développeurs travaillant sur chaque projet.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">Le tableau suivant présente les différentes tâches à effectuer par différents utilisateurs :</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">*Cluster-admin*</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">Créez des projets pour différentes applications ou charges de travail</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">Créez ClusterRoles et roles pour Storage-admin</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">Créez des rôles et des roleliaisons pour les développeurs qui assignaient un accès à des projets spécifiques</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[Facultatif] configurez les projets pour planifier des pods sur des nœuds spécifiques</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">*Storage-admin*</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">Créez des SVM sur NetApp ONTAP</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Création des systèmes back-end Trident</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">Créez des classes de stockage</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">Créer des devis de ressources de stockage</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">*Développeurs*</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">Valider l'accès pour créer ou corriger des demandes de volume persistant ou des pods dans le projet affecté</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">Valider l'accès pour créer ou corriger des demandes de volume persistant ou des pods dans un autre projet</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">Validez l'accès pour afficher ou modifier des projets, des ResourceQuotas et des classes de stockage</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">Suivant : prérequis.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">Configuration d'une colocation sur Red Hat OpenShift avec NetApp</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">De nombreuses entreprises qui exécutent plusieurs applications ou charges de travail sur des conteneurs ont tendance à déployer un cluster Red Hat OpenShift par application ou par workload. Ils peuvent ainsi mettre en œuvre une isolation stricte pour l'application ou la charge de travail, optimiser les performances et réduire les vulnérabilités de sécurité. Toutefois, le déploiement d'un cluster Red Hat OpenShift distinct pour chaque application présente ses propres problèmes. Cette solution augmente les frais d'exploitation liés à la surveillance et à la gestion seule de chaque cluster, ce qui augmente les coûts du fait de ressources dédiées pour différentes applications et entrave l'évolutivité efficace.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">Pour résoudre ces problèmes, il est possible d'exécuter toutes les applications ou charges de travail dans un seul cluster Red Hat OpenShift. Cependant, dans une telle architecture, l'isolement des ressources et les vulnérabilités liées à la sécurité des applications constituent l'un des défis majeurs. Toute vulnérabilité de sécurité dans une charge de travail pourrait naturellement se répandre sur une autre charge de travail, augmentant ainsi la zone d'impact. En outre, une application peut avoir une incidence soudaine et non contrôlée sur les performances d'une autre application, car il n'existe pas de stratégie d'allocation des ressources par défaut.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">Les entreprises recherchent donc des solutions qui offrent les meilleures des deux mondes, par exemple, en leur permettant d'exécuter toutes leurs charges de travail dans un cluster unique, tout en offrant les avantages d'un cluster dédié pour chaque charge de travail.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">L'une de ces solutions est utile : configurer la colocation sur Red Hat OpenShift. La colocation est une architecture qui permet à plusieurs locataires de coexister sur un même cluster avec une isolation appropriée des ressources, de la sécurité, etc. Dans ce contexte, un locataire peut être considéré comme un sous-ensemble des ressources du cluster qui sont configurées pour être utilisées par un groupe d'utilisateurs particulier à des fins exclusives. La configuration d'une colocation sur un cluster Red Hat OpenShift offre les avantages suivants :</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">Réduction des dépenses d'investissement et d'exploitation en permettant le partage des ressources du cluster</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">Réduisez les frais d'exploitation et de gestion</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">Sécurisation des charges de travail contre toute contamination croisée des failles de sécurité</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">Protection des charges de travail contre la dégradation inattendue des performances en raison des conflits des ressources</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">Pour un cluster OpenShift mutualisé entièrement réalisé, les quotas et les restrictions doivent être configurés pour les ressources de cluster appartenant à différents compartiments de ressources : calcul, stockage, réseau, sécurité, etc. Bien que nous aborderons certains aspects de toutes les ressources de cette solution, Nous mettons l'accent sur les bonnes pratiques d'isolation et de sécurisation des données servies ou consommées par plusieurs charges de travail sur le même cluster Red Hat OpenShift en configurant la colocation sur des ressources de stockage allouées de façon dynamique par Astra Trident et sauvegardé par NetApp ONTAP.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Pour permettre à Astra Control Center de gérer vos charges de travail, vous devez d'abord enregistrer votre cluster Red Hat OpenShift.</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Enregistrez vos clusters Red Hat OpenShift avec Astra Control Center</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Enregistrez les clusters Red Hat OpenShift</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">La première étape consiste à ajouter les clusters OpenShift au Centre de contrôle Astra et à les gérer. Accédez aux clusters et cliquez sur Ajouter un cluster, téléchargez le fichier kubeconfig pour le cluster OpenShift, puis cliquez sur Sélectionner un stockage.</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Création d'un cluster avec le centre de contrôle Astra</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">Le fichier kubeconfig peut être généré pour s'authentifier avec un nom d'utilisateur et un mot de passe ou un jeton. Les jetons expirent après un délai limité et peuvent laisser le cluster enregistré inaccessible. NetApp recommande d'utiliser un fichier kubeconfig avec un nom d'utilisateur et un mot de passe pour enregistrer vos clusters OpenShift sur Astra Control Center.</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center détecte les classes de stockage admissibles. Maintenant, sélectionnez la façon dont storageclass provisionne les volumes en utilisant Trident sauvegardé par un SVM sur NetApp ONTAP et Click Review. Dans le volet suivant, vérifiez les détails et cliquez sur Ajouter un cluster.</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center crée un stockage de groupe</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">Enregistrez les deux clusters OpenShift comme décrit à l'étape 1. Lorsqu'elles sont ajoutées, les clusters passent à l'état découverte pendant qu'Astra Control Center les inspecte et installe les agents nécessaires. L'état du cluster est modifié en cours d'exécution après son enregistrement.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Groupes de commandes Astra Control Center disponibles</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Tous les clusters Red Hat OpenShift devant être gérés par Astra Control Center doivent avoir accès au registre d'images utilisé pour son installation lorsque les agents installés sur les clusters gérés extraient les images de ce registre.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Importation de clusters ONTAP comme ressources de stockage à gérer en tant que système back-end par Astra Control Center. Lorsque des clusters OpenShift sont ajoutés à Astra et qu'un storageclass est configuré, il détecte et inspecte automatiquement le cluster ONTAP qui soutient le storageclass, mais ne l'importe pas dans le Control Center Astra à gérer.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Découverte du centre de contrôle Astra</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">Pour importer les clusters ONTAP, accédez aux systèmes back-end, cliquez sur la liste déroulante et sélectionnez gérer en regard du cluster ONTAP à gérer. Entrez les informations d'identification du cluster ONTAP, cliquez sur vérifier les informations, puis sur Importer le stockage back-end.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Le centre de contrôle Astra crée un back-end</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">Une fois que le système back-end est ajouté, le statut devient disponible. Ces systèmes back-end disposent désormais d'informations sur les volumes persistants dans le cluster OpenShift et sur les volumes correspondants sur le système ONTAP.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Systèmes back-end Astra Control Center disponibles</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Pour la sauvegarde et la restauration entre les clusters OpenShift avec Astra Control Center, vous devez provisionner un compartiment de stockage objet qui prend en charge le protocole S3. Les options ONTAP S3, StorageGRID et AWS S3 sont actuellement prises en charge. Pour les besoins de cette installation, nous allons configurer un compartiment AWS S3. Accédez à godets, cliquez sur Ajouter un compartiment et sélectionnez Generic S3. Entrez les informations d'identification du compartiment S3 et des informations d'identification pour y accéder, cochez la case « définir ce compartiment par défaut pour le cloud », puis cliquez sur Ajouter.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Le centre de contrôle Astra crée un godet</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">Suivant : choisissez les applications à protéger.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="d7b2cdc877c7db996d45c651b4e7834a" category="paragraph">Ce document décrit la configuration et la validation de la plateforme de stockage NetApp ONTAP avec la plateforme Anthos sur un système d'exploitation de Google Cloud à l'aide de NetApp Astra Trident, l'orchestrateur de stockage open source pour Kubernetes, afin de déployer et de gérer le stockage persistant pour les conteneurs d'applications avec état.</block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">Le déploiement actuel de cette solution a été soumis à deux processus de validation rigoureux, à l'aide d'outils fournis par l'équipe Google Cloud.</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">Validation des solutions</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">Le déploiement actuel de cette solution a été soumis à deux processus de validation rigoureux, à l'aide d'outils fournis par l'équipe Google Cloud. Ces validations incluent un sous-ensemble des tests suivants :</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Validation par les partenaires de la plateforme pour Anthos :</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">Vérifiez que tous les services de plateforme Anthos sur système d'exploitation sont installés et exécutés.</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">Faites évoluer vos ressources physiques sur un cluster bare Metal, passant de quatre nœuds workers à trois, puis à quatre.</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">Créez et supprimez un espace de noms personnalisé.</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Créez un déploiement du serveur web Nginx, en faisant évoluer ce déploiement en augmentant le nombre de répliques.</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Créez une entrée pour l'application Nginx et vérifiez la connectivité en curling index.html.</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">Nettoyez toutes les activités de la suite de tests avec succès et remettez le cluster en état de pré-test.</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Validation par les partenaires du stockage prêt pour Anthos :</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">Créez un déploiement avec une demande de volume persistant.</block>
  <block id="2b9593caebc55ca069d98dcb7a3473c8" category="list-text">Utilisez NetApp Astra Trident pour provisionner et joindre le volume persistant demandé à NetApp ONTAP.</block>
  <block id="c0724935c9b9fa3acfd0441317cac5e4" category="list-text">Validez la capacité de détachement et de rattachement des volumes persistants.</block>
  <block id="05053a6eeca3d00f1ffdaead4d65118f" category="list-text">Valider l'accès multi-attacher et en lecture seule des volumes persistants à partir d'autres pods sur le nœud.</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">Valider l'opération de redimensionnement du volume hors ligne.</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">Vérifiez que le volume persistant survit à une opération de mise à l'échelle du cluster.</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">Les fonctionnalités indépendantes du matériel de Anthos sur un système d'exploitation sans système d'exploitation vous permettent de sélectionner une plateforme de calcul optimisée pour votre cas d'utilisation. Votre infrastructure peut donc s'adapter à votre infrastructure existante, ce qui réduit vos dépenses d'investissement.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">De la solution</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">Calcul : Bring your own Server</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">Les fonctionnalités indépendantes du matériel de Anthos sur un système bare Metal vous permettent de sélectionner une plateforme de calcul optimisée pour votre cas d'utilisation. Votre infrastructure peut donc s'adapter à votre infrastructure existante, ce qui réduit vos dépenses d'investissement.</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">Le tableau suivant répertorie le nombre minimal de composants matériels de calcul requis pour implémenter cette solution, bien que les modèles matériels utilisés puissent varier en fonction des exigences du client.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">Du stockage</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">Matériel et modèle</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">Nœuds d'administration</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">Nœuds worker</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">Stockage : NetApp ONTAP</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">Le tableau suivant répertorie le nombre minimal de composants de matériel de stockage nécessaire pour implémenter la solution, bien que les modèles matériels utilisés puissent varier en fonction des exigences du client.</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2 (1 paire HA)</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">Les versions logicielles identifiées dans le tableau suivant ont été utilisées par NetApp et ses partenaires pour valider la solution avec NetApp, mais les composants logiciels utilisés peuvent varier en fonction des besoins du client.</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">Système d'exploitation sur 3 administrateurs</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Se sur Worker4</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Se sur Worker3</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Se sur Worker2</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Se sur Worker1</block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="cell">Anthos sur bare Metal</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">Orchestration de conteneurs</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">OS de stockage</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">Gestion du stockage de conteneurs</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">Cet environnement multi-systèmes d'exploitation montre l'interopérabilité avec les versions de système d'exploitation prises en charge de la solution Anthos sur des systèmes d'exploitation sans système d'exploitation. Nous prévoyons que les clients standardiseront sur un ou plusieurs systèmes d'exploitation à des fins de déploiement.</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Documentation Anthos sur les métaux nus</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">Pour obtenir des informations sur les exigences matérielles et logicielles pour Anthos, consultez le<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> page.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">Suivant : récapitulatif du déploiement.</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">Anthos sur un système bare Metal avec NetApp offre une plateforme robuste pour exécuter efficacement des charges de travail basées sur des conteneurs en permettant la personnalisation de l'infrastructure déployée.</block>
  <block id="65ffe919dd9568cce4454508d8e543bd" category="paragraph">Anthos sur un système bare Metal avec NetApp offre une plateforme robuste pour exécuter efficacement des charges de travail basées sur des conteneurs en permettant la personnalisation de l'infrastructure déployée. Les clients peuvent utiliser l'infrastructure de serveur et le système d'exploitation pris en charge de leur choix, ou même déployer la solution au sein de leur infrastructure existante. La puissance et la flexibilité de ces environnements s'améliorent considérablement grâce à l'intégration de NetApp ONTAP et de NetApp Astra Trident, qui prennent en charge les workloads applicatifs avec état en provisionnant et en gérant efficacement le stockage persistant pour les conteneurs. En étendant le potentiel de Google Cloud à leur data Center optimisé par NetApp, vous bénéficiez d'une solution Kubernetes entièrement prise en charge, extrêmement disponible, facilement évolutive et entièrement gérée pour le développement et la production de vos workloads applicatifs.</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">Centre de documentation NetApp ONTAP</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="list-text">Anthos de Google Cloud</block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="c8a326f53d0d33a113452a303c243987" category="summary">NetApp et Google Cloud se sont solides depuis plusieurs années, et NetApp a d'abord lancé des services de données cloud vers Google Cloud avec Cloud Volumes ONTAP et Cloud Volumes Service. Cette relation a ensuite été développée en validant la plateforme NetApp HCI pour être utilisée avec Google Cloud Anthos sur site, une solution Kubernetes multicloud hybride basée sur hyperviseur et déployée sur VMware vSphere. NetApp a ensuite réussi la qualification Anthos Ready pour NetApp Astra Trident, ONTAP et le protocole NFS, afin de fournir un stockage persistant dynamique pour les conteneurs.</block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337 : Anthos sur les métaux nus</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">Alan Cowles et Nikhil M Kulkarni, NetApp</block>
  <block id="f989491ea62ea4778f84ec6b21a68adf" category="paragraph">NetApp et Google Cloud se sont solides depuis plusieurs années, et NetApp a lancé pour la première fois des services de données cloud pour Google Cloud avec Cloud Volumes ONTAP et Cloud Volumes Service. Cette relation a ensuite été développée en validant la plateforme NetApp HCI pour être utilisée avec Google Cloud Anthos sur site, une solution Kubernetes multicloud hybride basée sur hyperviseur et déployée sur VMware vSphere. NetApp a ensuite réussi la qualification Anthos Ready pour NetApp Astra Trident, ONTAP et le protocole NFS, afin de fournir un stockage persistant dynamique pour les conteneurs.</block>
  <block id="1349318f8c0f3a02420c7453ca5cda7d" category="paragraph">Anthos peut désormais être installée directement sur des serveurs bare-Metal dans l'environnement d'un client, ce qui offre une possibilité supplémentaire aux clients d'étendre Google Cloud à leurs data centers locaux sans hyperviseur. Avec les fonctionnalités du système d'exploitation du stockage NetApp ONTAP et de l'Astra Trident, vous pouvez étendre les fonctionnalités de votre plateforme en intégrant le stockage persistant pour les conteneurs.</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">Cette combinaison vous permet d'exploiter tout le potentiel de vos serveurs, de votre stockage et de vos ressources réseau, ainsi que l'assistance, les niveaux de service, la facturation mensuelle et la flexibilité à la demande offertes par Google Cloud. Comme vous utilisez votre propre matériel, votre réseau et votre stockage, vous bénéficiez d'un contrôle direct sur l'évolutivité des applications, la sécurité et la latence du réseau, tout en bénéficiant des avantages des applications gérées et conteneurisées de Anthos sur un système bare Metal.</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">Pour la validation initiale de cette solution, NetApp s'est associé à la technologie World Wide Technology (WWT) afin d'établir un environnement au Advanced Technology Center (ATC) de WWT. Anthos a été déployée sur une infrastructure bare Metal à l'aide de l'outil bmctl fourni par Google Cloud. La section suivante détaille le déploiement utilisé pour la validation.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">Récapitulatif du déploiement</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">La solution NetApp pour Anthos a été conçue comme un cluster hybride haute disponibilité avec trois nœuds de contrôle Anthos et quatre nœuds workers Anthos.</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">Les nœuds de plan de contrôle utilisés étaient des serveurs lames Cisco UCS B200M3 hébergés dans un châssis et configurés avec une seule carte d'interface réseau virtuelle (vNIC) sur chacun d'entre eux, ce qui permettait un basculement A/B au niveau de la plateforme Cisco UCS pour assurer la tolérance aux pannes. Le châssis Cisco UCS est connecté en amont à deux interconnexions de fabric Cisco UCS 6248 qui fournissent des chemins disparates pour la séparation du trafic le long de la structure A et de la structure B. Ces interconnexions de fabric sont connectées en amont à deux commutateurs de data Center Cisco Nexus 5548, qui sont rattachés au réseau principal de WWT.</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">Les nœuds workers étaient les nœuds HP ProLiant DL360, exécutant chacun une des distributions Linux prises en charge pour Anthos sur un système bare Metal : Red Hat Enterprise Linux 8.2, CentOS 8.2, Ubuntu 20.04 LTS ou Ubuntu 18.04 LTS. Les nœuds Red Hat Enterprise Linux 8 et CentOS 8 ont été configurés avec des équipes NIC fonctionnant en mode LACP et câblés à deux commutateurs Nexus 9k C93180YC-FX pour la tolérance aux pannes. Les serveurs Ubuntu ont été configurés pour la liaison réseau en mode LACP et câblés sur la même paire de commutateurs Nexus 9k pour la tolérance aux pannes.</block>
  <block id="4ed7e16612fd7090efc8d89c68421b74" category="paragraph">Le système de stockage NetApp AFF A300 qui exécute le logiciel ONTAP 9.7 a été installé et connecté physiquement à la même paire de commutateurs Nexus 9k que les nœuds Anthos. Ces liaisons montantes réseau ont été regroupées dans un groupe d'interfaces (a0A) et le VLAN approprié du réseau de données a été marqué pour permettre aux nœuds workers d'interagir avec le système de stockage. Un SVM (Storage Virtual machine) a été créé avec des LIF de données qui prennent en charge le protocole NFS et dédiées aux opérations de stockage pour Trident. Ces LIF offrent un stockage persistant aux conteneurs déployés dans le cluster Anthos sur des systèmes bare Metal. Ces volumes persistants ont été fournis par NetApp Astra Trident 20.10, la dernière version de l'orchestrateur de stockage open source NetApp entièrement pris en charge pour Kubernetes.</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">La figure suivante représente un schéma de câblage physique de la solution vers le haut des commutateurs de data Center en rack.</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">La figure suivante présente une vue logique de la solution telle que déployée et validée sur le matériel en laboratoire chez le partenaire de NetApp WWT.</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">Ensuite, validation de la solution.</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF est une plateforme de stockage 100 % Flash robuste qui offre une faible latence, une protection intégrée des données, une prise en charge multiprotocole et la continuité de l'activité. Optimisé par le logiciel de gestion des données ONTAP, NetApp AFF assure la continuité de l'activité, de la maintenance aux mises à niveau, en passant par le remplacement complet de votre système de stockage.</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp ONTAP sur les systèmes NetApp AFF/FAS</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP est un puissant outil de gestion du stockage offrant des fonctionnalités telles qu'une interface graphique intuitive, des API REST avec intégration de l'automatisation, des analyses prédictives basées sur l'IA et des actions correctives, des mises à niveau matérielles sans interruption et des importations intersystèmes de stockage.</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">*NetApp FlexClone.* assure le provisionnement instantané d'une copie lisible et inscriptible d'un volume NetApp à partir d'une copie Snapshot. Pour plus d'informations sur ONTAP, consultez le<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a5e993e443aa30456050e2589b6e1a7" category="paragraph">NetApp Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Google Cloud Anthos. Ce logiciel est compatible avec tous les produits de stockage NetApp, y compris le logiciel NetApp ONTAP. Trident est conforme à la directive CSI et accélère le workflow DevOps en vous permettant de provisionner et de gérer le stockage à partir de vos systèmes de stockage NetApp, sans intervention de l'administrateur du stockage. Trident est déployé en tant qu'opérateur qui communique directement avec le terminal API Kubernetes pour servir les demandes de stockage des conteneurs sous la forme de demandes de volume persistant en créant et en gérant les volumes dans le système de stockage NetApp.</block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">Les volumes persistants sont provisionnés en fonction des classes de stockage définies dans l'environnement Kubernetes. Ils utilisent les systèmes back-end créés par un administrateur de stockage (personnalisation en fonction des besoins des projets), ainsi que des modèles de système de stockage pour permettre la mise en œuvre de nombreuses fonctionnalités de stockage avancées, comme la compression, des types de disques spécifiques ou des niveaux de QoS pour garantir les performances.</block>
  <block id="eb3bc37ad07db70234f55e02bb4fa499" category="paragraph">Pour en savoir plus sur NetApp Astra Trident, rendez-vous sur le<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> page.</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident orchestre le stockage à partir de chaque système et service dans le portefeuille NetApp.</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Anthos est une solution de data Center basée sur le cloud qui permet aux entreprises de concevoir et de gérer des infrastructures modernes de cloud hybride tout en adoptant des workflows agiles axés sur le développement d'applications. Anthos sur un système bare Metal étend la capacité d'exécution de Anthos sur site directement sur des serveurs physiques sans couche d'hyperviseur et interopérabilité avec les clusters GKE dans Google Cloud.</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">En adoptant les conteneurs, le maillage des services et d'autres technologies de transformation, les entreprises peuvent bénéficier de cycles de développement d'applications cohérents et de charges de travail prêtes pour la production dans des environnements locaux et cloud.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos offre les fonctionnalités suivantes :</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">*La gestion de la configuration Anthos* automatise la stratégie et la sécurité des déploiements Kubernetes hybrides.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">*Anthos Service mesh.* améliore l'observabilité, la sécurité et le contrôle des applications grâce à un maillage de service optimisé par Istio.</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">*Google Cloud Marketplace pour les applications Kubernetes.* Un catalogue d'applications pour conteneurs mis en place pour faciliter le déploiement.</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">*Migrer pour Anthos.* migration automatique de services physiques et de machines virtuelles depuis les sites vers le cloud. La Figure 3 décrit la solution Anthos et le mode de déploiement dans un data Center sur site qui interconnecte avec l'infrastructure dans le cloud.</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Site Web Anthos</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Pour plus d'informations sur Anthos, consultez le<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>.</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">La figure suivante présente l'architecture Anthos de Google Cloud.</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">Anthos sur un système bare Metal est une extension de GKE déployée dans le data Center privé d'un client. Une entreprise peut déployer les mêmes applications que celles conçues pour s'exécuter dans des conteneurs dans Google Cloud dans des clusters Anthos sur site. Anthos sur des serveurs physiques fonctionne directement sur des serveurs physiques avec le choix du système d'exploitation Linux sous-jacent par l'utilisateur. Elle offre aux clients un environnement de cloud hybride à part entière, capable de s'exécuter au cœur ou à la périphérie de leurs data centers.</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">Anthos sur les solutions bare Metal offre les avantages suivants :</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">*Indépendant du matériel.* les clients peuvent exécuter Anthos sur leur plate-forme matérielle optimisée de leur choix dans leurs datacenters existants.</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">*Économies.* vous pouvez réaliser d'importantes économies en utilisant vos propres ressources physiques pour les déploiements d'applications au lieu de provisionner des ressources dans l'environnement Google Cloud.</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">*Développer puis publier.* vous pouvez utiliser des déploiements sur site alors que les applications sont en cours de développement, ce qui permet de tester les applications dans la confidentialité de votre centre de données local avant de les rendre accessibles au public dans le cloud.</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">* Meilleures performances.* les applications intensives qui exigent une faible latence et les niveaux de performance les plus élevés peuvent être exécutées plus près du matériel.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">*Exigences de sécurité.* les clients ayant des préoccupations de sécurité accrues ou des jeux de données sensibles qui ne peuvent pas être stockés dans le cloud public peuvent exécuter leurs applications à partir de la sécurité de leurs propres data centres, ce qui répond aux exigences de l'organisation.</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">* Gestion et opérations.* Anthos sur métal nu est fourni avec une large gamme d'installations qui augmentent l'efficacité opérationnelle telles que la mise en réseau intégrée, la gestion du cycle de vie, diagnostics, contrôles de santé, l'enregistrement, et contrôle.</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">Ensuite, les exigences de la solution.</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">Pour activer l'intégration de Trident avec le système de stockage NetApp ONTAP, il faut créer un back-end permettant la communication avec le système de stockage.</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">Configuration NetApp ONTAP NFS</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">Des exemples de fichiers backend sont disponibles dans l'archive d'installation téléchargée dans le<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> hiérarchie des dossiers. Pour les systèmes NetApp ONTAP servant de protocole NFS, copiez le<block ref="d897e4d05156cbf9998e98200d6190aa" prefix=" " category="inline-code"></block> dans votre répertoire de travail et modifiez le fichier.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">Modifier le backendName, la gestion LIF, dataLIF, svm, nom d'utilisateur, et les valeurs de mot de passe dans ce fichier.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">Il est recommandé de définir la valeur backendName personnalisée comme combinaison du storageDriverName et de la dataLIF qui sert NFS pour une identification facile.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">Il y a un champ facultatif appelé<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> qui est défini dans ce fichier. Cette ligne peut être supprimée dans les systèmes back-end NFS.</block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere est une plateforme de virtualisation qui permet de gérer de manière centralisée un grand nombre de serveurs et de réseaux virtualisés exécutés sur l'hyperviseur ESXi.</block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="doc">OpenShift sur VMware vSphere</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">Site Web VMware vSphere</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">Pour plus d'informations sur VMware vSphere, consultez<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere offre les fonctionnalités suivantes :</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">*VMware vCenter Server.* VMware vCenter Server assure une gestion unifiée de tous les hôtes et machines virtuelles à partir d'une console unique et rassemble la surveillance des performances des clusters, des hôtes et des machines virtuelles.</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">*VMware vSphere vMotion*. VMware vCenter vous permet, sur demande, de migrer à chaud les machines virtuelles entre les nœuds du cluster, sans aucune interruption.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">*Haute disponibilité vSphere* pour éviter les perturbations en cas de panne de l'hôte, VMware vSphere permet la mise en cluster des hôtes et leur configuration pour la haute disponibilité. Les machines virtuelles interrompues par une défaillance hôte sont redémarrée prochainement sur d'autres hôtes du cluster, afin de restaurer les services.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">*Distributed Resource Scheduler (DRS).* Un cluster VMware vSphere peut être configuré pour équilibrer la charge des besoins en ressources des machines virtuelles qu'il héberge. Les machines virtuelles avec contention de ressources peuvent être migrées à chaud vers d'autres nœuds du cluster pour garantir qu'un nombre suffisant de ressources est disponible.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">La solution Red Hat OpenShift sur NetApp utilise deux switchs de données pour assurer la connectivité des données primaires à 25 Gbit/s. Il utilise également deux commutateurs de gestion supplémentaires qui fournissent une connectivité à 1 Gbit/s pour la gestion intrabande des nœuds de stockage et la gestion hors bande des fonctionnalités IPMI. OCP utilise le réseau logique VM sur VMware vSphere pour la gestion de son cluster. Cette section décrit l'organisation et l'objectif de chaque segment de réseau virtuel utilisé dans la solution et décrit les conditions préalables au déploiement de la solution.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">Red Hat OpenShift sur VMware vSphere est conçu pour séparer logiquement le trafic réseau à différents fins à l'aide de réseaux locaux virtuels (VLAN). Cette configuration peut être adaptée aux besoins du client ou pour assurer une isolation supplémentaire pour des services réseau spécifiques. Le tableau suivant répertorie les VLAN nécessaires à la mise en œuvre de la solution lors de sa validation chez NetApp.</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">Gestion des nœuds physiques et IPMI</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">Réseau de VM</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">Accès réseau invité virtuel</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">Réseau de stockage</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">Réseau de stockage pour ONTAP NFS</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">Réseau de stockage pour ONTAP iSCSI</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">Réseau de gestion dans la bande</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">Gestion des nœuds ESXi, vCenter Server, ONTAP Select</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">Réseau de stockage pour NetApp Element iSCSI</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">Réseau de migration</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">Réseau pour migration invité virtuel</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">L'infrastructure suivante doit être en place avant le déploiement de la plateforme de conteneurs OpenShift :</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">Au moins un serveur DNS fournissant une résolution complète du nom d'hôte accessible depuis le réseau de gestion intrabande et le réseau VM.</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">Bonnes pratiques pour les déploiements en production</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">Cette section répertorie plusieurs meilleures pratiques à prendre en considération avant de déployer cette solution en production.</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">Déployez OpenShift sur un cluster ESXi d'au moins trois nœuds</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">L'architecture vérifiée dans ce document présente le déploiement matériel minimum adapté aux opérations haute disponibilité en déployant deux nœuds d'hyperviseur ESXi et en assurant une configuration avec tolérance aux pannes en activant VMware vSphere HA et VMware vMotion. Cette configuration permet aux VM déployées de migrer entre les deux hyperviseurs et de redémarrer en cas d'indisponibilité d'un hôte.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Red Hat OpenShift se déploie initialement avec trois nœuds maîtres, au moins deux maîtres dans une configuration à deux nœuds peuvent occuper le même nœud dans certains cas, ce qui peut entraîner une interruption possible pour OpenShift si ce nœud spécifique devient indisponible. C'est donc une meilleure pratique Red Hat qu'au moins trois nœuds d'hyperviseur ESXi doivent être déployés de manière à ce que les maîtres OpenShift puissent être répartis de façon homogène, ce qui offre un degré supplémentaire de tolérance aux pannes.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">Configuration de l'affinité des hôtes et des machines virtuelles</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">Assurer la distribution des maîtres OpenShift sur plusieurs nœuds d'hyperviseur peut être obtenue grâce à l'activation des VM et de l'affinité des hôtes.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">Une affinité ou une anti-affinité permet de définir des règles pour un ensemble de VM et/ou d'hôtes qui déterminent si les VM s'exécutent sur le même hôte ou sur des hôtes du groupe ou sur des hôtes différents. Elle est appliquée aux VM par la création de groupes d'affinités comprenant des VM et/ou des hôtes avec un ensemble de paramètres et de conditions identiques. Selon que les VM d'un groupe d'affinité s'exécutent sur le même hôte ou sur les hôtes du groupe ou séparément sur des hôtes différents, les paramètres du groupe d'affinités peuvent définir une affinité positive ou négative.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">Documentation vSphere 6.7 : utilisation des règles d'affinité DRS</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">Pour configurer des groupes d'affinités, reportez-vous à la section<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">Utilisez un fichier d'installation personnalisé pour le déploiement OpenShift</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI facilite le déploiement des clusters OpenShift via l'assistant interactif présenté plus haut dans ce document. Cependant, il est possible que vous deviez modifier certaines valeurs par défaut dans le cadre d'un déploiement de cluster.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift installation d'un cluster sur vSphere avec personnalisation</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">Dans ces instances, vous pouvez exécuter et exécuter l'assistant sans déployer immédiatement un cluster, mais à la place, l'assistant crée un fichier de configuration à partir duquel le cluster peut être déployé ultérieurement. Cette approche est très utile pour modifier les paramètres par défaut des IPI ou pour déployer plusieurs clusters identiques dans votre environnement à des fins autres que la colocation. Pour plus d'informations sur la création d'une configuration d'installation personnalisée pour OpenShift, consultez<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">Suivant : présentation du stockage NetApp.</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">Solution NetApp de gestion avancée des clusters pour Kubernetes sur Red Hat OpenShift.</block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Déploiement de la gestion avancée des clusters pour Kubernetes</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">Pour installer Advanced Cluster Management pour Kubernetes sur un cluster OpenShift, effectuez les opérations suivantes :</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">Choisissez un cluster OpenShift en tant que cluster Hub et connectez-vous avec les privilèges cluster-admin.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Accédez à Operators &gt; Operators Hub et recherchez Advanced Cluster Management pour Kubernetes.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">Carreaux ACM</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Sélectionnez Advanced Cluster Management pour Kubernetes et cliquez sur Install.</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">Détails sur les carreaux ACM</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Dans l'écran Install Operator, indiquez les détails nécessaires (NetApp recommande de conserver les paramètres par défaut) et cliquez sur Install.</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">Poser la mosaïque de l'opérateur ACM</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">Installation de l'opérateur ACM en cours</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">Une fois l'opérateur installé, cliquez sur Créer MultiClusterHub.</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">Conducteur ACM MulticlusterHub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Dans l'écran Créer MultiClusterHub, cliquez sur Créer après avoir donné les détails. Cela initie l'installation d'un hub multi-cluster.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">Écran Créer un concentrateur Multicluster</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">Une fois que tous les pods passent à l'état d'exécution dans l'espace de noms d'open-cluster-management et que l'opérateur passe à l'état « réussi », Advanced Cluster Management pour Kubernetes est installé.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">Opérateur ACM installé</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">L'installation du concentrateur prend un certain temps et, une fois cette opération effectuée, le concentrateur MultiCluster passe à l'état d'exécution.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">Concentrateur Multicluster prêt</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">Elle crée une route dans l'espace de noms Open-cluster-management. Connectez-vous à l'URL de la route pour accéder à la console Advanced Cluster Management.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">Acheminement de la console ACM</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">Suivant : fonctionnalités - Cluster Lifecycle Management.</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Une fois les charges de travail applicatives gérées par Astra Control Center, vous pouvez configurer les paramètres de protection pour ces charges de travail.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">Protégez vos applications</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">Création d'un instantané d'application</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">Un snapshot d'une application crée une copie Snapshot ONTAP qui peut être utilisée pour restaurer ou cloner l'application à un point dans le temps spécifique en fonction de cette copie Snapshot.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">Pour prendre un instantané de l'application, accédez à l'onglet applications &gt; gestion, puis cliquez sur l'application dont vous souhaitez effectuer une copie Snapshot. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur instantané.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Bouton instantané du centre de contrôle Astra</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">Entrez les détails du snapshot, cliquez sur Suivant, puis sur instantané. La création du Snapshot prend environ une minute et son état est disponible une fois celui-ci créé.</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center crée un snapshot</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">Création d'une sauvegarde d'application</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">Une sauvegarde d'une application capture l'état actif de l'application et la configuration des ressources informatiques, les analyse en fichiers et les stocke dans un compartiment de stockage objet distant.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Pour la sauvegarde et la restauration des applications gérées dans le Centre de contrôle Astra, vous devez configurer les paramètres de superutilisateur des systèmes ONTAP de secours au préalable. Pour ce faire, entrez les commandes suivantes.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Pour créer une sauvegarde de l'application gérée dans Astra Control Center, accédez à l'onglet applications &gt; géré et cliquez sur l'application dont vous souhaitez effectuer une sauvegarde. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur Sauvegarder.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Bouton de secours Astra Control Center</block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">Entrez les détails de la sauvegarde, sélectionnez le compartiment de stockage objet pour contenir les fichiers de sauvegarde, cliquez sur Next (Suivant) et, après avoir vérifié les détails, cliquez sur Backup (Sauvegarder). Selon la taille de l'application et des données, la sauvegarde peut prendre plusieurs minutes, et l'état de la sauvegarde est disponible une fois la sauvegarde terminée.</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Créez une sauvegarde avec Astra Control Center</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">Restauration d'une application</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">En appuyant sur un bouton, vous pouvez restaurer une application sur l'espace de noms d'origine dans le même cluster ou sur un cluster distant afin d'assurer la protection des applications et la reprise sur incident.</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">Pour restaurer une application, accédez à applications &gt; onglet géré et cliquez sur l'application en question. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur<block ref="2bd339d85ee3b33e513359ce781b60cc" prefix=" " category="inline-code"></block>.</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Bouton clone du centre de contrôle Astra</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">Entrez le nom de l'espace de noms de restauration, sélectionnez le cluster vers lequel vous souhaitez le restaurer et choisissez si vous souhaitez le restaurer à partir d'un snapshot existant ou à partir d'une sauvegarde de l'application. Cliquez sur Suivant.</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Restauration du centre de contrôle Astra</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">Dans le volet de révision, entrez<block ref="bb2ac0b8da1f64a3498af147ba43fc10" prefix=" " category="inline-code"></block> Puis cliquez sur Restaurer une fois que vous avez examiné les détails.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Examen de la restauration d'Astra Control Center</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">La nouvelle application passe à l'état de restauration tandis qu'Astra Control Center restaure l'application sur le cluster sélectionné. Une fois que toutes les ressources de l'application sont installées et détectées par Astra, l'application passe à l'état disponible.</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Une nouvelle application Astra Control Center a été découverte</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">Clonage d'une application</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">Vous pouvez cloner une application sur le cluster d'origine ou sur un cluster distant à des fins de développement/test ou de protection des applications et de reprise sur incident. Le clonage d'une application au sein d'un même cluster sur le même système back-end utilise la technologie NetApp FlexClone, qui clonez instantanément les demandes de volume persistant et économise de l'espace de stockage.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">Pour cloner une application, accédez à l'onglet applications &gt; gestion et cliquez sur l'application en question. Cliquez sur le menu déroulant en regard du nom de l'application, puis cliquez sur Cloner.</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">Entrez les détails du nouveau namespace, sélectionnez le cluster vers lequel vous souhaitez le cloner à partir d'un snapshot existant ou d'une sauvegarde ou de l'état actuel de l'application. Cliquez ensuite sur Suivant et sur Cloner dans le volet d'évaluation une fois que vous avez passé en revue les détails.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">La nouvelle application passe à l'état découverte tandis que Astra Control Center crée l'application sur le cluster sélectionné. Une fois que toutes les ressources de l'application sont installées et détectées par Astra, l'application passe à l'état disponible.</block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">Ensuite : validation/utilisation de la solution.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform offre une base intégrée pour créer, déployer et faire évoluer un cloud privé OpenStack sécurisé et fiable.</block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="doc">OpenShift sur Red Hat OpenStack Platform</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP est un cloud IaaS (infrastructure en tant que service) implémenté par un ensemble de services de contrôle qui gèrent les ressources de calcul, de stockage et de mise en réseau. L'environnement est géré via une interface Web qui permet aux administrateurs et aux utilisateurs de contrôler, de provisionner et d'automatiser les ressources OpenStack. De plus, l'infrastructure OpenStack est simplifiée par une vaste interface de ligne de commande et une API poussée permettant de disposer de fonctionnalités d'automatisation complètes pour les administrateurs et les utilisateurs finaux.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">Le projet OpenStack est un projet communautaire rapidement développé qui propose des versions mises à jour tous les six mois. Dans un premier temps, Red Hat OpenStack Platform a su suivre le rythme de ce cycle de sortie en publiant une nouvelle version, ainsi que chaque version en amont, et en assurant une prise en charge à long terme pour chaque troisième version. Avec la version OSP 16.0 (basé sur OpenStack train), Red Hat a récemment choisi de ne pas suivre le rythme des numéros de version, mais de proposer de nouvelles fonctionnalités dans des sous-versions. La version la plus récente est Red Hat OpenStack Platform 16.1, qui inclut des fonctionnalités avancées backportées des versions Ussuri et Victoria en amont.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Site Web de Red Hat OpenStack Platform</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">Pour plus d'informations sur OSP, consultez le<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">Services OpenStack</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">Les services de plateforme OpenStack sont déployés sous forme de conteneurs, qui permettent d'isoler les services les uns des autres et de faciliter les mises à niveau. La plateforme OpenStack utilise un ensemble de conteneurs conçus et gérés avec Kolla. Le déploiement des services s'effectue en extrayant des images de conteneur à partir du portail personnalisé Red Hat. Ces conteneurs de service sont gérés à l'aide de la commande Podman, et sont déployés, configurés et gérés avec Red Hat OpenStack Director.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">Service</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">Nom du projet</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">Tableau de bord</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">Horizon</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">Tableau de bord Web que vous utilisez pour gérer les services OpenStack.</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">Identité</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">Keystone</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">Service centralisé d'authentification et d'autorisation des services OpenStack, et de gestion des utilisateurs, des projets et des rôles.</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">La mise en réseau d'OpenStack</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">Neutron</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">Assure la connectivité entre les interfaces des services OpenStack.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">Stockage basé sur des blocs</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">Cinder</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">Gère les volumes de stockage bloc persistants pour les machines virtuelles (VM).</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">Nouvelle</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">Gère et provisionne les VM s'exécutant sur les nœuds de calcul.</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">Coup d'œil</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">Service de registre utilisé pour stocker des ressources telles que des images de machines virtuelles et des instantanés de volumes.</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">Stockage objet</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">SWIFT</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">Permet aux utilisateurs de stocker et de récupérer des fichiers et des données arbitraires.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">Télémétrie</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilamomètre</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">Mesure l'utilisation des ressources du cloud.</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">Orchestration</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">Chaleur</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">Moteur d'orchestration basé sur des modèles qui prend en charge la création automatique de piles de ressources.</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">La solution Red Hat OpenShift avec NetApp utilise deux switchs de données pour assurer la connectivité des données primaires à 25 Gbit/s. Il utilise également deux commutateurs de gestion supplémentaires qui fournissent une connectivité à 1 Gbit/s pour la gestion intrabande des nœuds de stockage et la gestion hors bande des fonctionnalités IPMI.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">Red Hat OpenStack Director exige une fonctionnalité IPMI pour déployer Red Hat OpenStack Platform à l'aide du service de provisionnement sans système d'exploitation ironique.</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">Red Hat OpenShift avec NetApp est conçu pour séparer logiquement le trafic réseau à différents fins à l'aide de réseaux locaux virtuels (VLAN). Cette configuration peut être adaptée aux besoins du client ou pour assurer une isolation supplémentaire pour des services réseau spécifiques. Le tableau suivant répertorie les VLAN nécessaires à la mise en œuvre de la solution lors de sa validation chez NetApp.</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">Réseau utilisé pour la gestion des nœuds physiques et du service IPMI pour ironique.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">De stockage existante</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">Utilisé par le réseau pour les nœuds de contrôleur, pour mapper les volumes directement pour prendre en charge des services d'infrastructure tels que Swift.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">Stockage Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">Réseau utilisé pour mapper et rattacher des volumes de blocs directement aux instances virtuelles déployées dans l'environnement.</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">API interne</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">Réseau utilisé pour la communication entre les services OpenStack à l'aide de la communication API, des messages RPC et de la communication avec les bases de données.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">Locataire</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron fournit à chaque locataire ses propres réseaux par tunneling via VXLAN. Le trafic réseau est isolé dans chaque réseau de locataires. Chaque réseau de locataires est associé à un sous-réseau IP, et les espaces de noms réseau signifient que plusieurs réseaux de locataires peuvent utiliser la même plage d'adresses sans entraîner de conflits.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">Gestion du stockage</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage (Swift) utilise ce réseau pour synchroniser les objets de données entre les nœuds de réplication participants. Le service proxy fait office d'interface intermédiaire entre les demandes des utilisateurs et la couche de stockage sous-jacente. Le proxy reçoit les demandes entrantes et localise la réplique nécessaire pour récupérer les données demandées.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director assure le démarrage PXE dans le service de provisionnement bare Metal ironique afin d'orchestrer l'installation du Overcloud OSP.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">Externe</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">Réseau public qui héberge le tableau de bord OpenStack (Horizon) pour une gestion graphique et permet aux appels d'API publiques de gérer les services OpenStack.</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">Permet d'accéder aux fonctions d'administration système telles que l'accès SSH, le trafic DNS et le trafic NTP (Network Time Protocol). Ce réseau fait également office de passerelle pour les nœuds sans contrôleur.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">Au moins un serveur DNS qui fournit une résolution complète de nom d'hôte.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">Au moins trois serveurs NTP qui peuvent garder le temps synchronisé pour les serveurs de la solution.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(Facultatif) connectivité Internet sortante pour l'environnement OpenShift.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">Déployez OpenShift dans un cloud privé OSP avec au moins trois nœuds de calcul</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">L'architecture vérifiée décrite dans ce document présente le déploiement matériel minimum adapté aux opérations HA en déployant trois nœuds de contrôleur OSP et deux nœuds de calcul OSP. Cette architecture garantit une configuration tolérante aux pannes dans laquelle les deux nœuds de calcul peuvent lancer des instances virtuelles et les machines virtuelles déployées peuvent migrer entre les deux hyperviseurs.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Dans la mesure où Red Hat OpenShift se déploie initialement avec trois nœuds maîtres, une configuration à deux nœuds risque d'entraîner l'occupation d'au moins deux maîtres du même nœud, ce qui peut entraîner une interruption possible d'OpenShift si ce nœud spécifique devient indisponible. C'est pourquoi il s'agit d'une meilleure pratique Red Hat de déployer au moins trois nœuds de calcul OSP afin que les maîtres OpenShift puissent être distribués uniformément et que la solution reçoive un degré supplémentaire de tolérance aux pannes.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">Configuration de l'affinité hôte/machine virtuelle</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">Distribution des maîtres OpenShift sur plusieurs nœuds d'hyperviseur peut être obtenue grâce à l'affinité VM/hôte.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">L'affinité est un moyen de définir des règles pour un ensemble de VM et/ou d'hôtes qui déterminent si les VM s'exécutent sur le même hôte ou sur des hôtes du groupe ou sur des hôtes différents. Elle est appliquée aux VM par la création de groupes d'affinités comprenant des VM et/ou des hôtes avec un ensemble de paramètres et de conditions identiques. Selon que les VM d'un groupe d'affinité s'exécutent sur le même hôte ou sur les hôtes du groupe ou séparément sur des hôtes différents, les paramètres du groupe d'affinités peuvent définir une affinité positive ou négative. Dans Red Hat OpenStack Platform, il est possible de créer et d'appliquer des règles d'affinité des hôtes et d'anti-affinité en créant des groupes de serveurs et en configurant des filtres de sorte que les instances déployées par Nova dans un groupe de serveurs se déploient sur différents nœuds de calcul.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">Un groupe de serveurs possède un maximum de 10 instances virtuelles par défaut pour lesquelles il peut gérer le placement. Ceci peut être modifié en mettant à jour les quotas par défaut pour Nova.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">Il existe une limite stricte d'affinité/d'anti-affinité pour les groupes de serveurs OSP. S'il n'y a pas suffisamment de ressources à déployer sur des nœuds distincts ou pas assez de ressources pour permettre le partage des nœuds, la machine virtuelle ne démarre pas.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">Comment configurer l'affinité et la anti-affinité pour les instances OpenStack ?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">Pour configurer des groupes d'affinités, voir<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift installation d'un cluster sur OpenStack avec personnalisation</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">Dans ces cas, vous pouvez exécuter et effectuer la tâche sans déployer immédiatement un cluster ; il crée alors un fichier de configuration à partir duquel le cluster peut être déployé ultérieurement. Cette approche est très utile pour modifier les valeurs par défaut des IPI ou pour déployer plusieurs clusters identiques dans votre environnement pour d'autres utilisations telles que la colocation. Pour plus d'informations sur la création d'une configuration d'installation personnalisée pour OpenShift, consultez<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV est une plateforme de data Center virtuel d'entreprise qui s'exécute sur Red Hat Enterprise Linux (RHEL) et utilise l'hyperviseur KVM.</block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="doc">OpenShift sur Red Hat Virtualization</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization (RHV) est une plateforme de data Center virtuel d'entreprise qui s'exécute sur Red Hat Enterprise Linux (RHEL) et utilise l'hyperviseur KVM.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Site Web Red Hat Virtualization</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">Pour plus d'informations sur RHV, reportez-vous au<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV offre les caractéristiques suivantes :</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">*Gestion centralisée des VM et des hôtes.* le gestionnaire RHV s'exécute en tant que machine physique ou virtuelle (VM) dans le déploiement et fournit une interface utilisateur Web pour la gestion de la solution à partir d'une interface centrale.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">*Moteur auto-hébergé.* pour minimiser la configuration matérielle requise, RHV permet le déploiement de RHV Manager (RHV-M) en tant que VM sur les mêmes hôtes qui exécutent des machines virtuelles invitées.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">*Haute disponibilité.* pour éviter les perturbations en cas de défaillance de l'hôte, RHV permet de configurer les machines virtuelles pour une haute disponibilité. Les machines virtuelles haute disponibilité sont contrôlées au niveau du cluster à l'aide de règles de résilience.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">*Haute évolutivité.* Un seul cluster RHV peut disposer de 200 hôtes d'hyperviseur, ce qui lui permet de prendre en charge les besoins de machines virtuelles massives pour héberger des charges de travail exigeantes en ressources.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">*Sécurité améliorée.* les technologies RHV, Secure Virtualization (sVirt) et Security Enhanced Linux (SELinux) sont utilisées par RHV à des fins de sécurité et de renforcement pour les hôtes et les machines virtuelles. L'avantage principal de ces fonctionnalités est l'isolation logique d'une machine virtuelle et des ressources qui lui sont associées.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">La solution Red Hat OpenShift sur NetApp utilise deux switchs de données pour assurer la connectivité des données primaires à 25 Gbit/s. Il utilise également deux commutateurs de gestion supplémentaires qui fournissent une connectivité à 1 Gbit/s pour la gestion intrabande des nœuds de stockage et la gestion hors bande des fonctionnalités IPMI. OCP utilise le réseau logique de la machine virtuelle sur RHV pour la gestion des clusters. Cette section décrit l'organisation et l'objectif de chaque segment de réseau virtuel utilisé dans la solution et décrit les conditions préalables au déploiement de la solution.</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">Red Hat OpenShift sur RHV est conçu pour séparer logiquement le trafic réseau à différents fins à l'aide de réseaux locaux virtuels (VLAN). Cette configuration peut être adaptée aux besoins du client ou pour assurer une isolation supplémentaire pour des services réseau spécifiques. Le tableau suivant répertorie les VLAN nécessaires à la mise en œuvre de la solution lors de sa validation chez NetApp.</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">Gestion des nœuds RHV-H, RHV-Manager et du réseau d'administration serveur</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">Déployez OpenShift sur un cluster RHV d'au moins trois nœuds</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">L'architecture vérifiée décrite dans ce document présente le déploiement matériel minimum adapté aux opérations haute disponibilité en déployant deux nœuds d'hyperviseur RHV-H, et en assurant une configuration avec tolérance aux pannes dans laquelle les deux hôtes peuvent gérer le moteur hébergé et les VM déployés peuvent migrer entre les deux hyperviseurs.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Red Hat OpenShift se déployant initialement avec trois nœuds maîtres, il est garanti dans une configuration à deux nœuds qui occupera au moins deux maîtres, ce qui peut entraîner une interruption possible pour OpenShift si ce nœud spécifique devient indisponible. C'est donc une meilleure pratique de Red Hat qu'au moins trois nœuds d'hyperviseur RHV-H peuvent être déployés dans le cadre de la solution de façon à ce que les maîtres OpenShift puissent être distribués uniformément et que la solution bénéficie d'un degré de tolérance aux pannes supplémentaire.</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">Vous pouvez distribuer les maîtres OpenShift sur plusieurs nœuds d'hyperviseur en activant l'affinité VM/hôte.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">L'affinité est un moyen de définir des règles pour un ensemble de VM et/ou d'hôtes qui déterminent si les VM s'exécutent sur le même hôte ou sur des hôtes du groupe ou sur des hôtes différents. Elle est appliquée aux VM par la création de groupes d'affinités comprenant des VM et/ou des hôtes avec un ensemble de paramètres et de conditions identiques. Selon que les VM d'un groupe d'affinité s'exécutent sur le même hôte ou sur les hôtes du groupe ou séparément sur des hôtes différents, les paramètres du groupe d'affinités peuvent définir une affinité positive ou négative.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">Les conditions définies pour les paramètres peuvent être soit application stricte, soit application souple. Une mise en œuvre stricte permet de garantir que les VM d'un groupe d'affinité suivent toujours l'affinité positive ou négative strictement sans égard aux conditions externes. La mise en œuvre logicielle garantit qu'une préférence plus élevée est définie pour les VM d'un groupe d'affinité afin de suivre l'affinité positive ou négative lorsque cela est possible. Dans la configuration à deux ou trois hyperviseurs décrite dans ce document, soft affinité est le paramètre recommandé. Dans les clusters de plus grande taille, l'affinité matérielle peut distribuer correctement les nœuds OpenShift.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11. Documentation des groupes d'affinités</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">Pour configurer des groupes d'affinités, reportez-vous à la section<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI facilite le déploiement des clusters OpenShift via l'assistant interactif présenté plus haut dans ce document. Cependant, il est possible qu'il y ait des valeurs par défaut qui devront être modifiées dans le cadre du déploiement du cluster.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift installation d'un cluster sur RHV avec personnalisation</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">Dans ces instances, vous pouvez exécuter et tâches l'assistant sans déployer immédiatement un cluster. Au contraire, un fichier de configuration est créé à partir duquel le cluster peut être déployé ultérieurement. Cette fonction s'avère très utile pour modifier les valeurs par défaut des IPI ou pour déployer plusieurs clusters identiques dans votre environnement pour d'autres utilisations telles que la colocation. Pour plus d'informations sur la création d'une configuration d'installation personnalisée pour OpenShift, consultez<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="a003986254b5a6c136733113505348da" category="doc">Installation des presses à balles F5 BIG-IP Load Balancers</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP est un contrôleur de distribution d'applications (ADC) qui offre un large éventail de services avancés de gestion du trafic et de sécurité de niveau production, tels que L4-L7 d'équilibrage de charge, d'allègement de la charge SSL/TLS, de DNS, de pare-feu et bien d'autres. Ces services augmentent considérablement la disponibilité, la sécurité et les performances de vos applications.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP peut être déployé et utilisé de différentes façons, sur un matériel dédié, dans le cloud ou comme appliance virtuelle sur site. Reportez-vous à la documentation ici pour explorer et déployer F5 BIG-IP selon les besoins.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">Pour une intégration efficace des services F5 BIG-IP avec Red Hat OpenShift, F5 propose UN service CIS (BIG-IP Container Ingress Service). CIS est installé en tant que pod de contrôleur qui surveille l'API OpenShift pour certaines définitions de ressources personnalisées (CRD) et gère la configuration système F5 BIG-IP. F5 BIG-IP CIS peut être configuré pour contrôler les types de service LoadBalancers et les routes dans OpenShift.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">En outre, pour l'allocation automatique d'adresses IP pour le traitement du type LoadBalancer, vous pouvez utiliser le contrôleur F5 IPAM. Le contrôleur F5 IPAM est installé comme un pod de contrôleur qui surveille l'API OpenShift pour les services LoadBalancer avec une annotation ipamLabel afin d'allouer l'adresse IP à partir d'un pool préconfiguré.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">Cette page répertorie les instructions d'installation et de configuration pour F5 BIG-IP CIS et contrôleur IPAM. Un système F5 BIG-IP doit être déployé et sous licence. Il doit également être concédé sous licence pour les services SDN, qui sont inclus par défaut avec la licence de base BIG-IP VE.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP peut être déployé en mode autonome ou cluster. Aux fins de cette validation, F5 BIG-IP a été déployé en mode autonome, mais pour la production, il est préférable d'avoir un cluster de BIG-IP pour éviter un seul point de défaillance.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">Un système F5 BIG-IP peut être déployé sur un matériel dédié, dans le cloud ou en tant qu'appliance virtuelle sur site avec des versions supérieures à 12.x pour une intégration avec F5 CIS. Dans le cadre de ce document, le système F5 BIG-IP a été validé en tant qu'appliance virtuelle, par exemple en utilisant L'édition BIG-IP VE.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">Versions validées</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">Version logicielle</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE EDITION</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">Service F5 d'entrée de conteneur</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">Contrôleur F5 IPAM</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">AS3 F5</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">Installation</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">Référentiel GitHub F5 AS3</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">Installez l'extension F5 application Services 3 pour permettre aux systèmes BIG-IP d'accepter les configurations au format JSON au lieu de commandes impérative. Accédez à<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>Et téléchargez le dernier fichier RPM.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">Connectez-vous au système F5 BIG-IP, accédez à iApps &gt; Package Management LX et cliquez sur Importer.</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">Cliquez sur choisir un fichier et sélectionnez le fichier RPM AS3 téléchargé, cliquez sur OK, puis cliquez sur Télécharger.</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">Téléchargement iApps</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">Vérifiez que l'extension AS3 est correctement installée.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">Validation de l'installation AS3</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">Configurez ensuite les ressources requises pour la communication entre les systèmes OpenShift et BIG-IP. Commencez par créer un tunnel entre OpenShift et LE serveur BIG-IP en créant une interface de tunnel VXLAN sur le système BIG-IP pour OpenShift SDN. Naviguez jusqu'à réseau &gt; tunnels &gt; profils, cliquez sur Créer, puis définissez le profil parent sur vxlan et le type d'inondation sur Multicast. Entrez un nom pour le profil et cliquez sur terminé.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">Créer un profil VXLAN</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">Naviguez jusqu'à réseau &gt; tunnels &gt; liste de tunnels, cliquez sur Créer, puis entrez le nom et l'adresse IP locale du tunnel. Sélectionnez le profil de tunnel créé à l'étape précédente et cliquez sur terminé.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">Créer un tunnel VXLAN</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">Connectez-vous au cluster Red Hat OpenShift avec les privilèges cluster-admin.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">Créez un sous-réseau d'hôtes sur OpenShift pour le serveur F5 BIG-IP, qui étend le sous-réseau du cluster OpenShift au serveur F5 BIG-IP. Téléchargez la définition YAML du sous-réseau hôte.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">Modifiez le fichier de sous-réseau de l'hôte et ajoutez l'IP VTEP (VXLAN tunnel) BIG-IP pour le SDN OpenShift.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">Modifiez l'adresse IP de l'hôte et d'autres détails applicables à votre environnement.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">Créez la ressource HostSubnet.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">Obtenez la plage de sous-réseau IP du cluster pour le sous-réseau hôte créé pour le serveur F5 BIG-IP.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">Créez un auto-IP sur OpenShift VXLAN avec un IP dans la plage de sous-réseau hôte d'OpenShift correspondant au serveur F5 BIG-IP. Connectez-vous au système F5 BIG-IP, accédez à réseau &gt; Auto-IP et cliquez sur Créer. Entrez une adresse IP à partir du sous-réseau IP du cluster créé pour le sous-réseau hôte F5 BIG-IP, sélectionnez le tunnel VXLAN et entrez les autres détails. Cliquez ensuite sur terminé.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">Créer auto-IP pour VXLAN</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">Créez une partition dans le système F5 BIG-IP à configurer et à utiliser avec CIS. Accédez à système &gt; utilisateurs &gt; liste de partitions, cliquez sur Créer et entrez les détails. Cliquez ensuite sur terminé.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">Créer une partition BIG-IP</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5 recommande de ne pas effectuer de configuration manuelle sur la partition gérée par CIS.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">Installez F5 BIG-IP CIS à l'aide de l'opérateur depuis OperatorHub. Connectez-vous au cluster Red Hat OpenShift avec des privilèges cluster-admin et créez un secret avec les identifiants de connexion du système F5 BIG-IP. Il est indispensable pour l'opérateur.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">Installez les CRD F5 CIS.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Accédez à Operators &gt; OperatorHub, recherchez le mot-clé F5, puis cliquez sur la mosaïque F5 Container Ingress Service.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">F5 CIS dans OperatorHub</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">Lisez les informations de l'opérateur et cliquez sur installer.</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">F5 CIS Info dans OperatorHub</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Sur l'écran de l'opérateur d'installation, conservez tous les paramètres par défaut, puis cliquez sur installer.</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">Installer l'opérateur F5 CIS</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">L'installation de l'opérateur prend un certain temps.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS - progression de l'installation de l'opérateur</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">Une fois l'opérateur installé, le message installation réussie s'affiche.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Accédez à opérateurs &gt; opérateurs installés, cliquez sur F5 Container Ingress Service, puis cliquez sur Créer une instance sous la mosaïque F5BigIpCtlr.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">Créez F5BigIpCtlr</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">Cliquez sur vue YAML et collez le contenu suivant après la mise à jour des paramètres nécessaires.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">Mettre à jour les paramètres<block ref="9117e80b6a6843f23b631387abeed925" prefix=" " category="inline-code"></block>, ` openshift_sdn_name`,<block ref="957c32cdfcd5fb9c99f7a4e3311e7768" prefix=" " category="inline-code"></block> et<block ref="1155b6812ea5125b3144173aaaad6205" prefix=" " category="inline-code"></block> ci-dessous pour refléter les valeurs de votre configuration avant de copier le contenu.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">Après avoir collé ce contenu, cliquez sur Créer. Cela installe les modules CIS dans l'espace de noms du système kube.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">Valider les modules CIS F5</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">Par défaut, Red Hat OpenShift permet d'exposer les services via des routes pour l'équilibrage de charge L7. Un routeur OpenShift intégré est chargé de la publicité et du traitement du trafic pour ces routes. Cependant, vous pouvez également configurer F5 CIS pour prendre en charge les routes via un système F5 BIG-IP externe, qui peut s'exécuter soit en tant que routeur auxiliaire, soit en remplacement du routeur OpenShift auto-hébergé. CIS crée un serveur virtuel dans le système BIG-IP qui sert de routeur pour les routes OpenShift, et BIG-IP gère la publicité et le routage du trafic. Pour plus d'informations sur les paramètres permettant d'activer cette fonctionnalité, reportez-vous à la documentation ci-dessous. Notez que ces paramètres sont définis pour la ressource OpenShift Deployment dans l'API apps/v1. Par conséquent, lors de l'utilisation de ces traits avec l'API F5BigIpCtlr ressource cis.f5.com/v1, remplacer les traits d'Union (-) par des traits de soulignement (_) pour les noms de paramètres.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">Les arguments qui sont transmis à la création de ressources CIS sont notamment<block ref="49dcf57b3a065d02c9969c595e32ea50" prefix=" " category="inline-code"></block> et<block ref="5d0d2663dc7f08b0183abaddf17f8307" prefix=" " category="inline-code"></block>. Ces paramètres sont nécessaires pour activer l'intégration CIS avec un contrôleur IPAM. Vérifiez que le CIS a activé l'intégration IPAM en créant la ressource IP F5.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">Créez le compte de service, le rôle et la liaison en liaison rolerequises pour le contrôleur F5 IPAM. Créez un fichier YAML et collez le contenu suivant.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">Créez les ressources.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">Créez un fichier YAML et collez la définition de déploiement IPAM F5 indiquée ci-dessous.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">Mettez à jour le paramètre de plage ip dans spec.template.spec.containers[0].args ci-dessous pour refléter les plages d'adresses IP et ipamLabels correspondant à votre configuration.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IpamLabels <block ref="4795fc86aa645b109548974bcffefe07" prefix="[" category="inline-code"></block> et<block ref="0ce75607b46ab2a9cc08eab9ade2a24d" prefix=" " category="inline-code"></block> Dans l'exemple ci-dessous] sont nécessaires pour être annotés pour les services de type LoadBalancer pour le contrôleur IPAM afin de détecter et d'affecter une adresse IP à partir de la plage définie.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">Créer le déploiement du contrôleur F5 IPAM.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">Vérifiez que les modules de contrôleur F5 IPAM sont en cours d'exécution.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">Créez le schéma F5 IPAM.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">Vérification</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">Créez un service de type LoadBalancer</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">Vérifiez si le contrôleur IPAM lui attribue une adresse IP externe.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">Créez un déploiement et utilisez le service LoadBalancer qui a été créé.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Vérifiez que les modules sont en cours d'exécution.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">Vérifiez si le serveur virtuel correspondant est créé dans LE système BIG-IP pour le service de type LoadBalancer dans OpenShift. Accédez à trafic local &gt; serveurs virtuels &gt; liste de serveurs virtuels.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">Validez la création de serveurs virtuels BIG-IP pour le type de service correspondant LoadBalancer</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données intégrant la cohérence applicative pour les workloads Kubernetes avec état, déployés dans un environnement sur site avec la technologie NetApp de protection des données éprouvée.</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="doc">Protection intégrée avec les pipelines ci/CD et NetApp Astra Control</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">L'une des utilisations les plus courantes des workflows DevOps est l'intégration continue et les pipelines de déploiement continu qui créent, intègrent et exécutent des suites de tests automatisés sur des applications lors de l'exécution du nouveau code par les développeurs. Les ingénieurs DevOps et les ingénieurs de fiabilité des sites (SRE) ont généralement mis en œuvre des pipelines dédiés au développement de nouvelles fonctionnalités, aux tests de régression, aux correctifs, à l'ingénierie de la qualité et à d'autres fonctions dans le processus de développement.</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">À mesure que les équipes augmentent leur niveau d'automatisation, le rythme des changements dans les applications de production peut sembler compliqué. Par conséquent, certaines équipes préfèrent protéger les applications ou les services de production. Outre la protection des images du code et du conteneur, ils souhaitent également protéger l'état de l'application, les données de configuration (objets Kubernetes et ressources associées à l'application, par exemple) et les données persistantes d'une application.</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">Dans ce cas d'utilisation, nous examinons de plus près un pipeline de promotion en production qui déploie une nouvelle version d'une application : d'abord dans un environnement intermédiaire, puis dans un environnement de production. Cet exemple s'applique aussi bien aux principaux clouds publics que à un environnement sur site. Bien que nous montrons le déploiement d'une version de l'app, le pipeline peut également être utilisé avec d'autres stratégies, telles que le déploiement bleu/vert ou canari. Dans le cadre du pipeline ci/CD, nous allons protéger l'application en créant une sauvegarde complète de l'application. De nombreux workflows DevOps peuvent être utiles pour une sauvegarde de l'application en production intégrant la cohérence applicative, ainsi que ses données, son état et sa configuration.</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">L'architecture DevOps avec NetApp Astra : utilisation 1</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">Magento</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">Kit de développement logiciel NetApp Astra Control Python</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">Jenkins</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">L'application utilisée pour valider ce cas d'utilisation était<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>, Une solution de commerce électronique avec un front-end basé sur le Web, une instance Elasticsearch pour des fonctions de recherche et d'analyse et une base de données MariaDB qui suit tous les détails de l'inventaire des achats et des transactions. Cette application conteneurisée a été installée sur un cluster Red Hat OpenShift. Chaque pod de l'application utilisait des volumes persistants pour stocker les données. Les volumes persistants ont été automatiquement créés par NetApp Astra Trident, l'orchestrateur de stockage conforme à l'interface de conteneur pour Kubernetes, qui permet de provisionner le stockage sur des systèmes de stockage NetApp. En outre, avec les fonctionnalités de protection des applications d'Astra Control Center, l'application en question a été gérée par Astra Control, qui a ensuite été utilisée pour déclencher les sauvegardes d'application qui stockaient l'état de l'application ainsi que les données stockées dans des volumes persistants. Nous avons utilisé<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> Automatiser le processus de déclenchement des sauvegardes d'applications ; celles-ci ont ensuite été intégrées ou CD dans un pipeline. Ce pipeline a été créé et exécuté à l'aide d'un outil ci/CD appelé <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>] automatiser le flux pour créer, protéger et déployer l'application.</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">Passons en revue les conditions préalables et la procédure pour introduire la protection dans un pipeline ci/CD.</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">Conditions préalables à la validation du cas d'utilisation</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">Les outils ou plates-formes suivants ont été déployés et configurés comme conditions préalables :</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="list-text">Plateforme de conteneurs Red Hat OpenShift</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">NetApp Astra Trident a été installé sur OpenShift avec un système back-end configuré pour le système NetApp ONTAP</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">Configuration par défaut de storageclass pointant sur un back-end NetApp ONTAP</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">NetApp Astra Control Center installé sur un cluster OpenShift</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">Cluster OpenShift ajouté en tant que cluster géré à Astra Control Center</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins a installé sur un cluster OpenShift et configuré avec un nœud agent sur lequel un moteur Docker est installé</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">Installation de l'application</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">Commençons par l'installation initiale de l'application dans les environnements de stockage et de production. Pour les besoins de ce cas d'utilisation, cette étape est un prérequis, cette opération est effectuée manuellement. Le pipeline ci/CD est utilisé pour les workflows de création et de déploiement ultérieurs suite à la sortie de nouvelle version de l'application.</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">Dans ce cas d'utilisation, l'environnement de production est un espace de nom appelé<block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix=" " category="inline-code"></block>, et l'environnement de staging correspondant est un espace de noms appelé<block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix=" " category="inline-code"></block> Configuré sur le cluster Red Hat OpenShift. Pour passer à l'application, procédez comme suit :</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">Installez l'application Magento à l'aide du graphique de bitnami Helm sur l'environnement de production. Nous utilisons RWX PVS pour les pods Magento et MariaDB.</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Le diagramme de gouvernail Magento bitnami nécessite un service LoadBalancer pour exposer le service GUI de Magento. Nous avons utilisé <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> dans cet exemple, vous pouvez fournir un service d'équilibrage de charge sur site.</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">Après quelques minutes, vérifiez que tous les pods et services sont en cours d'exécution.</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">Répétez la même procédure pour l'environnement de staging.</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Gérer l'application Magento dans Astra Control Center</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">Accédez à applications et sélectionnez l'onglet applications découvertes.</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">Cliquez sur les points de suspension par rapport à l'application Magento dans l'environnement de production <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>), puis cliquez sur gérer.</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">L'application Magento est désormais gérée par Astra Control Center. Toutes les opérations prises en charge par Astra Control peuvent être exécutées sur l'application. Notez également la version de l'application.</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">Vérification de la version Magento avant la mise à niveau</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">Répétez les étapes de gestion de l'application Magento dans l'environnement de staging <block ref="b6e78b61f8d1e4d47cc09b947a8d4fb2" prefix="(" category="inline-code"></block>).</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">Pipeline ci/CD avec protection intégrée</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">Lorsque nous utilisons de nouvelles versions d'applications, nous utilisons un pipeline ci/CD pour créer l'image de conteneur, sauvegarder les environnements de stockage intermédiaire et de production, déployer la nouvelle version de l'application dans l'environnement intermédiaire, attendre l'approbation pour la promotion de la production, puis déployez la nouvelle version de l'application dans l'environnement de production. Pour utiliser un pipeline ci/CD, procédez comme suit :</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Connectez-vous à Jenkins et créez les informations d'identification requises : un pour les crds Magento, un pour les crds d'administration MariaDB, et le troisième pour les crds racine MariaDB.</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Accédez à Manage Jenkins &gt; Manage Credentials et cliquez sur le domaine approprié.</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">Cliquez sur Ajouter des informations d'identification et définissez le type sur Nom d'utilisateur avec le mot de passe et la portée définis sur Global. Entrez le nom d'utilisateur, le mot de passe et un ID pour les informations d'identification, puis cliquez sur OK.</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">Créer des informations d'identification</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">Répétez la même procédure pour les deux autres identifiants.</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">Retournez au tableau de bord, créez un pipeline en cliquant sur nouvel élément, puis cliquez sur Pipeline.</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Copiez le pipeline à partir du fichier Jenkinsfile<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>.</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">Collez le pipeline dans la section Jenkins Pipeline, puis cliquez sur Save.</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Remplissez les paramètres du pipeline Jenkins avec les détails respectifs, y compris la version du graphique Helm, la version de l'application Magento à mettre à niveau, la version de la boîte à outils Astra, le FQDN Astra Control Center, le jeton API et son ID d'instance. Spécifiez le registre docker, l'espace de noms et l'adresse IP Magento des environnements de production et de staging, ainsi que les ID d'identification des informations d'identification créées.</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">Cliquez sur Créer maintenant. Le pipeline commence à exécuter et progresse à travers les étapes. L'image de l'application est d'abord créée et téléchargée dans le registre du conteneur.</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">Progression du pipeline</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">Les sauvegardes d'applications sont lancées par Astra Control.</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">Sauvegarde initiée</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">Une fois les étapes de sauvegarde terminées, vérifiez les sauvegardes à partir du centre de contrôle Astra.</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">Sauvegarde réussie</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">La nouvelle version de l'application est ensuite déployée dans l'environnement temporaire.</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">Déploiement de la phase intermédiaire initié</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">Une fois cette étape terminée, le programme attend que l'utilisateur approuve le déploiement en production. À ce stade, supposons que l'équipe QA effectue des tests manuels et approuve la production. Vous pouvez ensuite cliquer sur approuver pour déployer la nouvelle version de l'application dans l'environnement de production.</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">En attente de promotion</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">Vérifiez que l'application de production est également mise à niveau vers la version souhaitée.</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">Application Prod mise à niveau</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">Dans le cadre du pipeline ci/CD, nous avons démontré la capacité à protéger l'application par la création d'une sauvegarde complète intégrant la cohérence applicative. Dans la mesure où l'application complète a été sauvegardée dans le cadre du pipeline de promotion à production, vous êtes davantage confiant en matière de déploiements d'applications hautement automatisés. Cette sauvegarde respectueuse des applications, incluant les données, l'état et la configuration de l'application, peut s'avérer utile pour de nombreux workflows DevOps. Un workflow important serait de revenir à la version précédente de l'application en cas de problèmes imprévus.</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Bien que nous ayons démontré un workflow ci/CD avec l'outil Jenkins, le concept peut être extrapolé facilement et efficacement à différents outils et stratégies. Pour voir ce cas d'utilisation en action, regardez la vidéo <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>.</block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">Suivant : vidéos et démonstrations - le DevOps avec NetApp Astra.</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">Déploiement rapide de la technologie FlexClone</block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">Accélération du développement logiciel avec la technologie NetApp FlexClone</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">Le clonage d'une application déployée dans un cluster Kubernetes est un outil très utile pour les développeurs qui souhaitent accélérer leurs workflows en partageant des environnements avec des partenaires ou en testant de nouvelles versions de code dans un environnement de développement sans interférer avec la version sur laquelle ils travaillent actuellement. Le clonage avec état et cohérence applicative d'une application Kubernetes est une fonctionnalité majeure incluse avec NetApp Astra Control, ainsi que la sauvegarde et la restauration des applications. Par ailleurs, si une application est clonée dans le même cluster Kubernetes avec le même système back-end de stockage, Astra Control utilise par défaut la technologie NetApp FlexClone pour la duplication des volumes de données persistants, accélérant ainsi le processus de façon significative. En accélérant ce processus, l'environnement cloné est provisionné et peut être utilisé en quelques instants. Les développeurs peuvent ainsi reprendre leur travail avec une courte pause lorsque l'on compare le redéploiement de leur environnement de test et de développement. Pour plus de commodité, vous pouvez appeler toutes les fonctions de NetApp Astra Control avec une API, qui facilite l'intégration dans les frameworks d'automatisation comme Ansible. Ainsi, les environnements peuvent être échelonnés encore plus rapidement, car seules des modifications mineures sont nécessaires dans un manuel de vente ou un rôle pour lancer la procédure de clonage.</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">Qu'est-ce que la technologie NetApp FlexClone ?</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">La technologie NetApp FlexClone est une copie Snapshot inscriptible instantanée à partir d'un environnement NetApp FlexVol. Elles sont provisionnées presque instantanément, contiennent toutes les données du volume source et ne consomment aucun espace de stockage supplémentaire tant que les données du nouveau volume ne sont pas nouvelles de la source. Elles sont souvent utilisées dans des environnements de développement ou basés sur des modèles lorsque plusieurs copies de données sont utiles pour la mise en scène ; les systèmes de stockage disposent de ressources limitées pour le provisionnement de ces volumes. Par rapport à un système de stockage traditionnel dans lequel les données doivent être copiées plusieurs fois plus vite et consommation d'espace de stockage important, la technologie NetApp FlexClone accélère les tâches dépendantes du stockage.</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">Image FlexClone</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documents NetApp</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">Pour en savoir plus sur la technologie NetApp FlexClone, consultez la page<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>.</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Une distribution Kubernetes prise en charge, telle que Red Hat OpenShift 4.6.8+, Rancher 2.5+ ou Kubernetes 1.19+.</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra Control Center, 21.12+.</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">Un système NetApp ONTAP avec un système back-end de stockage configuré via NetApp Astra Trident.</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9+.</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">Des modèles pour les environnements que vous souhaitez cloner en tant qu'applications gérées dans NetApp Astra Control.</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">Introduction au cas d'utilisation</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">Pour cette utilisation, nous visualisons un environnement similaire à celui-ci :</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">Image de workflow</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">Un utilisateur exécute ce manuel de vente ansible pour créer un nouvel environnement intermédiaire.</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible utilise le module URI-API pour appeler Astra Control afin d'exécuter l'opération de clonage.</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control exécute une opération de clonage sur un environnement modèle préprovisionné, créant ainsi une nouvelle application gérée.</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">Cet environnement peut être une seule application autonome en cours de développement ou dans l'ensemble d'un environnement de développement comme un pipeline ci/CD Jenkins.</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">L'utilisateur extrait ensuite une version de son code dans l'environnement de développement cloné à partir d'un référentiel en ligne tel que Gitea.</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">La nouvelle version de l'application est déployée et gérée par NetApp Astra Control.</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">Ces deux processus peuvent être automatisés.</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">L'utilisateur peut développer un nouveau code dans cet environnement cloné.</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">Lorsque l'utilisateur est satisfait de ses efforts de développement, il peut renvoyer le code vers le référentiel hébergé.</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">L'utilisation présentée ici dépend de l'existence de modèles optimisés pour les environnements ou les applications que vous souhaitez cloner. Dans notre environnement, nous avons créé trois de ces modèles, un pour un déploiement Wordpress, un pour un déploiement Magento, et un pour un environnement ci/CD Jenkins avec Gitea que nous avons intitulé DevTools.</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">Image des modèles</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">Chacun de ces environnements est géré par le contrôle NetApp Astra, avec des volumes persistants stockés sur un système de stockage NetApp ONTAP avec un back-end NFS fourni par NetApp Astra Trident.</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">Validation du cas d'utilisation</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">Clonez le kit ansible fourni par l'équipe NetApp Solutions Engineering, qui comprend le rôle de clonage et le PlayBook de mise à jour des applications.</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">Modifier<block ref="c4fe4210b1a8cc125caf1d344db07732" prefix=" " category="inline-code"></block> Et apportez les valeurs globales adaptées à votre environnement Astra Control.</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">Les valeurs globales d'environnement à remplir sont disponibles sous l'icône de profil utilisateur de NetApp Astra Control, sous le menu d'accès à l'API.</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">Image accès API</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">Lorsque les variables globales sont terminées, vous pouvez choisir les valeurs de l'application spécifique que vous souhaitez cloner. Pour cloner l'environnement devTools vers un environnement personnel appelé<block ref="2ab4557e919d8388e34d63b073eb0704" prefix=" " category="inline-code"></block>, procédez comme suit :</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">Pour tirer parti de la technologie NetApp FlexClone dans le processus de clonage,<block ref="4235aba0b7240b55d6c0b4e16f2b0c9a" prefix=" " category="inline-code"></block> et<block ref="57d3fb1ffc6c61e8386a14142cad2cfe" prefix=" " category="inline-code"></block> doit être identique.</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">Vous pouvez désormais exécuter le manuel de vente pour cloner l'application.</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">Le manuel tel qu'écrit doit être exécuté par l'utilisateur root ou par une personne pouvant faire remonter à travers le processus sudo en passant l'argument « -K ».</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">Lorsque le manuel de vente termine son exécution, l'application clonée apparaît comme disponible dans la console Astra Control Center.</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">Image d'application clonée</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">Un utilisateur peut ensuite se connecter à l'environnement Kubernetes où l'application a été déployée, vérifier que l'application est exposée avec une nouvelle adresse IP, et lancer son travail de développement.</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">Pour une démonstration de ce cas d'utilisation et un exemple de mise à niveau d'une application, voir <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>.</block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">Clonez l'application d'analyse post-mortem et restaurez votre application dans un pipeline ci/CD avec Astra Control Center</block>
  <block id="8b682694b3e16be71600ae19c5a6e2fe" category="doc">Utilisez NetApp Astra Control pour réaliser une analyse post-mortem et restaurer votre application</block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">Ensuite, découvrez NetApp Astra, le DevOps et NetApp.</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">Présentation du devops et des cas d'utilisation potentiels dans ce rapport technique.</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">Présentation du DevOps</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">Au cours des dernières années, les entreprises qui créent des logiciels adoptent les concepts du DevOps. Les pratiques DevOps éliminent les obstacles organisationnels en rapprochant les équipes de développement et opérationnelles. Les pratiques DevOps permettent également aux équipes d'accélérer la livraison, d'accroître la disponibilité et de renforcer la stabilité des services et des applications, ce qui améliore la productivité de l'équipe. En outre, l'adoption d'une structure d'automatisation constitue également un élément clé de la réussite : création, test et applications d'exploitation à grande échelle ou gestion d'une plateforme ou d'une pile d'infrastructure entièrement automatisée. Vous trouverez ci-dessous quelques exemples d'utilisation principaux du DevOps dans lesquels les solutions NetApp peuvent être mises en œuvre pour améliorer les expériences des professionnels DevOps dans leurs pratiques quotidiennes.</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">Cas d'utilisation de DevOps</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">Bien que le DevOps ne soit pas défini de manière universelle, les solutions pour les praticiens DevOps contiennent généralement des constructions ou des idéologies similaires qui permettent une mise en œuvre, des répétitions et une gestion à grande échelle. Les sections suivantes décrivent les cas d'utilisation potentiels des workflows DevOps de solutions NetApp.</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">Intégration continue, livraison continue et déploiement continu (ci/CD)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">L'intégration continue, la livraison continue et le déploiement continu (ci/CD) est une approche de codage qui encourage les développeurs à mettre en œuvre et à transformer leurs pratiques de codage en établissant une méthode qui leur permet de mettre à jour, de tester et de déployer le code de manière automatisée. La méthode la plus courante par laquelle l'intégration et la livraison continues sont implémentées dans la plupart des workflows DevOps est celle du pipeline ci/CD et plusieurs applications logicielles tierces peuvent aider à atteindre cet objectif.</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">Image ci/CD</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">Pour en savoir plus sur les workflows de type ci/CD, consultez les exemples d'applications classiques suivants :</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ArgoCD</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">Tekton</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">Certains des cas d'utilisation mentionnés plus loin dans ce rapport technique ont été démontrés dans Jenkins, mais les principes directeurs de l'IC/CD peuvent être appliqués à tous les outils qu'une entreprise a mis en œuvre dans ses propres pratiques.</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">Infrastructure-as-code</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">L'infrastructure-as-code permet de provisionner et de gérer les ressources IT via des commandes, des API et des kits de développement logiciel (SDK) automatisés. Ce concept améliore considérablement l'expérience DevOps en supprimant les limitations de ressources ou de data Center physiques susceptibles d'empêcher les développeurs d'atteindre leurs objectifs.</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">Image Infrastructure-as-Code</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">Python</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">Puppet</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">Les utilisateurs finaux utilisent souvent des langages de programmation tels que<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> ou des outils d'automatisation tels que<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> ou<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> pour créer des actions automatisées et reproductibles d'évolutivité de l'infrastructure qui peuvent être appelées par les développeurs lorsque cela s'avère nécessaire.</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">NetApp ONTAP et Astra Control contiennent des API publiques, des modules ansible ou des kits de développement logiciel qui facilitent l'automatisation des opérations et leur intégration dans les processus DevOps.</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">Suivant : présentation des systèmes de stockage NetApp.</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp propose plusieurs plateformes de stockage homologuées avec Astra Trident et Astra Control pour provisionner, protéger et gérer les données des applications conteneurisées, ce qui facilite la définition et l'optimisation du débit DevOps.</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">Présentation des systèmes de stockage NetApp</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">Ensuite, présentation des intégrations du stockage NetApp.</block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">Dans ce rapport technique, nous décrivons comment NetApp rend les cas d'utilisation du DevOps simples et efficaces sur plusieurs fronts, lors de l'utilisation d'applications conteneurisées. Il commence par détailler les systèmes de stockage NetApp et leur intégration avec les plateformes Kubernetes en utilisant la gamme Astra. Enfin, un certain nombre de validations de solutions et d'utilisations réelles sont explorées et documentées.</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">Tr-4919 : le DevOps avec NetApp Astra</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">L'architecture du DevOps avec NetApp Astra vise à offrir un niveau de valeur exceptionnel à ses clients dans plusieurs cas :</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">Déployez et gérez facilement des applications et des environnements de développement déployés sur les distributions Kubernetes prises en charge.</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">Discussion sur des cas d'utilisation réels pour les workflows DevOps et exemples d'outils et de méthodes que NetApp peut proposer pour faciliter l'adoption et l'utilisation de ces méthodes.</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">Exploration de la façon dont les snapshots, les sauvegardes et les clones cohérents au niveau des applications peuvent être utilisés pour améliorer l'expérience DevOps.</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">Valeur commerciale</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">La haute disponibilité à tous les niveaux de la pile afin que les flux de travail ne soient jamais interrompus.</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">La facilité de déploiement et de gestion des procédures pour l'utilisateur final.</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">Une infrastructure programmable et basée sur des API pour suivre le rythme des microservices et de l'agilité pour les développeurs.</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">Possibilité de faire évoluer l'infrastructure de manière indépendante et automatisée en fonction des besoins des workloads</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">Outre la protection des applications parallèlement à leurs datasets persistants de sauvegarde pour les workflows DevOps, les délais de mise sur le marché sont réduits, car la priorité n'est pas donnée à la redéploiement ou à la copie manuelle des données.</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">Compte tenu de ces fonctionnalités et de ces défis, ce rapport technique décrit le processus d'amélioration et de simplification des cas d'utilisation du DevOps pour les applications conteneurisées à l'aide du vaste portefeuille de produits NetApp.</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">La solution DevOps avec NetApp comprend plusieurs composants principaux :</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">Pratiques DevOps</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">Les pratiques DevOps se concentrent sur des opérations automatisées, reproductibles et facilement gérables qui améliorent le workflow de développement en permettant aux utilisateurs de contrôler l'environnement dans lequel ils développent leur code. Cette solution offre plusieurs exemples et cas d'utilisation pour lesquels la technologie NetApp peut bénéficier de ce type d'opérations.</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="section-title">Orchestration de conteneurs</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">De nombreuses plateformes d'orchestration de conteneurs sont actuellement utilisées. Bien que la plupart de ces plateformes reposent sur Kubernetes, les avantages et les inconvénients des deux plateformes sont chacun. Il est donc important de comprendre les ensembles de fonctionnalités et les intégrations lors de la sélection d'une plateforme d'orchestration de conteneurs pour les workflows DevOps. Avec la suite de produits NetApp Astra, nous prenons en charge les plateformes suivantes pour des cas d'utilisation complets du DevOps :</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8+</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">Rancher</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5+</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20+</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">VMware Tanzu Kubernetes Grid</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4+</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2+</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">Systèmes de stockage NetApp</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">Intégrations du stockage NetApp</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">Présentation du DevOps.</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">Présentation de NetApp Astra Control</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Pour obtenir un guide d'installation et d'exploitation détaillé sur le centre de contrôle Astra, suivez la documentation <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Automatisation du centre de contrôle Astra</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Center est doté d'une API REST entièrement fonctionnelle pour l'accès par programmation. Les utilisateurs peuvent utiliser n'importe quel langage ou utilitaire de programmation pour interagir avec les terminaux API REST Astra Control. Pour plus d'informations sur cette API, reportez-vous à la documentation <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>.</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">Si vous recherchez un kit de développement logiciel prêt à l'emploi pour interagir avec les API REST Astra Control, NetApp propose un kit avec le kit SDK Python Astra Control que vous pouvez télécharger <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">Si la programmation n'est pas propriétaire de votre situation et si vous souhaitez utiliser un outil de gestion de la configuration, vous pouvez cloner et exécuter les playbooks Ansible publiés par NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">Next : validations de cas d'utilisation : le DevOps avec NetApp Astra</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp propose plusieurs produits qui aident nos clients à orchestrer et à gérer les données persistantes dans des environnements basés sur des conteneurs.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">Présentation de l'intégration du stockage NetApp</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">Next : validations de cas d'utilisation : le DevOps avec NetApp Astra.</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Protection des données dans le pipeline ci/CD avec Astra Control Center</block>
  <block id="1c333560e2edbd1cefb05f127658b17f" category="doc">Protection des données dans le pipeline ci/CD avec Astra Control Center</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">Vidéos et démonstrations : le DevOps avec NetApp Astra</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">Les vidéos suivantes présentent certaines des fonctionnalités décrites dans ce document :</block>
  <block id="47a3fe612643a48831699e345fc50086" category="inline-link-macro">Vidéo : intégrez la protection des données dans le pipeline ci/CD avec Astra Control</block>
  <block id="b137de00495bfd71913e4fe2ecc2fbb5" category="list-text"><block ref="b137de00495bfd71913e4fe2ecc2fbb5" category="inline-link-macro-rx"></block></block>
  <block id="11a855b91bda336c24ae0014cf0b01aa" category="list-text"><block ref="11a855b91bda336c24ae0014cf0b01aa" category="inline-link-macro-rx"></block></block>
  <block id="760ebcab0161b35f2cbcee21a65a788a" category="list-text"><block ref="760ebcab0161b35f2cbcee21a65a788a" category="inline-link-macro-rx"></block></block>
  <block id="a7f77f303480f7b7143a247c228eaebb" category="doc">Accélérez le développement logiciel avec Astra Control et la technologie NetApp FlexClone</block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">Utilisez Astra Control pour faciliter l'analyse post-mortem et restaurer l'application</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">première utilisation</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">Dans le <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>, Nous avons démontré comment utiliser NetApp Astra Control Center pour protéger vos applications dans Kubernetes. Cette section décrit comment intégrer les sauvegardes d'applications via Astra Control directement dans votre workflow de développement à l'aide du kit de développement Python du kit NetApp Astra. Cette approche permet de protéger les environnements de développement et de production en automatisant les sauvegardes à la demande lors du processus d'intégration et de déploiement continus (ci/CD). Avec cette couche supplémentaire de protection des données cohérente au niveau des applications ajoutée au pipeline ci/CD et aux applications de production, les processus de développement sont en sécurité en cas de problème, ce qui favorise la continuité de l'activité.</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">Dans un workflow classique, après avoir rencontré un échec lors de la mise à niveau de l'application vers une nouvelle version, l'équipe de développement tenterait de résoudre le problème en temps réel en fonction des rapports de bogues fournis par les clients. Au premier signe de problème, l'équipe pourrait également tenter de redéployer l'application vers un environnement de débogage parallèle pour mettre ce processus hors ligne. Ils pouvaient redéployer une ancienne base de codes depuis une version précédente vers la production, afin de restaurer l'application en bon état de fonctionnement.</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">Workflow classique</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">Bien que cette approche fonctionne, l'équipe doit s'assurer que l'état de l'application de production défaillante correspond à celui de la version utilisée en production lorsque le problème survient. Il leur faudrait également consacrer du temps à promouvoir la version fiable en production en récupérant du code de leur référentiel et en redéployant les images de la machine pour restaurer l'application à un état de fonctionnement correct. De plus, dans ce scénario, nous ne voulions pas si la base de données de production elle-même était corrompue par le code défectueux. Idéalement, il existe des processus de sauvegarde distincts pour les données de la base de données, mais devons-nous supposer qu’ils sont cohérents avec l’état de l’application tel qu’il a été publié ? C'est là que les avantages offerts par Astra Control, notamment en matière de sauvegardes, de restaurations et de clones avec état et cohérents au niveau des applications, montrent véritablement leur valeur.</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">Nous pouvons tout d'abord utiliser Astra Control pour faciliter l'analyse post-mortem de l'état de l'application. Pour ce faire, nous clonons la version de production buggy vers un environnement de test parallèle de façon cohérente avec l'application. Cet environnement étant mis de côté, nous pouvons résoudre le problème en temps réel.</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">De plus, Astra Control prend en charge la fonctionnalité de restauration sur place qui nous permet de restaurer l'application de production vers une dernière sauvegarde acceptable (qui a précédé la version de code affligée). La version restaurée suppose la position de l'application de production buggy précédente, de façon cohérente avec les applications et avec état, y compris l'IP d'entrée précédemment attribuée. Par conséquent, les clients qui accèdent à l'environnement frontal ne connaissent pas la transition vers la version de sauvegarde.</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">Flux de travail post-mortem</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Plateforme de conteneurs Red Hat OpenShift.</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp Astra Trident installé sur OpenShift avec un système back-end configuré sur un système NetApp ONTAP.</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">Configuration par défaut de storageclass pointant sur un back-end NetApp ONTAP.</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">NetApp Astra Control Center installé sur un cluster OpenShift.</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">Cluster OpenShift ajouté en tant que cluster géré à Astra Control Center.</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins installé sur un cluster OpenShift.</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">Application Magento installée dans l'environnement de production. Dans ce cas d'utilisation, l'environnement de production est un espace de nom appelé « agento-prod » dans un cluster Red Hat OpenShift.</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">Application de production gérée par Astra Control Center.</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Sauvegarde(s) fiable(s) de l'application de production capturée avec Astra Control.</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">Cloner et restaurer le pipeline</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">Compte tenu du fait que l'application a été mise à niveau vers une nouvelle version, l'application dans l'environnement de production <block ref="5c755bccc6412e6f8ba1155b31007bd1" prefix="(" category="inline-code"></block>) ne se comporte pas comme prévu après la mise à niveau. Supposons que les données renvoyées par les requêtes frontales ne correspondent pas à la demande ou que la base de données a été endommagée. Pour cloner et restaurer le pipeline, effectuez la procédure suivante :</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">Echec de l'application</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Connectez-vous à Jenkins et créez un pipeline en cliquant sur nouvel élément, puis sur Pipeline.</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Copiez le pipeline à partir du fichier Jenkinsfile<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>.</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">Remplissez les paramètres du pipeline Jenkins avec les détails respectifs tels que la version actuelle de l'application Magento en production, le FQDN Astra Control Center, le jeton API, l'ID d'instance et le nom d'application ou l'espace de noms d'environnements de production et de débogage, ainsi que les noms de cluster source et de destination. Dans le cadre de cette utilisation, l'environnement de production est un espace de noms appelé « agento-prod » et l'environnement de débogage est un espace de noms appelé « agento-debug » configuré sur un cluster Red Hat OpenShift.</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">Cliquez sur Créer maintenant. Le pipeline commence à exécuter et progresse à travers les étapes. L'application est d'abord clonée dans l'état actuel dans un environnement de débogage, et l'application est ensuite restaurée dans la sauvegarde dont le fonctionnement a été vérifié.</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">Pipeline post-mortem</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">Vérifiez que l'application clonée est la version contenant le bogue.</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">Echec du clonage de l'application</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">Vérifiez que l'environnement de production est restauré sur une sauvegarde de travail et que l'application en production fonctionne comme prévu.</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">Application Prod restaurée</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">Ces deux opérations en tandem accélèrent le retour au fonctionnement normal de l'entreprise. Pour voir ce cas d'utilisation en action, regardez la vidéo <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>.</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">Validation du cas d'utilisation : le DevOps avec NetApp Astra</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">Les utilisations suivantes ont été validées avec NetApp Astra, pour le DevOps :</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">Contrôlez Astra pour faciliter l'analyse post-mortem et la restauration de l'application</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">Accélération du développement logiciel avec NetApp FlexClones</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">Ensuite, présentation des intégrations de stockage NetApp.</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">NetApp Astra, avec le DevOps</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Documentation Ansible</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Documentation de l'éleveur</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Documentation Kubernetes</block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">Reportez-vous à la documentation <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Pour installer et utiliser Astra Trident.</block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Gestion avancée des clusters pour Kubernetes : Red Hat OpenShift avec NetApp</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">Lorsqu'une application conteneurisée passe du développement à la production, de nombreuses entreprises ont besoin de plusieurs clusters Red Hat OpenShift pour prendre en charge les tests et le déploiement de cette application. Parallèlement, les entreprises hébergent généralement plusieurs applications ou charges de travail sur les clusters OpenShift. Par conséquent, chaque entreprise finit par gérer un ensemble de clusters. Les administrateurs OpenShift doivent donc faire face au défi que représente la gestion et la maintenance de plusieurs clusters sur un large éventail d'environnements répartis sur plusieurs data centers sur site et clouds publics. Pour relever ces défis, Red Hat a introduit la solution avancée de gestion de clusters pour Kubernetes.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Red Hat Advanced Cluster Management pour Kubernetes vous permet d'effectuer les tâches suivantes :</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">Créez, importez et gérez plusieurs clusters entre les data centers et les clouds publics</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">Déployer et gérer des applications ou des charges de travail sur plusieurs clusters à partir d'une console unique</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">Contrôler et analyser l'état et l'état des différentes ressources du cluster</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">Surveillez et appliquez la conformité aux règles de sécurité dans plusieurs clusters</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Red Hat Advanced Cluster Management pour Kubernetes est installé en tant qu'extension d'un cluster Red Hat OpenShift, et ce cluster est utilisé comme contrôleur central pour toutes ses opérations. Ce cluster est connu sous le nom de cluster de concentrateur et expose un plan de gestion permettant aux utilisateurs de se connecter à Advanced Cluster Management. Tous les autres clusters OpenShift importés ou créés via la console Advanced Cluster Management sont gérés par le cluster Hub et appelés clusters gérés. Il installe un agent appelé Klausterlet sur les clusters gérés afin de les connecter au cluster Hub et de répondre aux demandes différentes activités liées à la gestion du cycle de vie des clusters, à la gestion du cycle de vie des applications, à l'observabilité et à la conformité de la sécurité.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">Architecture ACM</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">Pour plus d'informations, reportez-vous à la documentation<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">Configuration iSCSI de NetApp Element</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">Pour activer l'intégration de Trident avec le système de stockage NetApp Element, vous devez créer un back-end permettant la communication avec le système de stockage via le protocole iSCSI.</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">Des exemples de fichiers backend sont disponibles dans l'archive d'installation téléchargée dans le<block ref="75e4a0ceb294a9d74374c938e4e8ddc8" prefix=" " category="inline-code"></block> hiérarchie des dossiers. Pour les systèmes NetApp Element servant iSCSI, copiez le<block ref="7989420add0b5baae954e866987ef264" prefix=" " category="inline-code"></block> dans votre répertoire de travail et modifiez le fichier.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">Modifiez l'utilisateur, le mot de passe et la valeur MVIP sur le<block ref="b7ae24ea48e61624a7e4078daa60bd78" prefix=" " category="inline-code"></block> ligne.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">Modifiez le<block ref="dcda39e13b00bf6bd40a507e1833a6f5" prefix=" " category="inline-code"></block> valeur.</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">Avec ce fichier back-end en place, exécutez la commande suivante pour créer votre premier back-end.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">Il y a un champ facultatif appelé<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> qui est défini dans ce fichier. Dans les systèmes back-end iSCSI, cette valeur peut être définie sur un type de système de fichiers Linux spécifique (XFS, ext4, etc.), ou elle peut être supprimée pour permettre à OpenShift de décider du système de fichiers à utiliser.</block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform réunit le développement et les opérations IT sur une plateforme unique pour concevoir, déployer et gérer de façon cohérente les applications dans l'ensemble des infrastructures de cloud hybride et sur site. Red Hat OpenShift repose sur l'innovation open source et sur les normes du secteur, notamment Kubernetes et Red Hat Enterprise Linux CoreOS, la principale distribution Linux d'entreprise au monde conçue pour les workloads basés sur des conteneurs.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">Présentation d'OpenShift</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform réunit le développement et les opérations IT sur une plateforme unique pour concevoir, déployer et gérer de façon cohérente les applications dans l'ensemble des infrastructures de cloud hybride et sur site. Red Hat OpenShift repose sur l'innovation open source et sur les normes du secteur, notamment Kubernetes et Red Hat Enterprise Linux CoreOS, la principale distribution Linux d'entreprise au monde conçue pour les workloads basés sur des conteneurs. OpenShift fait partie du programme Kubernetes certifié Cloud Native Computing Foundation (CNCF), qui assure la portabilité et l'interopérabilité des workloads de conteneurs.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift offre les fonctionnalités suivantes :</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">*Provisionnement en libre-service.* les développeurs peuvent rapidement et facilement créer des applications à la demande à partir des outils qu'ils utilisent le plus, tandis que les opérations conservent un contrôle total sur l'ensemble de l'environnement.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">*Stockage persistant.* en prenant en charge le stockage persistant, OpenShift Container Platform vous permet d'exécuter à la fois des applications avec état et des applications cloud sans état.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">*Intégration continue et développement continu (ci/CD).* cette plate-forme de code source gère les images de construction et de déploiement à grande échelle.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">*Normes Open-source.* ces normes intègrent l'Open Container Initiative (OCI) et Kubernetes pour l'orchestration des conteneurs, en plus d'autres technologies open-source. Vous n'êtes pas limité aux technologies ou à la feuille de route commerciale d'un fournisseur spécifique.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">*Ci/CD pipelines.* OpenShift offre une prise en charge prête à l'emploi des pipelines ci/CD afin que les équipes de développement puissent automatiser chaque étape du processus de distribution de l'application et s'assurer qu'elle est exécutée à chaque modification effectuée sur le code ou la configuration de l'application.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">*Contrôle d'accès basé sur les rôles (RBAC).* cette fonction permet de suivre l'équipe et l'utilisateur pour organiser un grand groupe de développeurs.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">*Création et déploiement automatisés.* OpenShift offre aux développeurs la possibilité de créer leurs applications conteneurisées ou de faire construire les conteneurs à partir du code source de l'application ou même des binaires. La plateforme automatise ensuite le déploiement de ces applications dans l'infrastructure en fonction de la caractéristique définie pour les applications. Par exemple, la quantité de ressources à allouer et le lieu où elles doivent être déployées sur l'infrastructure, afin qu'elles soient compatibles avec les licences tierces.</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">*Environnements cohérents.* OpenShift garantit que l'environnement provisionné pour les développeurs et tout au long du cycle de vie de l'application est cohérent du système d'exploitation aux bibliothèques, à la version d'exécution (par exemple, Java runtime), et même le runtime de l'application en cours d'utilisation (par exemple, tomcat) pour supprimer les risques proviennent d'environnements incohérents.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">*Gestion de la configuration.* la gestion de la configuration et des données sensibles est intégrée à la plate-forme pour s'assurer qu'une configuration d'application cohérente et indépendante de l'environnement est fournie à l'application, quelles que soient les technologies utilisées pour créer l'application ou quel environnement elle est déployée.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">*Journaux et mesures de l'application.* un retour rapide est un aspect important du développement de l'application. La surveillance intégrée et la gestion des journaux OpenShift fournissent aux développeurs des metrics immédiates afin d'étudier leur comportement à travers les changements et de pouvoir résoudre les problèmes le plus tôt possible au cours du cycle de vie de l'application.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">*Sécurité et catalogue de conteneurs.* OpenShift offre la colocation et protège l'utilisateur contre l'exécution de code nuisible en utilisant la sécurité établie avec Security-Enhanced Linux (SELinux), CGroups et Secure Computing mode (seccomp) pour isoler et protéger les conteneurs. Il fournit également le cryptage via des certificats TLS pour les différents sous-systèmes et l'accès aux conteneurs certifiés Red Hat (access.redhat.com/containers) qui sont analysés et classés en mettant l'accent sur la sécurité afin de fournir aux utilisateurs des conteneurs d'applications certifiés, fiables et sécurisés.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Méthodes de déploiement pour Red Hat OpenShift</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Depuis Red Hat OpenShift 4, les méthodes de déploiement d'OpenShift incluent les déploiements manuels utilisant l'UPI (User Provisioned Infrastructure) pour des déploiements hautement personnalisés ou des déploiements entièrement automatisés à l'aide de l'IPI (installer Provisioned Infrastructure).</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">La méthode d'installation IPI est la méthode privilégiée dans la plupart des cas, car elle permet le déploiement rapide des clusters OCP pour les environnements de développement, de test et de production.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Installation IPI de Red Hat OpenShift</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">Le déploiement d'IPI (installer Provisionfortes Infrastructure) d'OpenShift implique les étapes de haut niveau suivantes :</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">site web</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Visitez Red Hat OpenShift<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> Et connectez-vous à l'aide de votre login SSO.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Sélectionnez l'environnement dans lequel vous souhaitez déployer Red Hat OpenShift.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">Sur l'écran suivant, téléchargez le programme d'installation, le secret de collecte unique et les outils CLI pour la gestion.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">Suivez le<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Fourni par Red Hat pour un déploiement dans l'environnement de votre choix.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">Les déploiements OpenShift validés par NetApp</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp a testé et validé le déploiement de Red Hat OpenShift dans ses laboratoires à l'aide de la méthode de déploiement IPI (installer provisionnés Infrastructure) dans chacun des environnements de data Center suivants :</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">Gestion du cycle de vie des clusters</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">Pour gérer différents clusters OpenShift, vous pouvez les créer ou les importer dans Advanced Cluster Management.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">Commencez par automatiser les infrastructures &gt; clusters.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">Pour créer un cluster OpenShift, effectuez les opérations suivantes :</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">Créer une connexion fournisseur : accédez à connexions fournisseur et cliquez sur Ajouter une connexion, fournissez tous les détails correspondant au type de fournisseur sélectionné et cliquez sur Ajouter.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">Ajouter une connexion fournisseur</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">Pour créer un nouveau cluster, accédez à clusters et cliquez sur Ajouter un cluster &gt; Créer un cluster. Fournissez les détails du cluster et du fournisseur correspondant, puis cliquez sur Créer.</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">Ajouter des clusters</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">Une fois le cluster créé, il apparaît dans la liste des clusters avec l'état prêt.</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">Pour importer un cluster existant, procédez comme suit :</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">Accédez à clusters et cliquez sur Ajouter un cluster &gt; Importer un cluster existant.</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">Entrez le nom du cluster, puis cliquez sur Enregistrer l'importation et générer le code. Une commande permettant d'ajouter le cluster existant est affichée.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Cliquez sur Copy Command et exécutez la commande sur le cluster à ajouter au cluster Hub. Cette opération lance l'installation des agents nécessaires sur le cluster et, une fois ce processus terminé, le cluster apparaît dans la liste des clusters avec l'état prêt.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">Importer le cluster existant</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">Une fois que vous avez créé et importé plusieurs clusters, vous pouvez les surveiller et les gérer à partir d'une seule console.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">Suivant : fonctionnalités - gestion du cycle de vie des applications.</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">Migration des workloads : Red Hat OpenShift avec NetApp</block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">Flux de travail : Red Hat OpenShift Virtualization avec NetApp ONTAP</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">Migration en direct des machines virtuelles</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">Live migration est un processus de migration d'une instance de VM d'un nœud vers un autre dans un cluster OpenShift sans aucun temps d'indisponibilité. Pour que la migration en direct puisse fonctionner dans un cluster OpenShift, les VM doivent être liés aux demandes de volume virtuel avec le mode d'accès ReadWriteMany partagé. Le système back-end Astra Trident configuré avec un SVM sur un cluster NetApp ONTAP activé pour le protocole NFS prend en charge l'accès partagé ReadWriteMany pour les demandes de volume persistant. Par conséquent, les machines virtuelles avec des demandes de volume persistant demandées par les classes de stockage provisionnées par Trident à partir d'un SVM compatible NFS peuvent être migrées sans temps d'indisponibilité.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">Architecture de VM Live migration</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">Pour créer une VM liée à des demandes de volume virtuel avec un accès ReadWriteMany partagé :</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">Accédez à charges de travail &gt; virtualisation &gt; ordinateurs virtuels, puis cliquez sur Créer &gt; avec l'assistant.</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">Sélectionnez le système d'exploitation souhaité et cliquez sur Suivant. Supposons que l'OS sélectionné dispose déjà d'une source d'amorçage configurée avec celle-ci.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">Dans le volet révision et création, sélectionnez le projet dans lequel vous souhaitez créer la machine virtuelle et indiquez les détails de la machine virtuelle. Assurez-vous que la source de démarrage est sélectionnée pour être Clone et boot à partir du CD-ROM avec le PVC approprié affecté au système d'exploitation sélectionné.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">Cliquez sur Personnaliser l'ordinateur virtuel, puis sur stockage.</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">Cliquez sur les points de suspension en regard de rootdisk et assurez-vous que le storageclass provisionné à l'aide de Trident est sélectionné. Développez Avancé et sélectionnez accès partagé (RWX) pour le mode d'accès. Cliquez ensuite sur Enregistrer.</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">Rendre le disque RWX accessible</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">Cliquez sur vérifier et confirmer, puis sur Créer une machine virtuelle.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">Pour migrer manuellement un VM vers un autre nœud du cluster OpenShift, procédez comme suit.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">Accédez aux charges de travail &gt; virtualisation &gt; machines virtuelles.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">Pour la VM à migrer, cliquez sur les points de suspension, puis sur migrer la machine virtuelle.</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">Cliquez sur migrer lorsque le message s'affiche pour confirmer.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">Une instance de machine virtuelle d'un cluster OpenShift migre automatiquement vers un autre nœud lorsque le nœud d'origine est placé en mode maintenance si la stratégie d'éviction est définie sur LiveMigrate.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">Suivant : workflows : clonage de VM.</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">Validation</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">Pour valider l'architecture mutualisée configurée lors des étapes précédentes, procédez comme suit :</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">Valider l'accès pour créer des demandes de volume persistant ou des pods dans le projet attribué</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">Connectez-vous en tant qu'utilisateur ocp-project-1, développeur dans Project-1.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">Vérifiez l'accès pour créer un nouveau projet.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">Créez un PVC dans Project-1 en utilisant le storageclass affecté au projet-1.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">Vérifiez le volume persistant associé à la demande de volume persistant.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">Vérifiez que le volume persistant et son volume sont créés dans un SVM dédié à Project-1 sur NetApp ONTAP.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">Créez un pod dans Project-1 et montez le PVC créé à l'étape précédente.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">Vérifiez si le pod est en cours d'exécution et si il a monté le volume.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">Valider l'accès pour créer des demandes de volume persistant ou des pods dans un autre projet ou utiliser des ressources dédiées à un autre projet</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">Créez un PVC dans Project-1 en utilisant le storageclass affecté au projet-2.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">Création d'une demande de volume persistant dans Project-2.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">Assurez-vous que les ESV<block ref="1ff946dbad16e896f78812f54d491d28" prefix=" " category="inline-code"></block> et<block ref="146dc2badf14b242d7e386acd7f9b2aa" prefix=" " category="inline-code"></block> n'ont pas été créés.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">Créez un pod dans Project-2.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">Validez l'accès pour afficher et modifier les projets, ResourceQuotas et Storageclasses</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">Vérifiez l'accès pour créer de nouveaux projets.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">Valider l'accès pour afficher les projets.</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">Vérifiez si l'utilisateur peut afficher ou modifier ResourceQuotas dans Project-1.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">Vérifiez que l'utilisateur a accès à l'affichage des données de stockage.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">Vérifiez l'accès pour décrire les storageclasses.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">Validez l’accès de l’utilisateur pour modifier les storageclasses.</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">Suivant : évolutivité.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Présentation de VMware vSphere avec Tanzu</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">VMware vSphere avec Tanzu, également appelé vSphere Pods, vous permet d'utiliser les nœuds d'hyperviseur ESXi dans votre environnement VMware vSphere en tant que nœuds workers dans un environnement Kubernetes bare Metal.</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">VMware vSphere avec Kubernetes</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Un environnement VMware vSphere avec Tanzu est activé sous Workload Management comme un cluster TKGS natif.</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">Un cluster Supervisor Cluster virtualisé est créé pour fournir un plan de contrôle hautement disponible pour Kubernetes. Des espaces de noms individuels sont créés pour chaque application afin de garantir l'isolation des ressources pour les utilisateurs.</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Groupe de superviseurs</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Lorsque VMware vSphere avec Tanzu est activé, l'application Sphérelet est installée sur chacun des hôtes VMware ESXi. Cela permet à chaque nœud d'agir en tant que collaborateur dans un déploiement Kubernetes et de gérer les pods déployés sur chaque nœud.</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">Espace de noms</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">Actuellement, VMware vSphere avec Tanzu et vSphere Pods ne prennent en charge que le pilote vSphere CSI local. Pour cela, les administrateurs peuvent créer des règles de stockage dans le client vSphere, qui sélectionne parmi les cibles de stockage actuellement disponibles pour être utilisées comme datastores vSphere. Ces règles sont utilisées pour créer des volumes persistants pour les applications conteneurisées.</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">Bien qu'il ne soit actuellement pas pris en charge par le pilote NetApp Astra Trident CSI qui permet une connectivité directe vers des baies de stockage externes ONTAP et Element, ces systèmes de stockage NetApp sont souvent utilisés pour prendre en charge le stockage primaire pour l'environnement vSphere, Et les outils avancés de gestion des données et d'efficacité du stockage de NetApp peuvent être utilisés de cette manière.</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">Pour en savoir plus sur VMware vSphere avec Tanzu, consultez la documentation <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">Ensuite, présentation des systèmes de stockage NetApp.</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">VMware Tanzu Kubernetes Grid Service (également appelé vSphere avec Tanzu) vous permet de créer et d'exploiter des clusters Kubernetes tanzu de manière native dans vSphere. Il vous permet également d'exécuter des charges de travail plus petites directement sur les hôtes ESXi.</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">Présentation de VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">VMware Tanzu Kubernetes Grid Service (également appelé vSphere avec Tanzu) vous permet de créer et d'exploiter des clusters Kubernetes tanzu de manière native dans vSphere. Il vous permet également d'exécuter des charges de travail plus petites directement sur les hôtes ESXi. Elle vous permet de transformer vSphere en une plateforme pour exécuter des workloads conteneurisés sur la couche d'hyperviseur. Tanzu Kubernetes Grid Service déploie un cluster de supervision sur vSphere lorsqu'il est activé, ce service déploie et exécute les clusters requis pour les workloads. Il est intégré en mode natif à vSphere 7 et exploite de nombreuses fonctionnalités vSphere fiables telles que vCenter SSO, Content Library, la mise en réseau vSphere, le stockage vSphere HA et DRS, et la sécurité vSphere pour une expérience Kubernetes plus transparente.</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">VSphere avec Tanzu offre une plateforme unique pour les environnements applicatifs hybrides dans lesquels vous pouvez exécuter vos composants applicatifs dans des conteneurs ou dans des machines virtuelles. Les développeurs, les ingénieurs DevOps et les administrateurs vSphere bénéficient ainsi d'une meilleure visibilité et d'une plus grande simplicité d'exploitation. VMware TKGS n'est pris en charge qu'avec les environnements vSphere 7 et est le seul portefeuille d'opérations Kubernetes de Tanzanie qui vous permet d'exécuter des pods directement sur des hôtes ESXi.</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">Service VMware Tanzu Kubernetes</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Pour plus d'informations sur Tanzu Kubernetes Grid Service, consultez la documentation <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">De nombreux critères architecturaux doivent être pris en compte pour les fonctionnalités, la mise en réseau, etc. Selon l'architecture choisie, les prérequis et le processus de déploiement de Tanzu Kubernetes Grid Service diffèrent. Pour déployer et configurer le service Grid Kubernetes Tanzu dans votre environnement, suivez le guide <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>. De plus, pour vous connecter aux nœuds de cluster Kubernetes Tanzu déployés via TKGS, suivez la procédure décrite dans ce document<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>.</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp recommande de déployer tous les environnements de production dans plusieurs déploiements principaux pour une tolérance aux pannes avec le choix de la configuration des nœuds workers afin de répondre aux exigences de ces charges de travail. Ainsi, une classe de machine virtuelle recommandée pour une charge de travail très exigeante aurait au moins quatre CPU virtuels et 12 Go de RAM.</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Lorsque des clusters Kubernetes tanzu sont créés dans un espace de noms, les utilisateurs avec<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> ou<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> l'autorisation peut créer des modules directement dans n'importe quel espace de noms à l'aide du compte utilisateur. En effet, les utilisateurs de l'<block ref="72122ce96bfec66e2396d2e25225d70a" prefix=" " category="inline-code"></block> ou<block ref="de95b43bceeb4b998aed4aed5cef1ae7" prefix=" " category="inline-code"></block> l'autorisation est attribuée au rôle d'administrateur de cluster. Cependant, lors de la création de déploiements, de jeux de démons, de jeux avec état ou d'autres éléments dans un espace de noms, vous devez attribuer un rôle avec les autorisations requises aux comptes de service correspondants. Cela est nécessaire car les déploiements ou les jeux de démons utilisent des comptes de service pour déployer les pods.</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">Consultez l'exemple suivant de ClusterRoleBinding pour affecter le rôle d'administrateur de cluster à tous les comptes de service du cluster :</block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">Présentation de VMware Tanzu Kubernetes Grid Integrated Edition (TKGI)</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated (TKGI) Edition, anciennement VMware Enterprise PKS, est une plateforme autonome d'orchestration de conteneurs basée sur Kubernetes avec des fonctionnalités telles que la gestion du cycle de vie, le contrôle de l'état du cluster, la mise en réseau avancée, un registre de conteneurs, etc. TKGI provisionne et gère des clusters Kubernetes avec le plan de contrôle TKGI, qui se compose de BOSH et Ops Manager.</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGI peut être installé et exécuté sur des environnements vSphere ou OpenStack sur site ou dans l'un des principaux clouds publics de leurs offres IaaS respectives. De plus, l'intégration de TKGI à NSX-T et Harbour permet d'utiliser davantage de charges de travail d'entreprise. Pour en savoir plus sur TKGI et ses capacités, consultez la documentation <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>.</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGI est installé dans une variété de configurations sur une variété de plates-formes basées sur des cas d'utilisation et des conceptions différents. Suivez le guide <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> Pour installer et configurer TKGI et ses prérequis. TKGI utilise les machines virtuelles Bosh comme nœuds pour les clusters Kubernetes tanzu qui exécutent des images de configuration immuables et toutes les modifications manuelles sur les machines virtuelles Bosh ne restent pas conservées d'un redémarrage à l'autre.</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">Remarques importantes :</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Trident nécessite un accès privilégié aux conteneurs. Lors de l'installation TKGI, assurez-vous de cocher la case Activer les conteneurs privilégiés dans l'étape pour configurer les plans de nœuds de cluster Tanzu Kubernetes.</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">Conteneurs privilégiés dans TKGI</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp recommande de déployer tous les environnements de production dans plusieurs déploiements maîtres pour assurer la tolérance aux pannes avec le choix de la configuration des nœuds workers afin de répondre aux exigences de ces charges de travail. Ainsi, un plan de cluster TKGI recommandé serait composé d'au moins trois maîtres et trois travailleurs avec au moins quatre CPU virtuels et 12 Go de RAM pour une charge de travail très intensive.</block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Pour permettre au Centre de contrôle Astra de gérer vos charges de travail, vous devez d'abord enregistrer vos clusters Kubernetes Tanzu.</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">Enregistrez vos clusters Kubernetes VMware Tanzu avec le Centre de contrôle Astra</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">Enregistrez les clusters VMware Tanzu Kubernetes</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">La première étape consiste à ajouter les clusters Kubernetes tanzu au Centre de contrôle Astra et à les gérer. Accédez à clusters et cliquez sur Ajouter un cluster, téléchargez le fichier kubeconfig pour le cluster Kubernetes de Tanzanie, puis cliquez sur Sélectionner un stockage.</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">Lorsque le cluster est ajouté, il passe à l'état découverte pendant qu'Astra Control Center l'inspecte et installe les agents nécessaires. L'état du cluster est modifié en<block ref="396d45b57c2fbe3318e7b93272a2686b" prefix=" " category="inline-code"></block> une fois l'enregistrement terminé.</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Tous les clusters Kubernetes tanzu à gérer par Astra Control Center doivent avoir accès au registre d'images utilisé pour son installation, car les agents installés sur les clusters gérés extraient les images de ce registre.</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">Importation de clusters ONTAP comme ressources de stockage à gérer en tant que système back-end par Astra Control Center. Lorsque des clusters Kubernetes tanzu sont ajoutés à Astra et qu'un storageclass est configuré, il détecte et inspecte automatiquement le cluster ONTAP qui soutient le storageclass, mais ne l'importe pas dans le Control Center Astra à gérer.</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">Pour importer les clusters ONTAP, accédez aux systèmes back-end, cliquez sur la liste déroulante et sélectionnez gérer en regard du cluster ONTAP à gérer. Entrez les informations d'identification du cluster ONTAP, cliquez sur vérifier les informations, puis sur Importer le stockage back-end.</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">Une fois que le système back-end est ajouté, le statut devient disponible. Ces systèmes back-end disposent désormais d'informations sur les volumes persistants dans le cluster Kubernetes tanzu et sur les volumes correspondants sur le système ONTAP.</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Pour la sauvegarde et la restauration entre des clusters Kubernetes tanzu à l'aide d'Astra Control Center, vous devez provisionner un compartiment de stockage objet qui prend en charge le protocole S3. Les options actuellement prises en charge sont ONTAP S3, StorageGRID, AWS S3 et le stockage Microsoft Azure Blob Storage. Pour les besoins de cette installation, nous allons configurer un compartiment AWS S3. Accédez à godets, cliquez sur Ajouter un compartiment et sélectionnez Generic S3. Entrez les informations d'identification du compartiment S3 et des informations d'identification pour y accéder, cliquez sur la case à cocher définir ce compartiment comme compartiment par défaut pour le cloud, puis cliquez sur Ajouter.</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">Pour l'intégration du système de stockage NetApp ONTAP avec des clusters Kubernetes VMware tanzu pour les volumes persistants via iSCSI, la première étape consiste à préparer les nœuds en se connectant à chaque nœud et en configurant les utilitaires ou packages iSCSI pour le montage des volumes iSCSI.</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">Pour intégrer le système de stockage NetApp ONTAP avec des clusters Kubernetes VMware Tanzu pour les volumes persistants via iSCSI, la première étape consiste à préparer les nœuds en vous connectant à chaque nœud et en configurant les utilitaires ou packages iSCSI pour le montage des volumes iSCSI. Pour ce faire, suivre la procédure décrite dans ce document <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>.</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp ne recommande pas cette procédure pour les déploiements NAT des clusters VMware Tanzu Kubernetes.</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI utilise les machines virtuelles Bosh comme nœuds pour les clusters Kubernetes tanzu qui exécutent des images de configuration immuables, et toute modification manuelle des packages iSCSI sur les machines virtuelles Bosh n'est pas conservée d'un redémarrage à l'autre. Par conséquent, NetApp recommande d'utiliser des volumes NFS pour le stockage persistant des clusters Kubernetes tanzu déployés et gérés par TKGI.</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">Une fois les nœuds de cluster prêts pour les volumes iSCSI, vous devez créer un back-end permettant la communication avec le système de stockage. Nous avons configuré un back-end de base dans cette solution, mais si vous cherchez des options plus personnalisées, consultez la documentation <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>.</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">Créer un SVM en ONTAP</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">Pour créer un SVM dans ONTAP, effectuez la procédure suivante :</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">Connectez-vous à ONTAP System Manager, accédez à Storage &gt; Storage VM, puis cliquez sur Add.</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">Entrer un nom pour le SVM, activer le protocole iSCSI, puis fournir le détail des LIFs de données.</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">LIF de données de SVM iSCSI</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">Entrez les détails du compte d'administration du SVM, puis cliquez sur Save.</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">Administration des SVM iSCSI</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">Pour attribuer les agrégats au SVM, accédez à Storage &gt; Storage VM, puis cliquez sur les points de suspension situés à côté du SVM qui vient d'être créé, puis cliquez sur Modifier. Cochez la case limiter la création de volume aux niveaux locaux préférés et joignez les agrégats requis à ceux-ci.</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">Allocation d'agrégats SVM</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">Création de systèmes back-end et de classes de stockage</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">Pour les systèmes NetApp ONTAP qui utilisent NFS, créez un fichier de configuration interne sur le jump avec la postname, degestion LIF, dataLIF, svm, nom d'utilisateur, mot de passe et autres détails.</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">Créez le back-end Trident en exécutant la commande suivante.</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">Une fois que vous avez créé un back-end, vous devez ensuite créer une classe de stockage. L'exemple de définition de classe de stockage suivant met en évidence les champs requis et de base. Le paramètre<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Doit refléter le pilote de stockage du nouveau système back-end Trident créé. Notez également la valeur nom-champ, qui doit être référencée ultérieurement.</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">Il y a un champ facultatif appelé<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> qui est défini dans ce fichier. Dans les systèmes back-end iSCSI, cette valeur peut être définie sur un type de système de fichiers Linux spécifique (XFS, ext4, etc.) ou peut être supprimée pour permettre aux clusters Kubernetes tanzu de décider du système de fichiers à utiliser.</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">Créez la classe de stockage en exécutant la commande kubectl.</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">Une fois la classe de stockage créée, vous devez ensuite créer la première demande de volume persistant. Un exemple de définition de PVC est donné ci-dessous. Assurez-vous que le<block ref="ee822781a3bd0ae0f8f6331dc4865d9c" prefix=" " category="inline-code"></block> le champ correspond au nom de la classe de stockage que vous venez de créer. La définition du volume persistant peut être personnalisée davantage selon les besoins, en fonction de la charge de travail à provisionner.</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">Créez la demande de volume persistant en exécutant la commande kubectl. La création peut prendre un certain temps en fonction de la taille du volume de sauvegarde en cours de création, de sorte que vous pouvez regarder le processus au fur et à mesure qu'il se termine.</block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">Cette page contient des liens vers des vidéos qui présentent certaines des fonctionnalités décrites dans ce document.</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">Vidéos et démonstrations : VMware Tanzu avec NetApp</block>
  <block id="811263b3dba6ff02a02f70eb9730ca2e" category="inline-link-macro">Utilisez Astra Trident pour provisionner le stockage persistant dans VMware Tanzu</block>
  <block id="6aa25c5e03abeab0ced9fac672bb2330" category="list-text"><block ref="6aa25c5e03abeab0ced9fac672bb2330" category="inline-link-macro-rx"></block></block>
  <block id="03a87e35f2de41c34385d72c2c717acf" category="inline-link-macro">Utilisez Astra Control Center pour cloner des applications dans VMware Tanzu</block>
  <block id="591774815c932f725e0adbded50b634b" category="list-text"><block ref="591774815c932f725e0adbded50b634b" category="inline-link-macro-rx"></block></block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">Suivant : informations complémentaires : VMware Tanzu avec NetApp.</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="945f7593bacdce2a986b2ea8ab58220b" category="summary">Cette page contient des liens vers une vidéo de démonstration qui montre comment utiliser Astra Control Center pour cloner des applications dans VMware Tanzu.</block>
  <block id="ff56b2be4aa6be0d45adf0bbeb76166d" category="doc">Utilisez Astra Control Center pour cloner des applications dans VMware Tanzu</block>
  <block id="db70f2aaf062f269f45b2fe61ad31160" category="admonition">Cette démo a été enregistrée comme un aperçu technique à l'aide de la version 1.3.1 de TKG et de la version 21.12 de Astra Control Center. Consultez la matrice de support pour connaître les versions officielles prises en charge.</block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">Une fois que vous avez enregistré vos clusters Kubernetes VMware Tanzu, vous pouvez détecter les applications qui sont déployées et les gérer via le Centre de contrôle Astra.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">Choisissez les applications à protéger</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Une fois que vous avez enregistré vos clusters Kubernetes Tanzu, vous pouvez découvrir les applications qui sont déployées et les gérer via le Centre de contrôle Astra.</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">Gestion des applications</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Une fois que les clusters Kubernetes tanzu et les systèmes back-end ONTAP sont enregistrés auprès du Centre de contrôle Astra, le centre de contrôle commence automatiquement à découvrir les applications dans tous les espaces de noms qui utilisent le storageclass configuré avec le back-end ONTAP spécifié.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="image-alt">Découverte d'applications Astra Control Center</block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">Accédez à applications &gt; découverte et cliquez sur le menu déroulant en regard de l'application que vous souhaitez gérer à l'aide d'Astra. Cliquez ensuite sur gérer.</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="image-alt">Astra Control Center gère les applications</block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">L'application passe à l'état disponible et peut être affichée sous l'onglet géré de la section applications.</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="image-alt">Applications Astra Control Center disponibles</block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">Ensuite, protégez vos applications.</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">Pour activer l'intégration de Trident avec le système de stockage NetApp ONTAP via NFS, vous devez créer un système back-end permettant la communication avec le système de stockage. Nous configurons un back-end de base dans cette solution, mais si vous cherchez des options plus personnalisées, consultez la documentation <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>.</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">Entrez un nom pour la SVM, activez le protocole NFS, cochez la case Autoriser NFS client Access et ajoutez les sous-réseaux sur lesquels sont situés les nœuds workers dans les règles d'export pour que les volumes soient montés en tant que PV dans les clusters de vos charges de travail.</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">Création de SVM avec NFS</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">Si vous utilisez le déploiement NAT'ed de clusters utilisateur ou de clusters de charge de travail avec NSX-T, vous devez ajouter le sous-réseau Egress (dans le cas de GSTK0 ou du sous-réseau IP flottant (dans le cas de TKGI) aux règles de politique d'exportation.</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">Fournir le détail des LIFs de données et les détails du compte d'administration des SVM, puis cliquer sur Save.</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">LIF de données SVM et administration du SVM</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">Assigner les agrégats à un SVM. Accédez à Storage &gt; Storage VM, cliquez sur les points de suspension situés à côté du SVM qui vient d'être créé, puis cliquez sur Modifier. Cochez la case limiter la création de volume aux niveaux locaux préférés et joignez les agrégats requis à ceux-ci.</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">Dans le cas de déploiements NAT de clusters d'utilisateurs ou de workloads sur lesquels Trident doit être installé, la demande de montage du stockage peut arriver à partir d'un port non standard du fait de SNAT. Par défaut, ONTAP autorise uniquement les demandes de montage de volume quand provient du port racine. Ainsi, connectez-vous à l'interface de ligne de commandes de ONTAP et modifiez le paramètre pour autoriser les demandes de montage à partir de ports non standard.</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">Lorsque le back-end est créé, vous devez ensuite créer une classe de stockage. L'exemple de définition de classe de stockage suivant met en évidence les champs requis et de base. Le paramètre<block ref="55b56fb238360663afa6230ad82e74a0" prefix=" " category="inline-code"></block> Doit refléter le pilote de stockage du nouveau système back-end Trident créé.</block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">Suivant : vidéos et démonstrations : VMware Tanzu avec NetApp.</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données intégrant la cohérence applicative pour les workloads Kubernetes avec état, déployés dans un environnement sur site et optimisé par les technologies NetApp de protection des données fiables.</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">Si vous recherchez un kit de développement logiciel prêt à l'emploi pour interagir avec les API REST Astra Control, NetApp propose un kit avec le kit de développement Python Astra Control que vous pouvez télécharger <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">Si la programmation n'est pas adaptée à votre situation et si vous souhaitez utiliser un outil de gestion de la configuration, vous pouvez cloner et exécuter les playbooks Ansible publiés par NetApp <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Conditions préalables à l'installation d'Astra Control Center</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">L'installation d'Astra Control Center requiert les conditions préalables suivantes :</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">Un ou plusieurs clusters Kubernetes tanzu gérés soit par un cluster de gestion, soit par TKGS ou TKGI. Les clusters de charges de travail TKG 1.4+ et les clusters utilisateur TKGI 1.12.2+ sont pris en charge.</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">Astra Trident doit déjà être installé et configuré sur chacun des clusters Kubernetes de Tanzanie.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">Un ou plusieurs systèmes de stockage NetApp ONTAP exécutant ONTAP 9.5 ou version ultérieure.</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">C'est une bonne pratique pour chaque installation de Kubernetes de tanzu sur un site qui dispose d'un SVM dédié pour le stockage persistant. Les déploiements multisites requièrent des systèmes de stockage supplémentaires.</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">Un système back-end de stockage Trident doit être configuré sur chaque cluster Kubernetes tanzu avec une SVM sauvegardée par un cluster ONTAP.</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">Classe de stockage par défaut configurée sur chaque cluster Kubernetes tanzu avec Astra Trident comme mécanisme de provisionnement du stockage.</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">Un équilibreur de charge doit être installé et configuré sur chaque cluster Kubernetes tanzu pour équilibrer la charge et exposer Astra Control Center si vous utilisez ingressType<block ref="0a3e1793e4eaf6bd67bdf43d1bca1c74" prefix=" " category="inline-code"></block>.</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">Un contrôleur d'entrée doit être installé et configuré sur chaque cluster Kubernetes tanzu pour exposer Astra Control Center si vous utilisez ingressType<block ref="8045a0a6c688b0635e3caccc408a1446" prefix=" " category="inline-code"></block>.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">Un registre d'images privées doit être configuré pour héberger les images du NetApp Astra Control Center.</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">Vous devez disposer d'un accès administrateur de cluster au cluster Kubernetes tanzu sur lequel Astra Control Center est installé.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">Vous devez disposer d'un accès d'administration aux clusters NetApp ONTAP.</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">Un poste de travail d'administration RHEL ou Ubuntu.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Poser le centre de contrôle Astra</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">Cette solution décrit une procédure automatisée pour installer Astra Control Center à l'aide d'un playbooks Ansible. Si vous recherchez une procédure manuelle pour installer le centre de contrôle Astra, suivez le guide d'installation et d'exploitation détaillé <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Créez ou obtenez le fichier kubeconfig avec un accès administrateur au cluster Kubernetes de l'utilisateur ou de la charge de travail Tanzu sur lequel Astra Control Center doit être installé.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">Après l'installation</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">L'installation peut prendre plusieurs minutes. Vérifier que tous les pods et services dans le<block ref="cde5355ebfdfe468e0d3516b20d95313" prefix=" " category="inline-code"></block> les espaces de noms sont opérationnels.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">Vérifier le<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> journaux pour vérifier que l'installation est terminée.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">Le message suivant indique que le centre de contrôle Astra a été installé avec succès.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Le nom d'utilisateur pour la connexion à Astra Control Center est l'adresse électronique de l'administrateur fournie dans le fichier CRD et le mot de passe est une chaîne<block ref="4e68cdd4eb0ff1a79e44dac42b52abd8" prefix=" " category="inline-code"></block> Joint à l'UUID du centre de contrôle Astra. Exécutez la commande suivante :</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">Dans cet exemple, le mot de passe est<block ref="bf7a8daff076079f839129b59f2bb759" prefix=" " category="inline-code"></block>.</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">Obtenez l'IP de l'équilibreur de charge du service traefik si ingressType est AccTraefik.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Ajoutez une entrée dans le serveur DNS pointant le FQDN fourni dans le fichier CRD Astra Control Center vers le<block ref="23edb0469b69e61c98ac7a9e1dca82e8" prefix=" " category="inline-code"></block> du service de trafik.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">Ajouter une entrée DNS pour l'interface utilisateur graphique ACC</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">Connectez-vous à l'interface graphique d'Astra Control Center en parcourant son FQDN.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Connexion au centre de contrôle Astra</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">Lorsque vous vous connectez à l'interface graphique d'Astra Control Center pour la première fois à l'aide de l'adresse e-mail d'administration fournie dans CRD, vous devez modifier le mot de passe.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Modification obligatoire du mot de passe du centre de contrôle Astra</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Si vous souhaitez ajouter un utilisateur au Centre de contrôle Astra, accédez à compte &gt; utilisateurs, cliquez sur Ajouter, entrez les détails de l'utilisateur et cliquez sur Ajouter.</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Créer un utilisateur avec Astra Control Center</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Center requiert une licence pour toutes ses fonctionnalités. Pour ajouter une licence, accédez à compte &gt; Licence, cliquez sur Ajouter une licence et téléchargez le fichier de licence.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center ajoute une licence</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">En cas de problème avec l'installation ou la configuration de NetApp Astra Control Center, la base de connaissances des problèmes connus est disponible<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>.</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">Ensuite : enregistrez vos clusters Kubernetes Tanzu.</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">Créer un instantané d'application</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">Un snapshot d'une application crée une copie ONTAP Snapshot et une copie des métadonnées d'application qui peuvent être utilisées pour restaurer ou cloner l'application à un point dans le temps spécifique en fonction de cette copie Snapshot.</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">Création d'une sauvegarde d'application</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">Pour restaurer une application, accédez à l'onglet applications &gt; gestion et cliquez sur l'application en question. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur Restaurer.</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">Entrez les détails du nouvel espace de noms, sélectionnez le cluster vers lequel vous souhaitez le cloner à partir d'un snapshot existant, puis choisissez si vous souhaitez le cloner à partir d'une sauvegarde ou à partir de l'état actuel de l'application. Cliquez sur Suivant, puis sur Cloner dans le volet de révision une fois que vous avez passé en revue les détails.</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">Présentation de l'intégration du stockage NetApp</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">Ensuite, présentation de NetApp Astra Control.</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">Présentation de VMware Tanzu Kubernetes Grid (TKG)</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">VMware Tanzu Kubernetes Grid, également appelé TKG, vous permet de déployer des clusters Kubernetes tanzu dans des environnements de cloud hybride ou de cloud public. TKG est installé en tant que cluster de gestion, qui est un cluster Kubernetes lui-même, qui déploie et exploite les clusters Kubernetes Tanzu. Ces clusters Kubernetes tanzu sont des clusters Kubernetes de type workload sur lesquels la charge de travail réelle est déployée.</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid repose sur quelques projets de la communauté en amont prometteurs et fournit une plateforme Kubernetes développée, commercialisée et prise en charge par VMware. En plus de sa distribution Kubernetes, Tanzu Kubernetes Grid fournit des add-ons supplémentaires qui sont des services essentiels pour la production, tels que le registre, l'équilibrage de la charge, l'authentification, etc. VMware TKG avec cluster de gestion est largement utilisé dans les environnements vSphere 6.7 et, bien qu'il soit pris en charge, il ne constitue pas un déploiement recommandé pour les environnements vSphere 7 car TKGS possède des capacités d'intégration natives avec vSphere 7.</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">VMware Tanzu Kubernetes Grid avec cluster de gestion</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Pour plus d'informations sur Tanzu Kubernetes Grid, reportez-vous à la documentation <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>.</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">Selon que le Tanzu Kubernetes Grid est installé sur site sur un cluster vSphere ou dans des environnements cloud, préparez et déployez Tanzu Kubernetes Grid en suivant le guide d'installation <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>.</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Après avoir installé le cluster de gestion pour Tanzu Kubernetes Grid, déployez les clusters utilisateur ou les clusters de workloads selon les besoins en suivant la documentation <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>. Le cluster de gestion VMware TKG requiert qu'une clé SSH soit fournie pour l'installation et le fonctionnement des clusters Kubernetes de Tanzanie. Cette clé peut être utilisée pour se connecter aux nœuds du cluster à l'aide de<block ref="5ef871b8f1f696f9bb22de1dff45a81c" prefix=" " category="inline-code"></block> utilisateur.</block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris VMware Tanzu.</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Présentation d'Astra Trident</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Déploiement de l'opérateur Trident à l'aide de Helm</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">Ajoutez le référentiel NetApp Astra Trident Helm.</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Mettre à jour les référentiels Helm.</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Créez un nouvel espace de nom pour l'installation de Trident.</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">Créez un secret avec les informations d'identification DockerHub pour télécharger les images Astra Trident.</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">Pour les clusters utilisateur ou de charge de travail gérés par TKGS (vSphere avec Tanzu) ou TKG avec des déploiements de clusters de gestion, procédez comme suit pour installer Astra Trident :</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">Assurez-vous que l'utilisateur connecté dispose des autorisations nécessaires pour créer des comptes de service dans l'espace de noms trident et que les comptes de service dans l'espace de noms trident disposent des autorisations de créer des pods.</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">Exécutez la commande ci-dessous Helm pour installer l'opérateur Trident dans l'espace de noms créé.</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">Pour un cluster utilisateur ou de charge de travail géré par des déploiements TKGI, exécutez la commande Helm suivante pour installer l'opérateur Trident dans l'espace de noms créé.</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Vérifiez que les modules Trident sont opérationnels.</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Une fois l'installation d'Astra Trident Operator, vous devez configurer le système back-end pour la plateforme de stockage NetApp spécifique que vous utilisez. Suivez les liens ci-dessous pour poursuivre l'installation et la configuration d'Astra Trident.</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="40ef898131b1ea0532620ff9cb12840c" category="summary">Cette page contient un lien vers une vidéo de démonstration de l'utilisation d'Astra Trident pour le provisionnement du stockage persistant dans VMware Tanzu.</block>
  <block id="e0d2648924bbf778345db6153fddf464" category="doc">Utilisez Astra Trident pour provisionner le stockage persistant dans VMware Tanzu</block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzu est une gamme de produits qui permet aux entreprises de moderniser leurs applications et l'infrastructure sur laquelle elles s'exécutent. La pile complète de fonctionnalités de VMware Tanzu réunit les équipes de développement et d'opérations INFORMATIQUES sur une seule plateforme afin d'adopter la modernisation à la fois de leurs applications et de leur infrastructure, de manière cohérente dans les environnements sur site et de cloud hybride, afin de fournir en permanence de meilleurs logiciels en production.</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">Présentation de VMware Tanzu</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">Gamme VMware Tanzu</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Pour en savoir plus sur les différentes offres et leurs capacités dans le portefeuille de Tanzanie, consultez la documentation <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">En ce qui concerne le catalogue des opérations Kubernetes de Tanzanie, VMware dispose de diverses implémentations pour Tanzu Kubernetes Grid, qui provisionnent et gèrent tous le cycle de vie des clusters Kubernetes de Tanzanie sur diverses plateformes. Un cluster Kubernetes tanzu est une distribution Kubernetes à part entière conçue et prise en charge par VMware.</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp a testé et validé le déploiement et l'interopérabilité des produits suivants du portefeuille VMware Tanzu en laboratoire :</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="inline-link-macro">Réseau VMware Tanzu Kubernetes (TKG)</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="inline-link-macro">VMware Tanzu Kubernetes Grid Service (TKGS)</block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid intégré (TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphere avec Tanzu (vSphere Pods)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">Ce document de référence apporte une validation du déploiement de différentes solutions Kubernetes VMware tanzu, déployées sous la forme Tanzu Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) ou Tanzu Kubernetes Grid Integrated (TKGI) dans plusieurs environnements de data Center différents et validés par NetApp.</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166 : VMware Tanzu avec NetApp</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">Ce document de référence apporte une validation du déploiement de différentes solutions Kubernetes VMware tanzu, déployées sous la forme Tanzu Kubernetes Grid (TKG), Tanzu Kubernetes Grid Service (TKGS) ou Tanzu Kubernetes Grid Integrated (TKGI) dans plusieurs environnements de data Center différents et validés par NetApp. Il décrit également l'intégration du stockage avec les systèmes de stockage NetApp et l'orchestrateur de stockage Astra Trident pour la gestion du stockage persistant et Astra Control Center pour la sauvegarde et le clonage des applications avec état qui utilisent ce stockage persistant. Enfin, ce document propose des démonstrations vidéo des intégrations et validations de solutions.</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">L'architecture de la solution VMware Tanzu avec NetApp a été conçue pour offrir une valeur exceptionnelle aux clients dans les cas d'utilisation suivants :</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">Solutions VMware Tanzu Kubernetes Grid faciles à déployer et à gérer sur VMware vSphere et intégrées avec les systèmes de stockage NetApp.</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">La puissance combinée des workloads virtualisés et de conteneurs d'entreprise avec les offres VMware Tanzu Kubernetes Grid.</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">Des cas d'utilisation et de configuration réels soulignant les fonctionnalités de VMware Tanzu utilisées avec le stockage NetApp et la suite de produits NetApp Astra.</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">Protection ou migration cohérentes au niveau des applications des workloads conteneurisés déployés sur des clusters VMware Tanzu Kubernetes Grid dont les données résident sur des systèmes de stockage NetApp via Astra Control Center.</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">Déploiement dans un modèle de cloud hybride avec conteneurs s'exécutant à la fois dans des data centers sur site et dans le cloud.</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">VMware Tanzu avec NetApp prend en compte ces défis et présente une solution qui aide à résoudre chaque problème en déployant des offres Kubernetes VMware Tanzu dans l'environnement de cloud hybride choisi par le client.</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">La solution VMware Tanzu avec NetApp comprend les principaux composants suivants :</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">Plateformes VMware Tanzu Kubernetes</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzu est présente dans une multitude de versions que l'équipe d'ingénieurs solutions de NetApp a validées dans nos laboratoires. Chaque version de Tanzu s'intègre avec succès avec le portefeuille de solutions de stockage de NetApp, et chacune d'elles peut répondre à certaines exigences de l'infrastructure. Les points saillants suivants décrivent les caractéristiques et les offres de chaque version de Tanzu décrite dans ce document.</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">*VMware Tanzu Kubernetes Grid (TKG)*</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">Environnement Kubernetes en amont standard déployé dans un environnement VMware vSphere.</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">Anciennement connu sous le nom de Essential PKS (de Heppo acquisition, février 2019).</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG est déployé avec une instance de cluster de gestion distincte pour la prise en charge de vSphere 6.7U3 ultérieure.</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">Les déploiements TKG peuvent être déployés dans le cloud, aussi bien avec AWS ou Azure.</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">Permet l'utilisation de nœuds workers Windows ou Linux (Ubuntu/Photon).</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSX-T, un proxy HA, un réseau AVI ou des équilibreurs de charge peuvent être utilisés pour le plan de contrôle.</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG prend en charge MetalLB pour le plan d'application/de données.</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">Peut utiliser vSphere CSI ainsi que des services tiers tels que NetApp Astra Trident.</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">*VMware Tanzu Kubernetes Grid Service (TKGS)*</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGS est déployé avec un cluster Supervisor et des clusters de charges de travail uniquement sur vSphere 7.0U1.</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS prend en charge MetalLB pour les plans d'application/de données.</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">Prend en charge les pods vSphere avec Tanzu, ce qui permet d'exécuter directement les pods sur des hôtes ESXi activés dans l'environnement.</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">*VMware Tanzu Kubernetes Grid Integrated (TKGI)*</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">Anciennement Enterprise PKS (d'après l'acquisition de Heptio, février 2019).</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">Peut utiliser NSX-T, HA Proxy ou AVI. Vous pouvez également fournir votre propre équilibreur de charge.</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">Prise en charge à partir de vSphere 6.7U3 et de AWS, Azure et GCP.</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">Configuration via un assistant pour faciliter le déploiement</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">Exécute Tanzu dans des machines virtuelles immuables contrôlées gérées par BOSH.</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">Vous pouvez utiliser vSphere CSI et des services tiers tels que NetApp Astra Trident (certaines conditions s'appliquent).</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">*VSphere avec Tanzu (vSphere Pods)*</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">Les pods vSphere natifs s'exécutent dans une couche mince basée sur des photons avec le matériel virtuel prescrit pour une isolation totale.</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">Utilise NSX-T, mais cela permet d'utiliser d'autres fonctionnalités comme un registre d'images Harbour.</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">Déployé et géré dans vSphere 7.0U1 à partir d'un cluster Supervisor virtuel tel que TKGS. Exécute les pods directement sur des nœuds ESXi.</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">Intégration complète à vSphere, visibilité et contrôle optimaux grâce à l'administration vSphere.</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">Des modules CRX isolés pour un niveau de sécurité optimal.</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">Prend uniquement en charge vSphere CSI pour le stockage persistant. Aucun orchestrateurs de stockage tiers pris en charge</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">NetApp Astra Control Center propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, déployé dans un environnement sur site et optimisé par la technologie de protection des données NetApp de confiance.</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris VMware Tanzu.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">Matrice de prise en charge actuelle pour les versions validées</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">Gestion des données intégrant la cohérence applicative</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">Orchestration du stockage</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4+</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">Service de grille VMware Tanzu Kubernetes</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [espaces de noms vSphere]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [Supervisor Cluster Kubernetes]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid intégré</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">Virtualisation du data Center</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7,0U3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">Data Center VMware NSX-T</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">Mise en réseau et sécurité</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">Équilibreur de charge avancé de VMware NSX</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">Équilibreur de charge</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">Suivant : présentation de VMware Tanzu.</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">Informations complémentaires : VMware Tanzu avec NetApp</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">Documentation VMware Tanzu</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">Documentation VMware Tanzu Kubernetes Grid</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">Documentation du service Grid VMware Tanzu Kubernetes</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">Documentation de VMware Tanzu Kubernetes Grid Integrated Edition</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">Cette page détaille les instructions d'installation et de configuration de l'équilibreur de charge MetalLB.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">Installation d'équilibreurs de charge MetalLB : Red Hat OpenShift avec NetApp</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">Cette page répertorie les instructions d'installation et de configuration de l'équilibreur de charge MetalLB.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB est un équilibreur de charge réseau hébergé automatiquement sur votre cluster OpenShift qui permet la création de services OpenShift d'équilibreur de charge dans les clusters qui ne s'exécutent pas sur un fournisseur cloud. Les deux principales caractéristiques de MetalLB qui fonctionnent ensemble pour prendre en charge les services LoadBalancer sont l'allocation d'adresses et l'annonce externe.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">Options de configuration MetalLB</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">D'après la façon dont MetalLB annonce l'adresse IP attribuée aux services LoadBalancer en dehors du cluster OpenShift, elle fonctionne selon deux modes :</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">*Mode de couche 2.* dans ce mode, un nœud du cluster OpenShift est propriétaire du service et répond aux demandes ARP pour cette IP pour la rendre accessible en dehors du cluster OpenShift. Seul le nœud annonce l'IP, il présente un goulot d'étranglement au niveau de la bande passante et des limitations de basculement lentes. Pour plus d'informations, reportez-vous à la documentation <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">*Mode BGP.* dans ce mode, tous les nœuds du cluster OpenShift établissent des sessions de peering BGP avec un routeur et annoncent les routes pour transférer le trafic vers les adresses IP du service. La condition préalable est d’intégrer MetalLB à un routeur de ce réseau. En raison du mécanisme de hachage dans BGP, il possède une certaine limite lors du mappage d'IP à nœud pour les modifications de service. Pour plus d'informations, reportez-vous à la documentation <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">Pour les besoins de ce document, nous allons configurer MetalLB en mode couche 2.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">Installation de l'équilibreur de charge MetalLB</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">Téléchargez les ressources MetalLB.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">Modifier le fichier<block ref="130d214581bb0aa3e8759729c9fbc133" prefix=" " category="inline-code"></block> et déposer<block ref="635a57f17cd40dc65b36973c9e14f9d1" prefix=" " category="inline-code"></block> À partir du déploiement du contrôleur et de l'ensemble des haut-parleurs.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">*Lignes à supprimer :*</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">Créer le<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> espace de noms.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">Créer la CR du MetalLB.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">Avant de configurer le haut-parleur MetalLB, accordez à l'intervenant DemonSet des privilèges élevés afin qu'il puisse effectuer la configuration réseau requise pour que les équilibreurs de charge fonctionnent.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">Configurez MetalLB en créant un<block ref="a941f8adb5ae079ebc739cb59407fd30" prefix=" " category="inline-code"></block> dans le<block ref="48f2018beab0b13a2087fae3aff05306" prefix=" " category="inline-code"></block> espace de noms.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">Maintenant que des services loadBALB sont créés, MetalLB attribue un IP externe aux services et annonce l'adresse IP en répondant aux demandes ARP.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">Si vous souhaitez configurer MetalLB en mode BGP, ignorez l'étape 6 ci-dessus et suivez la procédure décrite dans la documentation MetalLB <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">Bien que Red Hat OpenShift et Astra Trident avec NetApp ONTAP ne assurent pas l'isolation des charges de travail par défaut, ils offrent un large éventail de fonctionnalités qui peuvent être utilisées pour configurer la colocation. Pour mieux comprendre comment concevoir une solution mutualisée sur un cluster Red Hat OpenShift avec Astra Trident basée sur NetApp ONTAP, nous examinons un exemple d'exigences et nous présente la configuration qui l'entoure.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">Supposons qu'une entreprise exécute deux de ses charges de travail sur un cluster Red Hat OpenShift dans le cadre de deux projets sur lesquels deux équipes différentes travaillent. Les données de ces workloads résident sur des demandes de volume persistant qui sont provisionnées dynamiquement par Astra Trident sur un back-end NAS NetApp ONTAP. L'entreprise doit concevoir une solution mutualisée pour ces deux charges de travail et isoler les ressources utilisées pour ces projets afin de garantir la sécurité et la performance nécessaires. Elle est axée sur les données qui servent ces applications.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">La figure suivante décrit la solution mutualisée sur un cluster Red Hat OpenShift avec Astra Trident et NetApp ONTAP.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">Colocation sur le cluster Red Hat OpenShift avec Astra Trident et NetApp ONTAP</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">Exigences technologiques</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">Cluster de stockage NetApp ONTAP</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Cluster Red Hat OpenShift</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">Astra Trident</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Ressources Red Hat OpenShift – Cluster</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Du point de vue du cluster Red Hat OpenShift, la ressource de premier niveau à commencer est le projet. Un projet OpenShift peut être considéré comme une ressource de cluster qui divise l'ensemble du cluster OpenShift en plusieurs clusters virtuels. Ainsi, l'isolation au niveau du projet fournit une base pour la configuration de la colocation.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">Ensuite, vous devez configurer RBAC dans le cluster. La meilleure pratique consiste à configurer tous les développeurs sur un seul projet ou charge de travail dans un seul groupe d'utilisateurs du fournisseur d'identités. Red Hat OpenShift permet l'intégration IDP et la synchronisation des groupes d'utilisateurs, ce qui permet d'importer les utilisateurs et les groupes du PDI dans le cluster. Les administrateurs du cluster peuvent ainsi isoler l'accès aux ressources du cluster dédiées à un projet à un ou plusieurs groupes d'utilisateurs travaillant sur ce projet, ce qui limite l'accès non autorisé aux ressources du cluster. Pour en savoir plus sur l'intégration IDP avec Red Hat OpenShift, consultez la documentation<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">Il est important d'isoler le service de stockage partagé en tant que fournisseur de stockage persistant pour un cluster Red Hat OpenShift afin de vérifier que les volumes créés sur le stockage pour chaque projet apparaissent aux hôtes comme s'ils sont créés sur un stockage distinct. Pour ce faire, créez autant de SVM (Storage Virtual machines) sur NetApp ONTAP que des projets ou des charges de travail et dédier chaque SVM à une charge de travail.</block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">Une fois que vous avez des SVM différents pour les projets créés sur NetApp ONTAP, vous devez mapper chaque SVM sur un back-end Trident différent. La configuration back-end de Trident entraîne l'allocation du stockage persistant aux ressources de cluster OpenShift, et elle requiert le mappage des détails de la SVM sur. Il doit s'agir du pilote de protocole pour le back-end au minimum. Vous pouvez également définir la manière dont les volumes sont provisionnés sur le stockage et définir des limites pour la taille des volumes ou l'utilisation des agrégats, etc. Vous trouverez des informations détaillées sur la définition des systèmes back-end Trident<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift – ressources de stockage</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Une fois les systèmes back-end Trident configurés, l'étape suivante consiste à configurer les classes de stockage. Configurez autant de classes de stockage que les systèmes back-end, en donnant à chaque classe de stockage l'accès pour lancer des volumes sur un seul système back-end. Nous pouvons mapper la classe de stockage sur un back-end Trident en utilisant le paramètre storagePools lors de la définition de la classe de stockage. Les détails de la définition d'une classe de stockage sont disponibles<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. Il existe donc un mappage un-à-un de StorageClass vers le backend Trident qui pointe vers un SVM. Ainsi, toutes les demandes de stockage traitées par la classe de stockage allouée à ce projet sont servies par la SVM dédiée à ce projet uniquement.</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">Comme les classes de stockage ne namesles ressources qui ne sont pas adaptées, comment pouvons-nous nous assurer que les déclarations de stockage présentées dans la classe d'un projet par des pods dans un autre espace de noms ou dans des projets sont rejetées ? La réponse est d'utiliser ResourceQuotas. ResourceQuotas sont des objets qui contrôlent l'utilisation totale des ressources par projet. Elle peut limiter le nombre ainsi que la quantité totale de ressources pouvant être consommées par des objets dans le projet. Presque toutes les ressources d'un projet peuvent être limitées à l'aide de ResourceQuotas et l'utilisation efficace de cette solution peut aider les entreprises à réduire les coûts et les pannes dus au sur-provisionnement ou à la sur-consommation des ressources. Reportez-vous à la documentation<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">Pour ce cas d'utilisation, nous devons limiter les demandes de stockage provenant de classes de stockage qui ne sont pas dédiées à leur projet dans un projet particulier. Il nous faut donc limiter les demandes de volume persistant pour d'autres classes de stockage par paramètre<block ref="a21be23447e555ea751318f1aded4a38" prefix=" " category="inline-code"></block> à 0. En outre, un administrateur de cluster doit s'assurer que les développeurs d'un projet ne doivent pas avoir accès pour modifier les ResourceQuotas.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">Suivant : configuration.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">Déploiement de Red Hat OpenShift Virtualization avec NetApp ONTAP</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">Un cluster Red Hat OpenShift (version ultérieure à la version 4.6) installé sur une infrastructure bare-Metal avec des nœuds worker RHCOS</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">Le cluster OpenShift doit être installé via l'infrastructure provisionnée du programme d'installation (IPI).</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">Déploiement de vérifications de l'état des machines pour garantir la haute disponibilité des machines virtuelles</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">Un cluster NetApp ONTAP</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">Astra Trident installé sur le cluster OpenShift</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">Un système back-end Trident configuré avec un SVM sur le cluster ONTAP</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">Classe de stockage configurée sur le cluster OpenShift avec Astra Trident en tant que mécanisme de provisionnement</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">L'accès cluster-admin au cluster Red Hat OpenShift</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">Accès au cluster NetApp ONTAP par administrateur</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">Une station de travail d'administration avec des outils tridentctl et oc installés et ajoutés à $PATH</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">OpenShift Virtualization est gérée par un opérateur installé sur le cluster OpenShift et impose une surcharge supplémentaire pour la mémoire, le processeur et le stockage, ce qui doit être pris en compte lors de la planification des exigences matérielles du cluster. Voir la documentation<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">Vous pouvez également spécifier un sous-ensemble des nœuds du cluster OpenShift pour héberger les opérateurs, contrôleurs et VM OpenShift Virtualization en configurant des règles de placement des nœuds. Pour configurer les règles de placement des nœuds pour OpenShift Virtualization, suivez la documentation<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">Pour la prise en charge du stockage d'OpenShift Virtualization, NetApp recommande d'utiliser une classe de stockage dédiée qui demande le stockage auprès d'un back-end Trident spécifique, qui est ensuite soutenue par un SVM dédié. Cela permet à un niveau d'architecture en colocation s'agissant des données servies aux charges de travail basées sur des VM du cluster OpenShift.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">Suivant : déployer via l'opérateur.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">Pour installer OpenShift Virtualization, procédez comme suit :</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">Connectez-vous au cluster sans système d'exploitation Red Hat OpenShift avec l'accès cluster-admin.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Accédez à Operators &gt; OperatorHub et recherchez OpenShift Virtualization.</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">Sélectionnez la mosaïque OpenShift Virtualization et cliquez sur Install.</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">Titre de l'opérateur OpenShift Virtualization</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Sur l'écran installer l'opérateur, laissez tous les paramètres par défaut et cliquez sur installer.</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">Informations sur l'opérateur de virtualisation OpenShift</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">Installation d'OpenShift Virtualization Operator</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">Une fois l'opérateur installé, cliquez sur Créer une Hyperconvergé.</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">Opérateur de virtualisation OpenShift - Créer une infrastructure hyperconvergée</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">Sur l'écran Créer une Hyperconvergeance, cliquez sur Créer, accepter tous les paramètres par défaut. Cette étape démarre l'installation d'OpenShift Virtualization.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">Opérateur de virtualisation OpenShift - Détails des infrastructures hyperconvergées</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">Une fois que tous les pods passent à l'état d'exécution dans l'espace de noms openshift-cnv et que l'opérateur OpenShift Virtualization est dans l'état « réussi », l'opérateur est prêt à l'emploi. Les VM peuvent désormais être créés sur le cluster OpenShift.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">Installation de l'opérateur de virtualisation OpenShift terminée</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">Next : workflows : création d'une machine virtuelle.</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">Configuration : tâches d'administration du stockage</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">Les ressources suivantes doivent être configurées par un administrateur de stockage :</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">Connectez-vous au cluster NetApp ONTAP en tant qu'administrateur.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Accédez à Storage &gt; Storage VM et cliquez sur Add. Créer deux SVM, un pour le projet-1 et l'autre pour le projet-2, en fournissant les détails requis. Créer également un compte vsadmin pour gérer le SVM et ses ressources</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">Création de SVM sur ONTAP</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">Connectez-vous au cluster Red Hat OpenShift en tant qu'administrateur du stockage.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">Créer le backend pour projet-1 et le mapper au SVM dédié au projet NetApp recommande d'utiliser le compte vsadmin du SVM afin de connecter le backend au SVM au lieu d'utiliser l'administrateur du cluster ONTAP</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">Nous utilisons le pilote ontap-nas dans cet exemple. Utilisez le pilote approprié lors de la création du back-end en fonction du cas d'utilisation.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">Créer de la même manière le back-end Trident pour le projet-2 et le mapper sur le SVM dédié au projet-2.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">Créez ensuite les classes de stockage. Créez la classe de stockage pour Project-1 et configurez-la pour utiliser les pools de stockage du back-end dédié au projet-1 en définissant le paramètre storagePools.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">De même, créez une classe de stockage pour Project-2 et configurez-la pour utiliser les pools de stockage du système back-end dédié au projet-2.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">Créer un Resourcequota pour limiter les ressources dans le projet-1 demandant le stockage de storageclasses dédiés à d'autres projets.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">De même, créez un Resourcequota pour limiter les ressources du projet 2 demandant du stockage de storageclasses dédiés à d'autres projets.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">Suivant : validation.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">Un cluster Red Hat OpenShift (supérieur à la version 4.5) pour le cluster Hub</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">Clusters Red Hat OpenShift (supérieurs à la version 4.4.3) pour les clusters gérés</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">L'accès cluster-admin au cluster Red Hat OpenShift</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Un abonnement Red Hat à Advanced Cluster Management pour Kubernetes</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management est un module complémentaire du cluster OpenShift. Il existe donc certaines conditions et restrictions sur les ressources matérielles en fonction des fonctionnalités utilisées sur le concentrateur et les clusters gérés. Vous devez tenir compte de ces problèmes lors du dimensionnement des clusters. Voir la documentation<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> pour en savoir plus.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">Si le cluster Hub dispose de nœuds dédiés pour héberger les composants de l'infrastructure et que vous souhaitez installer les ressources Advanced Cluster Management uniquement sur ces nœuds, vous devez ajouter des tolérances et des sélecteurs à ces nœuds en conséquence. Pour plus de détails, consultez la documentation<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">Suivant : installation.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">Accélérez le développement logiciel avec Astra Control et la technologie NetApp FlexClone : Red Hat OpenShift avec NetApp</block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">Le logiciel NetApp Element offre des performances modulaires et évolutives, avec chaque nœud de stockage, qui garantissent la capacité et le débit à l'environnement. Les systèmes NetApp Element peuvent évoluer de 4 à 100 nœuds dans un seul cluster et offrir de nombreuses fonctionnalités avancées de gestion du stockage.</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">Le logiciel NetApp Element offre des performances modulaires et évolutives, avec chaque nœud de stockage, qui garantissent la capacité et le débit à l'environnement. Les systèmes NetApp Element peuvent évoluer de 4 à 100 nœuds dans un seul cluster et offrir de nombreuses fonctionnalités avancées de gestion du stockage.</block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">Site Web NetApp SolidFire</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">Pour plus d'informations sur les systèmes de stockage NetApp Element, consultez la<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">Fonctionnalités de redirection de connexion iSCSI et d'auto-rétablissement</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">Le logiciel NetApp Element s'appuie sur le protocole de stockage iSCSI, une méthode standard pour encapsuler les commandes SCSI sur un réseau TCP/IP traditionnel. Lorsque les normes SCSI changent ou que les performances des réseaux Ethernet s'améliorent, le protocole de stockage iSCSI est avantageux sans qu'il soit nécessaire de procéder à des modifications.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">Bien que tous les nœuds de stockage aient une adresse IP de gestion et une adresse IP de stockage, le logiciel NetApp Element annonce une adresse IP virtuelle de stockage unique (adresse SVIP) pour l'ensemble du trafic de stockage du cluster. Dans le cadre du processus de connexion iSCSI, le stockage peut répondre que le volume cible a été déplacé vers une autre adresse et qu'il ne peut donc pas poursuivre le processus de négociation. L'hôte réémet alors la demande de connexion vers la nouvelle adresse dans un processus qui ne nécessite aucune reconfiguration côté hôte. Ce processus est connu sous le nom de redirection de connexion iSCSI.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">La redirection de connexion iSCSI est un élément clé du cluster logiciel NetApp Element. En cas de réception d'une requête de connexion d'hôte, le nœud décide quel membre du cluster doit gérer le trafic en fonction des IOPS et des exigences de capacité du volume. Les volumes sont répartis sur le cluster logiciel NetApp Element et sont redistribués si un seul nœud traite un trop grand trafic pour ses volumes ou si un nouveau nœud est ajouté. Plusieurs copies d'un volume donné sont allouées à travers la baie.</block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">Ainsi, si une défaillance de nœud est suivie d'une redistribution du volume, la connectivité hôte n'a aucun effet au-delà d'une déconnexion et d'une connexion avec redirection vers le nouvel emplacement. Avec la redirection de connexion iSCSI, un cluster logiciel NetApp Element est une architecture scale-out autoréparatrice qui permet des mises à niveau et des opérations sans interruption.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">Qualité de service du cluster logiciel NetApp Element</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">Un cluster logiciel NetApp Element permet la configuration dynamique de la QoS par volume. Vous pouvez utiliser les paramètres QoS par volume pour contrôler les performances du stockage en fonction des SLA que vous définissez. Les trois paramètres configurables suivants définissent la QoS :</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">*IOPS minimum.* nombre minimum d'IOPS soutenues que le cluster logiciel NetApp Element fournit à un volume. La valeur d'IOPS minimale configurée pour un volume correspond au niveau garanti de performance d'un volume. La performance par volume ne descend pas en dessous de ce niveau.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">*Nombre maximal d'IOPS.* nombre maximal d'IOPS soutenu que le cluster logiciel NetApp Element fournit à un volume donné.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">*IOPS en rafale.* le nombre maximal d'IOPS autorisé dans un scénario en rafale courte. Le paramètre de durée de rafale est configurable, avec une valeur par défaut de 1 minute. Si un volume a été exécuté en dessous du niveau d'IOPS maximal, les crédits de bursting sont accumulés. Lorsque les niveaux de performance deviennent très élevés et sont poussés, les pics d'IOPS en dehors des IOPS maximales sont autorisés sur le volume.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">Colocation</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">La colocation sécurisée offre les fonctionnalités suivantes :</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">*Authentification sécurisée.* le protocole CHAP (Challenge-Handshake Authentication Protocol) est utilisé pour sécuriser l'accès au volume. Le protocole LDAP (Lightweight Directory Access Protocol) est utilisé pour sécuriser l'accès au cluster à des fins de gestion et de reporting.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">*Groupes d'accès de volume (VAGs).* si vous le souhaitez, les VAGs peuvent être utilisés à la place de l'authentification, mappant n'importe quel nombre de noms iSCSI qualifiés (IQN) spécifiques à un initiateur iSCSI à un ou plusieurs volumes. Pour accéder à un volume dans un VAG, l’IQN de l’initiateur doit figurer dans la liste IQN autorisé pour le groupe de volumes.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">*Réseaux locaux virtuels (VLAN) locataires.* au niveau du réseau, la sécurité réseau de bout en bout entre les initiateurs iSCSI et le cluster logiciel NetApp Element est facilitée par l'utilisation de VLAN. Pour tout VLAN créé pour isoler une charge de travail ou un locataire, le logiciel NetApp Element crée une adresse SVIP cible iSCSI distincte accessible uniquement via le VLAN spécifique.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">*VLAN activés par VRF* pour prendre en charge encore plus la sécurité et l'évolutivité dans le data Center, le logiciel NetApp Element vous permet d'activer n'importe quel VLAN locataire pour les fonctionnalités de type VRF. Cette fonctionnalité offre deux fonctionnalités clés :</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">*Routage L3 vers une adresse SVIP locataire.* cette fonctionnalité vous permet de situer les initiateurs iSCSI sur un réseau ou VLAN séparé de celui du cluster logiciel NetApp Element.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">*Sous-réseaux IP redondants ou dupliqués.* cette fonctionnalité vous permet d'ajouter un modèle aux environnements de tenant, permettant à chaque VLAN locataire respectif d'être affectés à des adresses IP à partir du même sous-réseau IP. Cette fonctionnalité peut être utile pour les environnements de fournisseurs de services où l'évolutivité et la préservation de l'IPspace sont importantes.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">Fonctionnalités d'efficacité du stockage</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">Le cluster logiciel NetApp Element améliore les performances et l'efficacité de stockage globales. Les fonctionnalités suivantes sont effectuées en ligne, sont toujours disponibles et ne nécessitent aucune configuration manuelle de la part de l'utilisateur :</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">*Déduplication.* le système stocke uniquement des blocs 4K uniques. Tous les blocs de 4 Ko dupliqués sont automatiquement associés à une version déjà stockée des données. Les données se trouvent sur des disques de niveau bloc et sont mises en miroir à l'aide du logiciel NetApp Element, protection des données Helix. Ce système réduit considérablement la consommation de capacité et les opérations d'écriture dans le système.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">*Compression.* la compression est effectuée en ligne avant que les données ne soient écrites dans la NVRAM. Les données sont compressées, stockées sous forme de blocs de 4 Ko, et restent compressées dans le système. Cette compression réduit considérablement la consommation de capacité, les opérations d'écriture et la consommation de bande passante dans le cluster.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">*Provisionnement fin.* cette fonctionnalité fournit la quantité de stockage appropriée au moment où vous en avez besoin, ce qui élimine la consommation de capacité provoquée par des volumes surprovisionnés ou sous-exploités.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">*Helix.* les métadonnées d'un volume individuel sont stockées sur un lecteur de métadonnées et sont répliquées sur un lecteur de métadonnées secondaire pour assurer la redondance.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">Element a été conçu pour l'automatisation. Toutes les fonctionnalités de stockage sont disponibles par le biais d'API. Ces API sont la seule méthode que l'interface utilisateur utilise pour contrôler le système.</block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">Cette page détaille les instructions d'installation et de configuration de l'équilibreur de charge.</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">Installation d'équilibreurs de charge en lacet</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">Cette page répertorie les instructions d'installation et de configuration de l'équilibreur de charge géré seesaw.</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">Seesaw est l'équilibreur de charge réseau géré par défaut installé dans un environnement Anthos de clusters sur VMware de versions 1.6 à 1.10.</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">Installation de l'équilibreur de charge en lacet</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">L'équilibreur de charge Seesaw est entièrement intégré aux clusters Anthos sur VMware. Le déploiement est automatisé dans le cadre des configurations de cluster Admin et User. Il y a des blocs de texte dans le<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> les fichiers de configuration qui doivent être modifiés pour fournir des informations sur l'équilibreur de charge, puis une étape supplémentaire est nécessaire avant le déploiement du cluster pour déployer l'équilibreur de charge à l'aide du logiciel intégré<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> outil.</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">Des équilibreurs de charge séesaw peuvent être déployés en mode HA ou non HA. Aux fins de cette validation, l'équilibreur de charge en lacet a été déployé en mode non HA, qui est le paramètre par défaut. Pour des raisons de production, NetApp recommande de déployer des technologies de seesaw dans une configuration haute disponibilité à des fins de tolérance aux pannes et de fiabilité.</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Intégration avec Anthos</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">Il existe une section dans chaque fichier de configuration, respectivement pour le cluster d'administration et dans chaque cluster utilisateur que vous choisissez de déployer pour configurer l'équilibreur de charge afin qu'il soit géré par Anthos sur site.</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">Le texte suivant est un exemple de la configuration de la partition pour le cluster GKE-Admin. Les valeurs qui doivent être non commentées et modifiées sont placées en gras ci-dessous :</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">L'équilibreur de charge a également un statique séparé<block ref="d218bc0ba36a7fb2d7aea32df7659206" prefix=" " category="inline-code"></block> fichier que vous devez fournir pour chaque déploiement de cluster. Ce fichier doit se trouver dans le même répertoire que le<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> le fichier de déploiement ou le chemin complet doit être spécifié dans la section ci-dessus.</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">Un échantillon du<block ref="1db10b36979626249cbedcd8e8818146" prefix=" " category="inline-code"></block> le fichier ressemble au script suivant :</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">Ce fichier fournit la passerelle et le masque de réseau du réseau que fournit l'équilibreur de charge au cluster sous-jacent, ainsi que l'adresse IP de gestion et le nom d'hôte de la machine virtuelle déployée pour exécuter l'équilibreur de charge.</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Anthos.</block>
  <block id="c91efa18f13fad38864e99107352d0c5" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Anthos. Trident fonctionne avec l'ensemble de la gamme de solutions de stockage NetApp, notamment les systèmes de stockage NetApp ONTAP et Element, et prend également en charge les connexions NFS et iSCSI. Trident accélère le workflow DevOps en permettant aux utilisateurs d'approvisionner et de gérer le stockage à partir de leurs systèmes de stockage NetApp, sans intervention de l'administrateur de stockage.</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">Un administrateur peut configurer plusieurs systèmes de stockage back-end en fonction des besoins des projets et des modèles de systèmes de stockage. Ces fonctionnalités avancées incluent la compression, des types de disques spécifiques et des niveaux de QoS garantissant un certain niveau de performance. Une fois définis, ces systèmes back-end peuvent être utilisés par les développeurs dans leurs projets pour créer des demandes de volume persistant et connecter le stockage persistant à la demande dans leurs conteneurs.</block>
  <block id="fbc20d9fb2c2f042edf73e3b39b3278a" category="paragraph"><block ref="fbc20d9fb2c2f042edf73e3b39b3278a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="239c66c0132fd8324d609e4f1ce89f79" category="paragraph">La dernière version d'Astra Trident, 22.04, a été lancée en avril 2022. Une matrice de prise en charge pour quelle version de Trident a été testée avec laquelle une distribution Kubernetes est disponible<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">Avec la version 22.04, un graphique Helm a été disponible pour faciliter l'installation de l'opérateur Trident.</block>
  <block id="27bed77b9cf648bc4592d40c2806fb43" category="paragraph">Pour utiliser Helm pour automatiser l'installation de Trident sur le cluster utilisateur déployé et provisionner un volume persistant, effectuez les étapes suivantes :</block>
  <block id="c9c8f06cd5f25063dedfc6eea2b08fa7" category="inline-link">Page d'installation de Helm</block>
  <block id="c49053fbce1331670d3c2e81d9625fec" category="admonition">Helm n'est pas installé par défaut sur la station de travail GKE-Admin. Il peut être téléchargé dans un format binaire qui fonctionne avec Ubuntu à partir du<block ref="3d578643c15f985f07ca6d975ab0e791" category="inline-link-rx"></block>.</block>
  <block id="43eba64dcd06763432addbcf8db2d367" category="list-text">Ajout du référentiel Trident Helm :</block>
  <block id="6a05a869c72ac896a6f7473fba5c9b1e" category="paragraph">Pour installer manuellement Trident sur le cluster d'utilisateurs déployé et provisionner un volume persistant, effectuez les opérations suivantes :</block>
  <block id="79273cfc4ab66c2763755b11b14fedb9" category="list-text">Téléchargez l'archive d'installation sur la station de travail d'administration et extrayez son contenu. La version actuelle de Trident est la version 22.04, que vous pouvez télécharger<block ref="c7e04c62da3fb5014b467863172d941c" category="inline-link-rx"></block>.</block>
  <block id="f0d8974fd014601f60573d339d525772" category="list-text">Définissez l'emplacement du cluster utilisateur<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Fichier en tant que variable d'environnement pour que vous n'ayez pas à le référencer, car Trident n'a pas d'option pour transmettre ce fichier.</block>
  <block id="deae9c61cc109057bffb21d54fd54cdc" category="paragraph">Une fois l'installation d'Astra Trident Operator, vous devez configurer le système back-end pour la plateforme de stockage NetApp spécifique que vous utilisez. Suivez le lien ci-dessous pour continuer l'installation et la configuration d'Astra Trident.</block>
  <block id="6ed9d9e6160cedf6c16c9fa74e9d08aa" category="inline-link-macro">Suivant : NetApp ONTAP NFS.</block>
  <block id="86beb69e1e89df92a89baa0d004b08b8" category="paragraph"><block ref="86beb69e1e89df92a89baa0d004b08b8" category="inline-link-macro-rx"></block></block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">Cette section est dédiée aux personnalisations que les utilisateurs du monde réel devraient probablement réaliser lors du déploiement de cette solution en production, telles que le déploiement d'instances personnalisées d'équilibreur de charge.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="doc">Options de configuration avancées</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">La solution la plus facile à déployer est généralement la mieux adaptée, mais dans certains cas, des personnalisations avancées sont nécessaires pour satisfaire les exigences ou les spécifications d'une application spécifique ou de l'environnement vers lequel la solution est déployée. À cette fin, la solution Red Hat OpenShift avec NetApp offre les personnalisations suivantes pour satisfaire ces besoins.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">Cette section décrit quelques options de configuration avancées, telles que l'utilisation d'équilibreurs de charge tiers ou la création d'un registre privé pour héberger des images de conteneurs personnalisées. Les deux conditions requises pour l'installation du centre de contrôle NetApp Astra sont essentielles.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les options de configuration avancée validées dans la solution Red Hat OpenShift avec NetApp :</block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">Suivant : exploration des options d'équilibrage de la charge.</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">Une sauvegarde d'une application capture l'état actif de l'application et la configuration de ses ressources, les analyse dans des fichiers et les stocke dans un compartiment de stockage objet distant.</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">Pour créer une sauvegarde d'application, procédez comme suit :</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Pour créer une sauvegarde de l'application gérée dans Astra Control Center, accédez à applications &gt; géré et cliquez sur l'application dont vous souhaitez effectuer la sauvegarde. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur Sauvegarder.</block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">Entrez les détails de la sauvegarde, sélectionnez le compartiment de stockage objet pour contenir les fichiers de sauvegarde, puis cliquez sur Next (Suivant). Après avoir vérifié les détails, cliquez sur Sauvegarder. Selon la taille de l'application et des données, la sauvegarde peut prendre plusieurs minutes. L'état de la sauvegarde devient disponible une fois la sauvegarde terminée.</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">Pour restaurer une application, procédez comme suit :</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">Accédez à applications &gt; onglet géré et cliquez sur l'application en question. Cliquez sur le menu déroulant en regard du nom de l'application et cliquez sur Restaurer.</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">Pour cloner une application, accédez à l'onglet applications &gt; gestion, puis cliquez sur l'application en question. Cliquez sur le menu déroulant en regard du nom de l'application, puis cliquez sur Cloner.</block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">Entrez les détails du nouvel espace de noms, sélectionnez le cluster vers lequel vous souhaitez le cloner à partir d'un snapshot existant, d'une sauvegarde ou de l'état actuel de l'application. Cliquez sur Suivant, puis sur Cloner dans le volet Revue après avoir consulté les détails.</block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">La nouvelle application passe à l'état découverte pendant que le Centre de contrôle Astra crée l'application sur le groupe d'instruments sélectionné. Une fois que toutes les ressources de l'application sont installées et détectées par Astra, l'application passe à l'état disponible.</block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp propose plusieurs produits qui aident nos clients à orchestrer et à gérer les données persistantes dans des environnements basés sur des conteneurs, tels que Anthos.</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Programme partenaire pour le stockage Anthos Ready.</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud demande régulièrement la mise à jour des intégrations du stockage pour les partenaires avec les nouvelles versions de Anthos dans le cadre de leur programme de partenariat pour le stockage Anthos. Vous trouverez une liste des solutions de stockage actuellement validées, des pilotes CSI, des fonctionnalités disponibles et des versions de Anthos prises en charge<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>.</block>
  <block id="ea3b8c601657928fee815e0d16908cf1" category="paragraph">NetApp a maintenu une conformité trimestrielle avec des demandes de validation de notre orchestrateur de stockage conforme à la gamme Astra Trident CSI et de nos systèmes de stockage ONTAP et Element avec des versions de Anthos.</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">Le tableau suivant contient les versions Anthos testées par les ingénieurs partenaires NetApp et NetApp pour la validation des pilotes et des ensembles de fonctionnalités NetApp Astra Trident CSI, dans le cadre du programme partenaires pour le stockage Anthos Ready :</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">Type de déploiement</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">System de stockage</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Version d'Astra Trident</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">Rédacteur multiple, extension de volume, snapshots</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">SAN</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">Bloc brut, extension de volume, snapshots</block>
  <block id="231afe47f3f37d3808096b36c28b4ded" category="cell">Elément</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">bare-metal</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp propose plusieurs produits pour orchestrer et gérer les données persistantes dans des environnements basés sur des conteneurs, tels que Anthos.</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Anthos. Pour en savoir plus, rendez-vous sur le site Web Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les produits NetApp validés pour la gestion des applications et du stockage persistant dans la solution Anthos avec NetApp.</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">Ensuite, présentation de NetApp Astra Trident.</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">*NetApp SnapLock.* administration efficace des données non réinscriptibles en les écrivant sur des volumes spéciaux qui ne peuvent pas être écrasés ou effacés pour une période déterminée.</block>
  <block id="99634a0c579c45d299cfbb8b818c51bb" category="paragraph"><block ref="99634a0c579c45d299cfbb8b818c51bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp offre des plateformes de stockage FAS fiables, 100 % Flash (AFF) et scale-out, sur mesure et offrant une faible latence, une protection des données intégrée et une prise en charge multiprotocole.</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">Ces deux systèmes sont optimisés par le logiciel de gestion des données NetApp ONTAP, le logiciel de gestion des données le plus avancé du secteur pour une gestion du stockage simplifiée, intégrée au cloud et hautement disponible. Il offre la vitesse, l'efficacité et la sécurité dont votre environnement Data Fabric a besoin.</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">Pour en savoir plus sur LES plateformes NETAPP AFF et FAS, cliquez<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="0a180196354cfbb6ec70b20db067fa6b" category="inline-link-macro">Suivant : NetApp Element.</block>
  <block id="73978739caea0775c3c807ecfc27f0c0" category="paragraph"><block ref="73978739caea0775c3c807ecfc27f0c0" category="inline-link-macro-rx"></block></block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">Cette section traite des options d'équilibrage de charge pour les utilisateurs qui souhaitent personnaliser Anthos avec le déploiement NetApp.</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">Exploration des options de l'équilibreur de charge</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Une application déployée dans Anthos est exposée au monde par un service fourni par un équilibreur de charge déployé dans l'environnement sur site Anthos.</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">Les pages suivantes contiennent des informations supplémentaires sur les options d'équilibreur de charge validées dans la solution Anthos avec NetApp :</block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="inline-link-macro">Installation des équilibreurs de charge F5 BIG-IP</block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="inline-link-macro">Installation des équilibreurs de charge MetalLB</block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">Suivant : installation de l'équilibreur de charge F5 BIG-IP.</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">Il y a un champ facultatif appelé<block ref="7cfbb6f07899c8071ff38e69dca190e2" prefix=" " category="inline-code"></block> qui est défini dans ce fichier. Dans les systèmes back-end iSCSI, cette valeur peut être définie sur un type de système de fichiers Linux spécifique (XFS, ext4, etc.), ou elle peut être supprimée pour permettre au système d'exploitation du nœud de travail de décider quel système de fichiers utiliser.</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">Exécutez le<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> pour créer la classe de stockage.</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">Créez le PVC en émettant le<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> commande. La création peut prendre un certain temps en fonction de la taille du volume de sauvegarde en cours de création, de sorte que vous pouvez regarder le processus au fur et à mesure qu'il se termine.</block>
  <block id="06a9f54df07db88477918bd7c3f597de" category="inline-link-macro">Suivant : iSCSI NetApp Element.</block>
  <block id="dd8532ad7059feaef43031ffa5970de1" category="paragraph"><block ref="dd8532ad7059feaef43031ffa5970de1" category="inline-link-macro-rx"></block></block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="summary">F5 BIG-IP est un contrôleur de distribution d'applications (ADC) qui offre un large éventail de services avancés de gestion du trafic et de sécurité de niveau production, tels que L4-L7 d'équilibrage de charge, de déchargement SSL/TLS, DNS, pare-feu et bien d'autres. Ces services augmentent considérablement la disponibilité, la sécurité et les performances de vos applications.</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IP est un contrôleur de distribution d'applications (ADC) qui offre un large éventail de services avancés de gestion du trafic et de sécurité de niveau production, tels que L4-L7 d'équilibrage de charge, de déchargement SSL/TLS, DNS, pare-feu, etc. Ces services améliorent considérablement la disponibilité, la sécurité et les performances de vos applications.</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IP peut être déployé et utilisé de différentes façons, notamment sur du matériel dédié, dans le cloud ou en tant qu'appliance virtuelle sur site. Consultez la documentation ici pour explorer et déployer F5 BIG-IP.</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IP a été la première solution d'équilibrage de charge fournie avec Anthos sur site. Elle a été utilisée pour valider les premières validations déjà validées par nos partenaires pour Anthos avec la solution NetApp.</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IP peut être déployé en mode autonome ou en mode cluster. Pour cette validation, F5 BIG-IP a été déployé en mode autonome. Cependant, à des fins de production, NetApp recommande de créer un cluster d'instances BIG-IP afin d'éviter les points de défaillance uniques.</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">Cette solution utilise l'appliance virtuelle déployée dans VMware vSphere. La mise en réseau de l'appliance virtuelle F5 Big-IP peut être configurée dans une configuration à deux ou trois armées en fonction de l'environnement réseau. Le déploiement dans ce document est basé sur la configuration à deux bras. Vous trouverez des détails supplémentaires sur la configuration de l'appliance virtuelle pour Anthos<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>.</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">L'équipe d'ingénierie des solutions NetApp a validé les versions présentées dans le tableau suivant dans notre laboratoire pour les déploiements Anthos sur site :</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">Marque</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">Pour installer F5 BIG-IP, procédez comme suit :</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">Téléchargez le fichier OVA (Virtual Appliance) de l'application virtuelle depuis F5<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>.</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">Pour télécharger l'appliance, l'utilisateur doit s'inscrire auprès de F5. Ils fournissent une licence de démonstration de 30 jours pour Big-IP Virtual Edition Load Balancer. NetApp recommande de disposer d'une licence permanente de 10 Gbit/s pour le déploiement en production d'une appliance.</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">Cliquez avec le bouton droit de la souris sur le pool de ressources d'infrastructure et sélectionnez déployer le modèle OVF. Un assistant se lance pour vous permettre de sélectionner le fichier OVA que vous venez de télécharger à l'étape 1. Cliquez sur Suivant.</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="inline-image-macro">Déployez une appliance Big-IP</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">Cliquez sur Suivant pour passer à chaque étape et accepter les valeurs par défaut pour chaque écran affiché jusqu'à ce que vous attetiez l'écran de sélection du stockage. Sélectionnez le VM_datastore sur lequel vous souhaitez déployer la machine virtuelle, puis cliquez sur « Next » (Suivant).</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">L'écran suivant présenté par l'assistant vous permet de personnaliser les réseaux virtuels à utiliser dans l'environnement. Sélectionnez VM_Network pour le champ externe et sélectionnez Management_Network pour le champ gestion. En effet, les configurations internes et haute disponibilité sont utilisées pour les configurations avancées de l'appliance F5 Big-IP et ne sont pas configurées. Ces paramètres peuvent être laissés seuls, ou ils peuvent être configurés pour se connecter à des groupes de ports distribués non liés à l'infrastructure. Cliquez sur Suivant.</block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Déployer l'appliance Big_IP, 2e partie</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">Vérifiez l'écran de résumé de l'appliance et, si toutes les informations sont correctes, cliquez sur Terminer pour lancer le déploiement.</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">Une fois l'appliance virtuelle déployée, cliquez dessus avec le bouton droit de la souris et mettez-la sous tension. Il doit recevoir une adresse DHCP sur le réseau de gestion. L'appliance est basée sur Linux et VMware Tools est déployé pour vous permettre d'afficher l'adresse DHCP qu'elle reçoit dans le client vSphere.</block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">Déployer l'appliance Big-IP, partie 3</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">Ouvrez un navigateur Web et connectez-vous à l'appliance à l'adresse IP de l'étape précédente. La connexion par défaut est admin/admin. Après la première connexion, l'appliance vous invite immédiatement à modifier le mot de passe admin. Elle vous renvoie alors à un écran où vous devez vous connecter avec les nouvelles informations d'identification.</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="inline-image-macro">Configuration BIG-IP</block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">Le premier écran invite l'utilisateur à terminer l'utilitaire de configuration. Commencez l'utilitaire en cliquant sur Suivant.</block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">Configuration BIG-IP, partie 2</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">L'écran suivant vous invite à activer la licence pour l'appareil. Cliquez sur Activer pour commencer. Lorsque vous y êtes invité à la page suivante, collez soit la clé de licence d'évaluation de 30 jours que vous avez reçue lorsque vous vous êtes inscrit au téléchargement, soit la licence permanente que vous avez acquise lors de l'achat de l'appareil. Cliquez sur Suivant.</block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">Configuration BIG-IP, partie 3</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">Pour que le terminal puisse effectuer l'activation, le réseau défini sur l'interface de gestion doit pouvoir accéder à Internet.</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">L'écran suivant présente le contrat de licence utilisateur final (CLUF). Si les termes de la licence sont acceptables, cliquez sur accepter.</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">L'écran suivant compte le temps écoulé lorsqu'il vérifie les modifications de configuration effectuées jusqu'à présent. Cliquez sur Continuer pour reprendre la configuration initiale.</block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">Configuration BIG-IP, partie 4</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">La fenêtre modification de la configuration se ferme et l'utilitaire de configuration affiche le menu approvisionnement des ressources. Cette fenêtre répertorie les fonctions actuellement sous licence et les allocations de ressources actuelles pour l'appliance virtuelle et chaque service en cours d'exécution.</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">Cliquer sur l'option de menu plate-forme sur la gauche permet une modification supplémentaire de la plate-forme. Les modifications incluent la définition de l'adresse IP de gestion configurée avec DHCP, la définition du nom d'hôte et du fuseau horaire dans lequel l'appliance est installée, et la sécurisation de l'appliance contre l'accessibilité SSH.</block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">Configuration BIG-IP, partie 6</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">Cliquez ensuite sur le menu réseau, qui vous permet de configurer les fonctions réseau standard. Cliquez sur Suivant pour lancer l'assistant Configuration réseau standard.</block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">Configuration BIG-IP, partie 7</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">La première page de l'assistant configure la redondance ; laissez les valeurs par défaut et cliquez sur Next (Suivant). La page suivante vous permet de configurer une interface interne sur l'équilibreur de charge. L'interface 1.1 correspond au VMNIC étiqueté interne dans l'assistant de déploiement OVF.</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">Configuration BIG-IP, partie 8</block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">Les espaces de cette page pour l'adresse IP personnelle, le masque de réseau et l'adresse IP flottante peuvent être remplis d'une adresse IP non routable à utiliser comme emplacement réservé. Ils peuvent également être remplis d'un réseau interne qui a été configuré en tant que groupe de ports distribués pour les invités virtuels si vous déployez la configuration à trois armées. Elles doivent être terminées pour continuer avec l'assistant.</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">La page suivante vous permet de configurer un réseau externe utilisé pour mapper les services sur les pods déployés dans Kubernetes. Sélectionnez une adresse IP statique dans la plage VM_Network, le masque de sous-réseau approprié et une adresse IP flottante dans cette plage. L'interface 1.2 correspond au VMNIC étiqueté externe dans l'assistant de déploiement OVF.</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">Configuration BIG-IP, partie 9</block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">Sur la page suivante, vous pouvez configurer un réseau haute disponibilité interne si vous déployez plusieurs appliances virtuelles dans l'environnement. Pour continuer, vous devez remplir les champs adresse IP auto-IP et masque réseau, et vous devez sélectionner interface 1.3 comme interface VLAN, qui correspond au réseau HA défini par l'assistant modèle OVF.</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">Configuration BIG-IP, partie 10</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">La page suivante vous permet de configurer les serveurs NTP. Cliquez ensuite sur Suivant pour continuer la configuration DNS. Les serveurs DNS et la liste de recherche de domaine doivent déjà être renseignés par le serveur DHCP. Cliquez sur Suivant pour accepter les valeurs par défaut et continuer.</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">Pour le reste de l'assistant, cliquez sur Next (Suivant) pour poursuivre la configuration du peering avancé, dont la configuration dépasse le cadre de ce document. Cliquez ensuite sur Terminer pour quitter l'assistant.</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Créez des partitions individuelles pour le cluster d'administration Anthos et chaque cluster utilisateur déployé dans l'environnement. Cliquez sur système dans le menu de gauche, accédez aux utilisateurs et cliquez sur liste des partitions.</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">Configuration BIG-IP, partie 11</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">L'écran affiché indique uniquement la partition commune actuelle. Cliquez sur Créer à droite pour créer la première partition supplémentaire et nommez-la<block ref="7b8bd901f7c351d00688bb6fecf79a3c" prefix=" " category="inline-code"></block>. Cliquez ensuite sur répéter et nommez la partition<block ref="b328b4839c0f0e2bfc22ab6fca60065e" prefix=" " category="inline-code"></block>. Cliquez à nouveau sur le bouton répéter pour nommer la partition suivante<block ref="916e48fa5c2bc8c7765c99a8f011dccb" prefix=" " category="inline-code"></block>. Enfin, cliquez sur terminé pour terminer l'assistant. L'écran liste des partitions s'affiche à nouveau avec toutes les partitions répertoriées.</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">Configuration BIG-IP, partie 12</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">Il existe une section dans chaque fichier de configuration, respectivement pour le cluster d'administration et chaque cluster utilisateur que vous choisissez de déployer pour configurer l'équilibreur de charge afin qu'il soit géré par Anthos sur site.</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">Le script suivant est un exemple de la configuration de la partition pour le cluster GKE-Admin. Les valeurs qui doivent être non commentées et modifiées sont placées en gras ci-dessous :</block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">Suivant : installation des équilibreurs de charge MetalLB.</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">Cette section vise à créer et à configurer un registre d'images privées avec le stockage persistant d'Astra Trident.</block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">Création de registres d'images privées</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">Quay.io</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">Pour la plupart des déploiements de Red Hat OpenShift, à l'aide d'un registre public comme<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> ou<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> répond à la plupart des besoins des clients. Cependant, il se peut qu'un client souhaite héberger ses propres images privées ou personnalisées.</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">Cette procédure décrit la création d'un registre d'images privées, sauvegardé par un volume persistant fourni par Astra Trident et NetApp ONTAP.</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center requiert un registre pour héberger les images dont les conteneurs Astra ont besoin. La section suivante décrit les étapes de configuration d'un registre privé sur un cluster Red Hat OpenShift et l'envoi des images requises pour prendre en charge l'installation d'Astra Control Center.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">Création d'un registre d'images privé</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">Supprimez l'annotation par défaut de la classe de stockage par défaut actuelle et annoter la classe de stockage sauvegardée par Trident par défaut pour le cluster OpenShift.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">Modifiez l'opérateur imageistry en saisissant les paramètres de stockage suivants dans le<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> section.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">Entrez les paramètres suivants dans le<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> Section permettant de créer une route OpenShift avec un nom d'hôte personnalisé. Enregistrer et quitter.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">La configuration de route ci-dessus est utilisée lorsque vous voulez un nom d'hôte personnalisé pour votre itinéraire. Si vous souhaitez qu'OpenShift crée une route avec un nom d'hôte par défaut, vous pouvez ajouter les paramètres suivants à l'<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> section :<block ref="b09e8357c45c55a2c3ca685c9742fa6e" prefix=" " category="inline-code"></block>.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">Certificats TLS personnalisés</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">Lorsque vous utilisez un nom d'hôte personnalisé pour la route, il utilise par défaut la configuration TLS par défaut de l'opérateur OpenShift Ingress. Cependant, vous pouvez ajouter une configuration TLS personnalisée à la route. Pour ce faire, procédez comme suit.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">Créez un secret avec les certificats TLS et la clé de la route.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Modifiez l'opérateur imageistry et ajoutez les paramètres suivants à la<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> section.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">Modifiez à nouveau l'opérateur imageistry et modifiez l'état de gestion de l'opérateur sur<block ref="80c202b1c3fd395a7bfe4d846c914bc3" prefix=" " category="inline-code"></block> état. Enregistrer et quitter.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">Si toutes les conditions préalables sont remplies, les ESV, les pods et les services sont créés pour le registre d'images privées. Dans quelques minutes, le registre devrait être mis en service.</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">Si vous utilisez les certificats TLS par défaut pour la route de registre OpenShift de l'opérateur d'entrée, vous pouvez récupérer les certificats TLS à l'aide de la commande suivante :</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">Pour permettre aux nœuds OpenShift d'accéder aux images et de les extraire du registre, ajoutez les certificats au client docker sur les nœuds OpenShift. Créez une configuration dans le<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Espace de noms à l'aide des certificats TLS et le patch dans la configuration d'image du cluster pour que le certificat soit fiable.</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">Le registre interne OpenShift est contrôlé par une authentification. Tous les utilisateurs OpenShift peuvent accéder au registre OpenShift, mais les opérations que l'utilisateur connecté peut exécuter dépendent des autorisations des utilisateurs.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">Pour permettre à un utilisateur ou à un groupe d'utilisateurs d'extraire des images du registre, le rôle du visualiseur de registre doit être affecté à l'utilisateur.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">Pour permettre à un utilisateur ou à un groupe d'utilisateurs d'écrire ou de diffuser des images, le rôle de l'éditeur de registre doit être affecté.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">Pour que les nœuds OpenShift puissent accéder au registre et envoyer ou extraire les images, vous devez configurer un secret Pull.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">Ce secret Pull peut ensuite être corrigé aux comptes de service ou être référencé dans la définition de pod correspondante.</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">Pour le corriger aux comptes de service, exécutez la commande suivante :</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">Pour référencer le secret Pull dans la définition du pod, ajoutez le paramètre suivant à l'<block ref="b979c2934ac0b4ba3f08dabfdd1b2299" prefix=" " category="inline-code"></block> section.</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">Pour pousser ou extraire une image des postes de travail en dehors du nœud OpenShift, effectuez les opérations suivantes :</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Ajoutez les certificats TLS au client docker.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">Connectez-vous à OpenShift à l'aide de la commande oc login.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">Connectez-vous au registre à l'aide des informations d'identification de l'utilisateur OpenShift avec la commande podman/docker.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">podman</block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">Si vous utilisez<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utilisateur doit se connecter au registre privé, puis utiliser un jeton au lieu d'un mot de passe.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">docker</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">Pousser ou extraire les images.</block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">Suivant : iSCSI NetApp ONTAP.</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">Ce document de référence permet de valider le déploiement de la solution Anthos avec NetApp, déployée dans plusieurs environnements de data Center comme validé par NetApp et ses partenaires d'ingénierie.</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165: Anthos avec NetApp</block>
  <block id="e961a4cbc5c7e2be5e3f72a578aeb4da" category="paragraph">Alan Cowles et Nikhil Kulkarni, NetApp</block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">Ce document de référence permet de valider le déploiement de la solution Anthos avec NetApp et de nos partenaires d'ingénierie lorsqu'elle est déployée dans de nombreux environnements de data Center. Il en est également question de l'intégration du stockage avec les systèmes de stockage NetApp avec l'orchestrateur de stockage Astra Trident pour la gestion du stockage persistant. Enfin, nous explorons et documentons un certain nombre de validations de solutions et d'utilisations réelles.</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">L'architecture de la solution NetApp pour Anthos a été conçue pour offrir une valeur exceptionnelle à ses clients pour :</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">Facile à déployer et à gérer, l'environnement Anthos déployé à l'aide de la solution fournie<block ref="f9d1b8d1854865b695167e2c5829f633" prefix=" " category="inline-code"></block> outil sur métal nu ou<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> Outil sur VMware vSphere.</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">kubevirt</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">Combiné à la puissance des conteneurs d'entreprise et des charges de travail virtualisées, Anthos a déployé virtuellement sur vSphere ou sur un système bare Metal avec<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>.</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">Exemples d'utilisation et de configuration réels pour Anthos dans le cadre d'une utilisation avec le stockage NetApp et Astra Trident, l'orchestrateur de stockage open source pour Kubernetes.</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">La solution Anthos with NetApp relève ces défis et propose une solution qui aide à résoudre chaque problème en implémentant le déploiement entièrement automatisé de Anthos sur site dans l'environnement de data Center du client.</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">La solution Anthos avec NetApp comprend plusieurs composants majeurs :</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Anthos sur site</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Anthos sur site est une plateforme Kubernetes d'entreprise entièrement prise en charge qui peut être déployée dans l'hyperviseur VMware vSphere ou sur une infrastructure bare Metal de votre choix.</block>
  <block id="42fc2dc2813b6a8c6bbca7ebe6d3f51e" category="paragraph">Pour plus d'informations sur Anthos, consultez le site Web de Anthos<block ref="bcfc39c80df16a8beb60f78ea034be9d" category="inline-link-rx"></block>.</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Anthos.</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">Cette section est dédiée aux personnalisations que les utilisateurs du monde réel devraient probablement réaliser lors du déploiement de cette solution en production, telles que la création d'un registre d'images privées dédié ou le déploiement d'instances personnalisées d'équilibreur de charge.</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8 février 9.9.1</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="cell">Anthos sur VMware</block>
  <block id="eb5d694ff9583283fe6d0190a39d5f7a" category="cell">6.7U3, 7.0U3</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">Suivant : vue d'ensemble de Anthos.</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="summary">Les fonctionnalités indépendantes du matériel de Anthos sur un système bare Metal vous permettent de choisir une plateforme de calcul optimisée pour votre cas d'utilisation personnalisée, et vous offrent également de nombreux avantages supplémentaires.</block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">Voici quelques exemples :</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">*Apportez votre propre serveur.* vous pouvez utiliser des serveurs qui correspondent à votre infrastructure existante pour réduire les dépenses d'investissement et les coûts de gestion.</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">* Apportez votre propre système d'exploitation Linux.* en choisissant le système d'exploitation Linux que vous souhaitez déployer votre environnement Anthos-sur-bare-Metal, vous pouvez vous assurer que l'environnement Anthos s'intègre parfaitement dans vos infrastructures et vos schémas de gestion existants.</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">* Amélioration des performances et réduction des coûts* sans hyperviseur, les clusters Anthos-sur-bare-Metal appellent à un accès direct aux ressources matérielles serveur, y compris les périphériques matériels optimisés pour les performances, tels que les GPU.</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">* Amélioration des performances réseau et réduction de la latence.* puisque les nœuds de serveur Anthos-sur-bare-Metal sont directement connectés à votre réseau sans couche d'abstraction virtualisée, ils peuvent être optimisés pour une faible latence et des performances faibles.</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud demande régulièrement la validation à jour des plateformes de serveurs de nos partenaires à l'aide des nouvelles versions de Anthos dans le cadre de leur programme de partenaires pour la plateforme Anthos. Vous trouverez une liste des plates-formes serveur actuellement validées et des versions prises en charge par Anthos<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>.</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">Le tableau suivant contient les plateformes de serveur qui ont été testées par les ingénieurs partenaires de NetApp et de NetApp pour la validation de Anthos dans les déploiements sans système d'exploitation.</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">Fabricant</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">ProLiant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">Les nœuds Anthos-on-bare-Metal peuvent être configurés avec plusieurs distributions Linux, selon le choix du client, afin de faire correspondre leur infrastructure de data Center actuelle.</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">Le tableau suivant contient la liste des systèmes d'exploitation Linux utilisés par NetApp et ses partenaires pour valider la solution.</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">Relâchez</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Versions Anthos</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8.4</block>
  <block id="6a3bfb64d8c5e16ce63f46624e637b30" category="cell">18.04 LTS</block>
  <block id="d4a5ee60a5a19102b6c00749a050feaf" category="cell">20.04 LTS</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">Matériel supplémentaire</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">Pour compléter le déploiement de Anthos sur un système bare Metal comme une solution entièrement validée, d'autres composants de data Center pour la mise en réseau et le stockage ont été testés par NetApp et nos ingénieurs partenaires.</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">Le tableau suivant fournit des informations sur ces composants d'infrastructure supplémentaires.</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">Nom du matériel</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Commutateurs</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250, A220</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">Logiciels supplémentaires</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">Le tableau suivant comprend une liste des versions de logiciel supplémentaires déployées dans l'environnement de validation.</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">Nom du logiciel</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3(5)</block>
  <block id="6ff97c39e8de9255f8ab9ffb6a483dce" category="cell">9.9.1, 9.10.1</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">Lors de la validation de la plateforme Anthos Ready réalisée par NetApp et par notre équipe partenaires autour de la technologie World Wide Technology (WWT), l'environnement de laboratoire a été conçu à partir du diagramme suivant, qui nous a permis de tester les fonctionnalités de chaque type de serveur, système d'exploitation, périphériques réseau, et des systèmes de stockage déployés dans la solution.</block>
  <block id="f8caba75d33af6e6a5a53160c246688e" category="paragraph"><block ref="f8caba75d33af6e6a5a53160c246688e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">Cet environnement multi-systèmes d'exploitation montre l'interopérabilité avec les versions de système d'exploitation prises en charge pour la solution Anthos-sur-bare-Metal. Nous prévoyons que les clients standardiseront sur un ou plusieurs systèmes d'exploitation pour leur déploiement.</block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">Ressources d'assistance à l'infrastructure</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">L'infrastructure suivante devrait être en place avant le déploiement de Anthos sur un système bare Metal :</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">Au moins un serveur DNS qui fournit une résolution complète du nom d'hôte accessible à partir du réseau de gestion.</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">Au moins un serveur NTP accessible depuis le réseau de gestion.</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(Facultatif) la connectivité Internet sortante pour le réseau de gestion intrabande.</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">Il existe une vidéo de démonstration d'un déploiement Anthos sur des systèmes bare Metal dans la section vidéos et démonstrations de ce document.</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">Ce document de référence permet de valider le déploiement de Anthos de Google Cloud dans plusieurs environnements de data Center validés par NetApp. Il détaille également l'intégration du stockage avec les systèmes de stockage NetApp grâce à l'orchestrateur de stockage Astra Trident pour la gestion du stockage persistant et à NetApp Astra Control Center pour la gestion et la protection des applications avec état. Enfin, un certain nombre de validations de solutions et d'utilisations réelles sont explorées et documentées.</block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Pour déployer Astra Control Center sur un playbooks Ansible, un ordinateur Ubuntu/RHEL doit être installé sur Ansible. Suivre la procédure décrite<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Pour Ubuntu et<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> Pour RHEL.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Créez ou obtenez un fichier kubeconfig avec un accès administrateur au cluster OpenShift sur lequel vous devez installer Astra Control Center.</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">Changez le répertoire en<block ref="01199d5fee9fe01be523a2944ceef91d" prefix=" " category="inline-code"></block>.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">Modifiez le fichier var/var.yml et remplissez les variables avec les informations requises.</block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">La vidéo associée à depuis cette page montre certaines des capacités documentées dans ce document.</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="doc">Vidéos et démonstrations</block>
  <block id="63e2e4c63022a2ca3a58778bd242195b" category="paragraph">La vidéo suivante met en évidence certaines des capacités documentées dans ce document :</block>
  <block id="1adda60fb6ef5adf0c35c53442bdd87d" category="inline-link-macro">Vidéo : déploiement de Anthos sur un système bare Metal</block>
  <block id="81082fb0b2db5311a27c6cd75db69481" category="paragraph"><block ref="81082fb0b2db5311a27c6cd75db69481" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos unifie les opérations de développement et D'IT sur une seule plateforme pour concevoir, déployer et gérer de manière cohérente les applications dans les infrastructures sur site et de cloud hybride. Anthos intègre directement des clusters GKE Kubernetes dans votre environnement de data Center, aux formats virtuels ou sans système d'exploitation.</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Présentation de Anthos</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">Anthos avec NetApp est une architecture de cloud hybride vérifiée et axée sur les meilleures pratiques pour déployer un environnement Google Kubernetes Engine (GKE) sur site de manière fiable et fiable. Ce document de référence Architecture vérifiée NetApp sert de guide de conception et de validation du déploiement de Anthos avec la solution NetApp déployée sur des environnements bare Metal et virtuels. L'architecture décrite dans ce document a été validée par des experts de NetApp et de Google Cloud pour vous apporter les avantages qu'représente l'exécution d'Anthos dans votre environnement de data Center d'entreprise.</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos est une solution de data Center basée sur Kubernetes pour le cloud hybride qui permet aux entreprises de concevoir et de gérer des infrastructures modernes de cloud hybride tout en adoptant des workflows agiles axés sur le développement d'applications. Anthos sur VMware, solution basée sur des technologies open source, exécute les applications sur site dans une infrastructure VMware vSphere qui peut se connecter et interagir avec Anthos GKE dans Google Cloud. En adoptant les conteneurs, le maillage des services et d'autres technologies de transformation, les entreprises peuvent bénéficier de cycles de développement d'applications cohérents et de charges de travail prêtes pour la production dans des environnements locaux et cloud. La figure suivante décrit la solution Anthos et le mode de déploiement dans un data Center sur site qui interconnecte avec l'infrastructure dans le cloud.</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">*Google Cloud Marketplace pour les applications Kubernetes.* Un catalogue d'applications pour conteneurs mis en place pour faciliter le déploiement.</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">*Migrer pour Anthos.* migration automatique de services physiques et de machines virtuelles depuis les sites vers le cloud.</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">*Stackdriver.* Service de gestion offert par Google pour la journalisation et la surveillance des instances Cloud.</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Méthodes de déploiement pour Anthos</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">Anthos sur VMware</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">Les clusters Anthos déployés dans les environnements VMware vSphere sont simples à déployer, à maintenir et à faire évoluer rapidement pour la plupart des charges de travail Kubernetes des utilisateurs.</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">Pour plus d'informations sur les clusters Anthos sur VMware déployés avec NetApp, consultez la page <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>.</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">Les clusters Anthos déployés sur des serveurs bare Metal sont indépendants du matériel et vous permettent de choisir une plateforme de calcul optimisée pour votre cas d'utilisation personnalisée.</block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">Pour plus d'informations sur Anthos sur les clusters bare Metal déployés avec NetApp, consultez le site <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>.</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">Suivant : Anthos clusters sur VMware.</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">Documentation NetApp Astra Trident</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">Clusters Anthos sur la documentation VMware</block>
  <block id="f5266df5a7db89637cf0d7391221b756" category="inline-link"><block ref="f5266df5a7db89637cf0d7391221b756" category="inline-link-rx"></block></block>
  <block id="1bdc624c553dda22bc7a529bda2dd06b" category="paragraph"><block ref="1bdc624c553dda22bc7a529bda2dd06b" category="inline-link-rx"></block></block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Documentation Anthos sur les métaux nus</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">Comment déployer une application sur site pour votre cluster Anthos GKE, à l'aide de Google Cloud Console.</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Déploiement d'une application à partir de Google Cloud Console Marketplace</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">Un cluster Anthos est déployé sur site et enregistré avec Google Cloud Console</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Un équilibreur de charge MetalLB configuré dans votre cluster Anthos</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">Un compte disposant des autorisations nécessaires pour déployer des applications sur le cluster</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">Un compte de facturation avec Google Cloud si vous choisissez une application avec des coûts associés (facultatif)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">Déploiement d'une application</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">Pour cette utilisation, nous déployons une application WordPress simple sur l'un de nos clusters Anthos à l'aide de Google Cloud Console. Le déploiement utilise le stockage persistant fourni par NetApp ONTAP dans une classe de stockage prédéfinie. Nous présentons ensuite deux méthodes différentes pour modifier le service par défaut des applications afin que l'équilibreur de charge MetalLB le livre avec une adresse IP et l'expose au monde.</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">Pour déployer une application de cette manière, procédez comme suit :</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">Vérifiez que le cluster à déployer est accessible dans Google Cloud Console.</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">Clusters enregistrés</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">Sélectionnez applications dans le menu de gauche, sélectionnez le menu d'options à trois points en haut et sélectionnez déployer à partir de Marketplace, qui ouvre une nouvelle fenêtre dans laquelle vous pouvez sélectionner une application dans Google Cloud Marketplace.</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">Application Marketplace</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">Recherchez l'application que vous souhaitez installer, dans ce cas WordPress.</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">Rechercher WordPress</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">Après avoir sélectionné l'application WordPress, un écran de présentation s'affiche. Cliquez sur le bouton configurer.</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">Écran de vue d'ensemble de WordPress</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">Sur la page suivante, vous devez sélectionner le cluster à déployer, dans notre cas Demo-Cluster. Sélectionnez ou créez un nouveau nom d'espace de noms et d'instance d'application et sélectionnez les classes de stockage et les tailles de volume persistant dont vous avez besoin pour l'application WordPress et sa base de données MariaDB de support. Dans les deux cas, nous avons choisi la classe de stockage ONTAP-NAS-CSI.</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">Configuration de WordPress</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">Ne sélectionnez pas Activer l'accès IP public. Cela crée un service de type NodePort non accessible à partir d'un déploiement Anthos sur site.</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">Après avoir cliqué sur le bouton déployer, une page contenant les détails de l'application s'affiche. Vous pouvez actualiser cette page ou vous connecter à votre cluster à l'aide de l'interface de ligne de commandes pour vérifier l'état du déploiement.</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">Détails de l'application</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">L'interface de ligne de commande permet de vérifier le statut de l'application lors de son déploiement en exécutant la commande pour récupérer les informations du pod dans notre espace de noms d'application :<block ref="f33e7514e1b666008863c58a5b3b8fc3" prefix=" " category="inline-code"></block>.</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">Kubectl</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">Notez dans cette capture d'écran qu'il existe un pod de déploiement dans un état d'erreur. C'est normal. Ce pod est un pod auxiliaire utilisé par Google Cloud Console pour déployer l'application qui se termine automatiquement après que les autres pods aient commencé leur processus d'initialisation.</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">Au bout de quelques instants, vérifiez que votre application est en cours d'exécution.</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">Application en cours d'exécution</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">Exposition de l'application</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">Une fois l'application déployée, vous disposez de deux méthodes pour l'attribuer à une adresse IP accessible au monde.</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Utilisation de Google Cloud Console</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">Vous pouvez exposer l'application à l'aide de Google Cloud Console et modifier la sortie YAML pour les services dans un navigateur afin de définir une adresse IP accessible au public. Pour ce faire, procédez comme suit :</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">Dans Google Cloud Console, cliquez sur Services et Ingress dans le menu de gauche.</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">Services et entrées</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">Cliquez sur le bouton<block ref="038c7925bdf387b6bedcaa4b32ec3a83" prefix=" " category="inline-code"></block> services. L'écran Détails du service s'affiche. Cliquez sur le bouton Modifier en haut.</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">Modifier les détails du service</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">La page modification des détails du service s'ouvre et contient les informations relatives à YAML pour le service. Faites défiler vers le bas jusqu'à ce que le s'affiche<block ref="084d5d41838f6b2d8b0c1f1176d66d01" prefix=" " category="inline-code"></block> et le<block ref="3190100143eef75fa97ee36e98fa3f8b" prefix=" " category="inline-code"></block> valeur, qui est définie sur<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block>. Définissez cette valeur sur<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> Puis cliquez sur le bouton Enregistrer.</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">Saisissez valeur ClusterIP</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">Saisissez valeur de l'équilibreur de charge</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">Lorsque vous revenez à la page Détails du service, le<block ref="e659b52eba1f0299b2d8ca3483919e72" prefix=" " category="inline-code"></block> maintenant listes<block ref="a38b02b14f77fc6ad85cfb7df9d27b2e" prefix=" " category="inline-code"></block> et le<block ref="918d33b6c8dd822ec40bbef2e2f58f3e" prefix=" " category="inline-code"></block> Le champ indique une adresse IP attribuée du pool MetalLB et le port par lequel l'application est accessible.</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">Version finale des détails du service</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Application de correctifs au service avec Kubectl</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">Vous pouvez exposer l'application à l'aide de l'interface de ligne de commande et de la<block ref="b40dfaf71508ce779421b1c4dde5f99f" prefix=" " category="inline-code"></block> Commande permettant de modifier votre déploiement et de définir une adresse IP accessible au public. Pour ce faire, procédez comme suit :</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">Dressez la liste des services associés aux pods dans votre espace de noms avec<block ref="3841f6ce7a9f7be216fe99eef26477f6" prefix=" " category="inline-code"></block> commande.</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">Services de liste</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">Modifiez le type de service à partir de<block ref="8fa769eb2083a1e8b123c7328287e112" prefix=" " category="inline-code"></block> à saisir<block ref="5c89f521cbb8685d397906bd6ce0efa1" prefix=" " category="inline-code"></block> utilisation de la commande suivante :</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">Ce nouveau type de service se voit automatiquement attribuer une adresse IP disponible à partir du pool MetalLB.</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">Correctif Service pour le type LoadBalancer</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">Consultez l'application sur l'adresse IP externe exposée</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">Maintenant que vous avez l'application exposée avec une adresse IP accessible publiquement, vous pouvez visiter votre instance WordPress à l'aide d'un navigateur.</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">WordPress dans le navigateur</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">Suivant : vidéos et démonstrations.</block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">Suivant : Options de configuration avancées.</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">Les clusters Anthos sur VMware sont une extension de Google Kubernetes Engine déployée dans le data Center privé d'un utilisateur final. Une entreprise peut déployer les mêmes applications que celles conçues pour s'exécuter dans des conteneurs dans Google Cloud dans des clusters Kubernetes sur site. Vous pouvez déployer des clusters Anthos sur VMware dans un environnement VMware vSphere existant pour votre data Center. Ainsi, vous économisez sur vos dépenses d'investissement et profitez d'opérations de déploiement et d'évolutivité plus rapides.</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">Le déploiement de clusters Anthos sur VMware inclut plusieurs composants :</block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">*Poste de travail administrateur Anthos.* Un hôte de déploiement dont<block ref="fb87177c7509d5723aa1bbc241ec2f7b" prefix=" " category="inline-code"></block> et<block ref="0f12ee5c9f1dd90158580f1c292b0d37" prefix=" " category="inline-code"></block> Les commandes peuvent être exécutées pour déployer et interagir avec les déploiements Anthos.</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">*Cluster Admin.* le cluster initial déployé lors de la configuration des clusters Anthos sur VMware. Ce cluster gère toutes les actions de cluster utilisateur subalterne, notamment le déploiement, l'évolutivité et la mise à niveau.</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">*Cluster utilisateur.* chaque cluster utilisateur est déployé avec sa propre instance d'équilibreur de charge ou partition, ce qui lui permet d'agir en tant que cluster Kubernetes autonome pour des utilisateurs ou des groupes individuels, ce qui contribue à assurer une colocation complète.</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">Le graphique suivant décrit un déploiement Anthos-clusters-sur-VMware.</block>
  <block id="d17685a3ddd89e969b430984ce944772" category="paragraph"><block ref="d17685a3ddd89e969b430984ce944772" category="inline-image-macro-rx" type="image"></block></block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">Les clusters Anthos sur VMware offrent les avantages suivants :</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">*Colocation avancée.* chaque utilisateur final peut se voir attribuer son propre cluster utilisateur, déployé avec les ressources virtuelles nécessaires à son propre environnement de développement.</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">*Économies.* les utilisateurs finaux peuvent réaliser d'importantes économies en déployant plusieurs clusters utilisateur dans le même environnement physique et en utilisant leurs propres ressources physiques pour le déploiement de leurs applications au lieu de provisionner des ressources dans leur environnement Google Cloud ou sur de grands clusters sans système d'exploitation.</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">*Développer puis publier.* les déploiements sur site peuvent être utilisés pendant le développement des applications, ce qui permet de tester les applications dans la confidentialité d'un centre de données local avant d'être rendues publiques dans le cloud.</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">*VMware vSphere vMotion*. VMware vCenter vous permet, sur demande, de migrer à chaud des machines virtuelles entre les nœuds du cluster sans interruption.</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">*Haute disponibilité vSphere* pour éviter les perturbations en cas de défaillance de l'hôte, VMware vSphere permet la mise en cluster des hôtes et leur configuration pour une haute disponibilité. Les machines virtuelles interrompues par une défaillance hôte sont redémarrée prochainement sur d'autres hôtes du cluster, afin de restaurer les services.</block>
  <block id="44da02789c784d2615f858b0e9007c1d" category="inline-link">NetApp FlexPod</block>
  <block id="08edd2123939d5309dced149763a50ee" category="inline-link">NetApp HCI</block>
  <block id="58d64ca3570be3edd23e4165a8c0d9ee" category="paragraph">Le tableau suivant contient des plateformes de serveur qui ont été testées par les ingénieurs partenaires NetApp et NetApp pour la validation des clusters Anthos sur les déploiements VMware. Cela inclut des solutions telles que le<block ref="5ea2f6a45afb6a8f064f7631dd737389" category="inline-link-rx"></block> Avec des serveurs Cisco UCS et le<block ref="3ff4d1b07fc6ed14e7fcf7636d0ad5aa" category="inline-link-rx"></block> plateforme d'infrastructure de cloud hybride.</block>
  <block id="bcb24d33d2a22de9b0c3e9f38becc496" category="cell">HCI</block>
  <block id="9f80c25863c6e1e85d8d5492b437cb64" category="cell">C410</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">Les clusters Anthos sur VMware peuvent être déployés dans les environnements vSphere 6 et 7, comme ils le souhaitent pour faire correspondre leur infrastructure de data Center actuelle.</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">Le tableau suivant contient une liste des versions vSphere utilisées par NetApp et ses partenaires pour valider la solution.</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">Pour terminer le déploiement de Anthos avec NetApp comme solution entièrement validée, nous avons testé d'autres composants de data Center pour le réseau et le stockage.</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox</block>
  <block id="92666505ce75444ee14be2ebc2f10a60" category="cell">N° DE SÉRIE</block>
  <block id="d7a84628c025d30f7b2c52c958767e76" category="cell">2010</block>
  <block id="2f72e4f4112efeb63b9fb0ed1eefd1c9" category="cell">A250</block>
  <block id="bf07aaec06ff922b8a11ef624141bfdb" category="cell">S410</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">Le tableau suivant comprend une liste des versions de logiciel déployées dans l'environnement de validation.</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">Nom du logiciel</block>
  <block id="3c537b8d673e06e2107129b600143391" category="cell">4.1(3f)</block>
  <block id="f932bed2d12442d21507b51d22b88dd7" category="cell">1.8</block>
  <block id="c1770c414b5c19c253a48e36fa2da50f" category="paragraph">Lors de la validation de la plateforme Anthos Ready effectuée par NetApp, l'environnement de laboratoire a été conçu à partir du diagramme suivant. Nous avons ainsi pu tester plusieurs clusters utilisateurs déployés avec plusieurs systèmes de stockage NetApp et systèmes back-end.</block>
  <block id="c1c59b2c25178eb5f3956ae189dc384b" category="paragraph"><block ref="c1c59b2c25178eb5f3956ae189dc384b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">L'infrastructure suivante devrait être en place avant le déploiement de Anthos :</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">Un serveur DHCP disponible pour offrir des locations d'adresses réseau à la demande si les clusters doivent évoluer de façon dynamique.</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Déployez Anthos dans un cluster ESXi d'au moins trois nœuds</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">Bien qu'il soit possible d'installer Anthos dans un cluster vSphere de moins de trois nœuds à des fins de démonstration ou d'évaluation, ce n'est pas recommandé pour les charges de travail de production. Bien que deux nœuds permettent la haute disponibilité de base et la tolérance aux pannes, une configuration de cluster Anthos doit être modifiée pour désactiver l'affinité d'hôte par défaut, et cette méthode de déploiement n'est pas prise en charge par Google Cloud.</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">Vous pouvez obtenir la distribution des nœuds de clusters Anthos sur plusieurs nœuds d'hyperviseur en activant les machines virtuelles et l'affinité des hôtes.</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">Pour configurer des groupes d'affinité, consultez le lien approprié ci-dessous pour votre version de VMware vSphere.</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">Documentation vSphere 7.0 : utilisation des règles d'affinité DRS</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>.<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>.</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos dispose d'une option de configuration pour chaque individu<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> Fichier pour créer automatiquement des règles d'affinité de nœud qui peuvent être activées ou désactivées en fonction du nombre d'hôtes ESXi dans votre environnement.</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">Suivant: Anthos sur bare Metal.</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Une fois vos clusters Red Hat OpenShift enregistrés, vous pouvez détecter les applications déployées et les gérer via Astra Control Center.</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">Une fois les clusters OpenShift et les systèmes back-end ONTAP enregistrés auprès de l'Astra Control Center, le centre de contrôle démarre automatiquement la détection des applications dans tous les namespaces qui utilisent le storageclass configuré avec le back-end ONTAP spécifié.</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp propose plusieurs plateformes de stockage qualifiées avec notre orchestrateur de stockage Trident pour provisionner le stockage pour les applications déployées sur Anthos.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">Présentation du stockage NetApp</block>
  <block id="f623f7fc1ffb9cfc3afddcf52e2fec23" category="paragraph">NetApp propose plusieurs plateformes de stockage compatibles avec notre orchestrateur de stockage Astra Trident qui sert à provisionner le stockage pour les applications déployées sur Anthos.</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">Suivant : NetApp ONTAP.</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">Avant de commencer l'installation, poussez les images du centre de contrôle Astra vers un registre d'images. Vous pouvez choisir de le faire avec Docker ou Podman ; les instructions pour les deux sont fournies dans cette étape.</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">Vous pouvez également créer un compte de service, attribuer un rôle d'éditeur de registre et/ou de visualiseur de registre (selon que vous avez besoin d'un accès Push/Pull) et vous connecter au registre à l'aide du jeton du compte de service.</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">Créez un fichier de script de shell et collez le contenu suivant dans celui-ci.</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">Si vous utilisez le<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utilisateur doit se connecter au registre privé, puis utiliser un jeton au lieu d'un mot de passe -<block ref="4c3c383f59a35199b206c06cf64ebc7c" prefix=" " category="inline-code"></block>.</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">Vous pouvez également créer un compte de service, attribuer un rôle d'éditeur de registre et/ou de visualiseur de registre (selon que vous avez besoin d'un accès push/pull) et vous connecter au registre à l'aide du jeton du compte de service.</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">Si vous utilisez un registre interne OpenShift avec des certificats TLS par défaut de l'opérateur d'entrée portant une route, vous devez suivre l'étape précédente pour corriger le nom d'hôte de la route. Pour extraire les certificats de l'opérateur Ingress, vous pouvez utiliser la commande<block ref="f3181390f5ac7b194eebf3ad3042d2f7" prefix=" " category="inline-code"></block>.</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">Créez un secret avec des informations d'identification pour vous connecter au registre d'images dans le<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> espace de noms.</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">Sélectionner<block ref="cadbba5231afda9b003503d57805b87d" prefix=" " category="inline-code"></block> Mosaïque et cliquez sur installer.</block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">Sur l'écran installer l'opérateur, acceptez tous les paramètres par défaut et cliquez sur installer.</block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">Une fois l'installation de l'opérateur réussie, accédez à View Operator (Afficher l'opérateur).</block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">Cliquez ensuite sur Créer une instance dans la mosaïque du centre de contrôle Astra de l'opérateur.</block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">Remplissez le<block ref="9eca463036a902158489237df8eb93bf" prefix=" " category="inline-code"></block> Et cliquez sur Créer.</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Entrez un nom de compte pour le centre de contrôle Astra et des détails d'administrateur tels que le prénom, le nom et l'adresse e-mail.</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">Dans le Registre d'images, entrez le FQDN de votre registre ainsi que le nom d'organisation tel qu'il a été donné lors de l'envoi des images au Registre (dans cet exemple,<block ref="6bde403d563a0c848b35e178652a7a84" prefix=" " category="inline-code"></block>).</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">Si vous utilisez un registre qui nécessite une authentification, entrez le nom secret dans la section Registre d'images.</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Configurez les options d'échelle pour les limites de ressources Astra Control Center.</block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Enregistrez vos clusters Red Hat OpenShift avec Astra Control Center</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">La première étape consiste à ajouter les clusters OpenShift au Centre de contrôle Astra et à les gérer. Accédez à clusters, cliquez sur Ajouter un cluster, téléchargez le<block ref="deabc6332aa53495b56c51d2e3eca54f" prefix=" " category="inline-code"></block> Fichier du cluster OpenShift, puis cliquez sur Select Storage.</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Pour la sauvegarde et la restauration entre les clusters OpenShift avec Astra Control Center, vous devez provisionner un compartiment de stockage objet qui prend en charge le protocole S3. Les options ONTAP S3, StorageGRID et AWS S3 sont actuellement prises en charge. Pour les besoins de cette installation, nous allons configurer un compartiment AWS S3. Accédez à godets, cliquez sur Ajouter un compartiment et sélectionnez Generic S3. Entrez les détails du compartiment S3 et les identifiants pour y accéder, cliquez sur la case à cocher définir ce compartiment par défaut pour le cloud, puis cliquez sur Ajouter.</block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">Suivant : choisissez les applications à protéger.</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">Cette page répertorie les instructions d'installation et de configuration de l'équilibreur de charge géré MetalLB.</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">L'équilibreur de charge MetalLB est entièrement intégré aux clusters Anthos sur VMware. Le déploiement est automatisé dans le cadre des configurations des clusters utilisateur et administrateur depuis la version 1.11. Les blocs de texte respectifs sont présents<block ref="c6ce65430f0e0c334f6b50da737f2e9b" prefix=" " category="inline-code"></block> les fichiers de configuration que vous devez modifier pour fournir des informations sur l'équilibreur de charge. Elle est hébergée de manière autonome sur votre cluster Anthos au lieu de déployer des ressources externes comme les autres solutions d'équilibrage de charge prises en charge. Vous pouvez également créer un pool ip qui attribue automatiquement des adresses avec la création de services Kubernetes d'équilibreur de charge dans les clusters qui ne s'exécutent pas sur un fournisseur cloud.</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Lorsque vous activez l'équilibreur de charge MetalLB pour Anthos admin, vous devez modifier quelques lignes dans l'<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> section qui existe dans<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> fichier. Les seules valeurs que vous devez modifier sont de définir<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block> puis définissez l'<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> Comme MetalLB. Consultez l'extrait de code suivant pour obtenir un exemple :</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">Lors de l'activation de MetalLB Load Balancer pour les clusters utilisateur Anthos, il existe deux zones dans chacune<block ref="aba03e96a3a4305fd83dc510e1607415" prefix=" " category="inline-code"></block> fichier que vous devez mettre à jour. Tout d'abord, de manière similaire à la<block ref="b58bb01ef49e2b97a31ca0536ef027fd" prefix=" " category="inline-code"></block> vous devez modifier le<block ref="0256ba7412d85da2acbcf1930256c21b" prefix=" " category="inline-code"></block>,<block ref="4fa041ebf362f3965af3570da03ef0fe" prefix=" " category="inline-code"></block>, et<block ref="c4b58542f9e0392c2110da5afb7437af" prefix=" " category="inline-code"></block> valeurs dans le<block ref="d4b71de62fea2275aed3155c187cb766" prefix=" " category="inline-code"></block> section. Consultez l'extrait de code suivant pour obtenir un exemple :</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">L'adresse IP d'ingresVIP doit exister dans le pool d'adresses IP affectées à l'équilibreur de charge MetalLB ultérieurement dans la configuration.</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">Vous devez ensuite naviguer jusqu'au<block ref="0ea77e636e8d12d9ce07b2dab6268822" prefix=" " category="inline-code"></block> et modifiez le<block ref="045d68a12437e8212f812d2bf506dbc0" prefix=" " category="inline-code"></block> en nommant le pool dans le<block ref="146d8d83713f4abd99cafc739779598c" prefix=" " category="inline-code"></block> variable. Vous devez également créer un pool d'adresses ip que MetalLB peut affecter aux services de type LoadBalancer en fournissant une plage à l'<block ref="336f9e008319434aa314ef3c1b8a682f" prefix=" " category="inline-code"></block> variable.</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">Le pool d'adresses peut être fourni comme une plage comme dans l'exemple, la limitant à un certain nombre d'adresses dans un sous-réseau particulier, ou il peut être fourni comme une notation CIDR si l'ensemble du sous-réseau est rendu disponible.</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">Lorsque des services Kubernetes de type LoadBalancer sont créés, MetalLB attribue automatiquement un externalIP aux services et annonce l'adresse IP en répondant aux requêtes ARP.</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">Suivant : installation d'équilibreurs de charge en seesaw.</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">Ensuite, chargez les certificats TLS du registre d'images sur les nœuds OpenShift. Pour ce faire, créez une configuration dans le<block ref="34dd8d8a3478a983eb249305316984b0" prefix=" " category="inline-code"></block> Espace de noms à l'aide des certificats TLS et le patch dans la configuration d'image du cluster pour que le certificat soit fiable.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">Présentation de NetApp Astra Control Center</block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center peut être installé sur un cluster Red Hat OpenShift que l'orchestrateur de stockage Astra Trident est déployé et configuré avec des classes de stockage et des systèmes back-end de stockage dans des systèmes de stockage NetApp ONTAP.</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">de ce document</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Pour l'installation et la configuration d'Astra Trident pour prendre en charge Astra Control Center, voir <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>.</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">Dans un environnement connecté au cloud, Astra Control Center utilise Cloud Insights pour fournir des fonctionnalités avancées de surveillance et de télémétrie. En l'absence de connexion Cloud Insights, un contrôle limité et une télémétrie (valeur de 7 jours de metrics) sont disponibles et exportés vers les outils de contrôle natifs Kubernetes (Prometheus et Grafana) via des terminaux ouverts.</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">En plus de la version payante d'Astra Control Center, une licence d'évaluation de 90 jours est disponible. La version d'évaluation est prise en charge par e-mail et dans le Channel Slack de la communauté. Les clients ont accès à ces ressources, à d'autres articles de la base de connaissances et à de la documentation disponibles dans le tableau de bord de support des produits.</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">Pour commencer avec NetApp Astra Control Center, rendez-vous sur le <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">Un ou plusieurs clusters Red Hat OpenShift. Les versions 4.6 EUS et 4.7 sont actuellement prises en charge.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">Astra Trident doit déjà être installé et configuré sur chaque cluster Red Hat OpenShift.</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">Il s'agit d'une bonne pratique pour chaque installation OpenShift sur un site qui dispose d'un SVM dédié pour le stockage persistant. Les déploiements multisites requièrent des systèmes de stockage supplémentaires.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Un système back-end de stockage Trident doit être configuré sur chaque cluster OpenShift avec un SVM sauvegardé par un cluster ONTAP.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">Classe de stockage par défaut configurée sur chaque cluster OpenShift avec Astra Trident comme provisionneur de stockage.</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">Un équilibreur de charge doit être installé et configuré sur chaque cluster OpenShift pour équilibrer les charges et exposer les services OpenShift.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">Voir le lien <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> pour plus d'informations sur les équilibreurs de charge qui ont été validés à cet effet.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">Voir le lien <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> Pour installer et configurer un registre privé OpenShift à cet effet.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Vous devez disposer d'un accès Cluster Admin au cluster Red Hat OpenShift.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Une station de travail d'administration avec docker ou podman, tridentctl et oc ou kubectl a été installée et ajoutée à votre $PATH</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Les installations Docker doivent avoir une version docker supérieure à 20.10 et les installations Podman doivent avoir une version podman supérieure à 3.0.</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">Utilisation de OperatorHub</block>
  <block id="60e34857d044a02ae86f645c2e97e40f" category="paragraph">Directive non résolue dans &lt;stdin&gt; - include::containers/rh-os-n_overview_astra_cc_install_Manual.adoc[]</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">Automatisation [Ansible]</block>
  <block id="2b0a99e34b337bd6d8ed27dd9482c9e6" category="paragraph">Directive non résolue dans &lt;stdin&gt; - include::containers/rh-os-n_overview_astra_cc_install_ansible.adoc[]</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">Étapes après l'installation</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">Vérifier le<block ref="83f93b05da174976bd534cc67ad9f7b4" prefix=" " category="inline-code"></block> journaux pour vérifier que l'installation est terminée.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">Procurez-vous l'IP d'équilibrage de charge du service traefik.</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">Lorsque vous vous connectez à l'interface graphique de Astra Control Center pour la première fois en utilisant l'adresse e-mail d'administration fournie dans CRD, vous devez changer le mot de passe.</block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center requiert une licence pour toutes ses fonctionnalités. Pour ajouter une licence, accédez à compte &gt; Licence, cliquez sur Ajouter une licence et téléchargez le fichier de licence.</block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">En cas de problème avec l'installation ou la configuration de NetApp Astra Control Center, la base de connaissances des problèmes connus est disponible<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">Ensuite, enregistrez vos clusters Red Hat OpenShift.</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="8a7ac28f4ab44e0d4f4da82c8faf774a" category="summary">Cette vidéo associée à depuis cette page explique comment déployer Anthos sur un cluster bare Metal.</block>
  <block id="6ca531ff48fc42e961c1b239f4302fab" category="doc">Déploiement d'un Anthos sur un cluster bare Metal</block>
  <block id="cb0b7b75afe3f65d378ff6ab2c93d899" category="paragraph">Cette vidéo présente comment déployer Anthos sur un cluster bare Metal.</block>
  <block id="97c62d2df3f6258616bde0882c4b890e" category="inline-link-macro">Suivant : informations supplémentaires.</block>
  <block id="5866caac5ce4e920cd3e5d0cd82ea8b7" category="paragraph"><block ref="5866caac5ce4e920cd3e5d0cd82ea8b7" category="inline-link-macro-rx"></block></block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="summary">Les exemples présentés sur cette page sont les validations et les utilisations de Anthos avec NetApp.</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="doc">Validation et utilisations des solutions</block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Installez une application à l'aide de Google Cloud Console</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">Cette section est dédiée aux personnalisations que les utilisateurs du monde réel devraient probablement réaliser lors du déploiement de cette solution en production, telles que la création d'un registre d'images dédié ou le déploiement d'instances personnalisées d'équilibreur de charge.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">Exploration des options de Load Balancer</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">Configuration des registres d'images privées</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">Utilisez l'Astra de NetApp pour effectuer une analyse post-mortem et restaurer votre application</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Pour l'installation et la configuration d'Astra Trident pour prendre en charge Astra Control Center, voir <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">Il est recommandé que chaque installation OpenShift sur un site dispose d'un SVM dédié pour le stockage persistant. Les déploiements multisites requièrent des systèmes de stockage supplémentaires.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Les installations Docker doivent avoir une version docker supérieure à 20.10 et les installations Podman doivent avoir une version podman supérieure à 3.0.</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Créez ou obtenez le fichier kubeconfig avec un accès administrateur au cluster OpenShift sur lequel vous devez installer Astra Control Center.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">Ensuite, enregistrez vos clusters Red Hat OpenShift avec Red Hat OpenShift.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">Gestion du cycle de vie des applications</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">Pour créer une application et la gérer dans un ensemble de clusters,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">Accédez à gérer les applications dans la barre latérale et cliquez sur Créer une application. Indiquez les détails de l'application que vous souhaitez créer et cliquez sur Enregistrer.</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">Créer une application</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">Une fois les composants de l'application installés, l'application apparaît dans la liste.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">Liste des applications</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">L'application peut désormais être contrôlée et gérée depuis la console.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">Suivant : caractéristiques - gouvernance et risque.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">Cette section explique comment déployer un pipeline d'intégration et de livraison continues avec Jenkins pour valider le fonctionnement de la solution.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">Déployez un pipeline ci/CD Jenkins avec le stockage persistant : Red Hat OpenShift avec NetApp</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">Cette section explique comment déployer un pipeline d'intégration/livraison continues ou de déploiement avec Jenkins pour valider le fonctionnement de la solution.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Créez les ressources requises pour le déploiement de Jenkins</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Pour créer les ressources nécessaires au déploiement de l'application Jenkins, procédez comme suit :</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Créez un nouveau projet appelé Jenkins.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">Dans cet exemple, nous avons déployé Jenkins avec du stockage persistant. Pour prendre en charge la construction Jenkins, créez le PVC. Accédez à stockage &gt; demandes de volume persistant et cliquez sur Créer une demande de volume persistant. Sélectionnez la classe de stockage créée, vérifiez que le nom de la demande de volume persistant est jenkins, sélectionnez la taille et le mode d'accès appropriés, puis cliquez sur Créer.</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">Déployez Jenkins avec le stockage persistant</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">Pour déployer Jenkins avec le stockage persistant, procédez comme suit :</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">Dans le coin supérieur gauche, modifiez le rôle de Administrateur à Développeur. Cliquez sur +Ajouter et sélectionnez à partir du catalogue. Dans la barre filtre par mot-clé, recherchez jenkins. Sélectionnez le service Jenkins avec le stockage persistant.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">Cliquez sur<block ref="42dcbbaa226af66223d0680206ea8547" prefix=" " category="inline-code"></block>.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">Par défaut, les détails de l'application Jenkins sont renseignés. En fonction de vos besoins, modifiez les paramètres et cliquez sur Créer. Ce processus crée toutes les ressources nécessaires pour prendre en charge Jenkins sur OpenShift.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Les modules Jenkins prennent environ 10 à 12 minutes pour entrer en état « prêt ».</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">Une fois les pods instanciés, accédez à réseau &gt; routes. Pour ouvrir la page Web Jenkins, cliquez sur l'URL fournie pour la route jenkins.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">OpenShift OAuth a été utilisé lors de la création de l'application Jenkins, cliquez sur « se connecter avec OpenShift ».</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Autoriser le compte de service Jenkins à accéder aux utilisateurs OpenShift.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">La page d'accueil de Jenkins s'affiche. Parce que nous utilisons une construction Maven, terminez d'abord l'installation Maven. Accédez à Manage Jenkins &gt; Global Tool Configuration, puis, dans le sous-titre Maven, cliquez sur Add Maven. Entrez le nom de votre choix et assurez-vous que l'option installer automatiquement est sélectionnée. Cliquez sur Enregistrer.</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">Vous pouvez désormais créer un pipeline pour démontrer le workflow ci/CD. Sur la page d'accueil, cliquez sur Créer de nouveaux travaux ou nouvel élément dans le menu de gauche.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">Sur la page Créer un élément, entrez le nom de votre choix, sélectionnez Pipeline, puis cliquez sur OK.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Sélectionnez l'onglet Pipeline. Dans le menu déroulant essayer un pipeline d'échantillon, sélectionnez Github + Maven. Le code est automatiquement renseigné. Cliquez sur Enregistrer.</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">Cliquez sur Créer maintenant pour déclencher le développement tout au long de la phase de préparation, de création et de test. Il peut prendre plusieurs minutes pour terminer l'ensemble du processus de construction et afficher les résultats de la construction.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">Chaque fois que du code change, le pipeline peut être reconstruit pour corriger la nouvelle version du logiciel permettant l'intégration et la livraison continues. Cliquez sur modifications récentes pour suivre les modifications apportées à la version précédente.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Protection des données dans le pipeline ci/CD avec Astra Control Center</block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp propose plusieurs produits qui aident nos clients à orchestrer et à gérer les données persistantes dans des environnements basés sur des conteneurs, tels que Red Hat OpenShift.</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp propose plusieurs produits pour orchestrer et gérer les données persistantes dans des environnements basés sur des conteneurs, tels que Red Hat OpenShift.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control propose un ensemble complet de services de gestion du stockage et des données respectueuse des applications pour les workloads Kubernetes avec état, optimisés par la technologie de protection des données NetApp. Astra Control Service est disponible pour la prise en charge des workloads avec état dans les déploiements Kubernetes cloud natifs. Le centre de contrôle Astra est disponible pour les workloads avec état dans les déploiements sur site, tels que Red Hat OpenShift. Pour en savoir plus, rendez-vous sur le site Web NetApp Astra Control<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident est un orchestrateur de stockage open source entièrement pris en charge pour les conteneurs et les distributions Kubernetes, y compris Red Hat OpenShift. Pour en savoir plus, rendez-vous sur le site Web Astra Trident<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les produits NetApp validés pour la gestion du stockage persistant et des applications dans la solution Red Hat OpenShift avec NetApp :</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">Ensuite, présentation du centre de contrôle NetApp Astra</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">Créer une machine virtuelle</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">Les machines virtuelles sont des déploiements avec état qui requièrent des volumes pour héberger le système d'exploitation et les données. Avec CNV, les machines virtuelles étant exécutées comme des pods, ces dernières sont sauvegardées par des volumes persistants hébergés sur NetApp ONTAP via Trident. Ces volumes sont connectés en tant que disques et stockent l'intégralité du système de fichiers, y compris la source de démarrage de la machine virtuelle.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">Créer une architecture de VM</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">Pour créer un serveur virtuel sur le cluster OpenShift, effectuez les opérations suivantes :</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">Sélectionnez le système d'exploitation souhaité et cliquez sur Suivant.</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">Si aucune source d'amorçage n'est configurée sur le système d'exploitation sélectionné, vous devez la configurer. Dans Source d'amorçage, indiquez si vous souhaitez importer l'image OS à partir d'une URL ou d'un registre et fournissez les détails correspondants. Développez Advanced et sélectionnez la classe de stockage sauvegardée par Trident. Cliquez ensuite sur Suivant.</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">Créer la source de démarrage pour la machine virtuelle</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">Si une source d'amorçage est déjà configurée sur le système d'exploitation sélectionné, l'étape précédente peut être ignorée.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">Si vous souhaitez personnaliser la machine virtuelle, cliquez sur Personnaliser la machine virtuelle et modifiez les paramètres requis.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">Cliquez sur Créer une machine virtuelle pour créer la machine virtuelle ; le pod correspondant est alors pivotez en arrière-plan.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">Lorsqu'une source d'amorçage est configurée pour un modèle ou un système d'exploitation à partir d'une URL ou d'un registre, elle crée une demande de volume persistant dans le<block ref="1f9b99deb0fa755d5d42404160cfd87f" prefix=" " category="inline-code"></block> Projetez et téléchargez l'image hôte KVM sur la demande de volume persistant. Vous devez vous assurer que les demandes de volume persistant du modèle disposent d'un espace provisionné suffisant pour prendre en charge l'image hôte KVM pour le système d'exploitation correspondant. Ces demandes de volume virtuel sont ensuite clonées et reliées en tant que rootdisks aux machines virtuelles lors de leur création à l'aide des modèles respectifs de n'importe quel projet.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">Suivant : workflows : migration dynamique VM.</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">Clonage de VM</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">Le clonage d'une machine virtuelle existante dans OpenShift est réalisé avec la prise en charge de la fonctionnalité de clonage de volumes CSI d'Astra Trident. Le clonage de volumes CSI permet de créer une nouvelle demande de volume persistant en utilisant une demande de volume en tant que source de données en dupliquant son volume persistant. Une fois le nouveau PVC créé, il fonctionne comme une entité distincte et sans lien ou dépendance sur le PVC source.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">Architecture de clonage de VM</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">Le clonage de volumes CSI peut prendre en compte certaines restrictions :</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">Le PVC source et le PVC de destination doivent être dans le même projet.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">Le clonage est pris en charge au sein de la même classe de stockage.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">Le clonage n'est possible que lorsque les volumes source et de destination utilisent le même paramètre Volumemode. Par exemple, un volume de bloc ne peut être cloné que vers un autre volume de bloc.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">Les VM d'un cluster OpenShift peuvent être clonés de deux manières :</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">En cours d'arrêt de la machine virtuelle source</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">En conservant la machine virtuelle source en service</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">En cours d'arrêt de la machine virtuelle source</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">Le clonage d'une machine virtuelle existante en fermant cette machine virtuelle est une fonctionnalité OpenShift native prise en charge d'Astra Trident. Procédez comme suit pour cloner une machine virtuelle.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">Accédez à charges de travail &gt; virtualisation &gt; machines virtuelles, puis cliquez sur les points de suspension situés à côté de la machine virtuelle que vous souhaitez cloner.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Cliquez sur Cloner l'ordinateur virtuel et fournissez les détails concernant la nouvelle machine virtuelle.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">cloner la machine virtuelle</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Cliquez sur Cloner l'ordinateur virtuel. La machine virtuelle source est arrêtée et commence la création de la machine virtuelle clone.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">Une fois cette étape terminée, vous pouvez accéder au contenu de la machine virtuelle clonée et le vérifier.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">Une machine virtuelle existante peut également être clonée en clonant le volume persistant existant de la machine virtuelle source, puis en créant une nouvelle machine virtuelle à l'aide du volume persistant cloné. Cette méthode n'exige pas l'arrêt de la machine virtuelle source. Procédez comme suit pour cloner une machine virtuelle sans la désactiver.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Accédez à Storage &gt; PersistentVolumeClaims et cliquez sur les points de suspension en regard du volume persistant associé à la machine virtuelle source.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Cliquez sur Cloner le PVC et fournir les détails du nouveau PVC.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">cloner la demande de volume persistant</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">Cliquez ensuite sur Cloner. Cela crée une demande de volume persistant pour la nouvelle machine virtuelle.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">Accédez à charges de travail &gt; virtualisation &gt; machines virtuelles, puis cliquez sur Créer &gt; avec YAML.</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">Dans la section spécifications &gt; modèle &gt; spécifications &gt; volumes, fixez le PVC cloné à la place du disque conteneur. Fournir tous les autres détails relatifs à la nouvelle machine virtuelle selon vos besoins.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">Cliquez sur Créer pour créer la nouvelle machine virtuelle.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">Une fois la machine virtuelle créée, accédez-y et vérifiez que la nouvelle machine virtuelle est un clone de la machine virtuelle source.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">Next : workflows : création d'une machine virtuelle à partir d'une copie Snapshot.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element : Red Hat OpenShift avec NetApp</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">Ainsi, si une défaillance de nœud est suivie d'une redistribution du volume, la connectivité hôte n'a aucun effet au-delà d'une déconnexion et d'une connexion avec redirection vers le nouvel emplacement. Avec la redirection de connexion iSCSI, un cluster logiciel NetApp Element est une architecture scale-out autoréparatrice qui permet des mises à niveau et des opérations sans interruption.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">Configuration : tâches d'administration du cluster</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Les tâches suivantes sont réalisées par Red Hat OpenShift Cluster-admin :</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Connectez-vous au cluster Red Hat OpenShift en tant qu'administrateur cluster.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">Créer deux projets correspondant à différents projets.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">Créer le rôle de développeur du projet-1.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">La définition de rôle fournie dans cette section n'est qu'un exemple. Les rôles de développeur doivent être définis en fonction des exigences de l'utilisateur final.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">De la même façon, créez des rôles de développement pour Project-2.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">Toutes les ressources de stockage OpenShift et NetApp sont généralement gérées par un administrateur du stockage. L'accès pour les administrateurs du stockage est contrôlé par le rôle de l'opérateur trident créé lors de l'installation de Trident. En outre, l'administrateur du stockage nécessite également l'accès à ResourceQuotas pour contrôler la consommation du stockage.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">Créez un rôle pour gérer ResourceQuotas dans tous les projets du cluster afin de le relier à l'administrateur de stockage.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">Assurez-vous que le cluster est intégré au fournisseur d'identité de l'entreprise et que les groupes d'utilisateurs sont synchronisés avec les groupes de clusters. L'exemple suivant montre que le fournisseur d'identités a été intégré au cluster et synchronisé avec les groupes d'utilisateurs.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">Configurer les liaisons ClusterRoleBindages pour les administrateurs de stockage.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">Pour les administrateurs du stockage, deux rôles doivent être liés : trident-Operator et Resource-quotas.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Créer des liaisons de type rôle pour les développeurs liant le rôle développeur-projet-1 au groupe correspondant (ocp-project-1) dans Project-1.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">De même, créez des liaisons de type rôle pour les développeurs qui lient les rôles de développeur au groupe d'utilisateurs correspondant dans Project-2.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">Suivant : tâches de l'administrateur du stockage</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">Ce document de référence assure la validation du déploiement de la solution Red Hat OpenShift, déployée via IPI (installer provisionnés Infrastructure) dans plusieurs environnements de data Center différents, comme validé par NetApp. Il détaille également l'intégration du stockage avec les systèmes de stockage NetApp grâce à l'orchestrateur de stockage Astra Trident pour la gestion du stockage persistant. Enfin, un certain nombre de validations de solutions et d'utilisations réelles sont explorées et documentées.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: Red Hat OpenShift avec NetApp</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">L'architecture de la solution Red Hat OpenShift avec NetApp a été conçue pour offrir une valeur exceptionnelle aux clients dans les cas d'utilisation suivants :</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">Déploiement et gestion simples de Red Hat OpenShift déployé avec IPI (installation Provisioné Infrastructure) sur un serveur bare Metal, Red Hat OpenStack Platform, Red Hat Virtualization et VMware vSphere.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">L'association de la puissance des workloads virtualisés et des conteneurs d'entreprise avec Red Hat OpenShift est déployée virtuellement sur OSP, RHV ou vSphere, ou sur un système bare Metal avec OpenShift Virtualization.</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">Exemples de configurations et d'utilisations réelles mettant en avant les fonctionnalités de Red Hat OpenShift avec le stockage NetApp et Astra Trident, l'orchestrateur de stockage open source pour Kubernetes.</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">Red Hat OpenShift avec NetApp reconnaît ces défis et présente une solution qui aide à résoudre chaque problème en mettant en œuvre le déploiement entièrement automatisé de Red Hat OpenShift IPI dans l'environnement de data Center choisi par le client.</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">La solution Red Hat OpenShift avec NetApp comprend les principaux composants suivants :</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Plateforme Red Hat OpenStack</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">Infrastructure de cloud privé</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat Virtualization</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">Suivant : présentation de Red Hat OpenShift.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">Validation et utilisations de la solution : Red Hat OpenShift avec NetApp</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">Les exemples présentés sur cette page sont les validations et les utilisations de Red Hat OpenShift avec NetApp.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">Déployez un pipeline ci/CD Jenkins avec le stockage persistant</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">Configurez la colocation sur Red Hat OpenShift avec NetApp</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">Création de registres d'images privées</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">Cette procédure décrit la création d'un registre d'images privées, sauvegardé par un volume persistant fourni par Astra Trident et NetApp ONTAP.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center requiert un registre pour héberger les images dont les conteneurs Astra ont besoin. La section suivante décrit les étapes de configuration d'un registre privé sur un cluster Red Hat OpenShift et l'envoi des images requises pour prendre en charge l'installation d'Astra Control Center.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">Si vous utilisez les certificats TLS par défaut pour la route de registre OpenShift de l'opérateur d'entrée, vous pouvez récupérer les certificats TLS à l'aide de la commande suivante.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">Le registre interne OpenShift est contrôlé par une authentification. Tous les utilisateurs OpenShift peuvent accéder au registre OpenShift, mais les opérations que l'utilisateur connecté peut exécuter dépendent des autorisations des utilisateurs.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">Pour le corriger aux comptes de service, exécutez la commande suivante.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">Pour pousser ou extraire une image des postes de travail en dehors du nœud OpenShift, procédez comme suit.</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+ REMARQUE : si vous utilisez<block ref="e8ab325768ed90db02e4c6f72419e835" prefix=" " category="inline-code"></block> l'utilisateur doit se connecter au registre privé, puis utiliser un jeton au lieu du mot de passe.</block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Migration des workloads avec Astra Control Center : Red Hat OpenShift avec NetApp</block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp dispose de plusieurs plateformes de stockage qualifiées dans notre orchestrateur de stockage Trident pour provisionner le stockage des applications déployées sur Red Hat OpenShift.</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp propose plusieurs plateformes de stockage compatibles avec notre orchestrateur de stockage Astra Trident qui sert à provisionner le stockage pour les applications déployées sur Red Hat OpenShift.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">Les pages suivantes présentent des informations supplémentaires sur les systèmes de stockage NetApp validés dans la solution Red Hat OpenShift avec NetApp :</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">Gouvernance et risque</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">Cette fonctionnalité vous permet de définir les stratégies de conformité des différents clusters et de vous assurer que ces clusters l'adhèrent. Vous pouvez configurer les règles pour les informer ou corriger toute déviation ou violation des règles.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">Accédez à gouvernance et risque depuis la barre latérale.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">Pour créer des stratégies de conformité, cliquez sur Créer une stratégie, entrez les détails des normes de stratégie et sélectionnez les clusters qui doivent respecter cette stratégie. Si vous souhaitez corriger automatiquement les violations de cette stratégie, cochez la case appliquer si elle est prise en charge, puis cliquez sur Créer.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">Création d'une règle de conformité</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">Une fois toutes les règles requises configurées, toutes les violations des règles ou des clusters peuvent être surveillées et remédier aux problèmes dans Advanced Cluster Management.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">Le suivi des règles</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">Ensuite, fonctionnalités - observabilité.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">Cluster NetApp ONTAP</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">Trident est installé sur le cluster</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">Station de travail Admin avec les outils tridentctl et oc installés et ajoutés à $PATH</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">Accès administrateur à ONTAP</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">L'accès cluster-admin au cluster OpenShift</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">Le cluster est intégré avec Identity Provider</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">Le fournisseur d'identités est configuré pour distinguer efficacement les utilisateurs de différentes équipes</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">Suivant : tâches d'administrateur de cluster.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">Créer un serveur virtuel à partir d'un Snapshot</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Avec Astra Trident et Red Hat OpenShift, les utilisateurs peuvent créer un snapshot du volume persistant avec les classes de stockage provisionnées par celui-ci. Avec cette fonctionnalité, les utilisateurs peuvent effectuer une copie instantanée d'un volume et l'utiliser pour créer un nouveau volume ou restaurer le même volume à un état précédent. Cela permet d'activer ou de prendre en charge de nombreux cas d'utilisation, de la restauration aux clones en passant par la restauration des données.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">Pour les opérations Snapshot dans OpenShift, les ressources VolumeSnapshotClass, VolumeSnapshot et VolumeContent doivent être définies.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">Un VolumeSnapshotContent est le snapshot réellement pris à partir d'un volume du cluster. Il s'agit d'une ressource à l'échelle du cluster, semblable au volume persistant pour le stockage.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">Un VolumeSnapshot est une demande de création du snapshot d'un volume. Il est similaire à une demande de volume persistant.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass permet à l'administrateur de spécifier différents attributs d'un VolumeSnapshot. Il vous permet d'avoir différents attributs pour les différents snapshots pris à partir du même volume.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">Machine virtuelle de l'architecture Snapshot</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">Pour créer le snapshot d'une machine virtuelle, effectuez la procédure suivante :</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">Créez une classe VolumeSnapshotClass qui peut ensuite être utilisée pour créer un Snapshot VolumeCas. Accédez à Storage &gt; VolumeSnapshotclasses et cliquez sur Create VolumeSnapshotClass.</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">Entrez le nom de la classe d'instantanés, entrez csi.trident.netapp.io pour le pilote, puis cliquez sur Créer.</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">Créer une classe de snapshot</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">Identifiez le volume de volume persistant connecté à la machine virtuelle source, puis créez un Snapshot de cette demande de volume persistant. Accédez à<block ref="fbbf264c8665570001a09df2b42a9873" prefix=" " category="inline-code"></block> Puis cliquez sur Créer des copies Snapshot VolumeCas.</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">Sélectionnez la demande de volume persistant pour laquelle vous souhaitez créer l'instantané, entrez le nom de l'instantané ou acceptez la valeur par défaut, puis sélectionnez la classe VolumeSnapshotClass appropriée. Cliquez ensuite sur Créer.</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">Créer un Snapshot</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">La création du snapshot de la demande de volume persistant est alors possible.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">Créer une nouvelle machine virtuelle à partir du snapshot</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">Tout d'abord, restaurez la copie Snapshot dans un nouveau volume persistant. Accédez à stockage &gt; Volumesnapshots, cliquez sur les points de suspension situés à côté du Snapshot que vous souhaitez restaurer, puis cliquez sur Restaurer en tant que nouveau volume de volume persistant.</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">Entrez les détails du nouveau PVC et cliquez sur Restaurer. Cela crée un nouveau PVC.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">Restaurez un Snapshot sur un nouveau volume de stockage persistant</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">Ensuite, créez une nouvelle machine virtuelle à partir de ce volume persistant. Accédez à charges de travail &gt; virtualisation &gt; machines virtuelles, puis cliquez sur Créer &gt; avec YAML.</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">Dans la section spec &gt; template &gt; spec &gt; volumes, spécifiez le nouveau PVC créé à partir de Snapshot au lieu du disque conteneur. Fournir tous les autres détails relatifs à la nouvelle machine virtuelle selon vos besoins.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">Une fois la machine virtuelle créée, accédez-y et vérifiez que la nouvelle machine virtuelle possède le même état que celle de la machine virtuelle dont le volume de demande de volume persistant a été utilisé pour créer le Snapshot au moment de la création du Snapshot.</block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">Le service NetApp Virtual Desktop peut être étendu aux environnements sur site lorsque la connectivité entre les ressources sur site et les ressources clouds. Les entreprises peuvent établir le lien vers Microsoft Azure à l'aide d'Express route ou d'une connexion VPN IPsec de site à site. Vous pouvez également créer des liens vers d'autres clouds de la même manière, soit à l'aide d'une liaison dédiée, soit avec un tunnel VPN IPsec.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">Environnement cloud hybride</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">Pour la validation de la solution, nous avons utilisé l'environnement décrit dans la figure suivante.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">Sur site, nous disposions de plusieurs VLAN pour la gestion, des hôtes de session de postes de travail distants, etc. Ils se trouvaient sur le sous-réseau 172.21.146-150.0/24 et étaient acheminés vers le réseau d'entreprise à l'aide du service d'accès de routage à distance de Microsoft. Nous avons également effectué les tâches suivantes :</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Nous avons noté l'adresse IP publique de Microsoft Routing and Remote Access Server (RRAS, identifié par IPchicken.com).</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Nous avons créé une ressource de passerelle réseau virtuel (VPN par route) pour l'abonnement Azure.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Nous avons créé la connexion fournissant l'adresse de passerelle réseau locale pour l'adresse IP publique du serveur Microsoft RRAS.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">Nous avons effectué la configuration VPN sur RRAS pour créer une interface virtuelle à l'aide de l'authentification pré-partagée fournie lors de la création de la passerelle VPN. S'il est configuré correctement, le VPN doit être à l'état connecté. Au lieu de Microsoft RRAS, vous pouvez également utiliser pfSense ou d'autres outils pertinents pour créer le tunnel VPN IPsec site à site. Étant donné qu'il est basé sur l'itinéraire, le tunnel redirige le trafic en fonction des sous-réseaux spécifiques configurés.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory fournit une authentification d'identité basée sur OAuth. Les authentifications de clients d'entreprise nécessitent généralement une authentification NTLM ou Kerberos. Les services de domaine Microsoft Azure Active Directory effectuent une synchronisation de hachage de mot de passe entre Azure Active Directory et les contrôleurs de domaine sur site à l'aide d'ADConnect.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">Pour la validation de cette solution VDS hybride, nous avons initialement déployé sur Microsoft Azure et avons ajouté un site supplémentaire avec vSphere. L'avantage de cette approche est que les services de plateforme ont été déployés sur Microsoft Azure et ont ensuite été sauvegardés à l'aide du portail. Les services peuvent alors être facilement accessibles depuis n'importe où, même si la liaison VPN du site est indisponible.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">Pour ajouter un autre site, nous avons utilisé un outil appelé DCConfig. Le raccourci vers cette application est disponible sur le bureau de la VM du gestionnaire d'espace de travail du cloud (CWMgr). Une fois cette application lancée, accédez à l'onglet sites de datacenter, ajoutez le nouveau site de datacenter et remplissez les informations requises comme indiqué ci-dessous. L'URL pointe vers l'adresse IP vCenter. Assurez-vous que la VM CWMgr peut communiquer avec vCenter avant d'ajouter la configuration.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">Assurez-vous que vSphere PowerCLI 5.1 sur CloudWorkspace Manager est installé pour permettre la communication avec l'environnement VMware vSphere.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">La figure suivante décrit la configuration du site d'un data Center sur site.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">Notez que des options de filtrage sont disponibles pour la ressource de calcul en fonction du cluster, du nom d'hôte ou de l'espace RAM disponible. Les options de filtrage de la ressource de stockage incluent l'espace libre minimal sur les datastores ou le nombre maximal de machines virtuelles par datastore. Les datastores peuvent être exclus à l'aide d'expressions régulières. Cliquez sur le bouton Enregistrer pour enregistrer la configuration.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">Pour valider la configuration, cliquez sur le bouton Test ou cliquez sur Charger l'hyperviseur et cochez une liste déroulante sous la section vSphere. Il doit être rempli avec les valeurs appropriées. Il est recommandé de conserver l'hyperviseur principal sur yes pour le site de provisionnement par défaut.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">Les modèles de machine virtuelle créés sur VMware vSphere sont utilisés en tant que collections de provisionnement sur VDS. Les collections de provisionnement sont disponibles sous deux formes : partagées et VDI. Le type de collecte de provisionnement partagé est utilisé pour les services de bureau à distance pour lesquels une stratégie de ressources unique est appliquée à tous les serveurs. Le type VDI est utilisé pour les instances WVD pour lesquelles la stratégie de ressources est attribuée individuellement. Les serveurs d'une collection de provisionnement peuvent être affectés à l'un des trois rôles suivants :</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">*TSDATA.* combinaison de services terminal Server et de rôle de serveur de données.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">*TS.* terminal Services (hôte de session).</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">*DONNÉES.* serveur de fichiers ou serveur de bases de données. Lorsque vous définissez le rôle de serveur, vous devez choisir le modèle de machine virtuelle et le stockage (datastore). Le datastore choisi peut être réservé à un datastore spécifique ou vous pouvez utiliser l'option la moins utilisée dans laquelle le datastore est sélectionné en fonction de l'utilisation des données.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">Chaque déploiement dispose des valeurs par défaut des ressources des machines virtuelles pour l'allocation des ressources cloud en fonction des utilisateurs actifs, du nombre fixe, de la charge des serveurs ou du nombre d'utilisateurs.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">Suivant : test de charge d'un serveur unique avec VSI de connexion</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">La VDI hybride avec NetApp VDS permet aux fournisseurs de services et aux administrateurs des postes de travail virtuels d'étendre facilement les ressources à d'autres environnements clouds sans affecter les utilisateurs. La présence de ressources sur site sur NetApp HCI permet un meilleur contrôle des ressources GPU et permet d'étendre les nœuds de calcul ou de stockage à la demande.</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">La VDI hybride avec NetApp VDS permet aux fournisseurs de services et aux administrateurs des postes de travail virtuels d'étendre facilement les ressources à d'autres environnements clouds sans affecter les utilisateurs. La présence de ressources sur site offre un meilleur contrôle des ressources et un large choix de solutions (calcul, GPU, stockage et réseau) pour répondre à la demande.</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">Le cloud bursting permet aux postes de travail et aux applications distants de bénéficier de plus de demande croissante</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">En réduisant le TCO des postes de travail et applications distants à longue durée d'exécution, et en les hébergeant sur site avec des ressources de processeurs graphiques et de stockage Flash</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">Facilité de gestion des postes de travail et des applications distants dans les environnements clouds</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">Bénéficiez de postes de travail et d'applications à distance en utilisant un modèle de logiciel en tant que service avec des ressources sur site</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">Les architectes EUC/VDI qui souhaitent comprendre les exigences d'un VDS hybride</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">Partenaires NetApp qui voudraient aider les clients en termes de besoins en termes d'applications et de postes de travail distants</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">Clients NetApp HCI existants qui souhaitent répondre aux besoins des applications et des postes de travail à distance</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">Suivant : présentation du service NetApp Virtual Desktop Service</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">Dans le cadre du déploiement, vous pouvez choisir la méthode des services de fichiers pour héberger le profil utilisateur, les données partagées et le dossier du lecteur de base. Les options disponibles sont serveur de fichiers, Azure Files ou Azure NetApp Files. Toutefois, après le déploiement, vous pouvez modifier ce choix à l'aide de l'outil Command Center pour pointer vers n'importe quel partage SMB. L'hébergement avec NetApp ONTAP présente divers avantages.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">Gestion des données</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">L'hébergement avec NetApp ONTAP présente divers avantages</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">Changer la couche de données</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">Dans le cadre du déploiement, vous pouvez choisir la méthode des services de fichiers pour héberger le profil utilisateur, les données partagées et le dossier du lecteur de base. Les options disponibles sont serveur de fichiers, Azure Files ou Azure NetApp Files. Toutefois, après le déploiement, vous pouvez modifier ce choix à l'aide de l'outil Command Center pour pointer vers n'importe quel partage SMB. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. Pour savoir comment modifier le partage SMB, reportez-vous à la section<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">Cache global de fichiers</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">Lorsque les utilisateurs sont répartis sur plusieurs sites au sein d'un espace de noms global, Global File cache permet de réduire la latence des données fréquemment utilisées. Le déploiement du cache de fichiers global peut être automatisé à l'aide d'un ensemble de provisionnement et d'événements avec script. Global File cache gère les caches de lecture et d'écriture localement et conserve les verrous de fichiers entre les emplacements. Le cache de fichiers global peut fonctionner avec tous les serveurs de fichiers SMB, y compris Azure NetApp Files.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">Le cache de fichiers global nécessite les éléments suivants :</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">Serveur de gestion (serveur de gestion des licences)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">Cœur</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">Bord avec une capacité de disque suffisante pour mettre les données en cache</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">Documentation Fibre Channel</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">Pour télécharger le logiciel et calculer la capacité du cache de disque pour Edge, reportez-vous à la section<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">À des fins de validation, nous avons déployé les ressources centrales et de gestion sur la même machine virtuelle dans Azure et les ressources Edge sur NetApp HCI. Notez que le cœur requiert l'accès aux données à volume élevé et que la périphérie fait partie du cœur. Une fois le logiciel installé, vous devez activer la licence activée avant utilisation. Pour ce faire, procédez comme suit :</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">Dans la section Configuration de la licence, cliquez ici pour terminer l'activation de la licence. Enregistrez ensuite le fichier « core ».</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">Fournissez le compte de service à utiliser pour le cache de fichiers global. Pour connaître les autorisations requises pour ce compte, reportez-vous à la section<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">Ajoutez un nouveau serveur de fichiers backend et fournissez le nom du serveur de fichiers ou l'adresse IP.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">Sur le bord, le lecteur de cache doit avoir la lettre D. Si ce n'est pas le cas, utilisez diskpart.exe pour sélectionner le volume et modifier la lettre du lecteur. Enregistrez-vous avec le serveur de licences en tant que périphérie.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">Si la configuration automatique des cœurs est activée, les informations de base sont extraites automatiquement du serveur de gestion des licences.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">À partir de n'importe quel ordinateur client, les administrateurs qui ont utilisé pour accéder au partage sur le serveur de fichiers peuvent y accéder avec Fibre Channel Edge à l'aide du chemin UNC<block ref="4fe16e12c05517e32740fd6ba0c0691f" prefix=" " category="inline-code"></block>. Les administrateurs peuvent inclure ce chemin dans le logonscript utilisateur ou GPO pour les utilisateurs mappage de lecteurs à l'emplacement en périphérie.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">Pour fournir un accès transparent aux utilisateurs du monde entier, un administrateur peut configurer Microsoft Distributed Filesystem (DFS) avec des liens pointant vers des partages de serveurs de fichiers et vers des emplacements en périphérie.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">Lorsque les utilisateurs se connectent à l'aide des identifiants Active Directory en fonction des sous-réseaux associés au site, le lien approprié est utilisé par le client DFS pour accéder aux données.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">Les icônes de fichier changent selon qu'un fichier est mis en cache ; les fichiers qui ne sont pas mis en cache ont un X gris dans le coin inférieur gauche de l'icône. Lorsqu'un utilisateur situé à l'emplacement d'une arête accède à un fichier, ce fichier est mis en cache et l'icône change.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">Lorsqu'un fichier est ouvert et qu'un autre utilisateur tente d'ouvrir le même fichier à partir d'un emplacement de bord, l'utilisateur est invité à sélectionner la commande suivante :</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">Si l'utilisateur sélectionne l'option de réception d'une notification lorsque la copie d'origine est disponible, l'utilisateur en est averti comme suit :</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Vidéo sur talon et Azure NetApp Files Deployment</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">Pour plus d'informations, reportez-vous à ce document<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">NetApp SaaS Backup</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS fournit une protection des données Salesforce et Microsoft Office 365, notamment Exchange, SharePoint et Microsoft OneDrive. La figure suivante montre comment NetApp VDS fournit SaaS Backup pour ces services de données.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">vidéo</block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Pour découvrir les fonctionnalités de protection des données Microsoft Office 365, consultez<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Pour une démonstration de la protection des données Salesforce, consultez<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">Suivant : gestion des opérations</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI est une infrastructure de cloud hybride constituée d'un ensemble de nœuds de stockage et de nœuds de calcul. Elle est disponible en tant qu'unité à deux racks ou en 1 unité, selon le modèle. L'installation et la configuration requises pour déployer les machines virtuelles sont automatisées avec le moteur de déploiement NetApp. Les clusters de calcul sont gérés avec VMware vCenter, et les clusters de stockage sont gérés à l'aide du plug-in vCenter déployé avec NDE.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">Présentation de NetApp HCI</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI est une infrastructure de cloud hybride constituée d'un ensemble de nœuds de stockage et de nœuds de calcul. Elle est disponible en tant qu'unité à deux racks ou en 1 unité, selon le modèle. L'installation et la configuration requises pour déployer les machines virtuelles sont automatisées avec le moteur de déploiement NetApp. Les clusters de calcul sont gérés avec VMware vCenter, et les clusters de stockage sont gérés à l'aide du plug-in vCenter déployé avec NDE. Une VM de gestion appelée le nœud M est déployée dans le cadre du moteur de déploiement NetApp.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI prend en charge les fonctions suivantes :</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">Mises à niveau des versions</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">Envoi d'événements vers vCenter</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">Gestion du plug-in vCenter</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">Un tunnel VPN pour la prise en charge</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">Collecteur NetApp Active IQ</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">L'extension des services cloud de NetApp sur site, ce qui donne la possibilité d'une infrastructure de cloud hybride. La figure suivante décrit les composants d'HCI.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">Nœuds de stockage</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">Les nœuds de stockage sont disponibles en unité de rack demi-largeur ou pleine largeur. Dans un premier temps, quatre nœuds de stockage au moins sont nécessaires et un cluster peut évoluer jusqu'à 40 nœuds. Un cluster de stockage peut être partagé entre plusieurs clusters de calcul. Tous les nœuds de stockage disposent d'un contrôleur de cache afin d'améliorer les performances en écriture. Un seul nœud fournit 50 000 ou 100 000 IOPS à une taille de bloc de 4 Ko.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">Les nœuds de stockage NetApp HCI exécutent le logiciel NetApp Element qui permet d'atteindre des limites de QoS minimales, maximales ou en rafale. Le cluster de stockage prend en charge plusieurs nœuds de stockage, bien qu'un nœud de stockage ne puisse pas dépasser un tiers de la capacité totale.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">Nœuds de calcul</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">Guide de compatibilité avec VMware</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp prend en charge son stockage connecté à n'importe quel serveur de calcul répertorié dans le<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">Les nœuds de calcul sont disponibles en demi-largeur, pleine largeur et en deux tailles d'unité de rack. Les nœuds NetApp HCI H410C et H610C sont basés sur des processeurs Intel Skylake évolutifs. La technologie H615C est basée sur des processeurs Intel Cascade Lake évolutifs de deuxième génération. Il existe deux modèles de calcul qui contiennent des GPU : ce dernier contient deux cartes NVIDIA M10 et la H615C contient trois cartes NVIDIA T4.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">La NVIDIA T4 dispose de 40 cœurs RT qui fournissent la puissance de calcul nécessaire pour réaliser le traçage des rayons en temps réel. Le même modèle de serveur utilisé par les concepteurs et les ingénieurs peut désormais être utilisé par les artistes pour créer des images photoréalistes qui offrent des rebondissements de lumière sur les surfaces comme dans la vie réelle. Ce processeur graphique compatible RTX permet de tracer en temps réel jusqu'à cinq rayons Giga par seconde. Combiné au logiciel Quadro Virtual Data Center Workstation (Quadro VDWS), le NVIDIA T4 permet aux artistes de créer des conceptions photoréalistes avec des ombres, des reflets et des réfractions précis sur n'importe quel appareil, où.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Les cœurs Tensor vous permettent d'exécuter des workloads d'inférence d'apprentissage profond. Lors de l'exécution de ces charges de travail, une NVIDIA T4 optimisée avec Quadro VDWS peut assurer des performances jusqu'à 25 fois plus rapides qu'une machine virtuelle basée sur un serveur à processeur uniquement. Un système NetApp H615C équipé de trois cartes NVIDIA T4 dans une unité de rack est une solution idéale pour les workloads graphiques et gourmands en ressources de calcul.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">La figure suivante répertorie les cartes graphiques NVIDIA et compare leurs fonctionnalités.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">Le processeur graphique M10 reste la solution de coût total de possession la plus adaptée aux cas d'utilisation des travailleurs du savoir. Toutefois, le T4 constitue une excellente alternative pour standardiser les GPU sur plusieurs cas d'utilisation, comme les postes de travail virtuels, la performance graphique, le rendu interactif en temps réel et l'inférence. Grâce au T4, le DÉPARTEMENT INFORMATIQUE peut exploiter les mêmes ressources GPU pour exécuter des charges de travail mixtes―, par exemple, exécuter une infrastructure VDI pendant la journée, puis requalifier les ressources pour exécuter des charges de travail de calcul le soir.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">Le nœud de calcul H610C est une taille de rack ; il s'agit d'une unité de rack qui consomme moins d'énergie. L' H615C prend en charge le codage et le décodage H.264 et H.265 (vidéo haute efficacité [HEVC]) 4:4:4. Il prend également en charge le décodeur VP9 de plus en plus intégré ; même le paquet de conteneurs WebM servi par YouTube utilise le codec VP9 pour la vidéo.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">Le nombre de nœuds d'un cluster de calcul est dicté par VMware ; actuellement, il est 96 avec VMware vSphere 7.0 Update 1. L'association de différents modèles de nœuds de calcul dans un cluster est prise en charge lorsque la compatibilité vMotion améliorée (EVC) est activée.</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">Next : les licences NVIDIA</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp Virtual Desktop Service fournit un environnement d'applications et de postes de travail virtuels très facile à utiliser, qui répond parfaitement aux enjeux métier. L'extension de VDS à NetApp HCI vous permet d'utiliser des fonctions NetApp puissantes dans un environnement VDS, notamment la déduplication à la volée, la compaction, le provisionnement fin et la compression.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp Virtual Desktop Service fournit un environnement d'applications et de postes de travail virtuels très facile à utiliser, qui répond parfaitement aux enjeux métier. L'extension de VDS à l'environnement ONTAP local vous permet d'utiliser des fonctionnalités NetApp puissantes dans un environnement VDS, notamment le clonage rapide, la déduplication à la volée, la compaction et le provisionnement fin et à la compression. Réduisez les coûts de stockage et améliorez la performance avec le stockage 100 % Flash. Avec l'hyperviseur VMware vSphere, réduisez les délais de provisionnement des serveurs grâce aux volumes virtuels et à l'API vSphere pour l'intégration des baies. Avec le cloud hybride, les clients peuvent choisir l'environnement qui convient à leurs workloads exigeants et réaliser des économies. La session de postes de travail exécutée sur site peut accéder à des ressources clouds basées sur des règles.</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp propose de nombreux services clouds, dont le provisionnement rapide du poste de travail virtuel avec WVD ou les applications à distance, y compris l'intégration rapide avec Azure NetApp Files.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">Présentation du service NetApp Virtual Desktop Service</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp propose de nombreux services clouds, dont le provisionnement rapide du poste de travail virtuel avec des applications WVD ou distantes et l'intégration rapide à Azure NetApp Files.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">Généralement, il faut plusieurs semaines pour provisionner et fournir des services de postes de travail distants aux clients. Outre le provisionnement, il peut être difficile de gérer les applications, les profils d'utilisateurs, les données partagées et les objets de stratégie de groupe pour appliquer les règles. Les règles de pare-feu peuvent augmenter la complexité et nécessiter des compétences et des outils séparés.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Avec le service Microsoft Azure Windows Virtual Desktop, Microsoft assure la maintenance des composants des services de poste de travail à distance. Ainsi, les clients peuvent se concentrer sur le provisionnement d'espaces de travail dans le cloud. Les clients doivent provisionner et gérer l'ensemble de la pile, ce qui nécessite des compétences particulières pour gérer leurs environnements VDI.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">Avec NetApp VDS, les clients peuvent déployer rapidement des postes de travail virtuels sans se soucier de l'emplacement des composants de l'architecture tels que les courtiers, les passerelles, les agents, etc. Les clients qui ont besoin d'un contrôle total de leur environnement peuvent travailler avec une équipe de services professionnels pour atteindre leurs objectifs. Les clients consomment VDS en tant que service et peuvent ainsi se concentrer sur leurs principaux défis commerciaux.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS est une offre SaaS qui permet de gérer de manière centralisée de multiples déploiements dans des environnements AWS, Azure, GCP et clouds privés. Microsoft Windows Virtual Desktop est uniquement disponible sur Microsoft Azure. NetApp VDS orchestre les services Microsoft Remote Desktop Services dans d'autres environnements.</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft propose plusieurs sessions sur Windows 10 exclusivement pour les environnements Windows Virtual Desktop sur Azure. L'authentification et l'identité sont gérées par la technologie de poste de travail virtuel ; WVD requiert la synchronisation d'Azure Active Directory (avec AD Connect) avec Active Directory et les VM de session joints à Active Directory. RDS requiert Active Directory pour l'identité et l'authentification des utilisateurs, ainsi que pour la jointure et la gestion du domaine de VM.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">La figure suivante présente un exemple de topologie de déploiement.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">Chaque déploiement est associé à un domaine Active Directory et fournit aux clients un point d'entrée d'accès pour les espaces de travail et les applications. Un fournisseur de services ou une entreprise qui possède plusieurs domaines Active Directory a généralement plus de déploiements. Un seul domaine Active Directory qui couvre plusieurs régions a généralement un déploiement unique avec plusieurs sites.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Pour WVD dans Azure, Microsoft propose une plateforme à la demande consommée par les systèmes NetApp VDS. Pour les autres environnements, NetApp VDS orchestre le déploiement et la configuration des services Microsoft Remote Desktop Services. Les systèmes VDS NetApp prennent en charge les ARM WVD Classic et WVD et ils peuvent également être utilisés pour mettre à niveau les versions existantes.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">Chaque déploiement dispose de ses propres services de plateforme, qui comprennent Cloud Workspace Manager (terminal d'API REST), une passerelle HTML 5 (connexion aux VM à partir d'un portail de gestion VDS), des passerelles RDS (point d'accès pour les clients) et un contrôleur de domaine. La figure suivante décrit l'architecture du plan de contrôle VDS pour la mise en œuvre RDS.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">Pour les implémentations RDS, NetApp VDS peut être facilement accessible depuis Windows et les navigateurs à l'aide d'un logiciel client personnalisable afin d'inclure le logo du client et les images. En fonction des informations d'identification de l'utilisateur, il permet à l'utilisateur d'accéder aux espaces de travail et aux applications approuvés. Il n'est pas nécessaire de configurer les détails de la passerelle.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">La figure suivante présente le client VDS NetApp.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Dans l'implémentation Azure WVD, Microsoft gère le point d'entrée d'accès pour les clients et peut être utilisé par un client Microsoft WVD disponible de manière native pour divers systèmes d'exploitation. Il est également accessible via un portail en ligne. La configuration du logiciel client doit être gérée par l'objet de stratégie de groupe (GPO, Group Policy Object) ou par d'autres méthodes que les clients préfèrent.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">La figure suivante décrit l'architecture du plan de contrôle VDS pour les implémentations Azure WVD.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">Outre le déploiement et la configuration des composants requis, NetApp VDS prend également en charge la gestion des utilisateurs, la gestion des applications, l'évolutivité des ressources et l'optimisation.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">Les systèmes VDS NetApp peuvent créer des utilisateurs ou octroyer l'accès aux comptes utilisateurs existants aux services d'espace de travail cloud ou d'application. Le portail peut également être utilisé pour les réinitialisations de mot de passe et la délégation de l'administration d'un sous-ensemble de composants. Les administrateurs du service d'assistance ou les techniciens de niveau 3 peuvent créer des clichés instantanés des sessions utilisateur pour le dépannage ou se connecter aux serveurs à partir du portail.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS peut utiliser des modèles d'images que vous créez ou utiliser des modèles existants depuis le Marketplace pour un provisionnement basé sur le cloud. Pour réduire le nombre d'images à gérer, vous pouvez utiliser une image de base et toutes les applications supplémentaires dont vous avez besoin peuvent être provisionnées à l'aide du framework fourni afin d'inclure tous les outils de ligne de commande tels que Chocolatey, MSIX app Attach, PowerShell, etc. Même les scripts personnalisés peuvent être utilisés dans le cadre des événements de cycle de vie de la machine.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">Suivant : présentation de NetApp HCI</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">Lors de l'utilisation d'un H610C ou d'une technologie H615C, la licence du GPU doit être obtenue auprès des partenaires NVIDIA autorisés à revendre les licences.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">Les licences NVIDIA</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">outil de recherche de partenaires</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">Lors de l'utilisation d'un H610C ou d'une technologie H615C, la licence du GPU doit être obtenue auprès des partenaires NVIDIA autorisés à revendre les licences. Vous pouvez trouver des partenaires NVIDIA avec le<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. Recherchez des compétences telles que Virtual GPU (vGPU) ou Tesla.</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">Le logiciel NVIDIA vGPU est disponible en quatre éditions :</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC (GRID VPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID Virtual applications (vApps)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">Station de travail NVIDIA Quadro Virtual Data Center (Quadro VDWS)</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA Virtual ComputeServer (vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">PC virtuel GRID</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">Ce produit est idéal pour les utilisateurs qui recherchent un poste de travail virtuel offrant une expérience utilisateur exceptionnelle pour les applications Microsoft Windows, les navigateurs, la vidéo haute définition et la prise en charge multi-moniteurs. La solution NVIDIA GRID Virtual PC offre une expérience native dans un environnement virtualisé, ce qui vous permet d'exécuter toutes les applications de votre PC à des performances optimales.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">APPLICATIONS virtuelles DE GRID</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">Les vApps DU GRID sont destinées aux entreprises qui déploient un hôte de session de bureau à distance (RDSH) ou d'autres solutions de streaming au niveau des applications ou des sessions. Conçus pour fournir des applications Microsoft Windows à des performances maximales, les postes de travail RDSH hébergés par Windows Server sont également pris en charge par les vApps DU GRID.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Station de travail Quadro Virtual Data Center</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">Cette édition est idéale pour les concepteurs grand public et haut de gamme qui utilisent de puissantes applications de création de contenu 3D comme Dassault CATIA, SOLIDWORKS, 3Dexcite, Siemens NX, PTC, Creo Schlumberger Petrel ou Autodesk Maya. La carte NVIDIA Quadro VDWS permet aux utilisateurs d'accéder à leurs applications graphiques professionnelles, avec des fonctionnalités et des performances complètes, partout sur n'importe quel périphérique.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA Virtual ComputeServer</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">De nombreuses entreprises exécutent des charges de travail serveur gourmandes en ressources système, telles que l'intelligence artificielle (IA), l'apprentissage profond (AP) et la data science. Pour ces cas d'utilisation, le logiciel NVIDIA vComputeServer virtualise le processeur graphique NVIDIA, qui accélère les charges de travail serveur intensives en ressources de calcul grâce à des fonctionnalités telles que le code de correction d'erreur, le retrait de page, la liaison peer-to-peer sur NVLink et le multivGPU.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Une licence Quadro VDWS vous permet d'utiliser GRID VPC et NVIDIA vComputeServer.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">Suivant : déploiement</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">Un espace de travail se compose d'un environnement de postes de travail partagé, où des sessions de postes de travail distants sont hébergées sur site ou dans tout environnement cloud de support. Avec Microsoft Azure, l'environnement de postes de travail peut être persistant avec les postes de travail virtuels Windows. Chaque espace de travail est associé à une organisation ou à un client spécifique.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">Gestion de l'espace de travail</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">Un espace de travail est constitué d'un environnement de postes de travail. Il peut s'agir de sessions de postes de travail distants partagées hébergées sur site ou dans tout environnement cloud pris en charge. Avec Microsoft Azure, l'environnement de postes de travail peut être persistant avec les postes de travail virtuels Windows. Chaque espace de travail est associé à une organisation ou à un client spécifique. Les options disponibles lors de la création d'un nouvel espace de travail sont visibles dans la figure suivante.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">Chaque espace de travail est associé à un déploiement spécifique.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">Les espaces de travail contiennent des applications et des services d'application associés, des dossiers de données partagés, des serveurs et une instance WVD. Chaque espace de travail peut contrôler des options de sécurité telles que l'application de la complexité des mots de passe, l'authentification multifactorielle, l'audit des fichiers, etc.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">Les espaces de travail peuvent contrôler la planification des charges de travail pour mettre sous tension des serveurs supplémentaires, limiter le nombre d'utilisateurs par serveur ou définir la planification des ressources disponibles pour une période donnée (toujours activé/désactivé). Les ressources peuvent également être configurées pour être réveillés à la demande.</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">L'espace de travail peut remplacer les valeurs par défaut des ressources de la machine virtuelle de déploiement, si nécessaire. Pour WVD, les pools d'hôtes WVD (qui contiennent des hôtes de session et des groupes d'applications) et les espaces de travail WVD peuvent également être gérés à partir du portail de la suite de gestion d'espace de travail cloud. Pour plus d'informations sur le pool hôte WVD, consultez ce document<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">Suivant : gestion des applications</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">Grâce à NetApp VDS, les administrateurs peuvent déléguer des tâches à d'autres personnes. Ils peuvent se connecter aux serveurs déployés pour résoudre les problèmes, afficher les journaux et exécuter des rapports d'audit. Tout en aidant les clients, le service d'assistance ou les techniciens de niveau 3 peuvent créer des clichés instantanés des sessions utilisateur, consulter les listes de processus et arrêter les processus si nécessaire.</block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Test de charge d'un serveur unique avec VSI à la connexion</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp Virtual Desktop Service utilise le protocole Microsoft Remote Desktop Protocol pour accéder aux applications et aux sessions des postes de travail virtuels. L'outil Login VSI détermine le nombre maximal d'utilisateurs pouvant être hébergés sur un modèle de serveur spécifique. Connexion VSI simule la connexion utilisateur à des intervalles spécifiques et effectue des opérations utilisateur telles que l'ouverture de documents, la lecture et la rédaction de messages, l'utilisation d'Excel et PowerPoint, l'impression de documents, la compression de fichiers et la prise de pauses aléatoires. Il mesure alors les temps de réponse. Le temps de réponse des utilisateurs est faible lorsque l'utilisation des serveurs est faible et augmente lors de l'ajout de sessions utilisateur supplémentaires. Login VSI détermine la base en fonction des sessions de connexion de l'utilisateur initiales et indique la session utilisateur maximale lorsque la réponse de l'utilisateur dépasse 2 secondes de la ligne de base.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">NetApp Virtual Desktop Service utilise le protocole Microsoft Remote Desktop Protocol pour accéder aux applications et sessions de postes de travail virtuels. Pour déterminer le nombre maximal d'utilisateurs pouvant être hébergés sur un modèle de serveur spécifique, nous avons utilisé l'outil Login VSI. Connectez-vous à VSI simule la connexion utilisateur à des intervalles spécifiques et effectue des opérations utilisateur telles que l'ouverture de documents, la lecture et la rédaction de messages, l'utilisation d'Excel et PowerPoint, l'impression de documents, la compression de fichiers, la prise de pauses aléatoires, etc. Il mesure également les temps de réponse. Le temps de réponse des utilisateurs est faible lorsque l'utilisation des serveurs est faible et augmente lors de l'ajout de sessions utilisateur supplémentaires. L'ISBC de connexion détermine la base en fonction des sessions de connexion utilisateur initiales et indique le nombre maximal de sessions utilisateur lorsque la réponse utilisateur dépasse 2 secondes de la ligne de base.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">Le tableau suivant contient le matériel utilisé pour cette validation.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">Nombre</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">Trois dans un cluster pour les lanceurs, AD, DHCP, etc. Un serveur pour le test de charge.</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2 x 24C Intel Xeon Gold 6282 @2,1 GHz. 1,5 TO DE RAM.</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">Le tableau suivant contient le logiciel utilisé pour cette validation.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">solution netapp</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">Modèle de machine virtuelle Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">OS serveur pour RDSH</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Connexion VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">Mise à jour 3 de VMware vSphere 6.7</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">Hyperviseur</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">Mise à jour 6.7 de VMware vCenter 3f</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">Outil de gestion VMware</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Les résultats du test Login VSI sont les suivants :</block>
  <block id="17126aef3e415713552604218f448967" category="cell">Configuration de machines virtuelles</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Connexion de base VSI</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Connexion VSI max</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">8 vCPU, 48 Go de RAM, 75 Go de disque, profil 8Q vGPU</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">12 vCPU, 128 Go de RAM, 75 Go de disque</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">Si l'on tient compte des frontières de la sous-NUMA et de l'hyperthreading, les huit machines virtuelles choisies pour le test et la configuration des machines virtuelles dépendent des cœurs disponibles sur l'hôte.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">Nous avons utilisé 10 machines virtuelles de lancement sur H610C, qui ont utilisé le protocole RDP pour se connecter à la session utilisateur. La figure suivante illustre les informations de connexion VSI.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">La figure suivante affiche le temps de réponse de Login VSI par rapport aux sessions actives du H610C.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">La figure suivante affiche le temps de réponse de Login VSI par rapport aux sessions actives de l' H615C.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">Les mesures de performances de Cloud Insights lors des tests VSI de connexion H615C pour l'hôte vSphere et les machines virtuelles sont présentées dans la figure suivante.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">Suivant : portail de gestion</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">Cette page présente l'outil DCConfig, les outils TestVcc et les fichiers journaux.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">Outils et journaux</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">Outil DCConfig</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">L'outil DCCconfig prend en charge les options d'hyperviseur suivantes pour l'ajout d'un site :</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">Le mappage de lettres de lecteur propre à l'espace de travail pour les données partagées peut être géré par GPO. Les services professionnels ou l'équipe de support peuvent utiliser l'onglet avancé pour personnaliser des paramètres tels que les noms d'UO Active Directory, l'option pour activer ou désactiver le déploiement de FSLogix, diverses valeurs de délai, etc.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Centre de commande (anciennement appelé Outils TestVcc)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Vue d'ensemble du centre de commande</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Pour lancer Command Center et le rôle requis, reportez-vous à la section <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">Vous pouvez effectuer les opérations suivantes :</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">Modifiez le chemin SMB d'un espace de travail.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">Modifier le site de collecte de provisionnement.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">Fichiers journaux</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">journaux d'automatisation</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>Fait <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">Gestion des opérations</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">Dépannage de la page actions VDA ayant échoué</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">Pour plus d'informations sur les fichiers journaux VDS, reportez-vous au<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">Page composants et autorisations VDA</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">Pour plus d'informations sur les autorisations minimales requises, reportez-vous à la section<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">Page clonage de machines virtuelles</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">Pour cloner manuellement un serveur, reportez-vous à la section<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">Augmenter automatiquement l'espace disque</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">Pour augmenter automatiquement la taille des disques de l'ordinateur virtuel, consultez la<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">Exigences de l'utilisateur final</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">Pour identifier l'adresse de passerelle permettant de configurer manuellement le client, reportez-vous à la section<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights est un outil de surveillance web qui offre une visibilité complète sur l'infrastructure et les applications exécutées sur NetApp et d'autres composants de l'infrastructure tiers. Cloud Insights prend en charge les clouds privés et publics pour surveiller, dépanner et optimiser les ressources.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">Seule la machine virtuelle de l'unité d'acquisition (peut être Windows ou Linux) doit être installée sur un cloud privé pour collecter des metrics à partir de collecteurs de données sans nécessiter d'agents. Les collecteurs de données basés sur un agent vous permettent d'extraire des mesures personnalisées à partir du moniteur de performances Windows ou de tout agent d'entrée pris en charge par Telegraf.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">La figure suivante représente le tableau de bord VDS Cloud Insights.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">Pour plus d'informations sur NetApp Cloud Insights, rendez-vous sur<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">Suivant : outils et journaux</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">Le portail NetApp VDS Cloud Workspace Management Suite permet une gestion centralisée de différents déploiements VDS, notamment un site défini pour les utilisateurs sur site, les administrateurs, le catalogue d'applications et les événements utilisant des scripts. Le portail est également utilisé par les utilisateurs administratifs pour le provisionnement manuel des applications si nécessaire et pour se connecter à n'importe quel ordinateur pour le dépannage.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">Portail de gestion</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">Le portail NetApp VDS Cloud Workspace Management Suite est disponible<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> la version à venir est également disponible<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">Le portail permet une gestion centralisée de différents déploiements VDS, y compris un site défini pour les utilisateurs sur site, les utilisateurs administratifs, le catalogue d'applications et les événements avec script. Le portail est également utilisé par les utilisateurs administratifs pour le provisionnement manuel des applications si nécessaire et pour se connecter à n'importe quel ordinateur pour le dépannage.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">Les prestataires de services peuvent utiliser ce portail pour ajouter leurs propres partenaires de distribution et leur permettre de gérer leurs propres clients.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">Suivant : gestion des utilisateurs</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">Vous pouvez déployer NetApp VDS sur Microsoft Azure à l'aide d'une application de configuration disponible en fonction de la base de code requise.</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">Vous pouvez déployer NetApp VDS sur Microsoft Azure à l'aide d'une application de configuration disponible en fonction de la base de code requise. La version actuelle est disponible<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> la version de présentation du produit à venir est également disponible<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">Voir<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> pour des instructions de déploiement.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">Prochain : environnement de cloud hybride</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS utilise Azure Active Directory pour l'authentification des identités et les services de domaine Azure Active Directory pour l'authentification NTLM/Kerberos. L'outil ADConnect permet de synchroniser un domaine Active Directory sur site avec Azure Active Directory.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">Gestion des utilisateurs</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">Vous pouvez ajouter de nouveaux utilisateurs à partir du portail ou activer l'espace de travail cloud pour les utilisateurs existants. Les autorisations pour les espaces de travail et les services d'application peuvent être contrôlées par des utilisateurs individuels ou par des groupes. À partir du portail de gestion, les utilisateurs administratifs peuvent être définis pour contrôler les autorisations du portail, des espaces de travail, etc.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">La figure suivante décrit la gestion des utilisateurs dans NetApp VDS.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">Chaque espace de travail réside dans sa propre unité d'organisation Active Directory (ou) sous l'unité d'organisation Cloud Workspace, comme illustré dans la figure suivante.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">Pour plus d'informations, voir<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> Sur les autorisations des utilisateurs et la gestion des utilisateurs dans NetApp VDS.</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">Lorsqu'un groupe Active Directory est défini comme un groupe CRAUserGroup à l'aide d'un appel API pour le centre de données, tous les utilisateurs de ce groupe sont importés dans CloudWorkspace pour la gestion à l'aide de l'interface utilisateur. Lorsque l'espace de travail Cloud est activé pour l'utilisateur, VDS crée des dossiers d'accueil utilisateur, des autorisations de paramètres, des mises à jour des propriétés utilisateur, etc.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">Si l'option utilisateur VDI activé est cochée, VDS crée une machine RDS d'une session dédiée à cet utilisateur. Elle demande le modèle et le datastore à provisionner.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">Suivant : gestion de l'espace de travail</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">Grâce aux calculs arithmétiques répétitifs, les GPU sont généralement utilisés pour la visualisation graphique (rendu). Ces fonctionnalités de calcul répétitives sont souvent utilisées pour l'IA et l'apprentissage profond.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">Considérations relatives aux GPU</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">Pour les applications graphiques exigeantes, Microsoft Azure propose la gamme NV basée sur la carte NVIDIA Tesla M60 avec un à quatre GPU par machine virtuelle. Chaque carte NVIDIA Tesla M60 comprend deux processeurs graphiques Maxwell, chacun avec 8 Go de mémoire GDDR5, pour un total de 16 Go.</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">Une licence NVIDIA est incluse dans la gamme NV.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">Avec NetApp HCI, le GPU H615C contient trois cartes NVIDIA Tesla T4. Chaque carte NVIDIA Tesla T4 dispose d'un processeur graphique Touring avec 16 Go de mémoire GDDR6. Lorsqu'elles sont utilisées dans un environnement VMware vSphere, les serveurs virtuels peuvent partager les GPU, chaque machine virtuelle disposant d'une mémoire tampon dédiée. Le suivi des rayons est disponible avec les processeurs graphiques de la NetApp HCI H615C pour produire des images réalistes comprenant les réflexions de lumière. Notez que vous devez disposer d'un serveur de licences NVIDIA avec une licence pour les fonctionnalités GPU.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">Pour utiliser le GPU, vous devez installer le pilote approprié, qui peut être téléchargé à partir du portail de licences NVIDIA. Dans un environnement Azure, le pilote NVIDIA est disponible en tant qu'extension de pilote GPU. Ensuite, les stratégies de groupe de la capture d'écran suivante doivent être mises à jour pour utiliser le matériel GPU pour les sessions de service de bureau à distance. Vous devez hiérarchiser le mode graphique H.264 et activer la fonctionnalité d'encodeur.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">Validez la surveillance des performances du GPU avec Task Manager ou à l'aide de l'interface de ligne de commande nvidia-smi lors de l'exécution d'échantillons WebGL. Assurez-vous que les ressources GPU, mémoire et encodeur sont utilisées.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">Pour s'assurer que la machine virtuelle est déployée dans NetApp HCI H615C avec le service de bureau virtuel, définissez un site avec la ressource de cluster vCenter dotée d'hôtes H615C. Le profil vGPU requis doit être associé au modèle VM.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">Pour les environnements partagés multi-sessions, envisagez d'allouer plusieurs profils vGPU homogènes. Cependant, pour une application graphique professionnelle haut de gamme, il est préférable que chaque machine virtuelle soit dédiée à un utilisateur afin d'isoler les machines virtuelles.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">Le processeur GPU peut être contrôlé par une stratégie QoS et chaque profil vGPU peut disposer de tampons de trame dédiés. Cependant, l'encodeur et le décodeur sont partagés pour chaque carte. Le placement d'un profil vGPU sur une carte GPU est contrôlé par la règle d'affectation des GPU de l'hôte vSphere, qui peut mettre en avant les performances (répartir les VM) ou la consolidation (regrouper les VM de groupe).</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">Ensuite : solutions pour le secteur.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">Les postes de travail graphiques sont généralement utilisés dans des secteurs tels que l'industrie, la santé, l'énergie, les médias et le divertissement, l'éducation, accidentelle, etc. La mobilité est souvent limitée pour les applications graphiques.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">Solutions industrielles</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">Pour résoudre les problèmes de mobilité, les services de postes de travail virtuels proposent un environnement de postes de travail pour tous les types de collaborateurs, des travailleurs chargés des tâches aux utilisateurs experts, en utilisant des ressources matérielles dans le cloud ou avec NetApp HCI, et en proposant notamment des options de configurations de processeurs graphiques flexibles. VDS permet aux utilisateurs d'accéder à leur environnement de travail depuis n'importe où avec des ordinateurs portables, des tablettes et d'autres appareils mobiles.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">Pour exécuter des charges de travail de fabrication avec des logiciels tels que ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3ds Max, Dassault systèmes SOLIDWORKS, Dassault systèmes CATIA, PTC Creo, Siemens PLM NX, etc. En janvier 2021, les GPU disponibles sur différents clouds sont répertoriés dans le tableau suivant.</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">Modèle de GPU</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute (GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">Services Web Amazon (AWS)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">Sur site (NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">Des sessions de postes de travail partagés avec d'autres utilisateurs et des postes de travail personnels dédiés sont également disponibles. Les postes de travail virtuels peuvent disposer de un à quatre processeurs graphiques ou utiliser des GPU partiels avec NetApp HCI. NVIDIA T4 est une carte graphique polyvalente qui répond aux demandes d'un large éventail de charges de travail des utilisateurs. Chaque carte graphique du NetApp HCI H615C dispose de 16 Go de mémoire tampon trame et de trois cartes par serveur. Le nombre d'utilisateurs pouvant être hébergés sur un seul serveur H615C dépend de la charge de travail de l'utilisateur.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">Utilisateurs/serveur</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">Lumière (4 Go)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">Moyen (8 Go)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">Lourd (16 Go)</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">Pour déterminer le type d'utilisateur, exécutez l'outil de profileur GPU lorsque les utilisateurs travaillent avec des applications exécutant des tâches types. Le profileur GPU capture les demandes en mémoire, le nombre d'affichages et la résolution dont les utilisateurs ont besoin. Vous pouvez ensuite choisir le profil vGPU qui répond à vos besoins.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">Les postes de travail virtuels avec processeurs graphiques peuvent prendre en charge une résolution d'affichage pouvant atteindre 8 Ko. Par ailleurs, l'utilitaire nView permet de diviser un seul moniteur en régions pour travailler avec différents jeux de données.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">Grâce au stockage de fichiers ONTAP, vous bénéficiez de nombreux avantages :</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">Un seul espace de nom pouvant atteindre 20 po de stockage avec 400 milliards de fichiers, sans qu'il soit nécessaire d'effectuer des tâches d'administration</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">Espace de noms pouvant s'étendre sur le globe avec un cache de fichiers global</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">Colocation sécurisée avec le stockage NetApp géré</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">La migration de données inactives vers des magasins d'objets à l'aide de NetApp FabricPool</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">Statistiques rapides sur les fichiers et analytique du système de fichiers</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">Évolutivité d'un cluster de stockage jusqu'à 24 nœuds pour de meilleures capacités et performances</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">La possibilité de contrôler l'espace de stockage à l'aide de quotas, de performances garanties et des limites de QoS</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">Sécurisation des données avec le chiffrement</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">Répondre aux exigences générales de conformité et de protection des données</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">Des options flexibles de continuité de l'activité</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">Fonctionnalités de ONTAP pour le service de postes de travail virtuels</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">Fonctionnalités de ONTAP pour le service de postes de travail virtuels</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">Les fonctionnalités ONTAP suivantes font du choix une solution intéressante pour un service de poste de travail virtuel.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">*Système de fichiers scale-out.* les volumes ONTAP FlexGroup peuvent atteindre une taille de plus de 20 po et contenir plus de 400 milliards de fichiers dans un seul espace de noms. Le cluster peut contenir jusqu'à 24 nœuds de stockage, chacun disposant d'un nombre flexible de cartes d'interface réseau en fonction du modèle utilisé.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">Les postes de travail virtuels, les dossiers locaux et les conteneurs de profil utilisateur, les données partagées, etc. Peuvent croître à la demande sans craindre les limitations du système de fichiers.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">*Analyse du système de fichiers.* vous pouvez utiliser l'outil XCP pour obtenir des informations sur les données partagées. Avec ONTAP 9.8+ et ActiveIQ Unified Manager, vous pouvez facilement interroger et récupérer les informations de métadonnées de fichier et identifier les données inactives.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">*Cloud Tiering.* vous pouvez migrer des données inactives vers un magasin d'objets dans le cloud ou vers tout stockage compatible S3 de votre datacenter.</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">*Les versions de fichiers*. Les utilisateurs peuvent restaurer des fichiers protégés par les copies Snapshot NetApp ONTAP. Les copies Snapshot de ONTAP sont très peu gourmandes en espace car elles n'enregistrent que les blocs modifiés.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">*Espace de noms global.* la technologie ONTAP FlexCache permet la mise en cache à distance du stockage de fichiers, ce qui facilite la gestion des données partagées à travers des emplacements contenant des systèmes de stockage ONTAP.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">*Prise en charge de la colocation sécurisée.* Un cluster de stockage physique unique peut être présenté sous forme de plusieurs baies de stockage virtuelles chacune avec ses propres volumes, protocoles de stockage, interfaces réseau logiques, domaine d'authentification et d'identité, utilisateurs de gestion, etc. C'est pourquoi vous pouvez partager la baie de stockage entre plusieurs unités commerciales ou environnements, comme le test, le développement et la production.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">Pour garantir les performances, vous pouvez utiliser la QoS adaptative pour définir des niveaux de performance en fonction de l'espace utilisé ou alloué. Vous pouvez également contrôler la capacité de stockage à l'aide de quotas.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">*Intégration VMware.* les outils ONTAP pour VMware vSphere fournissent un plug-in vCenter pour le provisionnement des datastores, la mise en œuvre des meilleures pratiques de l'hôte vSphere et la surveillance des ressources ONTAP.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP prend en charge les API vStorage pour l'intégration de baies (VAAI) pour transférer les opérations SCSI/fichiers vers la baie de stockage. ONTAP prend également en charge les API vStorage pour Storage Awareness (VASA) et les volumes virtuels pour les protocoles de niveau bloc et fichier.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">Le plug-in SnapCenter pour VMware vSphere constitue un moyen simple de sauvegarder et restaurer les machines virtuelles à l'aide de la fonctionnalité Snapshot sur une baie de stockage.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager offre une visibilité complète sur le réseau de stockage, dans un environnement vSphere. Les administrateurs peuvent facilement identifier les problèmes de latence susceptibles de survenir dans les environnements de postes de travail virtuels hébergés sur ONTAP.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">*Conformité à la sécurité.* avec Active IQ Unified Manager, vous pouvez surveiller plusieurs systèmes ONTAP avec des alertes pour toute violation de stratégie.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">*Prise en charge multiprotocole.* ONTAP prend en charge les blocs (iSCSI, FC, FCoE et NVMe/FC), les fichiers (NFSv3, Protocoles de stockage NFSv4.1, SMB2.x et SMB3.x) et objet (S3).</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">*Prise en charge de l'automatisation.* ONTAP fournit des modules API REST, Ansible et PowerShell pour automatiser les tâches avec le portail de gestion VDS.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">Suivant : la gestion des données</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">Cloud NetApp</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">Documentation produit NetApp VDS</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">Connectez votre réseau sur site à Azure avec VPN Gateway</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Portail Azure</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Postes de travail virtuels Microsoft Windows</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Inscription Azure NetApp Files</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">Les employés chargés de tâches peuvent rapidement lancer une application à partir de la liste des applications mises à leur disposition. Les services d'application publient des applications à partir des hôtes de session Remote Desktop Services. Avec WVD, les groupes d'applications offrent des fonctionnalités similaires à partir de pools d'hôtes Windows 10 multi-session.</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">Solutions d'end-user computing (EUC) et d'infrastructure de postes de travail virtuels (VDI)</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">Que vous déployiez des postes de travail virtuels sur site ou dans le cloud, NetApp propose une multitude de solutions EUC/VDI pour répondre à vos besoins.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp Virtual Desktop Services (VDS)</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">VDS (Virtual Desktop Service) NetApp orchestre les services RDS (Remote Desktop Services) dans les principaux clouds publics et privés.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">Solutions disponibles pour VDS :</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">VDI cloud hybride avec NetApp Virtual Desktop Service</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">End-User Computing avec VMware Horizon</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp a vérifié les architectures pour VMware Horizon couvrant plusieurs configurations de calcul. Les solutions disponibles incluent :</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">End-User Computing avec VMware (Guide de conception)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">End-User Computing avec VMware et processeurs graphiques NVIDIA (Guide de conception)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">End-User Computing avec VMware et processeurs graphiques NVIDIA (Guide de déploiement)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">End-user computing avec VMware pour les graphiques 3D</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">VDS (Virtual Desktop Service) NetApp orchestre les services RDS (Remote Desktop Services) dans les principaux clouds publics et privés. VDS prend en charge Windows Virtual Desktop (WVD) sur Microsoft Azure. VDS automatise de nombreuses tâches à effectuer après le déploiement de WVD ou RDS, notamment la configuration des partages de fichiers SMB (pour les profils d'utilisateurs, les données partagées et le disque dur domestique des utilisateurs), l'activation des fonctionnalités Windows, de l'installation des applications et des agents, du pare-feu et des règles, etc.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">Tr-4861 : VDI dans le cloud hybride avec service de postes de travail virtuels</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">T echnologiques Suresh, NetApp</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">Les utilisateurs consomment VDS pour les postes de travail dédiés, les postes de travail partagés et les applications distantes. VDS fournit des événements utilisant des scripts pour automatiser la gestion des applications des bureaux et réduit le nombre d'images à gérer.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS fournit un portail de gestion unique pour la gestion des déploiements dans des environnements clouds publics et privés.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">En valeur pour le client</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">Avec l'explosion de 2020 000 employés, les exigences de continuité de l'activité ont changé. Les départements INFORMATIQUES sont confrontés à de nouveaux challenges qui doivent provisionner rapidement les postes de travail virtuels. Par conséquent, ils nécessitent une agilité du provisionnement, une gestion à distance et les avantages en termes de coût total de possession d'un cloud hybride qui simplifie le provisionnement des ressources sur site et dans le cloud. Ils ont besoin d'une solution de cloud hybride qui :</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">Répond à la réalité de l'espace de travail post-COVID pour mettre en place des modèles de travail flexibles dotés de dynamiques mondiales</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">Favorise le travail par équipe en simplifiant et en accélérant le déploiement d'environnements de travail pour tous les employés, des travailleurs chargés de tâches aux utilisateurs intensifs</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">Mobilise vos équipes en fournissant des ressources VDI riches et sécurisées, quel que soit l'emplacement physique</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">Simplifie le déploiement du cloud hybride</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">Automatise et simplifie la gestion de la réduction des risques</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">Ensuite : cas d'utilisation</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">Gestion des applications</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">Pour les employés du bureau qui souhaitent pouvoir alimenter les utilisateurs, les applications dont ils ont besoin peuvent être provisionnées manuellement via un tableau de services ou provisionnées automatiquement à l'aide de la fonctionnalité d'événements scripts dans NetApp VDS.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">Droits des applications NetApp</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">Pour plus d'informations, reportez-vous à la section<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">Suivant : fonctionnalités ONTAP pour les services de postes de travail virtuels</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">Mise en route</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">Nouveautés</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">Infrastructures convergées pour les workloads d'IA</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">ONTAP AI AVEC NVIDIA</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">EF-Series ai avec NVIDIA</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">IBM Spectrum avec stockage NetApp E-Series</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Inférence d'IA en périphérie : NetApp avec Lenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP et Lenovo ThinkSystem SR670 pour l'IA</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">NetApp AFF A800 et le serveur Fujitsu PRIMERGY GX2570 M5 pour l'IA</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">Data Lakes et pipelines de données</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">Data Lake StorageGRID pour les workloads de conduite autonome</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">Déplacement des données avec E-Series et BeeGFS pour l'IA</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">L'IA dans le cloud hybride avec mise en cache des données</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">Orchidée et gestion</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">Plan de contrôle NetApp pour le pipeline d'IA et l'orchidée des espaces de travail</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Pipeline MLRun avec Iguazio</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">Solution d'orchestration NetApp avec exécution:IA</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">Analyse des sentiments</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">Prévision de taux par clic - formation distribuée dans Azure</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">Détection de voie - formation distribuée dans Azure</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">Conversationnel de l'IA avec NVIDIA Jarvis</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">Conduite autonome</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">Santé - imagerie diagnostique</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">Détection des fraudes par carte de crédit</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD : une solution NetApp et NVIDIA</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">BeeGFS sur NetApp (Guide de conception)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">BeeGFS sur NetApp (guide de déploiement)</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NVIDIA DGX SuperPOD avec NetApp (guide de conception)</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">Mise en route/meilleures pratiques</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp et VMware : mise en route</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">Avantages de NetApp ONTAP pour les administrateurs VMware vSphere</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">VMware vSphere avec les meilleures pratiques ONTAP</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">VMware dans le cloud public</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">Multicloud hybride NetApp avec VMware</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">NetApp pour AWS VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp pour Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp pour Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">Protection des données</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">VMware site Recovery Manager (SRM) avec NetApp ONTAP 9</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">Outils ONTAP pour VMware vSphere - sécurité produit</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">Automatisation VMware vSphere</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">Démos et tutoriels</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">Plus de ressources</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">Solutions de postes de travail virtuels</block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">Solutions NetApp pour VMware dans les clouds d'hyperscalers</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">Options de stockage prises en charge</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">Solutions prises en charge</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">Prise en charge des datastores NFS pour les régions</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">NetApp sur AWS (VMC)</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">Multicloud hybride NetApp avec VMware pour VMC</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">Configuration de l'environnement de virtualisation</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">FSX ONTAP en tant que datastore NFS supplémentaire : présentation</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP en tant que stockage connecté à l'invité</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO pour le stockage connecté à l'invité</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">Solutions multiclouds hybrides pour VMC</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">Prise en charge des datastores NFS dans AWS</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">NetApp sur Azure (AVS)</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">NetApp multicloud hybride avec VMware pour AVS</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">ANF en tant que datastore NFS supplémentaire : présentation</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">ANF comme stockage connecté par l'invité</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">Solutions multicloud hybrides pour AVS</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">Prise en charge des datastores NFS dans Azure</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">NetApp sur Google Cloud Platform (GCVE)</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">Multicloud hybride NetApp avec VMware pour GCVE</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS en tant que stockage connecté à l'invité</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">Solutions multiclouds hybrides pour GCVE</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">Présentation de la sécurité : NetApp CVS dans Google Cloud</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">Outils</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">FSX pour ONTAP + calculateur de TCO VMC</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">FSX pour simulateur ONTAP + VMC</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">CALCULATEUR DE TCO ANF + AVS</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">Simulateur ANF + AVS</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">Présentation supplémentaire du datastore NFS</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">Options supplémentaires de datastore NFS</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">Options de stockage connecté à l'invité</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">Solutions de protection des workloads</block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">Solutions de migration des workloads</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">Datastore NFS supplémentaire - préversion publique (Microsoft)</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">Google Cloud VMware Engine avec NetApp Cloud Volumes Service</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">Présentation de la sécurité - NetApp Cloud Volumes Service (CVS) dans Google Cloud</block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">Datastore NFS supplémentaire : présentation</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">Datastore NFS supplémentaire : options</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">VMware Cloud sur AWS : nouvelle région, stockage externe et options d'achat</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">Charge de travail Apache Spark avec la solution de stockage NetApp</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">Description de la solution d'analytique moderne</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">Et des meilleures pratiques</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Meilleures pratiques pour Kafka fluide</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 et Splunk Enterprise</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">NetApp EF600 avec Splunk Enterprise</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">Solutions de cloud hybride - cas d'utilisation d'Spark et d'Hadoop</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">Ressources supplémentaires</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">Blog : Apache Spark participe au jeu de jeu NetApp Data Analytics Playground</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">Blog : utilisez XCP pour la migration des données d'un Data Lake et d'HPC vers ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV : liste de diffusion analytique Big Data</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">Bases de données Oracle 19c RAC sur FlexPod datacenter</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">SAP avec Oracle sous UNIX et NFS avec NetApp clustered Data ONTAP</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">Déployer une base de données Oracle sur NetApp ONTAP</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="sidebar">Déploiement automatisé d'Oracle 19c pour ONTAP sur NFS</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">Protection automatisée des données Oracle</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Bases de données Oracle sur les baies NetApp EF-Series</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">Serveur SQL</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="sidebar">SQL Server sur Azure NetApp Files</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">SAP avec Microsoft SQL Server sur Windows et clustered Data ONTAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Modernisation de Microsoft SQL Server</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Guide des meilleures pratiques pour Microsoft SQL Server avec la gamme NetApp EF-Series</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">Solutions de base de données pour le cloud hybride</block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">Déploiement de bases de données Oracle sur les meilleures pratiques EC2/FSX</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">Solutions de base de données pour le cloud hybride avec SnapCenter</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">Anthos avec NetApp</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="sidebar">Intégrations du stockage NetApp</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="sidebar">Red Hat OpenShift avec NetApp</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">VMware Tanzu avec NetApp</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">DevOps avec NetApp</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">À propos de nos ressources pour les conteneurs</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">À propos de nos solutions partenaires</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Site Web Anthos</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Site Web Red Hat OpenShift</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">Site Web de VMware Tanzu</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">Documentation des solutions NetApp</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="sidebar">Les applications d'entreprise</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP HANA</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">Les solutions FlexPod</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">Solutions NetApp HCI existantes</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">À propos des solutions NetApp</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">Mentions légales</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">Modifier l'historique</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">Vidéos de démonstration</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">Pages d'accueil de la solution</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">Les bases de données d'entreprise</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">Multicloud hybride NetApp avec VMware</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP ET SAP HANA</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">Automatisation des demandes</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - une solution NetApp Cisco</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">Contenu technique Solutions FlexPod</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">Page de vente FlexPod</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">Proposer une nouvelle solution</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">Fournir des commentaires sur la solution</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">Migration des données NetApp XCP</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">Instructions sur les meilleures pratiques pour NetApp XCP</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">Migration des données CIFS avec listes de contrôle d'accès depuis le boîtier de stockage source vers ONTAP</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">Les infrastructures convergées d'IA</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">Guide de conception de ONTAP ai avec les systèmes NVIDIA DGX A100</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">Guide de déploiement de ONTAP ai avec NVIDIA DGX A100</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">Guide de conception de ONTAP ai avec systèmes NVIDIA DGX A100 et switchs Ethernet Mellanox Spectrum</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">Guide de déploiement de ONTAP ai avec des systèmes NVIDIA DGX A100 et des switchs Ethernet Mellanox Spectrum</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">EF-Series ai avec les systèmes NVIDIA DGX A100 et BeeGFS Design</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">EF-Series ai avec les systèmes NVIDIA DGX A100 et BeeGFS Deployment</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">Guide de déploiement BeeGFS avec NetApp E-Series</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS avec architecture de référence NetApp E-Series</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">Déploiement d'IBM Spectrum Scale avec un stockage NetApp E-Series</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">AFF A800 et le serveur Fujitsu PRIMERGY GX2570 M5 pour les charges de travail d'entraînement des modèles d'IA et DE ML</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">Pipelines de données, data Lakes et gestion</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">Data Lake NetApp StorageGRID pour les workloads de conduite autonome</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Déploiement Trident</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">Déplacement des données avec les E-Series et BeeGFS pour les workflows d'IA et d'analytique</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">IA responsable et inférence confidentielle : NetApp ai avec Protopia image transformation</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">Analyse des sentiments avec NetApp ai</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">Déploiement de l'analyse des sentiments du centre de support</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Formation distribuée dans Azure - prévision de taux par clic</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">Gestion des versions de datasets et de modèles à l'aide du kit d'outils NetApp DataOps</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">Ordinateurs portables Jupyter pour référence</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">Formation Azure distribuée - détection de voie</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">Détection de voie : entraînement distribué avec L'IA</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">Système d'exploitation pour le cloud hybride IA avec mise en cache des données</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">Déplacez les données d'un environnement Big Data vers un environnement d'IA</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Inférence d'IA en périphérie - NetApp avec Lenovo ThinkSystem - conception de la solution</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">Conversationnel de l'IA avec NVIDIA</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">Optimisation de l'utilisation des clusters et des GPU avec l'exécution d'IA</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">Exécutez l'installation d'IA</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">Exécuter des tableaux de bord et des vues d'IA</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">Soumission des tâches dans l'interface de ligne de commande Exécuter l'IA</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">NetApp ONTAP ai pour les workloads de conduite autonome</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">Architecture de référence NetApp ONTAP ai pour le secteur de la santé : imagerie diagnostique</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">Architecture de référence ONTAP ai pour les workloads de services financiers</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">Déploiement d'IA avec NetApp E-Series et BeeGFS</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">Guide de conception des systèmes Quantum StorNext avec NetApp E-Series</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">Guide de déploiement du système Quantum StorNext avec NetApp E-Series</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">Lancez-vous avec NetApp et VMware</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">Virtualisation VMware pour ONTAP</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">Gestion basée sur les volumes virtuels et les règles de stockage</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">VMware site Recovery Manager et NetApp ONTAP 9</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">Provisionnement classique du stockage bloc</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS - Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS : technologie Fibre Channel over Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS - iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS : NVMe over Fabric</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">Provisionnement traditionnel du stockage de fichiers</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS - v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS - v4.1</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware pour le cloud public</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">Cas d'utilisation du cloud hybride VMware</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">Présentation du cas d'utilisation</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="sidebar">Postes de travail virtuels</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">Services de postes de travail virtuels (VDS)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Test de charge d'un serveur unique avec VSI de connexion</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">Gestion des opérations</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">Considérations relatives aux GPU</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">Solutions industrielles</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">Validation technique ESG : une infrastructure VDI à l'échelle de l'entreprise avec NetApp Virtual Desktop Service</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">VMware Horizon</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">Solutions de virtualisation des postes de travail FlexPod</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">Plateforme de données NetApp E-Series et CommVault V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">Architecture de référence et bonnes pratiques de stockage E-Series et EF-Series avec Veeam Backup Replication 9.5</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">Déploiement de Veritas NetBackup avec le stockage NetApp E-Series</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">Contrôles de sécurité NIST pour FISMA avec HyTrust pour les infrastructures mutualisées</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">Mise en route avec les solutions d'automatisation NetApp et Ansible</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">Configuration de l'environnement d'automatisation</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">Automatisation des demandes</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">VMware Cloud pour clouds d'hyperscaler</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">Configurations compatibles</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">Configurez VMC pour AWS</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Configurez AVS pour Azure</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">Configurez GCVE pour GCP</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">Stockage NetApp dans les clouds d'hyperscaler</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">Datastore NFS supplémentaire pour VMC</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">Stockage connecté à l'invité pour VMC</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">Datastore NFS supplémentaire pour AVS</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">Stockage connecté à l'invité pour AVS</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">Stockage connecté invité pour GCVE</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">Résumé et conclusion</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">NetApp pour AWS/VMC</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">Protection des workloads</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">Migration des workloads</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">Migration des charges de travail vers FSX pour les datastores ONTAP à l'aide de VMware HCX</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp pour Azure/AVS</block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">Migrez des charges de travail vers le datastore ANF avec VMware HCX</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp pour GCP/GCVE</block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">Reprise après incident de l'application avec SnapCenter, CVO et Veeam Replication</block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">Présentation de l'architecture</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">Autres dépendances des services d'infrastructure NAS (KDC, LDAP, DNS)</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka avec les contrôleurs de stockage ONTAP NetApp</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">Synthèse des cas d'utilisation</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">De l'analytique Big Data à l'intelligence artificielle</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS vers NFS : étapes détaillées</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Les meilleures pratiques pour Kafka fluide</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Clusters à auto-rééquilibrage courants</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">Solutions de données de cloud hybride NetApp - Spark et Hadoop en fonction des cas d'utilisation clients</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">Cas d'utilisation 1 : sauvegarde des données Hadoop</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">Cas d'utilisation 2 : sauvegarde et reprise après incident du cloud vers des environnements sur site</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">Cas d'utilisation 3 : activation de DevTest sur les données Hadoop existantes</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">Cas d'utilisation 4 : protection des données et connectivité multicloud</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">Cas d'utilisation 5 - accélération des workloads d'analytique</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">Différentes solutions pour différentes stratégies d'analytique : Description de la solution</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID avec Splunk SmartStore</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Charge de travail Apache Spark avec la solution de stockage NetApp (guide de déploiement)</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="sidebar">Bases de données Oracle 19c RAC sur FlexPod datacenter avec Cisco UCS et NetApp AFF A800 via FC</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Déploiement de la base de données Oracle</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">Mise en route et conditions requises</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Déploiement automatisé Oracle 19c AWX/Tower</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">Déploiement automatisé de l'interface de ligne de commandes Oracle 19c</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Protection des données des bases de données Oracle</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">Protection automatisée des données Oracle pour AWX/Tower</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">Procédures de déploiement</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">Gestion des bases de données</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">Migration de base de données</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">Conception de référence (conception de haut niveau en temps réel)</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">Pour commencer l'utilisation sur site</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">Présentation des systèmes de stockage NetApp</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">Présentation des intégrations de stockage NetApp</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">Présentation de NetApp Astra Trident</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Options de configuration avancées pour Anthos</block>
  <block id="e131204502a58630f2f72937238604c8" category="sidebar">Vidéos / démos</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">Présentation de NetApp Astra Control Center</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">Utiliser les validations de cas</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Présentation de Red Hat OpenShift</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Enregistrez vos clusters Red Hat OpenShift</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">Choisissez les applications à protéger</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">Protégez vos applications</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">Options de configuration avancées pour OpenShift</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">Configurer la colocation sur Red Hat OpenShift avec NetApp ONTAP</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">Tâches d'administrateur de cluster</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">Tâches de l'administrateur du stockage</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">Évolutivité</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">Déploiement via l'opérateur</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">Flux de travail</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">Clonage de serveurs virtuels</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">Gestion du cycle de vie des applications</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">Gouvernance et risque</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">Création de ressources</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">Présentation de VMware TKG (Tanzu Kubernetes Grid)</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">Présentation de VMware TKGS (Tanzu Kubernetes Grid Service)</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">Présentation de VMware TKGI (Tanzu Kubernetes Grid Integrated Edition)</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Enregistrez vos clusters Kubernetes Tanzu</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">Solutions archivées</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp et VMware : faire mieux ensemble</block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">Et la suite ?</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">12/06/2022</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">7 vidéos supplémentaires pour la modernisation des bases de données Oracle dans le cloud hybride avec stockage Amazon FSX ont été ajoutées</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">L'intelligence artificielle (IA) et l'analytique moderne</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[Souligné]#*vidéos pour la modernisation d'Oracle avec le cloud hybride dans AWS et FSX*#</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">Partie 1 : cas d'utilisation et architecture de la solution</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">Partie 2a – migration des bases de données depuis les environnements sur site vers AWS grâce à la relocalisation automatisée de l'infrastructure de distribution des données avec une disponibilité maximale</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">2b : migration de base de données sur site vers AWS en utilisant la console BlueXP via SnapMirror</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">Partie 3 - Configuration automatisée de la réplication haute disponibilité/reprise après incident des bases de données, basculement, resynchronisation</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">Partie 4a : clone de base de données pour les opérations de développement/test avec l'interface utilisateur SnapCenter à partir de la copie de secours répliquée</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">Partie 4b : sauvegarde, restauration de base de données et clonage avec l'interface utilisateur SnapCenter</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">4e partie : sauvegarde de base de données, restauration avec sauvegarde et restauration des applications SaaS BlueXP</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp CVO (instance à nœud unique) sur AWS</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">Procédure</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">Précipitations :</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp CVO (HA pair) sur AWS</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp ONTAP FSX sur AWS</block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">Recettes :</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement d'ANF Volume sur Azure</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement d'ANF Volume avec Data protection sur Azure</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement d'ANF Volume avec un double protocole sur Azure</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement d'ANF Volume à partir de Snapshot sur Azure</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de Cloud volumes ONTAP sur Azure</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de CVO HA sur Azure</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp CVO (instance à nœud unique) sur GCP</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp CVO (HA pair) sur GCP</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">Fichiers de configuration Terraform pour le déploiement de NetApp CVS Volume sur GCP</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">Selon le scénario de déploiement, le serveur de sauvegarde Veeam, le référentiel de sauvegarde et le proxy de sauvegarde à déployer. Pour ce cas d'utilisation, nul besoin de déployer un magasin d'objets pour Veeam et le référentiel scale-out non plus requis.<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">12/15/2022</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">Ajout du document TR-4923 : SQL Server sur AWS EC2 avec Amazon FSX pour NetApp ONTAP</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">Tr-4923 : SQL Server sur AWS EC2 avec Amazon FSX pour NetApp ONTAP</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">Auteurs : Pat Sinthusan et Niyaz Mohamed, NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">La plupart des entreprises qui souhaitent migrer leurs applications de l'infrastructure sur site vers le cloud computing trouvent que les solutions de stockage sur site et les services de stockage cloud offrent bien des différences. Dans ce cas, la migration des applications d'entreprise telles que Microsoft SQL Server est beaucoup plus problématique. En particulier, les écarts dans les services requis pour exécuter une application d'entreprise, tels que des snapshots robustes, des fonctionnalités d'efficacité du stockage, une haute disponibilité, une fiabilité et une performance cohérente, ont contraint les clients à faire des compromis en termes de conception ou à renoncer à la migration des applications. Grâce à FSX pour NetApp ONTAP, les clients n'ont plus à faire des compromis. FSX pour NetApp ONTAP est un service AWS natif (1er fournisseur) vendu, pris en charge, facturé et entièrement géré par AWS. Il utilise la puissance de NetApp ONTAP pour fournir les mêmes fonctionnalités haute performance de gestion du stockage et des données que celles fournies par NetApp sur site pendant trois décennies dans AWS sous la forme d'un service géré.</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">ONTAP AWS FSX</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">Avec SQL Server sur des instances EC2, les administrateurs de bases de données peuvent accéder à leur environnement de base de données et le système d'exploitation sous-jacent, et les personnaliser. Une instance SQL Server sur EC2 en association avec<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> pour stocker les fichiers de base de données, assure des performances élevées, la gestion des données et un chemin de migration simple et facile à l'aide de la réplication au niveau des blocs. Vous pouvez donc exécuter votre base de données complexe sur AWS VPC avec une approche simplifiée du basculement, moins de clics et sans conversions de schéma.</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">Avantages liés à l'utilisation d'Amazon FSX pour NetApp ONTAP avec SQL Server</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">Amazon FSX pour NetApp ONTAP est le stockage de fichiers idéal pour les déploiements SQL Server dans AWS. Il présente les avantages suivants :</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">Des performances élevées et prévisibles, avec une faible latence</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">Mise en cache intelligente avec cache NVMe pour améliorer les performances</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">Un dimensionnement flexible qui permet d'augmenter ou de réduire la capacité, le débit et les IOPS à la volée</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">Réplication efficace des blocs sur site vers AWS</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">L'utilisation d'iSCSI, un protocole connu pour l'environnement de base de données</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">Fonctionnalités d'efficacité du stockage, telles que le provisionnement fin et les clones sans encombrement</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">Réduction du temps de sauvegarde de plusieurs heures à quelques minutes, ce qui réduit le RTO</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">Sauvegarde et restauration granulaires de bases de données SQL grâce à l'interface utilisateur intuitive de NetApp SnapCenter</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">Possibilité d'effectuer plusieurs migrations de tests avant la migration réelle</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">Un temps d'indisponibilité plus court pendant la migration et un dépassement des défis liés à la migration grâce à la copie au niveau des fichiers ou des E/S.</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">Réduction du délai moyen de résolution des incidents en identifiant la cause première après une mise à jour d'une version majeure ou d'un correctif</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">En déployant des bases de données SQL Server sur FSX ONTAP avec le protocole iSCSI, couramment utilisé sur site, vous disposez d'un environnement de stockage de base de données idéal offrant des performances, une efficacité du stockage et des fonctionnalités de gestion des données supérieures. En utilisant plusieurs sessions iSCSI, en supposant une taille de jeu de données de 5 %, une capacité Flash cache offre plus de 100 000 IOPS avec le service ONTAP FSX. Cette configuration permet un contrôle total des performances pour les applications les plus exigeantes. SQL Server s'exécutant sur de plus petites instances EC2 connectées à FSX pour ONTAP peut fonctionner de la même manière que SQL Server sur une instance EC2 beaucoup plus grande, car seules des limites de bande passante réseau sont appliquées à FSX pour ONTAP. La réduction de la taille des instances réduit également les coûts de calcul, ce qui assure un déploiement optimisé pour le TCO. L'association de SQL via iSCSI, SMB3.0 avec des partages de disponibilité continue multicanaux sur FSX pour ONTAP offre de nombreux avantages pour les charges de travail SQL.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">Avant de commencer</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">L'association d'Amazon FSX pour NetApp ONTAP et de SQL Server sur l'instance EC2 permet de créer des conceptions de stockage de bases de données d'entreprise capables de répondre aux exigences applicatives les plus exigeantes d'un jour. Afin d'optimiser ces deux technologies, il est essentiel de comprendre les modèles et caractéristiques d'E/S de SQL Server. Une infrastructure de stockage bien conçue pour une base de données SQL Server supporte les performances de SQL Server et la gestion de l'infrastructure SQL Server. Une bonne infrastructure de stockage permet également de mener à bien le déploiement initial et de faire évoluer l'environnement en toute transparence au fil du temps à mesure que l'entreprise se développe.</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">Avant de terminer les étapes de ce document, vous devez avoir les prérequis suivants :</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">Un compte AWS</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">Rôles IAM appropriés pour provisionner EC2 et FSX pour ONTAP</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">Un domaine Windows Active Directory sur EC2</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">Tous les nœuds SQL Server doivent pouvoir communiquer entre eux</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">Assurez-vous que la résolution DNS fonctionne et que les noms d'hôte peuvent être résolus. Si ce n'est pas le cas, utilisez l'entrée de fichier hôte.</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">Connaissances générales de l'installation de SQL Server</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">Consultez également les meilleures pratiques NetApp pour les environnements SQL Server pour obtenir la meilleure configuration de stockage.</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">Configurations des meilleures pratiques pour les environnements SQL Server sur EC2</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">Avec FSX ONTAP, l'acquisition de stockage est la tâche la plus simple et peut être effectuée en mettant à jour le système de fichiers. Ce processus simple permet d'optimiser les coûts et les performances dynamiques en fonction des besoins. Il permet également d'équilibrer la charge de travail SQL et constitue un excellent atout pour le provisionnement fin. Le provisionnement fin FSX ONTAP est conçu pour présenter un stockage logique plus important aux instances EC2 qui exécutent SQL Server que ce qui est provisionné dans le système de fichiers. De cette façon, il n'est pas nécessaire d'allouer de l'espace de stockage en amont, puisque celui-ci est alloué dynamiquement à chaque volume ou LUN à mesure que les données sont écrites. Dans la plupart des configurations, de l'espace libre est également libéré lorsque les données du volume ou de la LUN sont supprimées (et ne sont pas conservées par les copies Snapshot). Le tableau suivant fournit des paramètres de configuration pour l'allocation dynamique du stockage.</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">Aucun (défini par défaut)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">Réservation de LUN</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">réserve_fractionnaire</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0% (défini par défaut)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">snap_reserve</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">Dimensionnement automatique</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">Marche</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">Règle de Tiering des volumes</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">Snapshot uniquement</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">Avec cette configuration, la taille totale des volumes peut être supérieure au stockage réel disponible dans le système de fichiers. Si les LUN ou les copies Snapshot nécessitent plus d'espace que celui disponible dans le volume, les volumes augmentent automatiquement, ce qui prend plus d'espace à partir du système de fichiers contenant. Croissance automatique permet à FSX ONTAP d'augmenter automatiquement la taille du volume jusqu'à une taille maximale que vous prédéterminez. L'espace disponible dans le système de fichiers contenant doit être suffisant pour prendre en charge la croissance automatique du volume. Par conséquent, avec Autogrow activé, vous devez surveiller l'espace libre dans le système de fichiers contenant et mettre à jour le système de fichiers si nécessaire.</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">allocation d'espace</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">En plus de cela, définissez le<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> Option sur LUN à activé pour que FSX ONTAP notifie l'hôte EC2 lorsque le volume a un manque d'espace et que la LUN du volume ne peut pas accepter les écritures. De plus, cette option permet à FSX pour ONTAP de récupérer automatiquement de l'espace lorsque SQL Server sur l'hôte EC2 supprime des données. L'option d'allocation d'espace est définie sur Désactivé par défaut.</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">Si une LUN réservée à l'espace est créée dans un volume non garanti, alors la LUN se comporte de la même manière qu'une LUN non réservée à l'espace. En effet, un volume sans garantie n'a pas d'espace à allouer à la LUN ; le volume lui-même ne peut allouer de l'espace que si celui-ci est écrit à cause de sa garantie aucune.</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">Avec cette configuration, les administrateurs ONTAP FSX peuvent généralement dimensionner le volume de sorte qu'ils doivent gérer et surveiller l'espace utilisé du LUN côté hôte et dans le système de fichiers.</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">NetApp recommande l'utilisation d'un système de fichiers distinct pour les charges de travail SQL Server. Si le système de fichiers est utilisé pour plusieurs applications, surveillez l'utilisation de l'espace du système de fichiers et des volumes dans le système de fichiers pour vous assurer que les volumes ne sont pas en concurrence avec l'espace disponible.</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">Les copies Snapshot utilisées pour créer des volumes FlexClone ne sont pas supprimées par l'option de suppression automatique.</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">Le surengagement du stockage doit être soigneusement étudié et géré pour une application stratégique, telle que SQL Server, pour laquelle la moindre panne ne peut être tolérée. Dans un tel cas de figure, il est préférable de surveiller les tendances en matière de consommation du stockage afin de déterminer le degré acceptable, le cas échéant, de surallocation.</block>
  <block id="d846da4dd06c448920cac63b79adc614" category="list-text">Pour des performances de stockage optimales, provisionnez la capacité des systèmes de fichiers jusqu'à 1,5 fois supérieure à la taille totale de l'utilisation de la base de données.</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">Une surveillance adéquate accompagnée d'un plan d'action efficace est nécessaire lors de l'utilisation du provisionnement fin afin d'éviter l'interruption des applications.</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">Veillez à définir des alertes CloudWatch et d'autres outils de surveillance afin que les utilisateurs soient contactés suffisamment de temps pour réagir lorsque le stockage est rempli.</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">Configuration du stockage pour SQL Server et déploiement de SnapCenter pour les opérations de sauvegarde, de restauration et de clonage</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">Pour effectuer des opérations SQL Server avec SnapCenter, vous devez d'abord créer des volumes et des LUN pour SQL Server.</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">Créer des volumes et des LUN pour SQL Server</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">Pour créer des volumes et des LUN pour SQL Server, procédez comme suit :</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">Ouvrez la console Amazon FSX à l'adresse<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">Créez un système de fichiers Amazon FSX pour NetApp ONTAP à l'aide de l'option de création standard sous méthode de création. Cela vous permet de définir les informations d'identification FSxadmin et vsadmin.</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">Spécifiez le mot de passe de fsxadmin.</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">Préciser le mot de passe des SVM.</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">Création d'un volume sur FSX pour NetApp ONTAP</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">Créez des volumes en suivant l'étape indiquée dans<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>.</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">Désactivez les planifications de stockage Snapshot et les règles de conservation. Utilisez plutôt NetApp SnapCenter pour coordonner les copies Snapshot des volumes de données et de journaux SQL Server.</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">Configurez des bases de données sur des LUN individuelles sur des volumes distincts pour exploiter la fonctionnalité de restauration rapide et granulaire.</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">Placez les fichiers de données utilisateur (.mdf) sur des volumes distincts car ils sont des workloads de lecture/écriture aléatoires. Il est courant de créer des sauvegardes du journal de transactions plus fréquemment que les sauvegardes de bases de données. Pour cette raison, placez les fichiers journaux de transactions (.ldf) sur un volume distinct des fichiers de données afin que des planifications de sauvegarde indépendantes puissent être créées pour chacun d'entre eux. Cette séparation isole également les E/S d'écriture séquentielle des fichiers journaux des E/S de lecture/écriture aléatoires des fichiers de données et améliore considérablement les performances de SQL Server.</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">Tempdb est une base de données système utilisée par Microsoft SQL Server comme espace de travail temporaire, en particulier pour les opérations DBCC CHECKDB exigeantes en E/S. Placez donc cette base de données sur un volume dédié. Dans les grands environnements dans lesquels le nombre de volumes est un défi, vous pouvez consolider tempdb en un nombre réduit de volumes et le stocker dans le même volume que les autres bases de données système après une planification minutieuse. La protection des données pour tempdb n'est pas une priorité élevée car cette base de données est recréée chaque fois que Microsoft SQL Server est redémarré.</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">Utiliser la commande SSH suivante pour créer des volumes :</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Démarrez le service iSCSI avec PowerShell à l'aide de privilèges élevés dans Windows Server.</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Installez Multipath-IO avec PowerShell à l'aide de privilèges élevés dans les serveurs Windows.</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Recherchez le nom de l'initiateur Windows avec PowerShell en utilisant des privilèges élevés dans Windows Server.</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">Connectez-vous à des machines virtuelles de stockage (SVM) à l'aide de putty et créez un iGroup.</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">Utilisez la commande SSH suivante pour créer des LUN :</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">Pour obtenir un alignement des E/S avec le schéma de partitionnement du système d'exploitation, utilisez Windows_2008 comme type de LUN recommandé. Reportez-vous à<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> pour plus d'informations.</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">Utilisez la commande SSH suivante sur le groupe initiateur mappé sur les LUN que vous venez de créer.</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Pour un disque partagé qui utilise le cluster de basculement Windows, exécutez une commande SSH pour mapper le même LUN au groupe initiateur appartenant à tous les serveurs qui participent au cluster de basculement Windows.</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">Connectez Windows Server à un SVM avec une cible iSCSI. Recherchez l'adresse IP cible sur le portail AWS.</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">Dans Server Manager et le menu Outils, sélectionnez l'initiateur iSCSI. Sélectionnez l'onglet découverte, puis Discover Portal. Indiquez l'adresse IP iSCSI de l'étape précédente et sélectionnez Avancé. Dans le menu local adapter, sélectionnez Microsoft iSCSI Initiator. Dans IP de l'initiateur, sélectionnez l'adresse IP du serveur. Puis sélectionnez OK pour fermer toutes les fenêtres.</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">Répétez l'étape 12 pour la deuxième IP iSCSI depuis le SVM.</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">Sélectionnez l'onglet *cibles*, sélectionnez *connexion*, puis *Activer muti-path*.</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">Pour obtenir les meilleures performances, ajoutez d'autres sessions. NetApp recommande la création de cinq sessions iSCSI. Sélectionnez *Propriétés *&gt; *Ajouter session *&gt; *Avancé* et répétez l'étape 12.</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">Configurez cinq sessions iSCSI par interface cible pour des performances optimales.</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">Configurez une règle de séquence périodique pour obtenir les meilleures performances iSCSI globales.</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">Assurez-vous que la taille de l'unité d'allocation est définie sur 64 Ko pour les partitions lors du formatage des LUN</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">Exécutez la commande PowerShell suivante pour vous assurer que la session iSCSI est persistante.</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">Initialiser les disques avec la commande PowerShell suivante.</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">Exécutez les commandes Créer une partition et formater un disque avec PowerShell.</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">Vous pouvez automatiser la création de volumes et de LUN à l'aide du script PowerShell de l'Annexe B. Des LUN peuvent également être créés à l'aide de SnapCenter.</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">Une fois les volumes et les LUN définis, il est nécessaire de configurer SnapCenter pour pouvoir effectuer les opérations de base de données.</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">Présentation de SnapCenter</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter est un logiciel de protection des données nouvelle génération pour les applications d'entreprise de Tier 1. SnapCenter, grâce à son interface de gestion centralisée, automatise et simplifie les processus manuels, complexes et fastidieux associés à la sauvegarde, à la restauration et au clonage de plusieurs bases de données et d'autres charges de travail applicatives. SnapCenter exploite les technologies NetApp, notamment NetApp snapshots, NetApp SnapMirror, SnapRestore et NetApp FlexClone. Grâce à cette intégration, les services IT peuvent faire évoluer leur infrastructure de stockage, respecter les engagements de niveau de service de plus en plus rigoureux et améliorer la productivité des administrateurs à l'échelle de l'entreprise.</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">Configuration requise pour le serveur SnapCenter</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">Le tableau suivant répertorie la configuration minimale requise pour installer le serveur SnapCenter et le plug-in sur Microsoft Windows Server.</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">Composants</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">Conditions requises</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">Nombre minimal de processeurs</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">Quatre cœurs/CPU virtuels</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">Minimum : 8 Go recommandés : 32 Go</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">Espace de stockage</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">Espace minimum pour l'installation : 10 GO d'espace minimum pour le référentiel : 10 GO</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">Système d'exploitation pris en charge</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">Packs logiciels</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">.NET 4.5.2 ou version ultérieure</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">Windows Management Framework (WMF) 4.0 ou version ultérieure</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 ou version ultérieure</block>
  <block id="427d30c4045ae36c0130a14658100185" category="paragraph">Pour plus d'informations, voir exigences en matière d'espace et de dimensionnement <block ref="bcc48263fbca83f546b0bc02edad3f56" category="inline-link-rx"></block></block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">Pour la compatibilité de la version, voir<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>.</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">Disposition du stockage de la base de données</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">La figure suivante décrit quelques facteurs à prendre en compte lors de la création de l'infrastructure de stockage de la base de données Microsoft SQL Server lors de la sauvegarde avec SnapCenter.</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">Placez les bases de données sur un volume distinct lorsque les requêtes sont exigeantes en E/S ou dans une base de données volumineuse (500 Go ou plus) pour une restauration plus rapide. Ce volume doit également être sauvegardé par des travaux distincts.</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">Consolider les bases de données de petite à moyenne taille qui sont moins critiques ou présentent moins de besoins en E/S sur un seul volume. La sauvegarde d'un nombre élevé de bases de données résidant sur un même volume entraîne un nombre réduit de copies Snapshot à conserver. Il est également recommandé de consolider les instances de Microsoft SQL Server de manière à utiliser les mêmes volumes pour contrôler le nombre de copies Snapshot de sauvegarde effectuées.</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">Créez des LUN pour stocker les fichiers de texte et les fichiers associés à la diffusion en continu de fichiers.</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Attribuez des LUN distinctes par hôte pour stocker les sauvegardes des journaux Microsoft SQL Server.</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">Les bases de données système qui stockent les métadonnées du serveur de base de données et les détails des tâches ne sont pas fréquemment mis à jour. Placez les bases de données système/tempdb dans des unités ou des LUN distinctes. Ne placez pas les bases de données système dans le même volume que les bases de données utilisateur. Les bases de données utilisateur ont une stratégie de sauvegarde différente et la fréquence de sauvegarde des bases de données utilisateur n'est pas la même pour les bases de données système.</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Pour l'installation de Microsoft SQL Server Availability Group, placez les fichiers de données et de journaux des répliques dans une structure de dossiers identique sur tous les nœuds.</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">En plus de l'avantage de performances de séparer la disposition de la base de données utilisateur en différents volumes, la base de données affecte également de façon significative le temps nécessaire à la sauvegarde et à la restauration. La présence de volumes séparés pour les données et les fichiers journaux améliore considérablement la durée de restauration par rapport à un volume hébergeant plusieurs fichiers de données utilisateur. De même, les bases de données utilisateur équipées d'applications exigeantes en E/S peuvent augmenter le temps de sauvegarde. Une explication plus détaillée des pratiques de sauvegarde et de restauration est fournie plus loin dans ce document.</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">À partir de SQL Server 2012 (11.x), bases de données système (Master, Model, MSDB et TempDB), Et les bases de données utilisateur du moteur de base de données peuvent être installées avec un serveur de fichiers SMB comme option de stockage. Cela s'applique aux installations de cluster de basculement autonomes SQL Server et SQL Server. Cela vous permet d'utiliser FSX pour ONTAP avec toutes ses fonctionnalités de gestion des performances et des données, notamment la capacité de volumes, l'évolutivité des performances et les fonctionnalités de protection des données que SQL Server peut exploiter. Les partages utilisés par les serveurs d'applications doivent être configurés avec le jeu de propriétés disponible en continu et le volume doit être créé avec le style de sécurité NTFS. NetApp SnapCenter ne peut pas être utilisé avec les bases de données placées sur des partages SMB à partir de FSX pour ONTAP.</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">Pour les bases de données SQL Server qui n'utilisent pas SnapCenter pour effectuer des sauvegardes, Microsoft recommande de placer les données et les fichiers journaux sur des disques distincts. Pour les applications qui mettent à jour et demandent simultanément des données, le fichier journal est très gourmand en écriture et le fichier de données (selon votre application) consomme beaucoup de ressources en lecture/écriture. Pour la récupération des données, le fichier journal n'est pas nécessaire. Par conséquent, les demandes de données peuvent être satisfaites à partir du fichier de données placé sur son propre disque.</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">Lorsque vous créez une nouvelle base de données, Microsoft recommande de spécifier des disques distincts pour les données et les journaux. Pour déplacer des fichiers après la création de la base de données, la base de données doit être mise hors ligne. Pour plus d'informations sur les recommandations de Microsoft, reportez-vous à la section placer les fichiers de données et les fichiers journaux sur des lecteurs distincts.</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">Installation et configuration de SnapCenter</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">Installez le serveur SnapCenter</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">Installation du plug-in SnapCenter pour Microsoft SQL Server</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">Suivez le<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> et<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> Pour installer et configurer SnapCenter.</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">Après l'installation de SnapCenter, procédez comme suit pour le configurer.</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">Pour configurer les informations d'identification, sélectionnez *Paramètres* &gt; *Nouveau*, puis saisissez les informations d'identification.</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">Ajoutez le système de stockage en sélectionnant systèmes de stockage &gt; Nouveau et fournissez les informations FSX appropriées pour le stockage ONTAP.</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">Ajoutez des hôtes en sélectionnant *hosts* &gt; *Add*, puis fournissez les informations sur l'hôte. SnapCenter installe automatiquement le plug-in Windows et SQL Server. Ce processus peut prendre un certain temps.</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">Une fois tous les plug-ins installés, vous devez configurer le répertoire des journaux. Il s'agit de l'emplacement où réside la sauvegarde du journal de transactions. Vous pouvez configurer le répertoire des journaux en sélectionnant l'hôte, puis en sélectionnant configurer le répertoire des journaux.</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter utilise un répertoire du journal hôte pour stocker les données de sauvegarde du journal de transactions. Il est au niveau de l'hôte et de l'instance. Chaque hôte SQL Server utilisé par SnapCenter doit avoir un répertoire du journal hôte configuré pour effectuer des sauvegardes de journaux. SnapCenter dispose d'un référentiel de base de données. Les métadonnées liées aux opérations de sauvegarde, de restauration ou de clonage sont donc stockées dans un référentiel de base de données central.</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">La taille du répertoire du journal hôte est calculée comme suit :</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">Taille du répertoire du journal hôte = ((taille de la base de données système + (taille maximale de la base de données LDF × taux de modification quotidien du journal %)) × (conservation des copies Snapshot) ÷ (1 – espace de surcharge de LUN %)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">La formule de dimensionnement du répertoire du journal hôte utilise les éléments suivants :</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">Sauvegarde de la base de données système qui n'inclut pas la base de données tempdb</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">Un espace surcharge de 10 % des LUN place le répertoire journal hôte sur un volume ou une LUN dédié. La quantité de données dans le répertoire du journal hôte dépend de la taille des sauvegardes et du nombre de jours pendant lesquels les sauvegardes sont conservées.</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">Si les LUN ont déjà été provisionnées, vous pouvez sélectionner le point de montage pour représenter le répertoire du journal hôte.</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">Vous êtes désormais prêt à effectuer des opérations de sauvegarde, de restauration et de clonage pour SQL Server.</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">Sauvegardez la base de données avec SnapCenter</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">Après avoir placé la base de données et les fichiers journaux sur les LUN ONTAP FSX, SnapCenter peut être utilisé pour sauvegarder les bases de données. Les processus suivants sont utilisés pour créer une sauvegarde complète.</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">En termes SnapCenter, l'objectif RPO est d'être identifié comme la fréquence de sauvegarde. Par exemple, la fréquence à laquelle vous souhaitez planifier la sauvegarde de manière à réduire la perte de données à quelques minutes seulement. SnapCenter vous permet de planifier des sauvegardes toutes les cinq minutes. Cependant, il peut arriver qu'une sauvegarde ne s'effectue pas dans les cinq minutes suivant les pics de transaction ou lorsque le taux de changement de données est plus important dans le temps imparti. L'une des meilleures pratiques est de planifier des sauvegardes fréquentes du journal des transactions au lieu de sauvegardes complètes.</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">Il existe de nombreuses approches pour gérer les objectifs RPO et RTO. Une autre alternative à cette approche de sauvegarde consiste à définir des règles de sauvegarde distinctes pour les données et les journaux, avec des intervalles différents. Par exemple, à partir de SnapCenter, planifiez les sauvegardes des journaux par intervalles de 15 minutes et les sauvegardes de données par intervalles de 6 heures.</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">Utilisez un groupe de ressources pour une configuration de sauvegarde pour l'optimisation des snapshots et le nombre de tâches à gérer.</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">Sélectionnez *Ressources*, puis *Microsoft SQL Server *dans le menu déroulant en haut à gauche. Sélectionnez *Actualiser les ressources*.</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">Sélectionnez la base de données à sauvegarder, puis sélectionnez *Suivant* et (*+*) pour ajouter la stratégie si elle n'a pas été créée. Suivez la *Nouvelle stratégie de sauvegarde SQL Server* pour créer une nouvelle stratégie.</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">Sélectionnez le serveur de vérification si nécessaire. Ce serveur est le serveur sur lequel SnapCenter exécute DBCC CHECKDB après la création d'une sauvegarde complète. Cliquez sur *Suivant* pour la notification, puis sélectionnez *Résumé* pour la révision. Après vérification, cliquez sur *Terminer*.</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">Cliquez sur *Sauvegarder maintenant* pour tester la sauvegarde. Dans les fenêtres contextuelles, sélectionnez *Backup*.</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">Sélectionnez *Monitor* pour vérifier que la sauvegarde est terminée.</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">Sauvegardez la sauvegarde du journal de transactions à partir de SnapCenter afin que SnapCenter puisse lire tous les fichiers de sauvegarde et les restaurer automatiquement par séquence lors du processus de restauration.</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">Si des produits tiers sont utilisés pour la sauvegarde, sélectionnez Copy backup dans SnapCenter pour éviter les problèmes de séquence de journaux et testez la fonctionnalité de restauration avant de passer en production.</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">Restaurez la base de données avec SnapCenter</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">L'un des principaux avantages de l'utilisation de FSX ONTAP avec SQL Server sur EC2 est sa capacité à effectuer des restaurations rapides et granulaires à chaque niveau de la base de données.</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">Procédez comme suit pour restaurer une base de données individuelle vers un point dans le temps ou jusqu'à la minute avec SnapCenter.</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">Sélectionnez Ressources, puis sélectionnez la base de données que vous souhaitez restaurer.</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">Sélectionnez le nom de sauvegarde à partir duquel la base de données doit être restaurée, puis sélectionnez Restaurer.</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">Suivez les fenêtres contextuelles *Restore* pour restaurer la base de données.</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">Sélectionnez *Monitor* pour vérifier que le processus de restauration a réussi.</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">Considérations relatives à une instance avec un grand nombre de bases de données de toute taille</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter peut sauvegarder un grand nombre de bases de données volumineuses au sein d'une instance ou d'un groupe d'instances au sein d'un groupe de ressources. La taille d'une base de données n'est pas le facteur majeur du temps de sauvegarde. La durée d'une sauvegarde peut varier en fonction du nombre de LUN par volume, de la charge sur Microsoft SQL Server, du nombre total de bases de données par instance, et plus particulièrement de la bande passante d'E/S et de l'utilisation. Lors de la configuration de la règle de sauvegarde des bases de données à partir d'une instance ou d'un groupe de ressources, NetApp vous recommande de limiter le nombre maximal de bases de données sauvegardées par copie Snapshot à 100 par hôte. Assurez-vous que le nombre total de copies Snapshot ne dépasse pas la limite de 1,023 copies.</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">NetApp vous recommande également de limiter les tâches de sauvegarde exécutées en parallèle en regroupant le nombre de bases de données au lieu de créer plusieurs tâches pour chaque base de données ou instance. Pour des performances optimales de la durée de sauvegarde, réduisez le nombre de tâches de sauvegarde pouvant sauvegarder environ 100 bases de données ou moins à la fois.</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">Comme mentionné précédemment, l'utilisation des E/S est un facteur important dans le processus de sauvegarde. Le processus de sauvegarde doit attendre que toutes les opérations d'E/S d'une base de données soient terminées. Les bases de données prenant en charge des opérations d'E/S très exigeantes doivent être reportées sur un autre temps de sauvegarde ou doivent être isolées des autres tâches de sauvegarde pour éviter de nuire aux autres ressources du même groupe de ressources à sauvegarder.</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">Pour un environnement doté de six hôtes Microsoft SQL Server hébergeant 200 bases de données par instance, en supposant que quatre LUN par hôte et une LUN par volume créé, définissez la stratégie de sauvegarde complète avec le nombre maximal de bases de données sauvegardées par copie Snapshot à 100. Deux cents bases de données de chaque instance sont définies comme 200 fichiers de données distribués uniformément sur deux LUN, et 200 fichiers journaux sont répartis de façon égale sur deux LUN, soit 100 fichiers par LUN par volume.</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">Planifiez trois tâches de sauvegarde en créant trois groupes de ressources, chacun regroupant deux instances comprenant un total de 400 bases de données.</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">Le fait d'exécuter les trois tâches de sauvegarde en parallèle permet de sauvegarder simultanément 1,200 bases de données. Selon la charge sur le serveur et l'utilisation des E/S, les heures de début et de fin de chaque instance peuvent varier. Dans cette instance, un total de 24 copies Snapshot sont créées.</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">Outre la sauvegarde complète, NetApp recommande de configurer une sauvegarde du journal des transactions pour les bases de données critiques. Assurez-vous que la propriété de base de données est définie sur le modèle de récupération complète.</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">N'incluez pas la base de données tempdb dans une sauvegarde car les données qu'elle contient sont temporaires. Placez tempdb sur une LUN ou un partage SMB situé dans un volume de système de stockage dans lequel les copies Snapshot ne seront pas créées.</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">Une instance Microsoft SQL Server avec une application exigeante en E/S élevée doit être isolée dans une autre tâche de sauvegarde afin de réduire la durée totale des sauvegardes pour d'autres ressources.</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">Limitez le jeu de bases de données à sauvegarder simultanément à environ 100 et échelonnez le jeu de sauvegardes de base de données restant pour éviter un processus simultané.</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Utilisez le nom d'instance Microsoft SQL Server dans le groupe de ressources au lieu de plusieurs bases de données car chaque fois que de nouvelles bases de données sont créées dans une instance Microsoft SQL Server, SnapCenter considère automatiquement une nouvelle base de données pour la sauvegarde.</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">Si vous modifiez la configuration de la base de données, par exemple si vous remplacez le modèle de restauration de la base de données par un modèle de restauration complet, effectuez immédiatement une sauvegarde pour permettre des opérations de restauration en moins d'une minute.</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter ne peut pas restaurer les sauvegardes du journal de transactions créées en dehors de SnapCenter.</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">Lors du clonage de volumes FlexVol, assurez-vous de disposer d'un espace suffisant pour les métadonnées du clone.</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">Lors de la restauration des bases de données, assurez-vous que l'espace disponible sur le volume est suffisant.</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">Créez une stratégie distincte pour gérer et sauvegarder les bases de données système au moins une fois par semaine.</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">Clonage de bases de données avec SnapCenter</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">Pour restaurer une base de données sur un autre emplacement d'un environnement de développement ou de test, ou pour créer une copie à des fins d'analyse commerciale, il est recommandé d'utiliser la méthodologie de clonage afin de créer une copie de la base de données sur la même instance ou une autre instance.</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">Le clonage des bases de données de 500 Go sur un disque iSCSI hébergé sur un système FSX pour ONTAP prend généralement moins de cinq minutes. Une fois le clonage terminé, l'utilisateur peut effectuer toutes les opérations de lecture/écriture requises sur la base de données clonée. La plupart du temps est utilisé pour l'analyse des disques (diskpart). La procédure de clonage NetApp prend généralement moins de 2 minutes, quelle que soit la taille des bases de données.</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">Le clonage d'une base de données peut être effectué à l'aide de la méthode double : vous pouvez créer un clone à partir de la dernière sauvegarde. Vous pouvez aussi utiliser la gestion du cycle de vie des clones pour rendre la copie la plus récente disponible sur l'instance secondaire.</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter vous permet de monter la copie clone sur le disque requis afin de conserver le format de la structure de dossiers sur l'instance secondaire et continuer à planifier les tâches de sauvegarde.</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">Cloner les bases de données vers le nouveau nom de base de données dans la même instance</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">Les étapes suivantes peuvent être utilisées pour cloner les bases de données vers le nouveau nom de base de données dans la même instance de serveur SQL exécutant sur EC2 :</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">Sélectionnez Ressources, puis la base de données à cloner.</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">Sélectionnez le nom de sauvegarde à cloner et sélectionnez Cloner.</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">Pour terminer le processus de clonage, suivez les instructions de clonage des fenêtres de sauvegarde.</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">Sélectionnez Monitor pour vous assurer que le clonage est terminé.</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">Clonez les bases de données dans la nouvelle instance SQL Server qui s'exécute sur EC2</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">L'étape suivante sert à cloner les bases de données vers la nouvelle instance de serveur SQL exécutée sur EC2 :</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">Créez un nouveau SQL Server sur EC2 sur le même VPC.</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">Activez le protocole iSCSI et MPIO, puis configurez la connexion iSCSI à FSX pour ONTAP en suivant les étapes 3 et 4 de la section « Créer des volumes et des LUN pour SQL Server ».</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">Ajoutez un nouveau serveur SQL sous EC2 dans SnapCenter en suivant l'étape 3 de la section « installation et configuration pour SnapCenter ».</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">Sélectionnez ressource &gt; Afficher l'instance, puis Actualiser la ressource.</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">Sélectionnez Ressources, puis la base de données à cloner.</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">Sélectionnez le nom de sauvegarde à cloner, puis sélectionnez Cloner.</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">Suivez les instructions de clonage à partir de la sauvegarde en fournissant la nouvelle instance SQL Server sur EC2 et le nom d'instance pour terminer le processus de clonage.</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">Annexes</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">Annexe A : fichier YAML à utiliser dans le modèle de formation du Cloud</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">Le fichier .yaml suivant peut être utilisé avec le modèle de formation de Cloud dans la console AWS.</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">Lien GitHub</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">Pour automatiser la création de LUN ISCSI et l'installation de NetApp SnapCenter avec PowerShell, clonez le référentiel à partir de<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>.</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">Annexe B : scripts PowerShell pour le provisionnement de volumes et de LUN</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">Le script suivant est utilisé pour provisionner des volumes et des LUN et également pour configurer iSCSI en fonction des instructions fournies ci-dessus. Il existe deux scripts PowerShell :</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">Exécutez le fichier<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> le premier et le second script s'exécute automatiquement après le redémarrage du serveur. Ces scripts PowerShell peuvent être supprimés après leur exécution en raison de l'accès des informations d'identification au SVM.</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">Mise en route de FSX pour NetApp ONTAP</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">Présentation de l'interface SnapCenter</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">Parcourir les options du volet de navigation SnapCenter</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">Configuration du plug-in SnapCenter 4.0 pour SQL Server</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">Comment sauvegarder et restaurer des bases de données à l'aide de SnapCenter avec le plug-in SQL Server</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">Comment cloner une base de données à l'aide de SnapCenter avec le plug-in SQL Server</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">SQL Server sur AWS EC2 avec Amazon FSX pour NetApp ONTAP</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">En résumé, le passage des disques rotatifs au 100 % Flash améliore les performances. Le nombre de nœuds de calcul n'était pas un goulot d'étranglement. Avec le stockage 100 % Flash de NetApp, les performances d'exécution évoluent parfaitement.</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">Auteurs : Chris Reno, Josh Powell, Suresh Thoppay - Ingénierie de solutions NetApp</block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">Hypothèses, conditions requises et présentation des composants</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">Avant de déployer cette solution, vérifiez la présentation des composants, les conditions préalables requises pour déployer la solution et les hypothèses fournies pour documenter cette solution.</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">Besoins en solution DR, pré-requis et planification</block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">Effectuer une reprise après incident avec SnapCenter</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">Une fois connecté à la console, vous devez configurer SnapCenter pour la sauvegarde des bases de données SQL Server et Oracle.</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">Déploiement du serveur de sauvegarde et de réplication Veeam secondaire</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">Configuration du serveur Veeam Backup etamp secondaire ; Replication Server</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Veeam Backup etamp ; réplication</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp;amp ; serveur de réplication</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp; amp ; configuration de la réplication</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355 : plug-in SnapCenter pour VMware vSphere - sécurité du produit</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">Le plug-in NetApp SnapCenter pour l'ingénierie logicielle VMware vSphere exploite les activités de développement sécurisées suivantes :</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Test dynamique de sécurité des applications (DAST).* technologies conçues pour détecter les conditions vulnérables des applications dans leur état d'exécution. DAST teste les interfaces HTTP et HTML exposées des applications Web-enable.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Devise de code tierce.* dans le cadre du développement de logiciels et de l'utilisation de logiciels open-source (OSS), il est important de traiter les vulnérabilités de sécurité qui pourraient être associées à OSS qui a été intégré à votre produit. Il s'agit d'un effort continu car la version du composant OSS peut avoir une vulnérabilité nouvellement découverte signalée à tout moment.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* Tests de pénétration.* le test de pénétration est le processus d'évaluation d'un système, d'une application Web ou d'un réseau pour trouver des vulnérabilités de sécurité qui pourraient être exploitées par un attaquant. Les tests d'intrusion chez NetApp sont réalisés par un groupe d'entreprises tierces de confiance et approuvées. Leur domaine de test comprend le lancement d'attaques contre une application ou un logiciel comme des intrus hostiles ou des pirates informatiques à l'aide de méthodes ou d'outils d'exploitation sophistiqués.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">*Activité réponse aux incidents de sécurité des produits.* les vulnérabilités de sécurité sont découvertes à la fois en interne et en externe pour l'entreprise et peuvent poser un risque grave à la réputation de NetApps'ils ne sont pas traités en temps opportun. Pour faciliter ce processus, l'équipe d'intervention en cas d'incident de sécurité des produits (PSIRT) signale et effectue le suivi des vulnérabilités.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">Le plug-in NetApp SnapCenter pour VMware vSphere inclut les fonctionnalités de sécurité suivantes dans chaque version :</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Accès limité au shell.* SSH est désactivé par défaut, et les connexions à une seule fois ne sont autorisées que si elles sont activées à partir de la console VM.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Avertissement d'accès dans la bannière de connexion.* la bannière de connexion suivante s'affiche après que l'utilisateur ait entré un nom d'utilisateur dans l'invite de connexion :</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Une fois que l'utilisateur a terminé sa connexion via le canal SSH, les valeurs de sortie suivantes s'affichent :</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">*Contrôle d'accès basé sur des rôles (RBAC).* deux types de contrôles RBAC sont associés aux outils NetApp ONTAP :</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilèges de serveur vCenter natif.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Contrôle d'accès basé sur des rôles (RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilèges spécifiques au plug-in VMware vCenter. Pour plus d'informations, voir<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canaux de communication cryptés.* toutes les communications externes sont effectuées via HTTPS en utilisant TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">Le tableau suivant fournit les détails du port ouvert.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Numéro de port TCP v4/v6</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Connexions HTTPS pour interface graphique OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (désactivé par défaut)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (connexions internes uniquement, connexions externes désactivées par défaut)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (services de protection des données)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Comment créer et/ou importer un certificat SSL dans le plug-in SnapCenter pour VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Prise en charge des certificats signés par l'autorité de certification (CA).* le plug-in SnapCenter pour VMware vSphere prend en charge la fonctionnalité des certificats signés par l'autorité de certification. Voir<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Stratégies de mot de passe.* les stratégies de mot de passe suivantes sont en vigueur :</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Toutes les informations d'identification sont stockées à l'aide d'un hachage SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Image du système d'exploitation de base.* le produit est fourni avec le système d'exploitation de base Debian pour OVA avec accès restreint et accès au shell désactivé. Cela réduit l'empreinte d'attaque. Chaque système d'exploitation de base SnapCenter est mis à jour avec les derniers correctifs de sécurité disponibles pour une protection maximale.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp développe des fonctionnalités logicielles et des correctifs de sécurité en ce qui concerne le plug-in SnapCenter pour l'appliance VMware vSphere, puis les publie auprès de ses clients sous la forme d'un pack logiciel. Étant donné que ces dispositifs intègrent des dépendances spécifiques au système d'exploitation Linux et à notre logiciel propriétaire, NetApp vous recommande de ne pas modifier le système sous-exploitation, car il présente un potentiel important d'affecter l'appliance NetApp. Cela pourrait affecter la capacité de NetApp à prendre en charge l'appliance. NetApp recommande de tester et de déployer la dernière version de code pour les appliances, car elles sont publiées pour corriger les problèmes de sécurité.</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">Mars 2022</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; NOUS AVONS VALIDÉ la hiérarchisation du stockage Hadoop sur un contrôleur de stockage NetApp AFF et un contrôleur de stockage E-Series avec des disques SSD et SAS utilisant différentes règles de stockage. Le cluster Spark avec l'AFF-A800 dispose de quatre nœuds de traitement, tandis que le cluster avec l'E-Series en compte huit. Cette comparaison a notamment pour objectif de comparer les performances des SSD et des disques durs.</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">Nous avons validé la hiérarchisation du stockage Hadoop sur un contrôleur de stockage NetApp AFF et un contrôleur de stockage E-Series avec des disques SSD et SAS utilisant différentes règles de stockage. Le cluster Spark avec l'AFF-A800 dispose de quatre nœuds de traitement, tandis que le cluster avec l'E-Series en compte huit. Cela nous a principalement permis de comparer les performances des disques SSD aux disques durs. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">Grâce à Terasort, la configuration SSD a trié 1 To de données 1138.36 fois plus vite que la configuration NL-SAS. De plus, la configuration SSD utilisait deux fois moins de nœuds de calcul et deux fois moins de disques (24 disques SSD au total). Par conséquent, par disque, c'était environ trois fois plus rapide que la configuration NL-SAS. &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; TÊTE</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">En passant de disques rotatifs à un système 100 % Flash, le message clé est d'améliorer les performances. Le nombre de nœuds de calcul n'était pas un goulot d'étranglement. Avec le stockage 100 % Flash de NetApp, les performances d'exécution évoluent parfaitement.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">Avec NFS, les données étaient fonctionnellement équivalentes au regroupement des pools, ce qui permet de réduire le nombre de nœuds de calcul en fonction de votre charge de travail. Les utilisateurs du cluster Apache Spark n'ont pas besoin de rééquilibrer manuellement les données lors de la modification du nombre de nœuds de calcul.</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">Avec NFS, les données étaient fonctionnellement équivalentes au regroupement des pools, ce qui permet de réduire le nombre de nœuds de calcul en fonction de votre charge de travail. Les utilisateurs d'un cluster Apache Spark n'ont pas besoin de rééquilibrer manuellement les données lors de la modification du nombre de nœuds de calcul. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">Le plug-in SnapCenter VMware vSphere : sécurité du produit</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, comme iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN, ainsi que NFS (v3 et v4.1) et SMB ou S3 pour les connexions invités. Les clients sont libres de choisir ce qui fonctionne le mieux pour leur environnement et de combiner des protocoles en fonction des besoins sur un système unique.</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, comme iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN, ainsi que NFS (v3 et v4.1) et SMB ou S3 pour les connexions invités. Les clients sont libres de choisir ce qui fonctionne le mieux pour leur environnement et de combiner des protocoles en fonction des besoins sur un système unique. Par exemple, il est possible d'optimiser l'utilisation générale des datastores NFS avec quelques LUN iSCSI ou des partages invités.</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">*Copies NetApp Snapshot*.* ONTAP offre des copies Snapshot instantanées d'une machine virtuelle ou d'un datastore sans impact sur les performances lors de la création ou de l'utilisation d'une copie Snapshot. Ils peuvent être utilisés pour créer un point de restauration pour une machine virtuelle avant l'application de correctifs ou pour une protection simple des données. Notez qu'ils ne sont pas identiques aux snapshots VMware (cohérence). Pour créer une copie Snapshot ONTAP, le moyen le plus simple est d'utiliser le plug-in SnapCenter pour VMware vSphere pour sauvegarder des machines virtuelles et des datastores.</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">*NetApp Volume Encryption et NetApp Aggregate Encryption*. Les options de chiffrement NetApp permettent un chiffrement logiciel simple pour la protection des données au repos.</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">*REPOS et Ansible.* utilisation<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> pour automatiser la gestion du stockage et des données, et<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> Pour la gestion de la configuration de vos systèmes ONTAP.</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">Notez que certaines fonctionnalités ONTAP ne sont pas adaptées aux charges de travail vSphere. Par exemple, la technologie FlexGroup antérieure à ONTAP 9.8 ne disposait pas d'une prise en charge complète du clonage et n'a pas été testée avec vSphere (consultez la section FlexGroup pour en savoir plus sur l'utilisation de vSphere). La technologie FlexCache n'est pas encore optimale pour vSphere car elle est conçue pour des charges de travail essentiellement en lecture. Ce type d'écriture peut être problématique lorsque le cache est déconnecté de l'origine, ce qui entraîne des erreurs de datastore NFS des deux côtés.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Les outils ONTAP pour VMware vSphere sont un ensemble d'outils permettant d'utiliser le stockage ONTAP avec vSphere. Le plug-in vCenter, précédemment appelé Virtual Storage Console (VSC), simplifie les fonctionnalités de gestion et d'efficacité du stockage, améliore la disponibilité et réduit les coûts de stockage ainsi que les charges opérationnelles, que vous utilisiez SAN ou NAS. Il s'appuie sur les bonnes pratiques pour le provisionnement des datastores et optimise les paramètres d'hôte ESXi pour les environnements de stockage NFS et bloc. Pour tous ces avantages, NetApp recommande d'utiliser ces outils ONTAP comme meilleure pratique lorsque vous utilisez vSphere avec les systèmes exécutant le logiciel ONTAP. Elle comprend une appliance serveur, des extensions d'interface utilisateur pour vCenter, VASA Provider et Storage Replication adapter. La quasi-totalité des outils ONTAP peuvent être automatisés à l'aide d'API REST simples et consommables par la plupart des outils d'automatisation modernes.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*Extensions de l'interface utilisateur vCenter.* les extensions de l'interface utilisateur des outils ONTAP simplifient le travail des équipes opérationnelles et des administrateurs vCenter en intégrant des menus contextuels faciles à utiliser pour gérer les hôtes et le stockage, les portlets d'information et les fonctionnalités d'alerte natives directement dans l'interface utilisateur vCenter pour optimiser les flux de travail.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*VASA Provider pour ONTAP.* le fournisseur VASA pour ONTAP prend en charge l'infrastructure VMware vStorage APIs for Storage Awareness (VASA). Il est fourni en tant qu'appliance virtuelle unique, avec les outils ONTAP pour VMware vSphere pour une facilité de déploiement. Vasa Provider connecte vCenter Server avec ONTAP pour faciliter le provisionnement et la surveillance du stockage des machines virtuelles. Il assure la prise en charge de VMware Virtual volumes (vvols), la gestion des profils de capacité de stockage et les performances individuelles de VM vvols, ainsi que des alarmes pour le contrôle de la capacité et de la conformité avec les profils.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication adapter.* l'adaptateur SRA est utilisé avec VMware site Recovery Manager (SRM) pour gérer la réplication des données entre les sites de production et de reprise après incident et tester les répliques de reprise après incident sans interruption. Il permet d'automatiser les tâches de détection, de restauration et de reprotection. Elle inclut une appliance serveur SRA et des adaptateurs SRA pour le serveur Windows SRM et l'appliance SRM.</block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">Le plug-in NetApp NFS pour VMware VAAI est un plug-in pour les hôtes ESXi qui leur permet d'utiliser des fonctionnalités VAAI avec les datastores NFS sur ONTAP. Elle prend en charge la redirection des copies pour les opérations de clonage, la réservation d'espace pour les fichiers de disque virtuel non volumineux et la redirection des copies Snapshot. Le transfert des opérations de copie vers le stockage n'est pas forcément plus rapide. Toutefois, il réduit les besoins en bande passante réseau et réduit la charge des ressources hôte telles que les cycles de CPU, les tampons et les files d'attente. Vous pouvez utiliser les outils ONTAP pour VMware vSphere pour installer le plug-in sur des hôtes ESXi ou, le cas échéant, vSphere Lifecycle Manager (vLCM).</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">Nouveautés de la virtualisation VMware</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">01/12/2023</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">Ajout de blog : protégez vos charges de travail SQL Server avec NetApp SnapCenter avec Amazon FSX pour NetApp ONTAP</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">Protection de vos charges de travail SQL Server avec NetApp SnapCenter et Amazon FSX pour NetApp ONTAP</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Sept protocoles sont utilisés pour connecter VMware vSphere aux datastores sur un système exécutant le logiciel ONTAP :</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP et iSCSI sont des protocoles de bloc qui utilisent vSphere Virtual machine File System (VMFS) pour stocker des VM au sein de LUN ONTAP ou des espaces de noms NVMe contenus dans un volume ONTAP FlexVol. Notez que depuis vSphere 7.0, VMware ne prend plus en charge la technologie FCoE dans les environnements de production. NFS est un protocole de fichier qui place les machines virtuelles dans des datastores (qui sont simplement des volumes ONTAP) sans avoir besoin de VMFS. SMB (CIFS), iSCSI, NVMe/TCP ou NFS peuvent également être utilisés directement d'un système d'exploitation invité à ONTAP.</block>
  <block id="7469c178e150e10730dcab1094765f10" category="paragraph">Les tableaux suivants présentent les fonctionnalités de data store traditionnelles prises en charge par vSphere avec ONTAP. Ces informations ne s'appliquent pas aux datastores vvols, mais elles s'appliquent généralement aux versions vSphere 6.x et ultérieures utilisant des versions ONTAP prises en charge. Vous pouvez également consulter<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> Pour les versions de vSphere spécifiques afin de confirmer les limites spécifiques.</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN par hôte</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN par serveur</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 Namespeces par serveur</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Taille maximale des fichiers du datastore</block>
  <block id="fe299bb060ce245b8fe190de21d3978e" category="cell">16 To ou 62 To avec ONTAP 9.12.1RC1 et versions ultérieures avec des fichiers volumineux activés</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Négociation automatique</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">Se reporter à NFS.MaxQueueDepth dans<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">V3 uniquement**</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Oui, en utilisant le nouveau plug-in haute performance (HPP)</block>
  <block id="5663fa28fe2a703e07072185e3a90a94" category="paragraph">*NetApp recommande l'utilisation d'iSCSI « in-guest » pour les clusters Microsoft, plutôt que de VMDK « multiwriter » dans un datastore VMFS. Cette approche est entièrement prise en charge par Microsoft et VMware, et offre une grande flexibilité avec ONTAP (SnapMirror vers des systèmes ONTAP sur site ou dans le cloud), est facile à configurer et à automatiser et peut être protégée avec SnapCenter. VSphere 7 intègre une nouvelle option clustered VMDK. Cette approche est différente des VMDK compatibles avec plusieurs enregistreurs, qui requièrent un datastore présenté via le protocole FC pour lequel la prise en charge de VMDK en cluster est activée. D'autres restrictions s'appliquent. Voir VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentation pour les instructions de configuration.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**Les datastores utilisant NVMe-of et NFS v4.1 nécessitent une réplication vSphere. SRM ne prend pas en charge la réplication basée sur les baies.</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">Le déploiement de vSphere avec des datastores NFS ONTAP offre une implémentation très performante et facile à gérer qui fournit des ratios VM/datastore qui ne peuvent pas être obtenus avec des protocoles de stockage de niveau bloc. Cette architecture peut entraîner une multiplication par dix de la densité des datastores avec une corrélation réduction du nombre de datastores. Bien qu'un datastore plus volumineux puisse améliorer l'efficacité du stockage et offrir des avantages opérationnels, envisagez d'utiliser au moins quatre datastores (volumes FlexVol) pour stocker vos machines virtuelles sur un seul contrôleur ONTAP afin d'optimiser les performances des ressources matérielles. Cette approche vous permet également de créer des datastores avec différentes règles de restauration. Certaines peuvent être sauvegardées ou répliquées plus fréquemment que d'autres, en fonction des besoins de l'entreprise. Les volumes FlexGroup n'ont pas besoin de plusieurs datastores pour améliorer les performances, car ils évoluent indépendamment de la conception.</block>
  <block id="241f8fed1e3a823fcd4d0c1eb705b1a2" category="list-text">NetApp recommande l'utilisation des volumes FlexVol et, à partir des volumes ONTAP 9.8 FlexGroup, des datastores NFS. Les autres conteneurs de stockage ONTAP, tels que les qtrees, ne sont généralement pas pris en charge par les outils ONTAP pour VMware vSphere. Le déploiement de datastores sous forme de qtrees sur un volume unique peut être utile pour les environnements hautement automatisés qui peuvent bénéficier de quotas au niveau des datastores ou de clones de fichiers des machines virtuelles.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">Les datastores VMFS peuvent également être configurés avec des LUN accessibles via FC, iSCSI ou FCoE. VMFS permet d'accéder simultanément aux LUN classiques par chaque serveur ESX d'un cluster. Les datastores VMFS peuvent être jusqu'à 64 To et comprennent jusqu'à 32 LUN de 2 To (VMFS 3) ou un seul LUN de 64 To (VMFS 5). La taille de LUN maximale de ONTAP est de 16 To sur la plupart des systèmes et de 128 To sur les baies SAN. Il est donc possible de créer un datastore VMFS 5 de taille maximale sur la plupart des systèmes ONTAP en utilisant quatre LUN de 16 To. Bien que les charges de travail E/S élevées puissent bénéficier de la performance de plusieurs LUN (avec les systèmes FAS ou AFF haut de gamme), cet avantage peut être compensé par la complexité de gestion supplémentaire qui permet de créer, de gérer et de protéger les LUN des datastores et un risque de disponibilité accru. NetApp recommande généralement d'utiliser un volume LUN unique et important pour chaque datastore et ne peut être étendu que si le besoin de dépasser 16 To de data store. Comme pour NFS, envisagez l'utilisation de plusieurs datastores (volumes) pour optimiser les performances d'un seul contrôleur ONTAP.</block>
  <block id="040ffbbbbeda558bdae1e07f5371b4f5" category="list-text">Utilisez les commutateurs qui prennent en charge l'agrégation de liens des ports sur deux châssis de commutateurs distincts en utilisant une approche de groupe d'agrégation de liens multichâssis, comme Virtual PortChannel (VPC) de Cisco.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Désactiver LACP pour les ports de switch connectés à ESXi, sauf si vous utilisez dvswitches 5.1 ou version ultérieure avec LACP configuré.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">Utilisez LACP pour créer des agrégats de liens pour les systèmes de stockage ONTAP avec des groupes d'interface multimode dynamiques avec un hachage IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Utilisez une stratégie de regroupement de hachage IP sur ESXi.</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Les LIF SVM se connectent aux ports, aux groupes d'interface ou aux interfaces VLAN dotés de VLAN, MTU et d'autres paramètres. Cependant, les paramètres ne sont pas gérés au niveau de la SVM.</block>
  <block id="631e164314a103fe3183b00b759057b2" category="paragraph">SLM limite les nœuds qui annoncent les chemins vers une LUN donnée. Il est recommandé à NetApp d'utiliser au moins une LIF par nœud par SVM et SLM pour limiter les chemins annoncés vers le nœud hébergeant la LUN et son partenaire de haute disponibilité. Bien que d’autres chemins existent, ils ne sont pas annoncés par défaut. Il est possible de modifier les chemins annoncés avec les arguments de noeud de rapport ajouter et supprimer dans SLM. Notez que les LUN créées dans les versions antérieures à 8.3 annoncent tous les chemins et doivent être modifiés uniquement pour annoncer les chemins vers la paire HA d'hébergement. Pour plus d'informations sur SLM, consultez la section 5.9 de<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. La méthode précédente de ensembles de ports peut également être utilisée pour réduire davantage les chemins disponibles pour une LUN. Les jeux de ports permettent de réduire le nombre de chemins visibles via lesquels les initiateurs d'un groupe initiateur peuvent voir les LUN.</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware prend en charge NFSv3 depuis VMware Infrastructure 3. VSphere 6.0 a ajouté la prise en charge de NFSv4.1, offrant des fonctionnalités avancées telles que la sécurité Kerberos. Dans le cas où NFSv3 utilise un verrouillage côté client, NFSv4.1 utilise un verrouillage côté serveur. Bien qu'un volume ONTAP puisse être exporté via les deux protocoles, ESXi ne peut être monté que via un seul protocole. Ce montage de protocole unique n'empêche pas les autres hôtes ESXi de monter le même datastore dans une version différente. Veillez à spécifier la version du protocole à utiliser lors du montage de sorte que tous les hôtes utilisent la même version et, par conséquent, le même style de verrouillage. Ne pas mélanger les versions NFS sur les hôtes. Si possible, utilisez des profils hôtes pour vérifier la conformité.</block>
  <block id="d8119941da55a672db49a624330ea7f0" category="list-text">Les export policy NFS permettent de contrôler l'accès des hôtes vSphere. Vous pouvez utiliser une seule règle avec plusieurs volumes (datastores). Avec NFSv3, ESXi utilise le style de sécurité sys (UNIX) et requiert l'option de montage root pour exécuter les VM. Dans ONTAP, cette option est appelée superutilisateur et, lorsque l'option superutilisateur est utilisée, il n'est pas nécessaire de spécifier l'ID utilisateur anonyme. Notez que l'export-policy rules avec des valeurs différentes de<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> et<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Peut entraîner des problèmes de découverte des SVM à l'aide des outils ONTAP. Voici un exemple de politique :</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anonyme</block>
  <block id="49bb4e84b97bfe104e9fe7eb7df07a38" category="list-text">Les volumes des datastores NFS sont rassemblés dans le volume racine du SVM. Par conséquent, ESXi doit également avoir accès au volume racine pour naviguer et monter des volumes de datastores. L'export policy pour le volume racine, et pour tous les autres volumes dans lesquels la jonction du volume datastore est imbriquée, doit inclure une ou plusieurs règles pour les serveurs ESXi leur accordant un accès en lecture seule. Voici un exemple de stratégie pour le volume racine, également à l'aide du plug-in VAAI :</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Protocole d'accès : nfs (qui inclut nfs3 et nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">Règle d'accès RW : jamais (meilleure sécurité pour le volume racine)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superutilisateur : sys (également requis pour le volume racine avec VAAI)</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Lors de la création de datastores pour clusters VMware avec le plug-in, sélectionnez le cluster plutôt qu'un seul serveur ESX. Ce choix permet de monter automatiquement le datastore sur tous les hôtes du cluster.</block>
  <block id="1abaee3673de53b378351ee9dc679daa" category="list-text">Actuellement, VMware et NetApp ne prennent pas en charge une approche commune de mise en réseau multivoie. Pour NFSv4.1, NetApp prend en charge pNFS, tandis que VMware prend en charge l'agrégation de sessions. NFSv3 ne prend pas en charge plusieurs chemins physiques vers un volume. Pour les environnements FlexGroup avec ONTAP 9.8, nous vous recommandons de laisser les outils ONTAP pour VMware vSphere effectuer le montage unique, car les effets de l'accès indirect sont généralement minimes (microsecondes). Il est possible d'utiliser un DNS Round-Robin pour distribuer des hôtes ESXi sur des LIF sur différents nœuds du FlexGroup, mais cela nécessiterait la création et le montage du FlexGroup sans les outils ONTAP pour VMware vSphere. Dans ce cas, les fonctionnalités de gestion des performances ne sont pas disponibles.</block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
  <block id="03b125f503e8b797be1fe5a21a10d220" category="summary">Cette section décrit comment protéger votre base de données Oracle avec l'outil azacsnap et le Tiering de sauvegarde, de restauration et de snapshots vers Azure Blob.</block>
  <block id="b47faaf85acf415e557bd0b669342659" category="doc">Protégez votre base de données Oracle dans le cloud Azure</block>
  <block id="cec4dbc9c066ab7b22ef743151be75eb" category="paragraph"><block ref="cec4dbc9c066ab7b22ef743151be75eb" category="inline-link-macro-rx"></block></block>
  <block id="06a2961d48a854a133ddfe05c7912732" category="section-title">Sauvegardez la base de données Oracle avec snapshot à l'aide de l'outil AzAcSnap</block>
  <block id="30462dbcf926561966ea824afd44e355" category="paragraph">L'outil Azure application-cohérent Snapshot Tool (AzAcSnap) est un outil de ligne de commande qui permet de protéger les données des bases de données tierces en gérant l'orchestration nécessaire pour les placer dans un état cohérent entre les applications avant de créer une copie Snapshot de stockage. Il renvoie ensuite les bases de données à un état opérationnel.</block>
  <block id="07612935f16f2665ef52f490f9b1f43b" category="paragraph">Dans le cas d'Oracle, vous mettez la base de données en mode de sauvegarde pour prendre un instantané, puis sortez-la du mode de sauvegarde.</block>
  <block id="070d0b63c9af5e43d43102c1869d4262" category="section-title">Sauvegarde des données et des volumes de journaux</block>
  <block id="7dd57abd8929da4f18cc94d1940161a1" category="paragraph">La sauvegarde peut être configurée sur l'hôte du serveur de base de données à l'aide d'un script shell simple qui exécute la commande snapshot. Ensuite, le script peut être planifié pour s'exécuter à partir de crontab.</block>
  <block id="087916fda35dba838b68193ed8bc3aeb" category="paragraph">Généralement, la fréquence de sauvegarde dépend des objectifs RTO et RPO souhaités. La création fréquente de snapshots consomme plus d'espace de stockage. Il existe un compromis entre la fréquence de sauvegarde et la consommation d'espace.</block>
  <block id="e2ece357797b760af1c814632edcf99d" category="paragraph">En général, les volumes de données consomment plus d'espace de stockage que les volumes de journaux. Ainsi, vous pouvez créer des snapshots sur des volumes de données toutes les quelques heures et plus fréquemment sur les volumes des journaux toutes les 15 à 30 minutes.</block>
  <block id="2a2c2eb0d2bde8c24cc55a11862ca857" category="paragraph">Reportez-vous aux exemples suivants de scripts de sauvegarde et de planification.</block>
  <block id="e048ccd48425229cea678849ba68a190" category="paragraph">Pour les copies Snapshot de volumes de données :</block>
  <block id="f0d6345b8e5345f55c21610283eaeedd" category="paragraph">Pour les instantanés de volume de journal :</block>
  <block id="68b7e37ef318c0e56eabf3e1aded4216" category="paragraph">Horaire de crontab: 15,30,45 * * * * /home/azacsnap/snap_log.sh 0 */2 * * * /home/azacsnap/snap_data.sh</block>
  <block id="adf4ba1e0f3190afb18557f038ae1ecf" category="admonition">Lors de la configuration de la sauvegarde<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> fichier de configuration, ajoutez tous les volumes de données, y compris le volume binaire, à<block ref="0fb9dff864caebba259b119756a2ce17" prefix=" " category="inline-code"></block> et tous les volumes de log à<block ref="5e5fb0a2540d102aeebc3dac60712494" prefix=" " category="inline-code"></block>. La rétention maximale des snapshots est de 250 copies.</block>
  <block id="a93091ed018686dcf478589ba04fd6f6" category="section-title">Validation des snapshots</block>
  <block id="8a46f2968d5dc184634cff75cd1b8b8e" category="paragraph">Accédez au portail Azure &gt; Azure NetApp Files/volumes pour vérifier si les snapshots ont été créés.</block>
  <block id="3542e11f657b779fcef8cc387987e9f2" category="inline-image-macro">Cette capture d'écran illustre deux fichiers dans la liste de snapshot.</block>
  <block id="c2dd243538b072e19882bdcd6ac2c6c9" category="inline-image-macro">Cette capture d'écran illustre huit fichiers dans la liste de capture d'écran.</block>
  <block id="af143d815dcd69aae3ff8d8bdde9fd58" category="paragraph"><block ref="bf87ea8d7de67f1fdc628b6bb4b400e5" category="inline-image-macro-rx" type="image"></block>
<block ref="1d682e6513772285b95199f0646e28da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7479b02641600cb6142d8594c1360d11" category="section-title">Restauration et restauration Oracle à partir de la sauvegarde locale</block>
  <block id="76265d8fce7f282b6ff5a8581df8879c" category="paragraph">L'un des principaux avantages de la sauvegarde Snapshot est sa coexistence avec les volumes de base de données source, et les volumes de base de données primaires peuvent être redéployés presque instantanément.</block>
  <block id="878609e3e12819fffdd7247406f655be" category="section-title">Restauration et restauration d'Oracle sur le serveur principal</block>
  <block id="8733b7b64c8d2c32caa423c7eb2955fc" category="paragraph">L'exemple suivant montre comment restaurer et récupérer une base de données Oracle à partir du tableau de bord et de l'interface de ligne de commande Azure sur le même hôte Oracle.</block>
  <block id="aa30a622663e0f34541394e008fe82cd" category="list-text">Créez une table de tests dans la base de données à restaurer. [oracle@acao-ora01 ~]$ sqlplus / as sysdba</block>
  <block id="ea16560565f3889db4dabf938628b462" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le lundi 12 19 septembre 02:35 2022 version 19.8.0.0.0</block>
  <block id="0409b2fce118cc126a532dea158d2943" category="paragraph">SQL&gt; create table testsnapshot( ID entier, event varchar(100), dt timestamp);</block>
  <block id="bec6da77877c0793c1d3eb6c6896e98e" category="paragraph">Table créée.</block>
  <block id="a5b83945adfd5370663cb2d9c4f31d09" category="paragraph">SQL&gt; insère dans les valeurs testsnapshot(1,'insérez un marqueur de données pour valider la restauration snapshot',sysdate) ;</block>
  <block id="6ba18fa8fa7d170dfd8fc80f0f3d39f7" category="paragraph">1 ligne créée.</block>
  <block id="d1d2dcb121f8bf8fd39724ea075c6409" category="paragraph">SQL&gt; validation ;</block>
  <block id="a92090dde5e820fde0a68705ee3f2bd0" category="paragraph">Validation terminée.</block>
  <block id="fd9736dfc88a182f9cb6e5f6a2b97487" category="paragraph">SQL&gt; sélectionner * dans testsnapshot ;</block>
  <block id="2817b9cf9fc0cd0d8bf9fb03acbfc93f" category="list-text">Déposez le tableau après les sauvegardes de snapshot.</block>
  <block id="07b56c53a9fec8c477afb0cb5f2394af" category="paragraph">[oracle@acao-ora01 ~]$ sqlplus / as sysdba</block>
  <block id="dcd4d50ecf59b4752c161f0ddc44df44" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le Mar Sep 13 14:20:22 2022 version 19.8.0.0.0</block>
  <block id="bee0f13528c2f6f5b67053dc1e942328" category="paragraph">SQL&gt; déposer un instantané de test de table ;</block>
  <block id="cd85f26775e453b2177d5fcc6265b31d" category="paragraph">Table supprimée.</block>
  <block id="07e18ec921a195478cdbab47d8d68d89" category="paragraph">SQL&gt; Select * from testsnapshot; Select * from testsnapshot * ERROR at line 1: ORA-00942: Le tableau ou la vue n'existe pas</block>
  <block id="f06f4fbf6e3e0e45b0d4b241ceaf19c9" category="paragraph">SQL&gt; Arrêt immédiat ; base de données fermée. Base de données désinstallée. Arrêt de l'instance ORACLE. SQL&gt; exit déconnecté d'Oracle Database 19c Enterprise Edition version 19.0.0.0.0 - production version 19.8.0.0.0</block>
  <block id="09d4fe137595af1cc975247ba704462d" category="list-text">Depuis le tableau de bord Azure NetApp Files, restaurez le volume des journaux vers le dernier snapshot disponible. Choisissez *Revert volume*.</block>
  <block id="33ba8417b2640d4172513bbf9cbc3e55" category="inline-image-macro">Cette capture d'écran montre la méthode de reversion de snapshot pour les volumes du tableau de bord ANF.</block>
  <block id="546b967f1ce32832a90c77282f0cdf2b" category="paragraph"><block ref="546b967f1ce32832a90c77282f0cdf2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b728fe18b10b9b611a1d3ab6acc0df9" category="list-text">Confirmez la restauration du volume et cliquez sur *Revert* pour terminer la réversion du volume vers la dernière sauvegarde disponible.</block>
  <block id="5c7deeb27ad1e0e4c1d6d52b2a2a1bfc" category="inline-image-macro">« Êtes-vous sûr de vouloir le faire ? » page pour la nouvelle version de snapshot.</block>
  <block id="ef80226ab5a9d2865852e606297da2cf" category="paragraph"><block ref="ef80226ab5a9d2865852e606297da2cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18b9906dd2c95b12fdb987b7c2aa9917" category="list-text">Répétez les mêmes étapes pour le volume de données, puis assurez-vous que la sauvegarde contient la table à restaurer.</block>
  <block id="a38e609b2fd5c2dee1b4ccb1cbbac7d4" category="inline-image-macro">Cette capture d'écran montre la méthode de reversion de snapshot pour les volumes de données dans le tableau de bord ANF.</block>
  <block id="f0d819988fad0119995986a2bdfd9ad6" category="paragraph"><block ref="f0d819988fad0119995986a2bdfd9ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc824d4f774a64498f954eb2ebbc093b" category="list-text">Confirmez de nouveau la version du volume et cliquez sur « Revert ».</block>
  <block id="5e2296a09eabbd34b62da3492091ff33" category="inline-image-macro">« Êtes-vous sûr de vouloir le faire ? » page pour la nouvelle version du snapshot du volume de données.</block>
  <block id="af5f9a99ee2d86856d0e2477e417dc4c" category="paragraph"><block ref="af5f9a99ee2d86856d0e2477e417dc4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="170b40e31285910539e0d464f2bf33a6" category="list-text">Resynchroniser les fichiers de contrôle si vous disposez de plusieurs copies d'entre eux et remplacer l'ancien fichier de contrôle par la dernière copie disponible.</block>
  <block id="952cd3804f479f3c31f123d064ccbdf5" category="paragraph">[oracle@acao-ora01 ~]$ mv /u02/oradata/ORATST/control01.ctl /u02/oradata/ORATST/control01.ctl.bk [oracle@acao-ora01 ~]$ cp /u03/orareo/ORATST/control01/AT02/ORCOTRO.ST/AT01/AT2/ORCOTRO.ST/AT1/ORL.1/ORL.1/ORL.1</block>
  <block id="bd99bc18393147b05e3f350eb6a61f47" category="list-text">Connectez-vous à la machine virtuelle Oracle Server et exécutez la restauration de la base de données avec sqlplus.</block>
  <block id="125ab5cbfb90c4a6d038bcca4da6fdc4" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le Mar Sep 13 15:10:17 2022 version 19.8.0.0.0</block>
  <block id="010621501012cd31b6666d17dad683d2" category="paragraph">Connecté à une instance inactive.</block>
  <block id="6bd3f70e5ab38ca26f8cabd390e15fc0" category="paragraph">Montage de démarrage de SQL&gt; ; l'instance ORACLE a démarré.</block>
  <block id="424459a4363a5afdd1e45d31fcd11efe" category="paragraph">Total System Global Area 6442448984 octets taille fixe 8910936 octets taille variable 1090519040 octets mémoire de base de données 5335154688 octets tampons de Redo 7864320 octets montage de la base de données. SQL&gt; récupérer la base de données à l'aide de backup controlfile jusqu'à annuler; ORA-00279: Modifier 3188523 généré à 09/13/2022 10:00:09 nécessaire pour thread 1 ORA-00289: Suggestion : /u03/orareco/ORATST/archivelog/2022_09_13 3188523/o1_mf_1_43 43__22rnjq9q_00280: Modification de la séquence de thread_1_.1</block>
  <block id="db9afd3f7adaff3fe1135208fa6b6a09" category="paragraph">Spécifiez le journal : {&lt;RET&gt;=Suggested | filename | AUTO | CANCEL}</block>
  <block id="abc467423916c8ee7c16f566b4ab4ca8" category="paragraph">ORA-00279: Modification 3188862 générée à 09/13/2022 10:01:20 nécessaire pour thread 1 ORA-00289: Suggestion : /u03/orareco/ORATST/archivelog/2022_09_13/o1_mf_1_44__29f2lgb5_.arc-00280: Modification 3188862 pour ce fichier_44_00278/OR2log_2022 43_1_.o_09_1_13/o_1_fr/o_1_1_FR/o_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_1_2_2_1_1_2_1_1_2_1_1</block>
  <block id="479d2dfa77fdcde3bfd41fcdebbca1ff" category="paragraph">ORA-00279: Modification 3193117 générée à 09/13/2022 12:00:08 nécessaire pour thread 1 ORA-00289: Suggestion : /u03/orareco/ORATST/archivelog/2022_09_13/o1_mf_1_45__29h6qyw_.arc-00280: Modification 3193117 pour ce fichier_00278/ORF_45 09_2022 44_13/o_1_FR.1_2_1_2_1_1_2_1_2_1_1_2_1_1_1_2_1_2_1_2_1_1_1_2_FR</block>
  <block id="c76ff2f7e10a42adf7faec8f9e6faeab" category="paragraph">ORA-00279: Modification 3193440 générée à 09/13/2022 12:01:20 nécessaire pour thread 1 ORA-00289: Suggestion : /u03/orareco/ORATST/archivelog/2022_09_13/o1_mf_1_46_%archimu_.arc-00280: Modification 3193440 pour thread 1 est dans la séquence #46 09/ORqog_00278_/2022_13_fr_FR/ORqog_1__45_fr/o_fr_FR/o_1__FR/o_1__1_1_1_1_FR/ORqa__1_1_1_1_1_FR/ORqa_1_FR</block>
  <block id="0e98028493ec8c4a1d181c0d71c3ec7b" category="paragraph">Spécifiez le journal : {&lt;RET&gt;=Suggested | filename | AUTO | CANCEL} annule la récupération du support annulée. SQL&gt; Alter database open resetlogs ;</block>
  <block id="f6c9ea366c01da7d664a8c7c3813e0bd" category="paragraph">Base de données altérée.</block>
  <block id="8ad5254ade1fed8d3ccc482196b4c36c" category="paragraph">Cet écran montre que la table supprimée a été restaurée à l'aide de sauvegardes instantanées locales.</block>
  <block id="34d73a671fa85d8d86ba1eff63b238d8" category="paragraph"><block ref="34d73a671fa85d8d86ba1eff63b238d8" category="inline-link-macro-rx"></block></block>
  <block id="0c55b956af322a2409f5dd75af116fee" category="doc">WP-7357 : introduction du déploiement de bases de données Oracle sur EC2 et FSX Best Practices</block>
  <block id="b985336298cf9391b91c898572090625" category="summary">Cette section décrit l'architecture de solution de déploiement et de protection des données d'une base de données Oracle avec une machine virtuelle Azure et le stockage Azure NetApp Files.</block>
  <block id="fc6024ee9167308c3126789695e7353f" category="paragraph"><block ref="fc6024ee9167308c3126789695e7353f" category="inline-link-macro-rx"></block></block>
  <block id="91e17bfb5f535513b5320d68f6afe1fc" category="paragraph">Le schéma d'architecture suivant illustre un déploiement de base de données Oracle hautement disponible sur les instances de VM Azure et le stockage Azure NetApp Files.</block>
  <block id="520c5c426000f1dbbd8ac385d5547603" category="paragraph">Dans l'environnement, l'instance de calcul Oracle est déployée via une console de VM des services Azure. Plusieurs types d'instances Azure sont disponibles dans la console. NetApp recommande de déployer une instance de machine virtuelle Azure orientée base de données, qui répond aux attentes de votre workload.</block>
  <block id="9e20ded809aa2fa1bd072f48ceacfdd8" category="paragraph">En revanche, le stockage de base de données Oracle est déployé avec le service Azure NetApp Files disponible depuis la console Azure. Les volumes binaires, de données ou de journaux Oracle sont ensuite présentés et montés sur un hôte Linux d'instance de machine virtuelle Azure.</block>
  <block id="6b5cae77dbc9c4b759bf654b117eb10b" category="inline-image-macro">Cette image illustre la relation entre le site primaire, le site de secours et le peering vnet de chacun de ces sites. Ce formulaire forme quatre réseaux virtuels distincts.</block>
  <block id="2246b51fdf61c77213e0ce37d743cd03" category="paragraph"><block ref="2246b51fdf61c77213e0ce37d743cd03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03aa17a1290e1122adecd07d53463cde" category="paragraph">Par bien des aspects, l'implémentation de Azure NetApp Files dans le cloud Azure s'apparente à une architecture de stockage de données ONTAP sur site avec de nombreuses redondances intégrées, comme RAID et doubles contrôleurs. Pour la reprise après incident, un site de secours peut être configuré dans différentes régions et la base de données peut être synchronisée avec le site principal à l'aide de la réplication au niveau de l'application (par exemple, Oracle Data Guard).</block>
  <block id="6f1714a5ced243b141295d01d4038364" category="paragraph">Dans le cadre de notre validation de test pour le déploiement et la protection des données des bases de données Oracle, la base de données Oracle est déployée sur une seule machine virtuelle Azure, comme illustré dans le schéma ci-dessous :</block>
  <block id="fef3344ae2f384e724a169b6e9d90be7" category="inline-image-macro">Cette image illustre l'organisation d'une seule machine virtuelle Azure avec le peering de vnet afin de faire deux réseaux virtuels distincts.</block>
  <block id="f3699a22a9267b8e767816c81f821522" category="paragraph"><block ref="f3699a22a9267b8e767816c81f821522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69cf5342936c24c9fac1c6529c4f825f" category="paragraph">L'environnement Azure Oracle peut être géré avec un nœud de contrôleur Ansible pour l'automatisation à l'aide des kits d'outils fournis par NetApp pour le déploiement, la sauvegarde, la restauration et la migration de base de données. Toutes les mises à jour du noyau du système d'exploitation ou du correctif Oracle de l'instance de VM Oracle peuvent être effectuées en parallèle pour maintenir la synchronisation du système principal et du système de secours. En fait, les kits d'outils initiaux peuvent être facilement étendus pour effectuer des tâches Oracle quotidiennes si nécessaire. Si vous avez besoin d'aide pour configurer un contrôleur Ansible, reportez-vous à la section <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block> pour commencer.</block>
  <block id="149b87e0b981bcf1e3d652831c207e04" category="inline-link-macro">Ensuite : facteurs à prendre en compte.</block>
  <block id="0a9d288b4b8679857f2d7e7f0d5a63f6" category="paragraph"><block ref="0a9d288b4b8679857f2d7e7f0d5a63f6" category="inline-link-macro-rx"></block></block>
  <block id="41f2543265fcbcf566ce925409c1bfbb" category="summary">Cette section décrit comment migrer la base de données Oracle d'un système sur site vers un système Azure NetApp Files, et vice-versa.</block>
  <block id="3b99478aefcc6039ddcb29f19ce3f1ee" category="doc">Migration de la base de données sur site vers le cloud Azure</block>
  <block id="964310198f864c746c945ff1c6fffe3f" category="inline-link-macro">Précédent : protection de la base de données.</block>
  <block id="413dcfd081f137889743981159ac9abe" category="paragraph"><block ref="413dcfd081f137889743981159ac9abe" category="inline-link-macro-rx"></block></block>
  <block id="3c2b924258f32094eb64883db57a778a" category="paragraph">Suite à la décision d'Oracle de sortir les bases de données à instance unique, de nombreuses entreprises ont transformé des bases de données Oracle à instance unique en bases de données de conteneurs mutualisés. Cela permet de déplacer facilement un sous-ensemble de bases de données de conteneurs appelé PDB vers le cloud avec l'option de disponibilité maximale, ce qui réduit les temps d'indisponibilité lors de la migration.</block>
  <block id="a221bb2d4b0b28bb7e9aa40527e36333" category="paragraph">Toutefois, si vous disposez toujours d'une seule instance d'une base de données Oracle, vous pouvez d'abord la convertir en une base de données de conteneurs multi-locataires en place avant de tenter de déplacer le PDB.</block>
  <block id="3312d9383c6e42558bb6c7ffa86498b5" category="paragraph">Dans les deux cas, nous détaillés dans les sections suivantes, pour la migration des bases de données Oracle sur site vers le cloud Azure.</block>
  <block id="d7acbe14b605ece64e94636c2ac85151" category="section-title">Conversion d'une instance unique non-CDB en PDB dans un CDB mutualisé</block>
  <block id="b65ba7cc82289837e3a44b6025b8a104" category="paragraph">Si vous possédez toujours une base de données Oracle à instance unique, elle doit être convertie en base de données de conteneurs mutualisés, que vous souhaitiez la migrer vers le cloud ou non, car Oracle cessera bientôt de prendre en charge des bases de données à instance unique.</block>
  <block id="60a4157f0722b484d4ce9ec02662db31" category="paragraph">Les procédures suivantes connectent une base de données à instance unique à une base de données de conteneurs en tant que base de données enfichable ou PDB.</block>
  <block id="aefccbe3e9382cbdd83d84fee06a408d" category="list-text">Créez une base de données de conteneur de shell sur le même hôte que la base de données à instance unique dans une base séparée<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>.</block>
  <block id="182e093a477c76844c12680be3deb7a4" category="list-text">Arrêtez la base de données d'instance unique et redémarrez-la en mode lecture seule.</block>
  <block id="48270a516aeb2dd47c2b7f5d897c3182" category="list-text">Exécutez le<block ref="707fc638546e97f4dca068fcf2fbe277" prefix=" " category="inline-code"></block> procédure de génération des métadonnées de la base de données.</block>
  <block id="61c2d2d903cc3e2bc374cc66b3a1572d" category="list-text">Arrêtez la base de données à instance unique.</block>
  <block id="d0e90ac40083de7010746f1c7afa8680" category="list-text">Démarrez la base de données du conteneur.</block>
  <block id="c9b14b140c5af8df85a71e71e823fcd9" category="list-text">Exécutez le<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> Fonction permettant de déterminer si le non-CDB est compatible avec le CDB.</block>
  <block id="b4579eff709cfd4a9e9d9b3c7823a470" category="paragraph">Si la sortie est OUI, le non-CDB est compatible et vous pouvez passer à l'étape suivante.</block>
  <block id="b788542aadbeda07cae67fad51f01ecf" category="paragraph">Si la sortie est NON, alors le non-CDB n'est pas compatible et vous pouvez vérifier le<block ref="40bcd9431704d488bfba8de25bdd0469" prefix=" " category="inline-code"></block> afficher pour voir pourquoi il n'est pas compatible. Toutes les violations doivent être corrigées avant de continuer. Par exemple, toute discordance de version ou de correctif doit être résolue en exécutant une mise à niveau ou l'utilitaire opach. Après avoir corrigé les violations, exécutez<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> Encore une fois pour s'assurer que le non-CDB est compatible avec le CDB.</block>
  <block id="3dc81f6d88ee2f38ca30676e4b371634" category="list-text">Connectez l'instance unique non-CDB.</block>
  <block id="10a9ce9a6e151e6ff04bee976e0cb1de" category="admonition">S'il n'y a pas suffisamment d'espace sur l'hôte, le<block ref="4777c7eb130280b37f5b4b3abde7c586" prefix=" " category="inline-code"></block> Vous pouvez utiliser l'option pour créer le PDB. Dans ce cas, un non-CDB à instance unique n'est pas utilisable après la connexion en tant que PDB car les fichiers de données d'origine ont été utilisés pour le PDB. Veillez à créer une sauvegarde avant la conversion afin qu'il y ait quelque chose à redescendre en cas de problème.</block>
  <block id="03d9f2c68151dce9edd03b346e5b110c" category="list-text">Démarrez avec la mise à niveau PDB après la conversion si la version entre le non-CDB source à instance unique et le CDB cible sont différentes. Pour la conversion de la même version, cette étape peut être ignorée.</block>
  <block id="81954d0087f2bc7590c39792b2d3ff79" category="paragraph">Vérifiez le fichier journal de mise à niveau dans<block ref="8940bd010306ed7bc730469a2815003c" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="65f9a981d9b9caaa37a227c9d787c280" category="list-text">Ouvrez la base de données enfichable, recherchez les violations de plug-in pdb et recompilez les objets non valides.</block>
  <block id="f4d5586e12195159e664b1f0a78cccd3" category="list-text">L'exécution<block ref="30636d635a272a80dff68679e08f1c7a" prefix=" " category="inline-code"></block> pour mettre à jour le dictionnaire de données.</block>
  <block id="182d7c995640cc8ef16b728a670fbe58" category="paragraph">Arrêtez et redémarrez la base de données du conteneur. Le ncb est sorti du mode restreint.</block>
  <block id="d6af386b8be94481db3de6778b3fc24a" category="section-title">Migrez des bases de données Oracle sur site vers Azure avec la relocalisation de l'infrastructure de données</block>
  <block id="da5d44e97cbc406251573e1664b5e1f0" category="paragraph">La relocalisation d'Oracle PDB avec l'option de disponibilité maximale utilise la technologie de clonage à chaud PDB, qui active la disponibilité du PDB source pendant que le PDB est copié sur la cible. Lors du basculement, les sessions et les connexions sont redirigées automatiquement vers le PDB cible. Ainsi, le temps d'arrêt est réduit en fonction de la taille du PDB déplacé. NetApp fournit un kit d'outils basé sur Ansible qui automatise la procédure de migration.</block>
  <block id="a8efacce1c06e5f64504448dec25740a" category="list-text">Créez un CDB dans le cloud public Azure sur une machine virtuelle Azure avec la même version et le même niveau de patch.</block>
  <block id="0f09a4e81820f79a89d0b433bb0de6ca" category="list-text">Depuis le contrôleur Ansible, clonez une copie du kit d'automatisation.</block>
  <block id="33abd0ac6a3fb7ef8c104725e8360e85" category="list-text">Lisez les instructions du fichier README.</block>
  <block id="59082266ab8171963eb8785041055ee1" category="list-text">Configurez les fichiers de variables hôte Ansible pour les serveurs Oracle source et cible, ainsi que le fichier de configuration de l'hôte du serveur DB pour la résolution du nom.</block>
  <block id="166811e58fa2fd17b3ab3305ca4b1948" category="list-text">Installez les prérequis sur le contrôleur Ansible sur le contrôleur Ansible.</block>
  <block id="e40dd1f176a77cef20eb421dee4fea9f" category="list-text">Exécutez toutes les tâches de pré-migration sur le serveur sur site.</block>
  <block id="aba7f3209eb8c49aca729c7368fb42fe" category="admonition">L'utilisateur admin est l'utilisateur de gestion sur l'hôte serveur Oracle sur site avec des privilèges sudo. L'utilisateur admin est authentifié par un mot de passe.</block>
  <block id="a1da14dd2e192d36a7fe7bae327c2b23" category="list-text">Exécutez la relocalisation de l'APB Oracle depuis les sites vers l'hôte Oracle Azure cible.</block>
  <block id="39f1871870cabd138bd313c450662e67" category="admonition">Le contrôleur Ansible peut être situé sur site ou dans le cloud Azure. Le contrôleur doit disposer d'une connectivité avec l'hôte du serveur Oracle sur site et l'hôte VM Azure Oracle. Le port de base de données Oracle (tel que 1521) est ouvert entre l'hôte du serveur Oracle sur site et l'hôte VM Azure Oracle.</block>
  <block id="63a48a0f7ee4b39ef32c11b92acc2baa" category="section-title">Options supplémentaires de migration de base de données Oracle</block>
  <block id="7619081ba13aebf0c83d5660f9bf01bb" category="inline-link-macro">Processus de décision de migration de bases de données Oracle</block>
  <block id="0257ad9cf0c221fcf0c611f835c027ca" category="paragraph">Pour plus d'informations sur les options de migration, reportez-vous à la documentation Microsoft : <block ref="421a85ebca6e289a6eff559e7e35faf8" category="inline-link-macro-rx"></block>.</block>
  <block id="a73e5c65844b18c49122a8a79ef3fa65" category="doc">Procédures détaillées de déploiement d'Oracle sur Azure VM et Azure NetApp Files</block>
  <block id="f8de11946f5850d6f1597a7cf5fc2234" category="inline-link-macro">Précédent : facteurs à prendre en compte.</block>
  <block id="e9704920b930163220a6e7564d7d680e" category="paragraph"><block ref="e9704920b930163220a6e7564d7d680e" category="inline-link-macro-rx"></block></block>
  <block id="cf2fb9f52eae11aaa1b6818cc22ade30" category="section-title">Déployez une machine virtuelle Azure avec ANF pour Oracle via la console du portail Azure</block>
  <block id="5e89dc82cb54763baa7cece42e7c3189" category="paragraph">Si vous découvrez Azure, vous devez d'abord configurer un environnement de compte Azure. Vous pouvez notamment inscrire votre entreprise à l'utilisation d'Azure Active Directory. La section suivante récapitule ces étapes. Pour plus d'informations, consultez la documentation liée spécifique à Azure.</block>
  <block id="c743c9c56cd6cc2acf874405ef178af3" category="section-title">Créez et utilisez les ressources Azure</block>
  <block id="cc59653114a0ca329e90c87f8de8f2da" category="paragraph">Une fois votre environnement Azure configuré et qu'un compte est créé et associé à un abonnement, vous pouvez vous connecter au portail Azure avec le compte pour créer les ressources nécessaires à l'exécution d'Oracle.</block>
  <block id="4848dfd418cc69fdc8a92da472ac41b8" category="section-title">1. Créez un réseau virtuel ou un réseau virtuel</block>
  <block id="dd587303db328c6fc30f15fbf133eade" category="paragraph">Azure Virtual Network (vnet) est l'élément de base fondamental de votre réseau privé sur Azure. Vnet permet la communication de nombreux types de ressources Azure, notamment les machines virtuelles Azure, avec Internet et les réseaux sur site, en toute sécurité. Avant de provisionner une machine virtuelle Azure, vous devez d'abord configurer un vnet (où une machine virtuelle est déployée).</block>
  <block id="2b9029fce84bbf7056c94e4b86015679" category="inline-link-macro">Créez un réseau virtuel à l'aide du portail Azure</block>
  <block id="698a842fc17e080abbf6b6796628879b" category="paragraph">Voir <block ref="f497c9708f9505977884a23053323735" category="inline-link-macro-rx"></block> Pour créer un vnet.</block>
  <block id="66d98f4e89afee6dc557332b0e9ebe43" category="section-title">2. Créez un compte de stockage NetApp et un pool de capacité pour ANF</block>
  <block id="fecd60b0aedf111caefb4cf98b8d7be5" category="paragraph">Dans ce scénario de déploiement, un système d'exploitation de machine virtuelle Azure est provisionné à l'aide d'un stockage Azure standard, mais les volumes ANF sont provisionnés pour exécuter la base de données Oracle via NFS. Tout d'abord, il faut créer un compte de stockage NetApp et un pool de capacité pour héberger les volumes de stockage.</block>
  <block id="76dc01e3f39d83b88a3d3ad36c338654" category="inline-link-macro">Configurez Azure NetApp Files et créez un volume NFS</block>
  <block id="8a57d5f988c678cd141c2f704e110472" category="paragraph">Voir <block ref="2337ae471c0cc5402cdba65ad3b4dc78" category="inline-link-macro-rx"></block> Pour configurer un pool de capacité ANF.</block>
  <block id="ed39ba49be7769bdf483ae876d88cdff" category="section-title">3. Provisionnement d'Azure VM pour Oracle</block>
  <block id="acb4908e71af4ce0945c90f9039d0fc2" category="paragraph">En fonction du workload, déterminez le type de machine virtuelle Azure dont vous avez besoin, ainsi que la taille du processeur virtuel et de la mémoire RAM à déployer pour Oracle. Depuis la console Azure, cliquez sur l'icône de machine virtuelle pour lancer le workflow de déploiement de machine virtuelle.</block>
  <block id="20d1e12ba2a72916f3917e44ff29b40a" category="list-text">Sur la page VM Azure, cliquez sur *Créer*, puis choisissez *machine virtuelle Azure*.</block>
  <block id="94f088d23454b3c408a17cfff3cb8989" category="inline-image-macro">Cette capture d'écran affiche la liste des machines virtuelles Azure disponibles.</block>
  <block id="e28fc410c2020dcbd93af60f3d700d99" category="paragraph"><block ref="e28fc410c2020dcbd93af60f3d700d99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78ba4b8df4acae5536f056217b16c353" category="list-text">Choisissez l'ID d'abonnement pour le déploiement, puis choisissez le groupe de ressources, la région, le nom d'hôte, l'image de la machine virtuelle, la taille, et la méthode d'authentification. Accédez à la page disque.</block>
  <block id="cbbcba216ab68f94c8fab62d9c907a00" category="inline-image-macro">Cette capture d'écran montre les données saisies pour la page Créer une machine virtuelle.</block>
  <block id="825d4c0973e48f04ab75cc30df85bbdc" category="inline-image-macro">Cette capture d'écran affiche des informations supplémentaires pour la page Créer une machine virtuelle.</block>
  <block id="84982a7e7b9cc89bde9621d68800978e" category="paragraph"><block ref="a493253d19b28a6711494154a3160350" category="inline-image-macro-rx" type="image"></block>
<block ref="81b338659efc8df55ae98546f396c5b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c435f9a03a03e7cff44b06c9efafa31" category="list-text">Choisissez *Premium SSD* pour la redondance locale du système d'exploitation et laissez le disque de données vide car les disques de données sont montés depuis le stockage ANF. Accédez à la page réseau.</block>
  <block id="04faa74bfe9ea34a9831d24d039dc159" category="inline-image-macro">Cette capture d'écran montre les données saisies pour la page Créer des disques de machine virtuelle.</block>
  <block id="2e21daafaa3607d62dda1a3411975b12" category="paragraph"><block ref="2e21daafaa3607d62dda1a3411975b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c5742f2bffff7dd4a50e578bfb093b" category="list-text">Choisissez le vnet et le sous-réseau. Allouez une IP publique pour l'accès à un serveur virtuel externe. Ensuite, accédez à la page gestion.</block>
  <block id="0c0077e9a9d4700a64e70d30e9d110df" category="inline-image-macro">Cette capture d'écran affiche des informations supplémentaires pour la page Créer une machine virtuelle.</block>
  <block id="4aea6dbf72aa0b36bd98ced95acebcbd" category="paragraph"><block ref="4aea6dbf72aa0b36bd98ced95acebcbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5e4bb7568c6e8fb6a1f49aea08e975" category="list-text">Conservez toutes les valeurs par défaut pour la gestion et passez à la page Avancé.</block>
  <block id="45291c6293e8de1084c3b8de71bfe120" category="inline-image-macro">Cette capture d'écran montre les données saisies pour la page Créer une gestion de machine virtuelle.</block>
  <block id="b031dac11379aafec2eb9832f71648ba" category="paragraph"><block ref="b031dac11379aafec2eb9832f71648ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22b5d3beb0289dfe21618d5664538321" category="list-text">Conservez toutes les valeurs par défaut de la page Avancé, sauf si vous avez besoin de personnaliser une machine virtuelle après un déploiement avec des scripts personnalisés. Ensuite, accédez à la page balises.</block>
  <block id="1a911a2f1237ad150a29236bcfe044a0" category="inline-image-macro">Cette capture d'écran montre les données saisies pour la page Créer une machine virtuelle avancée.</block>
  <block id="00d8612fb98dc237476c6ecd9e0f52c9" category="paragraph"><block ref="00d8612fb98dc237476c6ecd9e0f52c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46dfe2059392afeb84a872afb7cd09d5" category="list-text">Ajoutez une balise pour la machine virtuelle si vous le souhaitez. Ensuite, accédez à la page révision + création.</block>
  <block id="85e3843de649be49b63e3b04c6887bcd" category="inline-image-macro">Cette capture d'écran montre les données saisies pour la page Créer une étiquette de machine virtuelle.</block>
  <block id="ddeecdecd575fb71cf4e83d7f09717bc" category="paragraph"><block ref="ddeecdecd575fb71cf4e83d7f09717bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a6346e9ebfe8164361d5e2facffb62" category="list-text">Le flux de travail de déploiement exécute une validation sur la configuration et, si la validation réussit, cliquez sur *Create* pour créer la VM.</block>
  <block id="dec1fd75845506029d8751bb7979c797" category="inline-image-macro">« Cette capture d'écran montre les données saisies pour la page Créer une machine virtuelle de révision et de création ».</block>
  <block id="786b4cd98c208b72f71277850831c1aa" category="paragraph"><block ref="786b4cd98c208b72f71277850831c1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c18c3fe2e695bda0cb8b3e7ecccbdc4e" category="section-title">4. Provisionnement de volumes de base de données ANF pour Oracle</block>
  <block id="f162c2b2b89920293c1f24ac435c520e" category="paragraph">Vous devez créer trois volumes NFS pour un pool de capacité ANF pour les volumes binaires, de données et de journaux Oracle respectivement.</block>
  <block id="09d8c19d5844128b31e1fa195808b215" category="list-text">Dans la console Azure, sous la liste des services Azure, cliquez sur Azure NetApp Files pour ouvrir un workflow de création de volumes. Si vous disposez de plusieurs comptes de stockage ANF, cliquez sur le compte à partir duquel vous souhaitez provisionner des volumes.</block>
  <block id="733cf6b848c8e38a49b4b604225141a5" category="inline-image-macro">Cette capture d'écran présente la page des services Azure avec la fonctionnalité ANF mise en surbrillance.</block>
  <block id="cc553796f259bc80d8c801687c0c1cd0" category="paragraph"><block ref="cc553796f259bc80d8c801687c0c1cd0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8972cd5a80e6e385a27023ce45537a9" category="list-text">Sous votre compte de stockage NetApp, cliquez sur *volumes*, puis sur *Add volume* pour créer de nouveaux volumes Oracle.</block>
  <block id="c8ce9170654447aba6747494e61bf3a2" category="inline-image-macro">Cette capture d'écran affiche l'écran d'accueil d'un compte de stockage NetApp.</block>
  <block id="b0d2d575f2aee1703b6e2896d43b72f9" category="inline-image-macro">Cette capture d'écran montre les volumes disponibles pour le compte de stockage NetApp.</block>
  <block id="3371cc932d04403ab2cd0788634d63e5" category="paragraph"><block ref="7266705f76a6cb3a106c34a6e8dc5540" category="inline-image-macro-rx" type="image"></block>
<block ref="f59831fbf7eaa0d216e8685698d0c55b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbeaec71dc2b8275a14b23283d51cc04" category="list-text">Il est conseillé d'identifier les volumes Oracle dont le nom d'hôte de la machine virtuelle est préfixe, puis le point de montage sur l'hôte, par exemple u01 pour le binaire Oracle, u02 pour les données Oracle et u03 pour le journal Oracle. Choisissez le même vnet pour le volume que pour la machine virtuelle. Cliquez sur *Suivant : Protocole&gt;*.</block>
  <block id="ce4ff1bdb6d954e6967a7c241ff89518" category="inline-image-macro">Écran de création de volume.</block>
  <block id="bacf4983022360caacd6f75352136f59" category="paragraph"><block ref="bacf4983022360caacd6f75352136f59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b50bdcda066df8ed373847c60bc2f546" category="list-text">Choisissez le protocole NFS, ajoutez l'adresse IP de l'hôte Oracle au client autorisé et supprimez la stratégie par défaut qui autorise toutes les adresses IP 0.0.0.0/0. Cliquez ensuite sur *Suivant : balises&gt;*.</block>
  <block id="f8bc211f91c2b350b268959a57418393" category="inline-image-macro">Entrée de protocole sur l'écran de création de volume.</block>
  <block id="8ac138d8c4a217ce018b45be622db1ed" category="paragraph"><block ref="8ac138d8c4a217ce018b45be622db1ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fffcdc9cd5233d4718046c8f6d19c80b" category="list-text">Ajoutez une balise de volume si vous le souhaitez. Cliquez ensuite sur *Revue + Créer&gt;*.</block>
  <block id="05864b350d713935d13966f3c8fcbcd7" category="inline-image-macro">Saisie de balises sur l'écran de création de volume.</block>
  <block id="9bead8568a27fcf83faf41e77f52b246" category="paragraph"><block ref="9bead8568a27fcf83faf41e77f52b246" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e574c0c875926f1fe654026995f3543" category="list-text">Si la validation réussit, cliquez sur *Créer* pour créer le volume.</block>
  <block id="4a585922412f050ac4a7fbcc34a2655b" category="inline-image-macro">Passer en revue et créer l'étape de l'écran de création de volume.</block>
  <block id="e9c713f1ad3a3f0b14801d722fb77f16" category="paragraph"><block ref="e9c713f1ad3a3f0b14801d722fb77f16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d2dbc217706d8bb1248bc209e0ab9da" category="section-title">Installez et configurez Oracle sur Azure VM avec ANF</block>
  <block id="7beaf3d9487c79b7245a1d9ae42d46aa" category="paragraph">L'équipe NetApp a créé de nombreux kits d'automatisation basés sur Ansible afin de vous aider à déployer Oracle sur Azure de façon fluide. Suivez ces étapes pour déployer Oracle sur une machine virtuelle Azure.</block>
  <block id="0c782f45b1de4e6d016eafeeb60d286f" category="section-title">Configurez un contrôleur Ansible</block>
  <block id="58a105c56c05508f7233082bc282a654" category="paragraph">Si vous n'avez pas configuré de contrôleur Ansible, reportez-vous à la section <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block>, Qui contient des instructions détaillées sur la configuration d'un contrôleur Ansible.</block>
  <block id="ce9ef6052d2c6ac4b97c01049ee4ec2b" category="section-title">Kit d'automatisation du déploiement Oracle</block>
  <block id="52eae91ee8ea917bc73df6d9f1792469" category="paragraph">Cloner une copie du kit de déploiement Oracle dans votre répertoire local sous l'ID utilisateur que vous utilisez pour vous connecter au contrôleur Ansible.</block>
  <block id="19cd6e3dfb797a7325548b346dc358f1" category="section-title">Exécuter le kit d'outils avec votre configuration</block>
  <block id="aa98393908153ea46a2cef869e7dd100" category="paragraph">Voir la <block ref="e7ab084e08308da08da1b2dd8151530b" category="inline-link-macro-rx"></block> Pour exécuter le manuel de vente avec l'interface de ligne de commande. Vous pouvez ignorer la partie ONTAP de la configuration des variables dans le fichier global VARS lorsque vous créez des volumes de base de données à partir de la console Azure plutôt que de l'interface de ligne de commande.</block>
  <block id="24e16cc700e2ced028e529370af380e1" category="admonition">Le kit d'outils par défaut déploie Oracle 19c avec RU 19.8. Il peut être facilement adapté à n'importe quel autre niveau de patch avec des modifications mineures de configuration par défaut. Les fichiers journaux actifs par défaut de la base de données d'origine sont également déployés dans le volume de données. Si vous avez besoin de fichiers journaux actifs sur le volume du journal, il doit être déplacé après le déploiement initial. Demandez de l'aide à l'équipe NetApp solution si nécessaire.</block>
  <block id="dd52a71d2066e527d28efdbd46784e07" category="section-title">Configurez l'outil de sauvegarde AzAcSnap pour les snapshots cohérents avec les applications pour Oracle</block>
  <block id="211e60df4f320c617afaa9a96f62758f" category="paragraph">Azure application Snapshot Tool (AzAcSnap) est un outil de ligne de commandes qui protège les données des bases de données tierces en gérant toute l'orchestration requise pour les placer dans un état cohérent avec les applications avant de créer une copie Snapshot de stockage. Il renvoie ensuite ces bases de données à un état opérationnel. NetApp recommande d'installer l'outil sur le serveur de base de données hôte. Voir les procédures d'installation et de configuration suivantes.</block>
  <block id="40390144ce134a2e38bfef9f590f867b" category="section-title">Installer l'outil AzAcSnap</block>
  <block id="c2d834909e264a2f3bf3d3facd27740b" category="inline-link-macro">Le programme d'installation AzArcSnap</block>
  <block id="aed9be57adbc2906c27b7f325e1322aa" category="list-text">Obtenir la version la plus récente du <block ref="696590d44d21e9b71649cae0895a0bca" category="inline-link-macro-rx"></block>.</block>
  <block id="243004130aa732bde904924170fa2e5c" category="list-text">Copiez le programme d'installation automatique téléchargé sur le système cible.</block>
  <block id="1aa45c54511185e4e2043ee91e8969bc" category="list-text">Exécutez le programme d'installation automatique en tant qu'utilisateur racine avec l'option d'installation par défaut. Si nécessaire, rendre le fichier exécutable à l'aide de<block ref="48c01707d676030dd223de543c6beb09" prefix=" " category="inline-code"></block> commande.</block>
  <block id="483944250a0e1f955ad6fec7c6578bde" category="section-title">Configurez la connectivité Oracle</block>
  <block id="b6f7df8a3ada5b45cee3400740b83c9a" category="paragraph">Les outils de snapshot communiquent avec la base de données Oracle et ont besoin d'un utilisateur de base de données disposant des autorisations appropriées pour activer ou désactiver le mode de sauvegarde.</block>
  <block id="6cd11918e51f60b6ce021e9d56c9e74a" category="section-title">1. Configurez l'utilisateur de la base de données AzAcSnap</block>
  <block id="84fe6666ea577b7ede5c61912d97705e" category="paragraph">Les exemples suivants illustrent la configuration de l’utilisateur de la base de données Oracle et l’utilisation de sqlplus pour la communication avec la base de données Oracle. Les commandes exemple configurent un utilisateur (AZACSLAP) dans la base de données Oracle et modifient l'adresse IP, les noms d'utilisateur et les mots de passe selon les besoins.</block>
  <block id="342df2b2fb63c81cdd53e5e7bc5d00b9" category="list-text">À partir de l'installation de la base de données Oracle, lancez sqlplus pour vous connecter à la base de données.</block>
  <block id="ab0840eee4ba613870ae404c907c1948" category="list-text">Créez l'utilisateur.</block>
  <block id="e90b9dc19df07f784e3fc408169077df" category="list-text">Accordez les autorisations utilisateur. Cet exemple définit l'autorisation pour l'utilisateur AZACSLAP de mettre la base de données en mode de sauvegarde.</block>
  <block id="f508d634fc1aa5df7fed84e6b58afce9" category="list-text">Modifier l'expiration du mot de passe de l'utilisateur par défaut sur illimité.</block>
  <block id="bc5fff092e99ce3d1966b94061cb5953" category="list-text">Valider la connectivité azacsnap pour la base de données.</block>
  <block id="8e0d0fb1cb3a50066ecd397700dfd22e" category="section-title">2. Configurez azacsnap Linux-utilisateur pour l'accès à la base de données avec le portefeuille Oracle</block>
  <block id="7140a904f4b795616fdc3c3efbdcd066" category="paragraph">L'installation par défaut d'AzAcSnap crée un utilisateur azacsnap OS. L'environnement Bash Shell doit être configuré pour l'accès à la base de données Oracle avec le mot de passe stocké dans un portefeuille Oracle.</block>
  <block id="c54cf7bb99b0e669ce6dc05ec8272470" category="list-text">En tant qu'utilisateur root, exécutez le<block ref="760381f8107a856bc583301b7b272917" prefix=" " category="inline-code"></block> Commande permettant d'identifier les variables ORACLE_HOME et ORACLE_SID sur l'hôte.</block>
  <block id="2a4941dc3f20c8f34a09b066691e66a5" category="list-text">Ajoutez ORACLE_HOME, ORACLE_SID, TNS_ADMIN et les variables DE CHEMIN au profil bash de l'utilisateur azacsnap. Modifiez les variables selon vos besoins.</block>
  <block id="e3c85fad3d30c470aac355430e98dc21" category="list-text">En tant qu'utilisateur Linux azacsnap, créez le portefeuille. Vous êtes invité à saisir le mot de passe du porte-monnaie.</block>
  <block id="83617bd12022f2dd9ba94816c7e56670" category="list-text">Ajoutez les informations d'identification de la chaîne de connexion à Oracle Wallet. Dans l'exemple de commande suivant, AZACSLAP est le ConnectString à utiliser par AzAcSnap, azacsnap est l'utilisateur Oracle Database, et AzPasswd1 est le mot de passe de la base de données de l'utilisateur Oracle. Vous êtes à nouveau invité à saisir le mot de passe du porte-monnaie.</block>
  <block id="02f08719de6240015b4e67725107792a" category="list-text">Créer le<block ref="9de875b13677cf9b036a438bf9aedf5c" prefix=" " category="inline-code"></block> fichier. Dans l'exemple de commande suivant, L'HÔTE doit être défini sur l'adresse IP de la base de données Oracle et le SID du serveur doit être défini sur le SID de la base de données Oracle.</block>
  <block id="0eec77cc5ed96c42afb08c83ea3f1e3b" category="list-text">Créer le<block ref="0501c2d94325e267bf15055591fb8157" prefix=" " category="inline-code"></block> fichier.</block>
  <block id="cafefcc0e796f3e73bc39de23dfc6b68" category="list-text">Testez l'accès Oracle à l'aide du portefeuille.</block>
  <block id="8bf6bfb76bcf25b5e1bb9c1d4ede3d34" category="paragraph">La sortie attendue de la commande : [azacsnap@acao-ora01 ~]$ sqlplus /@AZACCSNAP en tant que SYSBACKUP</block>
  <block id="9fac4799a7cb503012dac3d131cf3c15" category="paragraph">SQL*plus: Version 19.0.0.0.0 - production le jeu septembre 8 18:02:07 2022 version 19.8.0.0.0</block>
  <block id="54eb020b97d7e8a9f56d67e93754e270" category="section-title">Configurez la connectivité ANF</block>
  <block id="8c9356aaf30e863db064ba22b7d4b204" category="paragraph">Cette section explique comment activer la communication avec Azure NetApp Files (avec une VM).</block>
  <block id="d78964ac0334c0f69ef24aada9864028" category="list-text">Dans une session Azure Cloud Shell, assurez-vous d'être connecté à l'abonnement que vous souhaitez associer par défaut au principal de service.</block>
  <block id="8611ff0fcccf2f05ff0dbde909379c14" category="list-text">Si l'abonnement est incorrect, utilisez la commande suivante :</block>
  <block id="2d66e076b40e24c73ffa7a1704d985db" category="list-text">Créez un service principal en utilisant l'interface de ligne de commandes Azure, comme dans l'exemple suivant :</block>
  <block id="707cc085819c641d15b9ea2b3b13cb53" category="paragraph">Résultat attendu :</block>
  <block id="e8e3af5b539b9415092afd10fc182ff7" category="paragraph">{ "ClientID": "00aa000a-aaaa-0000-00a0-00aa000aaa0a", "clientSecret": "00aa000a-aaaaa-0000-00a0-00aa000aaa0a", "abeineptionId": "00aa000a-aaa0-0000-0000-ingaA0-in00aa00aa00a00a00a-U00a00a00a00a-U00a00a00a00a-U00a00a00a00a00a00a00a", "una00a00a00a00a00a00a00a00a00a <block ref="abe1a2134e98a87862a225c33f62cde4" category="inline-link-rx"></block>, "ResourceManagerEndpointUrl": <block ref="5bbe1c35abcaa8749119f86fe8d12120" category="inline-link-rx"></block>, "ActiveDirectoryGraphResourceId": <block ref="91645ab7f47cce4ce23956a6c4c7df7c" category="inline-link-rx"></block>, "SqlManagementEndpointUrl": <block ref="2ce5923f710fffcd9fdcfffa2d0db664" category="inline-link-rx"></block>, "GalleryEndpointUrl": <block ref="92fb62298a12469265ac683928098931" category="inline-link-rx"></block>, "Gestion EndpointUrl": <block ref="9a3197a885535f07c09e058a5f76aa0c" category="inline-link-rx"></block>}</block>
  <block id="c51a1e8c830ed4f63c489347dbcce1a7" category="list-text">Coupez et collez le contenu de sortie dans un fichier appelé<block ref="b50999884a39c5efe8da46cd87acfeb2" prefix=" " category="inline-code"></block> Stocké dans le répertoire bin de l'utilisateur Linux azacsnap et sécurisez le fichier avec les autorisations système appropriées.</block>
  <block id="211f39ae9cd979a9f01bb800eca0b832" category="admonition">Assurez-vous que le format du fichier JSON est exactement comme décrit ci-dessus, en particulier avec les URL placées en guillemets doubles (").</block>
  <block id="c1f6adfa882cba0dbd256d4909ac588c" category="section-title">Terminez la configuration de l'outil AzAcSnap</block>
  <block id="e0e7b63ff02eb3221940162934949dd0" category="paragraph">Procédez comme suit pour configurer et tester les outils de snapshot. Une fois les tests réussis, vous pouvez effectuer le premier snapshot de stockage cohérent pour les bases de données.</block>
  <block id="fe615094ac9bb468d26149280e3769d7" category="list-text">Passez au compte utilisateur de snapshot.</block>
  <block id="4ef9af49185e683998d060aa71c30e2b" category="list-text">Modifier l'emplacement des commandes.</block>
  <block id="412d274adbc3fc7cb51ab315d7a77f82" category="list-text">Configurer un fichier de détails de sauvegarde de stockage. Cela crée un<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> fichier de configuration.</block>
  <block id="d4c18f094b4959d27f52ee2a9709a6b9" category="paragraph">Résultat attendu avec trois volumes Oracle :</block>
  <block id="849abd2456a4bd2ccddb94a12dfcc37d" category="paragraph">[Azacsnap@acao-ora01 bin]$ azacsnap -c configure --configuration nouveau fichier de configuration Ajouter un commentaire au fichier de configuration (entrée vide pour quitter ajout de commentaires) : Oracle snapshot bkup Ajouter un commentaire au fichier de configuration (entrée vide pour quitter l'ajout de commentaires) : entrez le type de base de données à ajouter, 'hana', 'oracle' ou 'no database' (no exit)</block>
  <block id="fa7ad5b9d050b7a5baa27ffcd8863c42" category="paragraph">==== Ajouter les détails de la base de données Oracle ==== SID de la base de données Oracle (par exemple CDB1) : adresse du serveur de base de données ORATST (nom d'hôte ou adresse IP) : 172.30.137.142 chaîne de connexion Oracle (par exemple /@AZACSLAP) : /@AZACSLNAP</block>
  <block id="44b11046a63da89febd351b4213758cf" category="paragraph">==== Détails du stockage Azure NetApp Files === utilisez-vous Azure NetApp Files pour la base de données ? (y/n) [n] : y -- volumes DE DONNÉES l'application est-elle placée dans un état cohérent avant qu'il ne s'agit de snapshot --- Ajouter une ressource Azure NetApp Files à la section de volume DE DONNÉES de la configuration de la base de données ? (y/n) [n] : y ID de ressource de volume de stockage Azure NetApp Files complet (par exemple /souscriptions/.../resourceGroups/.../baladers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /souscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/Authentication providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u01 ID de fichier principal de service ou de fichier de base de ressources<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> oracle.json Ajouter une ressource Azure NetApp Files à la section Volume DE DONNÉES de la configuration de la base de données ? (y/n) [n] : y ID de ressource de volume de stockage Azure NetApp Files complet (par exemple /souscriptions/.../resourceGroups/.../baladers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /souscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/Authentication providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u02 ID de fichier principal de service ou de fichier de base de ressources<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> oracle.json Ajouter une ressource Azure NetApp Files à la section Volume DE DONNÉES de la configuration de la base de données ? (y/n) [n] : n --- LES AUTRES volumes sont des copies Snapshot immédiatement sans préparer d'application pour snapshot --- Ajouter une ressource Azure NetApp Files à UNE autre section de volume de la configuration de la base de données ? (y/n) [n] : y ID de ressource de volume de stockage Azure NetApp Files complet (par exemple /souscriptions/.../resourceGroups/.../baladers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...): /souscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/Authentication providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u03 ID de fichier principal de service ou de fichier de base de ressources<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> oracle.json Ajouter une ressource Azure NetApp Files à UNE autre section Volume de la configuration de la base de données ? (o/n) [n] : n</block>
  <block id="e16c4d13d5c9c936ac3ca975a729784f" category="paragraph">==== Détails du disque géré Azure === utilisez-vous des disques gérés Azure pour la base de données ? (o/n) [n] : n</block>
  <block id="e5e08e0b27271cd7952c3cd754436294" category="paragraph">===== grande instance Azure (bare Metal) Détails du stockage === utilisez-vous Azure grande instance (bare Metal) pour la base de données ? (o/n) [n] : n</block>
  <block id="cec7485a9812da8e268c6d53917d0776" category="paragraph">Entrez le type de base de données à ajouter, 'hana', 'oracle' ou 'exit' (sans base de données) : exit</block>
  <block id="c63145a4ad8c93cb8bdff88f44cf483b" category="paragraph">Modification de la configuration terminée, écriture de la sortie dans 'azacsnap.json'.</block>
  <block id="72b0a1cda785576a979ca4ee2e3c8c62" category="list-text">En tant qu'utilisateur azacsnap Linux, exécutez la commande azacsnap test pour une sauvegarde Oracle.</block>
  <block id="ce9bfcddebc567805a4fdb6bcdf15515" category="paragraph">[Azacsnap@acao-ora01 bin]$ azacsnap -c test --test oracle --configfile azacsnap.json DÉBUT : processus de test démarré pour Oracle COMMENCE : tests Oracle DB RÉUSSI : connectivité à Oracle DB version 1908000000 FIN : processus de test complet pour Oracle [azacao-ora01 bin]</block>
  <block id="7be23e8f29bfc799fd8fbcdc55fe0e77" category="list-text">Exécutez votre première sauvegarde snapshot.</block>
  <block id="42481f217667e9b11be3ea64c971056a" category="inline-link-macro">Protection de la base de données ensuite.</block>
  <block id="d39c73ea41fa36408b518637e929e754" category="paragraph"><block ref="d39c73ea41fa36408b518637e929e754" category="inline-link-macro-rx"></block></block>
  <block id="87561d435f6cd79a59659b543d2991ca" category="summary">Cette section décrit l'architecture d'une solution de déploiement personnalisé Oracle RDS avec le stockage personnalisé Oracle RDS et FSX ONTAP.</block>
  <block id="312f941d9e8f224f54ae372016e8f35a" category="paragraph">Dans l'environnement, l'instance de calcul Oracle est déployée via une console d'instance AWS EC2. Plusieurs types d'instances EC2 sont disponibles depuis la console. NetApp recommande de déployer un type d'instance EC2 axé sur les bases de données, comme une image m5 Ami avec RedHat Enterprise Linux 8 et jusqu'à 10Gps de bande passante réseau.</block>
  <block id="830579b4d0c33e9e4fa1f11c61cb73a7" category="inline-image-macro">Cette image illustre un exemple d'architecture comprenant le cluster haute disponibilité principal (cluster haute disponibilité de secours, nœuds de gestion) et les nœuds de connexion associés.</block>
  <block id="73793421735093db194ae82163f894b3" category="paragraph"><block ref="73793421735093db194ae82163f894b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d0f7ae75ed6e0e3b522ecc7cac710b" category="paragraph">Un cluster de stockage FSX est conçu avec une double redondance, afin que les clusters de stockage principal et de secours soient déployés dans deux zones de disponibilité différentes. Les volumes de base de données sont répliqués depuis un cluster FSX primaire vers un cluster FSX de secours à un intervalle configurable par l'utilisateur pour tous les volumes binaires, de données et de journaux Oracle.</block>
  <block id="0008c12bed67fcf1f82ece8ff10b5c81" category="paragraph">Cet environnement Oracle haute disponibilité est géré avec un nœud de contrôleur Ansible et un serveur de sauvegarde et un outil d'interface utilisateur SnapCenter. L'installation, la configuration et la réplication Oracle sont automatisées à l'aide des outils PlayBook Ansible. Toute mise à jour du système d'exploitation du noyau de l'instance Oracle EC2 ou de la correction Oracle peut être exécutée en parallèle pour maintenir la synchronisation du système principal et du système de secours. En fait, la configuration initiale de l'automatisation peut être facilement étendue pour exécuter certaines tâches Oracle quotidiennes récurrentes si nécessaire.</block>
  <block id="1332f9ef53fc751a6087660a11f07ba6" category="paragraph"><block ref="1332f9ef53fc751a6087660a11f07ba6" category="inline-link-macro-rx"></block></block>
  <block id="1572d96530c843cddbe2d0a8b47abf8a" category="summary">Ce guide des bonnes pratiques présente une solution pour le déploiement et la protection d'une base de données Oracle sur le stockage de fichiers Azure NetApp et Azure VM.</block>
  <block id="2e0520fcae6cb49914d2308fbaf4e1a8" category="doc">Tr-4954 : déploiement et protection de bases de données Oracle sur Azure NetApp Files</block>
  <block id="7e6f7643afec42d9c47efa933debef3e" category="paragraph">Allen Cao, Niyaz Mohamed, NetApp</block>
  <block id="b2bd5134cf9b573edd93cbfe6ee4559d" category="paragraph">De nombreuses bases de données d'entreprise Oracle stratégiques sont toujours hébergées sur site, et de nombreuses entreprises cherchent à migrer ces bases de données Oracle vers un cloud public. Souvent, ces bases de données Oracle sont axées sur les applications et requièrent donc des configurations spécifiques à l'utilisateur, une fonctionnalité qui n'offre pas de nombreuses offres de cloud public « base de données en tant que service ». Par conséquent, l'environnement actuel de la base de données nécessite une solution de base de données Oracle basée sur le cloud public, conçue à partir d'un service de calcul et de stockage évolutif haute performance capable de répondre à des besoins uniques. Les instances de calcul de machine virtuelle Azure et le service de stockage Azure NetApp Files peuvent être les pièces manquantes dans ce puzzle que vous pouvez exploiter pour créer et migrer des workloads de bases de données Oracle stratégiques vers un cloud public.</block>
  <block id="a58dc8965e4de69beb97a33a5a1935ea" category="paragraph">Les machines virtuelles Azure sont l'un des différents types de ressources informatiques à la demande et évolutives qu'Azure propose. Généralement, vous choisissez une machine virtuelle lorsque vous avez besoin de plus de contrôle sur l'environnement informatique que les autres choix. Azure Virtual machines offre un moyen simple et rapide de créer un ordinateur avec les configurations spécifiques nécessaires pour exécuter votre base de données Oracle, qu'il s'agisse de workloads gourmands en mémoire ou de calcul. Les machines virtuelles d'un réseau virtuel Azure peuvent facilement être connectées au réseau de votre entreprise, par exemple via un tunnel VPN sécurisé.</block>
  <block id="466d154dd31c873c4a2fd7113dc6b818" category="paragraph">Azure NetApp Files est un service Microsoft entièrement géré qui accélère et optimise la sécurité de vos workloads de bases de données dans le cloud. Ils ont été conçus pour répondre aux exigences essentielles de l'exécution de charges de travail haute performance, telles que les bases de données Oracle dans le cloud. Ils fournissent des tiers de performance qui reflètent les exigences de l'éventail réel d'IOPS, la faible latence, la haute disponibilité, la durabilité élevée, la facilité de gestion à grande échelle, sauvegarde, restauration et clonage rapides et efficaces. Ces fonctionnalités sont possibles, car Azure NetApp Files repose sur des systèmes NetApp ONTAP 100 % Flash physiques qui s'exécutent dans l'environnement de data Center Azure. Azure NetApp Files est entièrement intégré aux data centers et au portail Azure. Les clients peuvent utiliser la même interface graphique et les mêmes API pour créer et gérer des fichiers partagés que tous les autres objets Azure. Avec Azure NetApp Files, vous pouvez exploiter toutes les fonctionnalités d'Azure sans risques, coûts, délais supplémentaires et bénéficier de la seule solution de service de fichiers d'entreprise native dans Azure.</block>
  <block id="30106aaa3e986f62cbb327f935569bca" category="inline-link-macro">Les bases de données Oracle sur Microsoft Azure</block>
  <block id="bdb41d103336edebf957f48add0f3554" category="inline-link-macro">Automatisation NetApp</block>
  <block id="c2add34b573ef3798dd7c5b8972c008a" category="paragraph">Décrit en détail comment déployer, configurer et protéger une base de données Oracle avec une machine virtuelle Azure et un service de stockage Azure NetApp Files qui offre performances et durabilité similaires à celles d'un système sur site. Pour obtenir des conseils sur les meilleures pratiques, consultez le document TR-4780 <block ref="43d70d3cb7600babfb5820086b5480b6" category="inline-link-macro-rx"></block>. Plus important encore, NetApp propose également des kits d'automatisation qui automatisent la plupart des tâches requises pour le déploiement, la configuration, la protection des données, la migration et la gestion des charges de travail de vos bases de données Oracle dans le cloud public Azure. Les kits d'automatisation sont disponibles en téléchargement sur le site GitHub public de NetApp : <block ref="1b9adaed0e4ba13a6d8f6edc7ab8f2d8" category="inline-link-macro-rx"></block>.</block>
  <block id="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="paragraph"><block ref="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="inline-link-macro-rx"></block></block>
  <block id="cffc2899d8dda4926e6563cef4e76608" category="summary">Cette section fournit des informations sur les facteurs à prendre en compte lors du déploiement de la base de données Oracle sur le serveur virtuel Azure et le stockage Azure NetApp Files.</block>
  <block id="3cc4738ed2ec2e682ab2002688fa632b" category="paragraph"><block ref="3cc4738ed2ec2e682ab2002688fa632b" category="inline-link-macro-rx"></block></block>
  <block id="1a6a6241c0105da34f664d1e12534598" category="paragraph">Nous décrivons dans les sections ci-après les principales considérations relatives au déploiement d'une base de données Oracle dans le cloud public Azure sur une instance de machine virtuelle Azure avec le stockage Azure NetApp Files.</block>
  <block id="c2b3b1e82aa97a133f0f6bbc12843085" category="section-title">Type et dimensionnement des VM</block>
  <block id="4ca9712a9cd82ea80c8e225977fae1bb" category="inline-link-macro">Tailles des serveurs virtuels dans Azure</block>
  <block id="7c4a17715675ccfa7ce507eea6098318" category="paragraph">Il est important de choisir le type et la taille de VM appropriés pour assurer des performances optimales d'une base de données relationnelle dans un cloud public. Une machine virtuelle Azure propose plusieurs instances de calcul qui peuvent être utilisées pour héberger les workloads de la base de données Oracle. Consultez la documentation Microsoft <block ref="d854faa84ea41d8819c42ca3741a3561" category="inline-link-macro-rx"></block> Pour les différents types de machines virtuelles Azure et leur dimensionnement. En règle générale, NetApp recommande l'utilisation d'une machine virtuelle Azure générique pour le déploiement de bases de données Oracle de petite et moyenne taille. Pour le déploiement de bases de données Oracle plus volumineuses, une machine virtuelle Azure optimisée pour la mémoire est appropriée. Avec l'augmentation de la RAM disponible, une mémoire SGA ou un cache Flash intelligent d'Oracle peut être configuré pour réduire les E/S physiques, ce qui permet d'améliorer les performances de la base de données.</block>
  <block id="84942a15b69259aab0ff7c2620afcaf6" category="inline-link-macro">Tr-4780 : bases de données Oracle sur Microsoft Azure</block>
  <block id="760a7b6c1bd4f6ebab6918d42feb4825" category="paragraph">Azure NetApp Files fonctionne comme un montage NFS associé à une machine virtuelle Azure, qui offre un débit plus élevé et dépasse la limite de débit des serveurs virtuels optimisés pour le stockage par rapport au stockage local. Par conséquent, l'exécution d'Oracle sur Azure NetApp Files pourrait réduire le nombre de cœurs de processeurs Oracle sous licence et les coûts de licence. Voir <block ref="b46cbe9b7b18b9ff8101a014c206465f" category="inline-link-macro-rx"></block>, Section 7 - Comment fonctionne Oracle Licensing ?</block>
  <block id="71b93ac808ac25bb511ebcbb028e32e8" category="paragraph">D'autres facteurs doivent être pris en compte :</block>
  <block id="592bc946b588ad0e83c05f528895bcc8" category="list-text">Choisissez la combinaison de CPU virtuels et de RAM appropriée en fonction des caractéristiques de la charge de travail. Plus la taille de la RAM augmente sur la machine virtuelle, plus le nombre de cœurs de vCPU augmente. Il doit y avoir un équilibre à un moment donné que les frais de licence Oracle sont facturés sur le nombre de cœurs de CPU virtuels.</block>
  <block id="fb9844eb7ee0ff341d6f7066f78918ff" category="list-text">Ajoutez de l'espace d'échange à une machine virtuelle. Le déploiement de machine virtuelle Azure par défaut ne crée pas d'espace d'échange, ce qui n'est pas optimal pour une base de données.</block>
  <block id="81afc696937e3786d5701212de79c536" category="section-title">Performances d'Azure NetApp Files</block>
  <block id="c7bc5faed38f5284386f25a6fc3a5752" category="paragraph">Les volumes Azure NetApp Files sont alloués à partir d'un pool de capacité que le client doit provisionner sur son compte de stockage Azure NetApp Files. Chaque pool de capacité est attribué comme suit :</block>
  <block id="3af20f4cec87eac026d0990a8a3f4169" category="list-text">À un niveau de service qui définit la capacité de performance globale.</block>
  <block id="dd1fb66595c069d1b267fb8ca87e46eb" category="list-text">La capacité de stockage initialement provisionnée ou le Tiering pour ce pool de capacité. Niveau de qualité de service (QoS) qui définit le débit maximal global par espace provisionné.</block>
  <block id="9dc50220b7e70511b5aeebb862346fad" category="paragraph">Le niveau de service et la capacité de stockage initialement provisionnée déterminent le niveau de performance d'un volume de base de données Oracle spécifique.</block>
  <block id="59b8b6b998c3c0fcd2f1b107a68c290a" category="section-title">1. Niveaux de service pour Azure NetApp Files</block>
  <block id="f02ad1a8080bf1b50f8a15cb346ed483" category="paragraph">Azure NetApp Files prend en charge trois niveaux de services : ultra, Premium et Standard.</block>
  <block id="3eec40f71dc46b07f32031c9703968ec" category="list-text">*Stockage Ultra.* ce niveau fournit jusqu'à 128 Mio de débit par Tio de quota de volume attribué.</block>
  <block id="1b0fa75a1e8b815e03fb38f8a90d2a73" category="list-text">*Stockage Premium.* ce niveau fournit jusqu'à 64 Mio de débit par Tio de quota de volume attribué.</block>
  <block id="00792f6ec40d3e2833834d90802a7aa5" category="list-text">*Stockage standard.* ce niveau fournit jusqu'à 16 Mio de débit par Tio de quota de volume attribué.</block>
  <block id="7a720602d11a97fd37964c9979e2f1a5" category="section-title">2. Piscine de capacité et qualité de service</block>
  <block id="36ac84521252c58a4238292bf0c21d92" category="paragraph">Chaque niveau de service désiré est associé à un coût pour la capacité provisionnée et comprend un niveau de qualité de service (QoS) qui définit le débit maximal global pour l'espace provisionné.</block>
  <block id="7a93db9cf06fd65415faf241927e2087" category="paragraph">Par exemple, un pool à capacité unique provisionné de 10 Tio avec le niveau de service Premium fournit un débit global disponible pour tous les volumes de ce pool de capacité de 10 x 64 Mbit/s, soit 640 Mbit/s avec 40,000 (16 000) IOPS ou 80,000 (8 Ko) IOPS.</block>
  <block id="18dc8b2cbfb938a0ba32c141664fba0e" category="paragraph">La taille minimale des pools de capacité est de 4 Tio. Vous pouvez modifier la taille d'un pool de capacité par incréments d'un Tio en réponse aux modifications des besoins de vos charges de travail afin de gérer les besoins et les coûts du stockage.</block>
  <block id="8a26494cf7b0c3c3ca7cd38e89c068eb" category="section-title">3. Calculez le niveau de service à un volume de base de données</block>
  <block id="9ce59559a0b99338ee0bad0c153c961a" category="paragraph">La limite de débit d'un volume de base de données Oracle est déterminée par une combinaison des facteurs suivants : le niveau de service du pool de capacité auquel le volume appartient et le quota attribué au volume.</block>
  <block id="b87e1c6e437216fc2d3719c3dad93cb8" category="paragraph">Le diagramme suivant montre comment la limite de débit d'un volume de base de données Oracle est calculée.</block>
  <block id="1624b6f83446cd1719c94bae28cbbeb7" category="inline-image-macro">Cette image illustre l'équation appliquée aux trois niveaux de capacité afin de déterminer le débit brut.</block>
  <block id="4d06f88a6f007c9821ac2ea5741860c5" category="paragraph"><block ref="4d06f88a6f007c9821ac2ea5741860c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ce3321601c29c87cb29ae9817843b8d" category="paragraph">Dans l'exemple 1, un volume provenant d'un pool de capacité avec le niveau de stockage Premium auquel un quota de 2 Tio est affecté à un débit limité à 128 Mio (2Tio * 64 Mio). Cette scénario s'applique quelle que soit la taille du pool de capacité ou la consommation réelle du volume.</block>
  <block id="69da5d3e48cc26414a9177d843bd55d9" category="paragraph">Dans l'exemple 2, un volume d'un pool de capacité avec un niveau de stockage Premium auquel un quota est affecté 100 Gio est affecté à un débit limité à 6,25 millions (0,09765625Tio * 64MiBps). Cette scénario s'applique quelle que soit la taille du pool de capacité ou la consommation réelle du volume.</block>
  <block id="def2c2ae4fa72ee296eada07b44a0cc9" category="paragraph">La taille minimale du volume est de 100 Gio.</block>
  <block id="78ad659ec79d8ee9e7432271167d18d3" category="list-text">Pour les petites bases de données, utiliser la disposition d'un seul volume pour tous les fichiers Oracle.</block>
  <block id="51672f1f7a65c28f28e5e113376309bd" category="inline-image-macro">Cette image représente trois bases de données (DB1, DB2 et DB3) contenant chacune des fichiers de données, des journaux de reprise, des journaux d'archivage et des fichiers de contrôle, le tout dans un même pool de capacité.</block>
  <block id="6dab61143f0fe37930fbd783e5c57c81" category="paragraph"><block ref="6dab61143f0fe37930fbd783e5c57c81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="816445ad7ba016a8c0be293c985f068b" category="list-text">Pour les bases de données volumineuses, la disposition des volumes recommandée est constituée de plusieurs volumes : un pour les données Oracle et un fichier de contrôle dupliqué, un pour le journal actif Oracle, le journal archivé et le fichier de contrôle. NetApp recommande vivement d'allouer un volume au binaire Oracle plutôt qu'au disque local, de sorte que la base de données puisse être déplacée vers un nouvel hôte et restaurée rapidement.</block>
  <block id="955db4ecf8716abf17a3ea3f8e113671" category="inline-image-macro">Cette image représente deux bases de données avec deux volumes chacun. Le premier volume contient des fichiers de données, tandis que le second volume de chaque base de données contient des journaux de reprise, des journaux d'archivage et des fichiers de contrôle. Le tout dans un pool de capacité unique.</block>
  <block id="7432b939dcc290776a34b2e9610a2775" category="paragraph"><block ref="7432b939dcc290776a34b2e9610a2775" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efeaafaa286e164985a0c325f0727cf1" category="paragraph">Linux, le système d'exploitation le plus courant, comprend des fonctionnalités NFS natives. Oracle propose un client NFS direct (dNFS) intégré de manière native dans Oracle. Oracle dNFS ignore le cache du système d'exploitation et permet un traitement parallèle afin d'améliorer les performances des bases de données. Oracle a pris en charge NFSv3 pendant plus de 20 ans, et NFSv4 est pris en charge par Oracle 12.1.0.2 et versions ultérieures.</block>
  <block id="be5ef2ba2540e077db09ca784b1ac18f" category="paragraph">En utilisant dNFS (disponible depuis Oracle 11g), une base de données Oracle exécutée sur un ordinateur virtuel Azure peut générer beaucoup plus d'E/S que le client NFS natif. Le déploiement automatisé d'Oracle à l'aide du kit d'automatisation NetApp configure automatiquement dNFS sur NFSv3.</block>
  <block id="632bf0b812e05925eff22d7d0a7677c2" category="paragraph">Le schéma suivant présente le banc d'essai SLOB sur Azure NetApp Files avec Oracle dNFS.</block>
  <block id="08826656fd88155bdfaebbb292320e33" category="inline-image-macro">Ce graphique démontre considérablement que dNFS améliore la latence (ms) du fichier séquentiel de la base de données par rapport à KNFS.</block>
  <block id="258bafba486e8ac35578ed4c5fff8ab1" category="paragraph"><block ref="258bafba486e8ac35578ed4c5fff8ab1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24019b0d54b5da3a46b400c6a6dfee77" category="paragraph">Pour des performances optimales, ajustez les paramètres du noyau qui contrôlent les tables d'emplacements TCP sur 128.</block>
  <block id="754e164c2de7ed1f02667d5f74297a0e" category="list-text">Le tableau suivant présente les options de montage NFS recommandées pour une instance unique de Linux NFSv3.</block>
  <block id="fa7abb28d1b83f9ee23d95aff1d3123b" category="inline-image-macro">Ce tableau présente les options de montage NFS détaillées pour les types de fichiers suivants, les fichiers de contrôle, les fichiers de données, les journaux de reprise, ORACLE_HOME, Et ORACLE_BASE.</block>
  <block id="082aad17dee7d03a3d502a422c1a8c53" category="paragraph"><block ref="082aad17dee7d03a3d502a422c1a8c53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b71b592b003a6232eebe484a1736be7a" category="paragraph"><block ref="b71b592b003a6232eebe484a1736be7a" category="inline-link-macro-rx"></block></block>
  <block id="d0dfaca5f0573d672a0f4dc66997c002" category="doc">Gestion de la base de données Oracle EC2 et FSX</block>
  <block id="4020b36b638694a9834cb01b53b25ffe" category="doc">Procédures détaillées de déploiement d'Oracle sur AWS EC2 et FSX</block>
  <block id="d842058c0e8814799a596324a98e5323" category="sidebar">Déploiement de bases de données Oracle sur AWS EC2 et FSX meilleures pratiques</block>
  <block id="879f2366c198b1fc05740657cacebcc1" category="sidebar">Déploiement et protection de bases de données Oracle sur Azure NetApp Files</block>
  <block id="fc305603a3cb90ea71cabdf327aaf437" category="sidebar">Protection des bases de données</block>
  <block id="2ca630161d7251bb59a9e458ddef241c" category="paragraph"><block ref="2ca630161d7251bb59a9e458ddef241c" category="inline-link-macro-rx"></block></block>
  <block id="68a03283d8017637709e60ab77052710" category="paragraph"><block ref="68a03283d8017637709e60ab77052710" category="inline-link-macro-rx"></block></block>
  <block id="fb558936249b78a9b426ac6a575ece20" category="paragraph"><block ref="fb558936249b78a9b426ac6a575ece20" category="inline-link-macro-rx"></block></block>
  <block id="8b742cda768ff35bcc87798d5c8efcf1" category="paragraph"><block ref="8b742cda768ff35bcc87798d5c8efcf1" category="inline-link-macro-rx"></block></block>
  <block id="c6f1106d361e6595d08ff6340c004516" category="paragraph"><block ref="c6f1106d361e6595d08ff6340c004516" category="inline-link-macro-rx"></block></block>
  <block id="3b872d3a96131109e4700e3031e4b158" category="inline-link-macro">NVA-1155 : bases de données Oracle 19c RAC sur FlexPod Datacenter avec Cisco UCS et NetApp AFF A800 over FC</block>
  <block id="202f51b1cd08b9562681a95f87429702" category="paragraph"><block ref="202f51b1cd08b9562681a95f87429702" category="inline-link-macro-rx"></block></block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b46d6d6e100776ecf2985ff50a451beb" category="cell">02/07/2023</block>
  <block id="6e6d4a2ed2ec59b98f8da1da20e890bb" category="cell">Ajout d'un blog : annonce de la disponibilité générale de la prise en charge des datastores NetApp Cloud Volumes Service pour Google Cloud VMware Engine</block>
  <block id="7240c168839eaf56e1bc86326fb29d5b" category="cell">Ajout du rapport TR-4955 : reprise après incident avec FSX pour ONTAP et VMC (AWS VMware Cloud)</block>
  <block id="dd4fe8081ff6ae9c7e9975937aff6576" category="list-text">Azure NetApp Files (ANF) comme datastore NFS supplémentaire</block>
  <block id="b2bf74ba9b2080c50a7214bcabdb670c" category="list-text">Cloud Volumes Service (CVS) comme datastore NFS supplémentaire</block>
  <block id="ef7615d9ff40c00e9893de8051347a72" category="cell">ANF<block ref="11e701f660af04a4005e56e6ac4b1c05" category="inline-link-macro-rx"></block></block>
  <block id="b577d5e5fe684be74c0fcbceb61e27d4" category="cell">CVS<block ref="2bc02f38a6be3889a69283e362618186" category="inline-link-macro-rx"></block></block>
  <block id="d7fe32206230432c446b09e24ab3f41a" category="doc">Tr-4955 : reprise après incident avec FSX pour ONTAP et VMC (AWS VMware Cloud)</block>
  <block id="e99df6551992d3c39b8c5e87ee8a451f" category="paragraph">La reprise d'activité dans le cloud est une solution résiliente et économique de protection des workloads contre les pannes sur site et la corruption des données, par exemple, par ransomware. Avec la technologie NetApp SnapMirror, les charges de travail VMware sur site peuvent être répliquées vers FSX pour ONTAP exécutées dans AWS.</block>
  <block id="c52f53db08961cb5fa061b55ca6812c7" category="paragraph">L'orchestrateur de reprise après incident (DRO, solution avec interface utilisateur) permet de restaurer de manière fluide les workloads répliqués depuis une infrastructure sur site vers FSX pour ONTAP. DRO automatise la restauration depuis le niveau SnapMirror, via l'enregistrement des machines virtuelles vers VMC, en passant par les mappages du réseau directement sur NSX-T. Cette fonction est incluse dans tous les environnements VMC.</block>
  <block id="273c8112241e399eaf04dc840d119fb6" category="image-alt">Ce graphique représente la structure et les interconnexions entre un data Center sur site, une instance SDDC VMware Cloud sur AWS et Amazon FSX pour NetApp ONTAP. Il s'agit notamment de la réplication SnapMirror, du trafic DRaaS Ops, d'Internet ou de connexion directe et de VMware Transit Connect.</block>
  <block id="246c1b44b3a8dc5d7fec2fdc031e49c5" category="section-title">Déploiement et configuration de VMware Cloud sur AWS</block>
  <block id="f828dbeef2a459e165a6fbd33ccf4781" category="paragraph"><block ref="88a970f127e79f2a50f427561bb2a4f6" category="inline-link-macro-rx"></block> Offre une expérience cloud native pour les charges de travail VMware dans l'écosystème AWS. Chaque SDDC (VMware Software-Defined Data Center) s'exécute dans un Amazon Virtual Private Cloud (VPC) et offre une pile VMware complète (y compris vCenter Server), la mise en réseau Software-defined NSX-T, le stockage Software-defined VSAN et un ou plusieurs hôtes ESXi qui fournissent des ressources de calcul et de stockage aux charges de travail. Pour configurer un environnement VMC sur AWS, procédez comme suit <block ref="48c40480356563b3c93ca3177b91e728" category="inline-link-macro-rx"></block>. Un cluster de lampe témoin peut également être utilisé pour la reprise après incident.</block>
  <block id="c3b336e3bd0ee5f4a24fd28ce72d7dea" category="admonition">Dans la version initiale, l'analyseur DRO prend en charge un bloc de feux de pilotage existant. La création d'un SDDC à la demande sera disponible dans une prochaine version.</block>
  <block id="09a69d8335838329a7615e73fa6b1fe0" category="section-title">Provisionnement et configuration de FSX pour ONTAP</block>
  <block id="37973daf609f18c7a64511d10e65453e" category="paragraph">Amazon FSX pour NetApp ONTAP est un service entièrement géré qui offre un stockage de fichiers extrêmement fiable, évolutif, haute performance et riche en fonctionnalités basé sur le système de fichiers populaire NetApp ONTAP. Suivez les étapes à cet effet <block ref="a5f36f80544ed8547e72f1f36fb2285b" category="inline-link-macro-rx"></block> Pour provisionner et configurer FSX pour ONTAP.</block>
  <block id="7f38204cc308b0521e747e38f1cb0062" category="section-title">Déploiement et configuration de SnapMirror vers FSX pour ONTAP</block>
  <block id="4a6b91648345db53156af03bcc00bde8" category="paragraph">L'étape suivante consiste à utiliser NetApp BlueXP et à découvrir le FSX provisionné pour ONTAP sur une instance AWS, ainsi que à répliquer les volumes de datastore souhaités depuis un environnement sur site vers FSX pour ONTAP à la fréquence appropriée et à conserver les copies NetApp Snapshot :</block>
  <block id="6a4903522028d4e4bd24b3880afcf49f" category="image-alt">Ce graphique illustre la carte de relation BlueXP Canvas qui montre les différentes interactions entre les services activés.</block>
  <block id="45568e41c66e2e325c210961987178e7" category="paragraph">Suivez les étapes de ce lien pour configurer BlueXP. Vous pouvez également utiliser l'interface de ligne de commande de NetApp ONTAP pour planifier la réplication en suivant ce lien.</block>
  <block id="07f3fd5642ddcadbf716c250ccf987f0" category="admonition">Une relation SnapMirror est un prérequis qui doit être créée au préalable.</block>
  <block id="8513f47f7075dac35da070dbceb25a2e" category="section-title">Installation de DRO</block>
  <block id="9f8fa80dd85e2409bd0b4495b821f0f3" category="paragraph">Pour commencer avec DRO, utilisez le système d'exploitation Ubuntu sur une instance EC2 ou une machine virtuelle désignée pour vous assurer que vous respectez les conditions préalables. Installez ensuite le package.</block>
  <block id="7bf01cb2204f9dd0fdff029933600264" category="list-text">Vérifiez l'existence d'une connectivité entre le vCenter source et le système de stockage et les systèmes de vCenter source et de destination.</block>
  <block id="4c915967cda97460076cfdb71bc58421" category="list-text">La résolution DNS doit être en place si vous utilisez des noms DNS. Sinon, vous devez utiliser des adresses IP pour vCenter et les systèmes de stockage.</block>
  <block id="3cfe50231d6e1ba1b199fc7421fb72e6" category="list-text">Créez un utilisateur avec des autorisations root. Vous pouvez également utiliser sudo avec une instance EC2.</block>
  <block id="6e968857b32243865ebf039c1facf6cf" category="section-title">Configuration requise pour le système d'exploitation</block>
  <block id="184e93a2064767475a538c600a47eb17" category="list-text">Les packages suivants doivent être installés sur la machine virtuelle de l'agent désigné :</block>
  <block id="1dfe00693fad27f5da719e6aeea58ef6" category="list-text">Docker-composer</block>
  <block id="31b4674ec2f7760117c224c883183141" category="list-text">JQ</block>
  <block id="240f5270a2e18be8a75b0712b343d07a" category="paragraph">Modifiez les autorisations<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block>:<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>.</block>
  <block id="76af5eb969b6b58ab010f271730ae0ee" category="admonition">Le<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> le script exécute toutes les conditions préalables requises.</block>
  <block id="478159949d5b4b537a6ca19613ae98bf" category="section-title">Installez l'emballage</block>
  <block id="54d75811a77a2a9b1526f372bc0a733e" category="list-text">Téléchargez le package d'installation sur la machine virtuelle désignée :</block>
  <block id="97c5338b12461548bb0ceefccd562486" category="admonition">L'agent peut être installé sur site ou dans un VPC AWS.</block>
  <block id="2d2a358ce62dfc056eddea09ea87d1d1" category="list-text">Décompressez le package, exécutez le script de déploiement et saisissez l'adresse IP de l'hôte (par exemple, 10.10.10.10).</block>
  <block id="4e26021fda30753473246136bacc8094" category="list-text">Accédez au répertoire et exécutez le script de déploiement comme suit :</block>
  <block id="f1f49b31dc9a5d88e8029b9d361b9059" category="image-alt">Écran de connexion à Disaster Recovery Orchestrator.</block>
  <block id="7b7ad84593d701138003778be3b6079f" category="section-title">Configuration DRO</block>
  <block id="e9ff74e9030350261c678f0da3a354ee" category="paragraph">Une fois que FSX pour ONTAP et VMC ont été configurés correctement, vous pouvez commencer à configurer DRO pour automatiser la restauration des charges de travail sur site vers VMC à l'aide des copies SnapMirror en lecture seule sur FSX pour ONTAP.</block>
  <block id="0a99b6b57603a6a9f7dc56799a0fdd8e" category="paragraph">NetApp recommande de déployer l'agent DRO dans AWS et de choisir le même VPC où FSX pour ONTAP est déployé (qui peut également être connecté à des pairs), Afin que l'agent DRO puisse communiquer via le réseau avec vos composants sur site ainsi qu'avec les ressources FSX pour ONTAP et VMC.</block>
  <block id="c7c5a0daa14b8062f69791fd594efd37" category="paragraph">La première étape consiste à découvrir et à ajouter les ressources cloud et sur site (vCenter et du stockage) à DRO. Ouvrez DRO dans un navigateur pris en charge et utilisez le nom d'utilisateur et le mot de passe par défaut (admin/admin) et Ajouter des sites. Vous pouvez également ajouter des sites à l'aide de l'option découverte. Ajoutez les plates-formes suivantes :</block>
  <block id="16ee49909b80df9050959890b8f578cb" category="list-text">VCenter sur site</block>
  <block id="e7aed9ec7e7600627310e041dbd517f7" category="list-text">Système de stockage ONTAP</block>
  <block id="e3691c446d2915370eb25cbc68a6521a" category="list-text">VMC vCenter</block>
  <block id="36df1b975561708b246ef1801ea416e5" category="list-text">FSX pour ONTAP</block>
  <block id="c532da281c4c378954b0254be09c051b" category="image-alt">Description temporaire de l'image de marque de réservation.</block>
  <block id="3506b8840bdbadcda795249c636510c4" category="image-alt">Page d'aperçu du site de DRO contenant les sites source et de destination.</block>
  <block id="cf5e0df8cb3adb3df51d336ec0b2211a" category="paragraph">Une fois ajouté, DRO effectue une détection automatique et affiche les machines virtuelles sur lesquelles les répliques SnapMirror correspondantes s'effectuent depuis le stockage source vers FSX pour ONTAP. DRO détecte automatiquement les réseaux et les groupes de ports utilisés par les VM et les remplit.</block>
  <block id="abf7897bce5034c7714d0b7757ccac4c" category="image-alt">Écran de détection automatique contenant 219 machines virtuelles et 10 datastores.</block>
  <block id="8ad855ec9cdd9c029c645af01c256999" category="paragraph">L'étape suivante consiste à regrouper les machines virtuelles requises dans des groupes fonctionnels pour servir de groupes de ressources.</block>
  <block id="cdac0221d4dabd98123be4284952f872" category="section-title">Regroupements de ressources</block>
  <block id="7546309b604714e5c864eef677efcd63" category="paragraph">Une fois les plates-formes ajoutées, vous pouvez regrouper les machines virtuelles que vous souhaitez restaurer dans des groupes de ressources. Les groupes de ressources DRO vous permettent de regrouper un ensemble de VM dépendants en groupes logiques contenant leurs ordres de démarrage, leurs délais de démarrage et les validations d'applications facultatives qui peuvent être exécutées lors de la récupération.</block>
  <block id="265d81bb1af077020a501dcc75af41e1" category="paragraph">Pour commencer à créer des groupes de ressources, procédez comme suit :</block>
  <block id="a226ebee500532f5a9b1a5cbcb1db6d9" category="list-text">Accédez à *groupes de ressources*, puis cliquez sur *Créer un nouveau groupe de ressources*.</block>
  <block id="cfc3c82954c855841a78a216dec1b32b" category="list-text">Sous *Nouveau groupe de ressources*, sélectionnez le site source dans la liste déroulante et cliquez sur *Créer*.</block>
  <block id="c47c9ace957accd98c45c515282fb851" category="list-text">Fournissez *Détails du groupe de ressources* et cliquez sur *Continuer*.</block>
  <block id="5e4c1f12f71cc535b41e76690fd718e3" category="list-text">Sélectionnez les machines virtuelles appropriées à l'aide de l'option de recherche.</block>
  <block id="de5c4b583db3aa4040c8d082ee2d1bcd" category="list-text">Sélectionnez l'ordre de démarrage et le délai de démarrage (s) pour les machines virtuelles sélectionnées. Définissez l'ordre de mise sous tension en sélectionnant chaque VM et en définissant sa priorité. La valeur par défaut est Three pour toutes les machines virtuelles.</block>
  <block id="c32b3a0f06aa80c00476ddcabd88fde1" category="paragraph">Les options sont les suivantes :</block>
  <block id="a89a043e6faeacde759612c6bfa5cc1c" category="paragraph">1 – première machine virtuelle à mettre sous tension 3 – valeur par défaut 5 – dernière machine virtuelle à mettre sous tension</block>
  <block id="84a63bc4997af6ded1933281f4b8babb" category="list-text">Cliquez sur *Créer un groupe de ressources*.</block>
  <block id="0942dfbe3d3b0a1d41f357604f7e9fb2" category="image-alt">Capture d'écran de la liste des groupes de ressources avec deux entrées : test et DemoRG1.</block>
  <block id="a8fc43ecd23ee9eb5e9efa5c60cb20b9" category="section-title">Plans de réplication</block>
  <block id="901831e404573eb9a2cc09f43d42e661" category="paragraph">Vous devez disposer d'un plan de restauration des applications en cas d'incident. Sélectionnez les plates-formes vCenter source et cible dans la liste déroulante et sélectionnez les groupes de ressources à inclure dans ce plan, ainsi que le regroupement de la manière dont les applications doivent être restaurées et mises sous tension (par exemple, contrôleurs de domaine, puis niveau 1, niveau 2, etc.). De tels plans sont parfois appelés des plans de projet. Pour définir le plan de reprise, accédez à l'onglet *Plan de réplication* et cliquez sur *Nouveau Plan de réplication*.</block>
  <block id="f2e437ba3d91f90c4bd8d4b35ce32b78" category="paragraph">Pour commencer à créer un plan de réplication, procédez comme suit :</block>
  <block id="7e2b1b88ae2fef26c3f9f94bc389f0d1" category="list-text">Accédez à *plans de réplication*, puis cliquez sur *Créer un nouveau plan de réplication*.</block>
  <block id="84ef8711a6a318c8bf4b8acfd4f1551c" category="image-alt">Capture d'écran de l'écran du plan de réplication contenant un plan appelé DemoRP.</block>
  <block id="b9493784814dfebf88fc26091f72b601" category="list-text">Sous *Nouveau plan de réplication*, indiquez un nom pour le plan et ajoutez des mappages de reprise en sélectionnant le site source, le serveur vCenter associé, le site de destination et le serveur vCenter associé.</block>
  <block id="88cedf638ed2d7e4779e1c47ee7c5ea1" category="image-alt">Capture d'écran des détails du plan de réplication, y compris le mappage de reprise.</block>
  <block id="d360387ddbca9636208f2b8a948f56b0" category="list-text">Une fois le mappage de restauration terminé, sélectionnez le mappage de cluster.</block>
  <block id="57e1d9c7da09c1484785ce5de748a5a4" category="list-text">Sélectionnez *Détails du groupe de ressources* et cliquez sur *Continuer*.</block>
  <block id="28a5e1b451c50affbe5e71d787ef2818" category="list-text">Définissez l'ordre d'exécution du groupe de ressources. Cette option vous permet de sélectionner la séquence d'opérations lorsqu'il existe plusieurs groupes de ressources.</block>
  <block id="35e931afb6f8f9ea976030c41d20091d" category="list-text">Une fois que vous avez terminé, sélectionnez le mappage réseau au segment approprié. Les segments doivent déjà être configurés dans VMC, sélectionnez donc le segment approprié pour mapper la VM.</block>
  <block id="4279ce58393302704e1d9f4ef8e18ca2" category="list-text">En fonction de la sélection des machines virtuelles, les mappages des datastores sont sélectionnés automatiquement.</block>
  <block id="920e197d79d1f4f66caaef11426066ba" category="admonition">SnapMirror est au niveau du volume. Par conséquent, tous les VM sont répliqués sur la destination de réplication. Veillez à sélectionner toutes les machines virtuelles faisant partie du datastore. Si elles ne sont pas sélectionnées, seules les machines virtuelles qui font partie du plan de réplication sont traitées.</block>
  <block id="76074b4a55fc86674d98cacd953dd720" category="list-text">Sous les détails de la machine virtuelle, vous pouvez éventuellement redimensionner les paramètres de CPU et de RAM de la machine virtuelle. Cette approche peut être très utile pour restaurer de grands environnements sur des clusters cibles plus petits ou pour effectuer des tests de reprise sur incident sans avoir à provisionner une infrastructure physique VMware individuelle. Vous pouvez également modifier l'ordre de démarrage et le délai de démarrage (en secondes) de toutes les machines virtuelles sélectionnées au sein des groupes de ressources. Il existe une option supplémentaire permettant de modifier l'ordre de démarrage si des modifications sont requises de celles sélectionnées lors de la sélection de l'ordre de démarrage du groupe de ressources. Par défaut, l'ordre de démarrage sélectionné lors de la sélection du groupe de ressources est utilisé ; toutefois, les modifications peuvent être effectuées à ce stade.</block>
  <block id="61b06cf38207274281ff2f90f66b49fa" category="list-text">Cliquez sur *Créer un plan de réplication*.</block>
  <block id="8066d08fcf99bee6a3bb8bc060a5d031" category="paragraph">Une fois le plan de réplication créé, l'option de basculement, l'option test-failover ou l'option de migration peuvent être exercées en fonction des exigences. Lors des options de basculement et de test/basculement, la copie Snapshot la plus récente est utilisée ou une copie Snapshot spécifique peut être sélectionnée à partir d'une copie Snapshot instantanée (conformément à la règle de conservation de SnapMirror). L'option instantanée peut être utile si vous êtes confronté à un événement de corruption comme les ransomwares, où les répliques les plus récentes sont déjà compromises ou chiffrées. DRO affiche tous les points disponibles dans le temps. Pour déclencher un basculement ou un basculement de test avec la configuration spécifiée dans le plan de réplication, vous pouvez cliquer sur *basculement* ou *Test basculement*.</block>
  <block id="9f6a9153365f1438c116145bc14ba9a9" category="image-alt">Dans cet écran, vous disposez des détails de l'instantané du volume et vous avez le choix entre utiliser le dernier instantané et choisir un instantané spécifique.</block>
  <block id="45c261be0b43693546955e87bd6ac10f" category="paragraph">Le plan de réplication peut être surveillé dans le menu des tâches :</block>
  <block id="0225a4a711bba4eb595e835ad67356fc" category="image-alt">Le menu des tâches affiche toutes les tâches et options du plan de réplication, et vous permet également de voir les journaux.</block>
  <block id="8d2831d40faa91653285bd44edc3917d" category="paragraph">Après le déclenchement du basculement, les éléments restaurés sont visibles dans le vCenter du VMC (machines virtuelles, réseaux, datastores). Par défaut, les machines virtuelles sont restaurées dans le dossier Workload.</block>
  <block id="d45215d9339daaa38e8c825812d30a02" category="paragraph">Le retour arrière peut être déclenché au niveau du plan de réplication. Dans le cas d'un basculement test, l'option redescendre peut être utilisée pour annuler les modifications et supprimer la relation FlexClone. La restauration liée au basculement est un processus en deux étapes. Sélectionnez le plan de réplication et sélectionnez *Inverser la synchronisation des données*.</block>
  <block id="5f3ce61b7a4ffe23687402e421b81e18" category="image-alt">Capture d'écran de la vue d'ensemble du plan de réplication avec liste déroulante contenant l'option Inverser la synchronisation des données.</block>
  <block id="acd827a33a3e445ce9d2c9d94ff63886" category="paragraph">Une fois cette opération terminée, vous pouvez déclencher un retour arrière pour revenir au site de production d'origine.</block>
  <block id="0c86039a87483290f146f9170e80b40b" category="image-alt">Capture d'écran de la vue d'ensemble du plan de réplication avec la liste déroulante contenant l'option de retour arrière.</block>
  <block id="503c1e37074b31fdcd74fbffb13e3983" category="image-alt">Capture d'écran de la page de résumé DRO avec le site de production d'origine opérationnel.</block>
  <block id="0d95c1c8686951d59b82bdc816a93231" category="paragraph">De NetApp BlueXP, nous pouvons constater que la réplication est défaillante pour les volumes appropriés (ceux qui ont été mappés à VMC comme volumes en lecture-écriture). Pendant le basculement de test, DRO ne mappe pas le volume de destination ou de réplica. Il effectue plutôt une copie FlexClone de l'instance SnapMirror (ou Snapshot) requise et expose l'instance FlexClone, qui ne consomme pas de capacité physique supplémentaire pour FSX pour ONTAP. Ce processus permet de s'assurer que le volume n'est pas modifié et que les tâches de réplication peuvent se poursuivre même pendant les tests de reprise d'activité ou les workflows de triage. En outre, ce processus garantit que, si des erreurs se produisent ou si des données corrompues sont récupérées, la récupération peut être nettoyée sans le risque de destruction de la réplique.</block>
  <block id="648a04436d5621ca9c7c65c66c55cb79" category="section-title">Restauration par ransomware</block>
  <block id="f1d63aa61bd9bd59550523eea84313e8" category="paragraph">Récupérer des données suite à un ransomware peut être une tâche extrêmement fastidieuse. En particulier, il peut être difficile pour les services INFORMATIQUES d'identifier le point de retour sécurisé et, une fois déterminé, de protéger les charges de travail récupérées contre les attaques de réexécution, par exemple, des programmes malveillants en sommeil ou des applications vulnérables.</block>
  <block id="c6ceeada99ad37301b94760e7f4bcab8" category="paragraph">DRO résout ces problèmes en vous permettant de récupérer votre système à partir de n'importe quel point disponible dans le temps. Vous pouvez également restaurer les charges de travail sur des réseaux fonctionnels mais isolés pour que les applications puissent fonctionner et communiquer entre elles à un endroit où elles ne sont pas exposées au trafic du nord du sud. Votre équipe de sécurité dispose ainsi d'un endroit sûr pour mener des analyses et s'assurer qu'il n'y a aucun programme malveillant caché ou en veille.</block>
  <block id="468a6beafe68b7f0e997ea3b22eaf021" category="list-text">Utilisation de la réplication SnapMirror efficace et résiliente.</block>
  <block id="8dc2f1e4e39bbf8b271892846d90aee7" category="list-text">Restauration à tout point dans le temps avec la conservation des copies Snapshot</block>
  <block id="6aaf12643047ec9787cc07db9f7e812a" category="list-text">Automatisation complète de toutes les étapes nécessaires à la restauration de centaines de milliers de machines virtuelles à partir des étapes de validation du stockage, du calcul, du réseau et des applications.</block>
  <block id="3067ce32bcf775ef4562f0900ee04ccf" category="list-text">Restauration de charge de travail avec la technologie ONTAP FlexClone utilisant une méthode qui ne modifie pas le volume répliqué.</block>
  <block id="6359f2b426c28e13cbb7b8382496081c" category="list-text">Évite le risque de corruption des données pour les volumes et les copies Snapshot.</block>
  <block id="cd08b15dd8bc6a19026ca47b4bcd618d" category="list-text">Utilisation potentielle des données de reprise d'activité avec des ressources de cloud computing pour les workflows hors reprise d'activité, comme DevTest, les tests de sécurité, les tests de correctifs ou de mise à niveau, et les tests de résolution de problèmes.</block>
  <block id="7d73fdff5300d11e557be0d55023b8e8" category="list-text">L'optimisation du processeur et de la RAM pour réduire les coûts liés au cloud grâce à la restauration sur des clusters de calcul plus petits.</block>
  <block id="d923ff878d26dac68fc7ac0c94a428f0" category="inline-link-macro">Reprise après sinistre (DRO) avec FSX pour ONTAP et VMC</block>
  <block id="1ecab9e830a635b196a9f6c159eefe2c" category="list-text"><block ref="1ecab9e830a635b196a9f6c159eefe2c" category="inline-link-macro-rx"></block></block>
  <block id="46d1e37416bef4df8c1962b95c983bb0" category="sidebar">GCVE + ESTIMATEUR DU COÛT TOTAL DE POSSESSION CVS</block>
  <block id="15a2a7497ac6041e1b73d7cb41406245" category="doc">Tr-4811 : Architecture de référence NetApp ONTAP ai pour le secteur de la santé : imagerie diagnostique - conception de la solution</block>
  <block id="5c6168ae6047f496e6903dde0fd3033c" category="paragraph"><block ref="5c6168ae6047f496e6903dde0fd3033c" category="inline-link-macro-rx"></block></block>
  <block id="4adfb8f589471885ed2256c4719146a6" category="doc">Tr-4815 : charges de travail d'entraînement des modèles ai et ML : système NetApp AFF A800 et serveur Fujitsu PRIMERGY GX2570 M5</block>
  <block id="d6f6c54736f64c202c28a1736214c268" category="paragraph"><block ref="d6f6c54736f64c202c28a1736214c268" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN : guide de design Quantum StorNext avec les systèmes NetApp E-Series</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="7054aac0ed39fa340a2d8034700f7366" category="doc">NVA-1151-DESIGN : guide de conception de NetApp ONTAP ai avec les systèmes NVIDIA DGX A100</block>
  <block id="c3e7dfc3691f26701d35cccf4caf7151" category="paragraph"><block ref="c3e7dfc3691f26701d35cccf4caf7151" category="inline-link-macro-rx"></block></block>
  <block id="c95fe91ba2d256285401bdabdd666ca7" category="doc">NVA-1151-DEPLOY : NetApp ONTAP ai avec systèmes NVIDIA DGX A100</block>
  <block id="3f8a5951b902f50dcbc39690406ade15" category="paragraph"><block ref="3f8a5951b902f50dcbc39690406ade15" category="inline-link-macro-rx"></block></block>
  <block id="83c4efb371f86415987632c0baa2d086" category="doc">NVA-1156-DESIGN : NetApp EF-Series ai avec les systèmes NVIDIA DGX A100 et BeeGFS</block>
  <block id="2003f72965a4dbc9f31bdaa3da5deaa2" category="paragraph"><block ref="2003f72965a4dbc9f31bdaa3da5deaa2" category="inline-link-macro-rx"></block></block>
  <block id="716c8038f7ef1bc60bc3fe6c036e2d3b" category="doc">Tr-4807 : architecture de référence NetApp ONTAP ai pour les workloads de services financiers - conception de la solution</block>
  <block id="96ac76dbb46fec3f4db7ec194dc52d2a" category="paragraph"><block ref="96ac76dbb46fec3f4db7ec194dc52d2a" category="inline-link-macro-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">Tr-4851 : Data Lake NetApp StorageGRID pour les charges de travail de conduite autonome - conception de solutions</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY : guide de déploiement Quantum StorNext avec les systèmes NetApp E-Series</block>
  <block id="74e37c842f0aa66d129305c85d5f458a" category="paragraph">Ce document explique en détail comment déployer une solution de systèmes de fichiers parallèles StorNext avec les systèmes de stockage NetApp E-Series. Cette solution englobe les baies 100 % Flash NetApp EF280, la baie NVMe 100 % Flash NetApp EF300, la baie NVMe 100 % Flash EF600 de NetApp et le système hybride NetApp E5760. Il offre une caractérisation des performances basée sur le banc d'essai Frametest, un outil largement utilisé pour les tests dans l'industrie des médias et du divertissement.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="837896d23c0eee81106906ab4cef7a6d" category="doc">Tr-4799 : architecture de référence NetApp ONTAP ai pour les workloads de conduite autonome</block>
  <block id="63e3877ed0a830d2fb8beed8fffb2df4" category="paragraph">La gamme NVIDIA DGX est la première plateforme d'intelligence artificielle intégrée au monde conçue spécialement pour l'IA d'entreprise. Les systèmes de stockage NetApp AFF combinent performances optimales et fonctionnalités de pointe pour la gestion des données dans le cloud hybride. NetApp et NVIDIA se sont associés pour créer l'architecture de référence NetApp ONTAP ai, afin de proposer une solution clé en main qui prend en charge les workloads d'IA et de machine learning (ML), tout en offrant des performances et une fiabilité exceptionnelles.</block>
  <block id="873b0fe1ee8adb4c5e6401e2fabf0734" category="paragraph"><block ref="873b0fe1ee8adb4c5e6401e2fabf0734" category="inline-link-macro-rx"></block></block>
  <block id="b7c82ef45da5d640a92ce6fb8fb757b7" category="doc">NVA-1153-DESIGN : NetApp ONTAP ai avec des systèmes NVIDIA DGX A100 et des switchs Ethernet Mellanox Spectrum</block>
  <block id="3dbdc92d258dcfc8f4fb9e2723a77875" category="paragraph"><block ref="3dbdc92d258dcfc8f4fb9e2723a77875" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">Tr-4859 : déploiement d'IBM Spectrum Scale avec stockage NetApp E-Series - installation et validation</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="9892437a073c63ca6232150c28b21c7b" category="doc">NVA-1156-DEPLOY : NetApp EF-Series ai avec systèmes NVIDIA DGX A100 et BeeGFS</block>
  <block id="ac6445146035971ff06dde08fd7cd295" category="paragraph"><block ref="ac6445146035971ff06dde08fd7cd295" category="inline-link-macro-rx"></block></block>
  <block id="9708ffc88c964c7e13b023f7eba9396b" category="doc">NVA-1153-DEPLOY : NetApp ONTAP ai avec systèmes NVIDIA DGX A100 et switchs Ethernet Mellanox Spectrum</block>
  <block id="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="paragraph"><block ref="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="inline-link-macro-rx"></block></block>
  <block id="3c2e1436532e8615aa8fdb7bb7432f80" category="paragraph">Si la base de données Oracle sur site est hébergée sur une baie de stockage ONTAP, il est plus facile de configurer la réplication pour la migration de la base de données à l'aide de la technologie NetApp SnapMirror intégrée au stockage AWS FSX ONTAP. Le processus de migration peut être orchestré à l'aide de la console NetApp BlueXP.</block>
  <block id="ed7c233990ddaa2e7103a9f5b77ee3de" category="list-text">Au moment du basculement, arrêtez l'application principale pour arrêter toutes les transactions. À partir de l'interface CLI Oracle sqlplus, exécutez un commutateur de journalisation en ligne Oracle et autorisez la synchronisation SnapMirror à transférer le dernier journal archivé vers le volume cible.</block>
  <block id="094ef1326e70f1212e06a1b5d65d2922" category="paragraph">La vidéo suivante explique comment migrer une base de données Oracle sur site vers AWS FSX/EC2 à l'aide de la console NetApp BlueXP et de la réplication SnapMirror.</block>
  <block id="0ed0689d68d30d32584025a19c85c9e1" category="inline-link-macro">Migration d'Oracle Database depuis les systèmes sur site vers FSX/EC2 via SnapMirror et BlueXP</block>
  <block id="bb74f90e0bd42cad827c08c3b5a1d1f8" category="paragraph"><block ref="bb74f90e0bd42cad827c08c3b5a1d1f8" category="inline-link-macro-rx"></block></block>
  <block id="e54801d4a4497c3566a98c0ef4ec6f18" category="section-title">Migrez des bases de données Oracle sur site vers AWS FSX/EC2 en utilisant la relocalisation des PDB avec une disponibilité maximale</block>
  <block id="16d584a60d17de3de7cd0dcc0828fee9" category="paragraph">Cette approche convient mieux aux bases de données Oracle qui sont déjà déployées dans le modèle mutualisé PDB/CDB, et le stockage ONTAP n'est pas disponible sur site. La méthode de relocalisation PDB utilise la technologie de clonage à chaud Oracle PDB pour déplacer les PDB entre un CDB source et un CDB cible tout en minimisant les interruptions de service.</block>
  <block id="c5bd16be343bf2e5a3c081284c6c799b" category="paragraph">Tout d'abord, créez un CDB dans AWS FSX/EC2 avec suffisamment de stockage pour héberger des bases de données PDB à migrer depuis des systèmes sur site. Plusieurs PDB sur site peuvent être déplacés un par un.</block>
  <block id="a6c9ea7b4477a21ac635b1db86abae5e" category="list-text">Si la base de données sur site est déployée dans une seule instance plutôt que dans le modèle de boîtier de distribution de données (PDB)/CDB mutualisé, suivez les instructions de la section <block ref="1a6a40cd2cc4844be72d5fbe9fd5f1e6" category="inline-link-macro-rx"></block> Pour convertir l'instance unique en PDB/CDB multi-tenant. Suivez ensuite l'étape suivante pour migrer l'APB converti vers le CDB dans AWS FSX/EC2.</block>
  <block id="92c29ab4b5bfbc6de30e29363bc9aea7" category="inline-link-macro">Migrez des bases de données Oracle sur site vers le cloud avec la relocalisation de l'infrastructure de données</block>
  <block id="522ca40aa0d528d119dec226eb9719b8" category="list-text">Si la base de données sur site est déjà déployée dans le modèle de boîtier de distribution de données (PDB)/CDB mutualisé, suivez les instructions de la section <block ref="02137814e079cdfea8552a492195c829" category="inline-link-macro-rx"></block> pour effectuer la migration.</block>
  <block id="499d7c245aad786a568d21227b5b65d8" category="paragraph">La vidéo suivante montre comment migrer une base de données Oracle (PDB) vers FSX/EC2 à l'aide de la relocalisation PDB avec une disponibilité maximale.</block>
  <block id="c0d2cea4b49d55201605052121b68ca7" category="inline-link-macro">Migrez votre infrastructure de base de données Oracle sur site vers le CDB AWS avec une disponibilité maximale</block>
  <block id="e3d2de69302b3f20931015cece4526e4" category="paragraph"><block ref="5deefe7b3e78f7f08541c2e7b5b56e54" category="inline-link-macro-rx"></block></block>
  <block id="5eae2f4290a9e1f77061f80c6c015bc6" category="admonition">Bien que les instructions des étapes 1 et 2 soient illustrées dans le contexte du cloud public Azure, les procédures sont applicables au cloud AWS sans aucun changement.</block>
  <block id="41099d15ad008ac11d04538ef8e57575" category="paragraph">L'équipe NetApp Solutions Automation propose un kit de migration qui facilite la migration des bases de données Oracle sur site vers le cloud AWS. Utilisez la commande suivante pour télécharger le kit de migration de base de données Oracle pour la relocalisation de PDB.</block>
  <block id="eef7539c8eab25bfe5c089aab85ec418" category="paragraph">Pour en savoir plus sur cette solution et son utilisation, regardez la vidéo de présentation suivante :</block>
  <block id="0df1fe5dfbca17caa87c91ffea49223a" category="inline-link-macro">Modernisez votre base de données Oracle avec le cloud hybride dans AWS et FSX ONTAP, Part1 - cas d'utilisation et architecture de solution</block>
  <block id="adf8d1fc36b4704904a6251fde19535e" category="paragraph"><block ref="bab032e290776958656c886d774a2bf6" category="inline-link-macro-rx"></block></block>
  <block id="3282bd4b5c29b5e9be65469e592bba18" category="doc">Modernisation de votre environnement Microsoft SQL Server</block>
  <block id="b5b095487ccabae138c7872353cadbe6" category="paragraph"><block ref="b5b095487ccabae138c7872353cadbe6" category="inline-link-macro-rx"></block></block>
  <block id="ebcadd0d5b1096e72d18133b1e0e3098" category="doc">Tr-4467 : SAP avec Microsoft SQL Server sur Windows - meilleures pratiques utilisant NetApp clustered Data ONTAP et SnapCenter</block>
  <block id="d90b6dfa1c90883fc207f3309f98b1bf" category="paragraph"><block ref="d90b6dfa1c90883fc207f3309f98b1bf" category="inline-link-macro-rx"></block></block>
  <block id="046c9e52934c311f81497ca664d86a24" category="doc">Tr-4764 : meilleures pratiques pour Microsoft SQL Server avec la gamme NetApp EF-Series</block>
  <block id="730874cec0e792d7ebad5a796a90b3be" category="paragraph"><block ref="730874cec0e792d7ebad5a796a90b3be" category="inline-link-macro-rx"></block></block>
  <block id="ffaaa5a04a78a6ce5d807980dbf83e64" category="paragraph">Ce guide de conception et de déploiement pour les bases de données Oracle 19c RAC sur FlexPod Datacenter avec Cisco UCS et NetApp AFF A800 over FC fournit des détails sur la conception de la solution, ainsi que des processus de déploiement détaillés pour l'hébergement de bases de données Oracle RAC sur la plus récente infrastructure FlexPod Datacenter avec Oracle Linux 8.2 Système d'exploitation et noyau compatible Red Hat.</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">Le rapport TR-4623 décrit l'architecture intégrée de la conception des systèmes NetApp E-Series et Splunk. Optimisé pour l'équilibre du stockage entre nœuds, la fiabilité, la performance, la capacité de stockage et la densité Cette conception utilise le modèle de nœud d'index en cluster Splunk, offrant une plus grande évolutivité et un TCO réduit. En découplant le stockage des ressources de calcul, vous contribuez à l'évolutivité individuelle, ce qui réduit le coût du sur-provisionnement l'un ou l'autre. De plus, ce document récapitule les résultats des tests de performances obtenus avec un outil de simulation d'événements du journal de machine Splunk.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY : charge de travail Apache Spark avec la solution de stockage NetApp</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY décrit la validation des performances et des fonctionnalités d'Apache Spark SQL sur les systèmes de stockage NetApp NFS AFF. Il examine la configuration, l'architecture et les tests de performances en fonction de différents scénarios, ainsi que les recommandations relatives à l'utilisation de Spark avec le logiciel de gestion des données NetApp ONTAP. Il couvre également les résultats des tests d'après une simple concaténation de disques durs (JBOD) et du contrôleur de stockage NetApp AFF A800.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="2eded16d414f6935c27c95495a25eb53" category="cell">01/24/2023</block>
  <block id="d75c9f4acb46fbd1cc7aeecbd376940e" category="cell">Ajout du rapport TR-4954 : déploiement et protection de la base de données Oracle sur Azure NetApp Files</block>
  <block id="f0a30c2a34036665913459cc735f4786" category="doc">Tr-4704 : déploiement de Veritas NetBackup avec le stockage NetApp E-Series</block>
  <block id="7ff53b7713dd7f38a4729f8a1a48f24e" category="paragraph"><block ref="7ff53b7713dd7f38a4729f8a1a48f24e" category="inline-link-macro-rx"></block></block>
  <block id="5e8c99d8eb1f9fde413c715abb6fa392" category="doc">Tr-4320 : NetApp E-Series et CommVault Data Platform V11 - Architecture de référence et meilleures pratiques de stockage</block>
  <block id="b5132c157b5da84909699e1aad5ea13d" category="inline-link-macro">Tr-4320 : NetApp E-Series et CommVault Data Platform V11 - architectures de référence et meilleures pratiques de stockage</block>
  <block id="65c8e697e97b6ce1bd59d8334eaaab6f" category="paragraph"><block ref="65c8e697e97b6ce1bd59d8334eaaab6f" category="inline-link-macro-rx"></block></block>
  <block id="849bdf40e7fa0e2cab1cb845682e6f56" category="doc">Tr-4471 : architecture de référence E-Series et EF-Series, et bonnes pratiques de stockage avec Veeam Backup &amp; Replication 9.5</block>
  <block id="3bad2cd66e539f0136fbf484133914dd" category="paragraph">Le rapport TR-4471 décrit l'architecture de référence et les bonnes pratiques relatives à l'utilisation d'un système de stockage NetApp E-Series dans un environnement Veeam Backup &amp; Replication 9.5.</block>
  <block id="f86686bed105d7053fbb06167a05f38e" category="inline-link-macro">Tr-4471 : architecture de référence pour les systèmes E-Series et EF-Series et bonnes pratiques de stockage dans Veeam Backup &amp;amp ; réplication 9.5</block>
  <block id="8a9473d2b45da95a2d08524f5b182c4d" category="paragraph"><block ref="30941a222a593c860776bbf0831d36d0" category="inline-link-macro-rx"></block></block>
  <block id="97b39392e3b66691f26174f9392c96d0" category="doc">NVA-1143: NetApp HCI - contrôles de sécurité NIST pour FISMA avec infrastructure HyTrust pour les environnements mutualisés - conception et déploiement NVA</block>
  <block id="86e20b04ba1f19de7a30d7843155e285" category="paragraph"><block ref="86e20b04ba1f19de7a30d7843155e285" category="inline-link-macro-rx"></block></block>
  <block id="7c3806f623157e3b19cc1801dd72a85d" category="inline-link-macro">Prise en charge du datastore NetApp Cloud Volumes Service pour Google Cloud VMware Engine (NetApp)</block>
  <block id="5e25da2b2b250c19fcd7efe36b782cc9" category="list-text"><block ref="5e25da2b2b250c19fcd7efe36b782cc9" category="inline-link-macro-rx"></block></block>
  <block id="c540d1dfacf4a64cc435acb640f4cbd4" category="inline-link-macro">Comment utiliser NetApp CVS en tant que data stores pour Google Cloud VMware Engine (Google)</block>
  <block id="4a8385e4a45d508eea692800bf2323d9" category="list-text"><block ref="4a8385e4a45d508eea692800bf2323d9" category="inline-link-macro-rx"></block></block>
  <block id="8031035e3922dbc188f876cc6fb8434d" category="inline-link-macro">Prise en charge du datastore NetApp Cloud Volumes Service pour Google Cloud VMware Engine (blog NetApp)</block>
  <block id="71f1bcf72187cb460ce8534fd5439962" category="inline-link-macro">Comment utiliser NetApp CVS en tant que datastores pour Google Cloud VMware Engine (blog Google)</block>
  <block id="5ca70e1272bcfe0644f6a52e2d971039" category="paragraph">En savoir plus sur <block ref="0d04aae7b3b1a3149a54ebc44d21fc72" category="inline-link-macro-rx"></block> ou <block ref="c1e740ec580b7430a1cc324eec4af172" category="inline-link-macro-rx"></block></block>
  <block id="2284540fd2f120164fbe2ca5d318f1f4" category="sidebar">Annonce supplémentaire de datastore NFS</block>
  <block id="92db868215c2d725770eeb14e1e377e1" category="sidebar">CVS en tant que datastore supplémentaire (blog NetApp)</block>
  <block id="d99ca343caa90da336986677343c31fa" category="sidebar">Options supplémentaires de datastores NFS (blog NetApp)</block>
  <block id="b4fd1d48279ed0bed231fbd3b96a1e3a" category="list-text">Ubuntu 20.04 (LTS) avec au moins 2 Go et 4 CPU virtuels</block>
  <block id="049e44fe327f7679318c6cf222207da7" category="list-text">Pour accéder à l'interface utilisateur, procédez comme suit :</block>
  <block id="b7bd19f19df4ca5ef3102741951e7a1b" category="paragraph">avec les informations d'identification par défaut suivantes :</block>
  <block id="d644796f5eb5712add7807df8829ee58" category="admonition">Le mot de passe peut être modifié à l'aide de l'option « Modifier le mot de passe ».</block>
  <block id="653a98af1c9a004c51b4e7358f06db9a" category="summary">Cette solution fournit des informations détaillées sur le déploiement de bases de données PostgreSQL et la configuration haute disponibilité/reprise après incident, le basculement et les synchronisations basées sur la technologie NetApp SnapMirror intégrée dans l'offre de stockage FSX ONTAP et le kit d'automatisation NetApp Ansible dans AWS.</block>
  <block id="e5f44d648a9d8c4db4e2b580d3370fbf" category="doc">Tr-4956 : déploiement haute disponibilité et reprise après incident PostgreSQL automatisé dans AWS FSX/EC2</block>
  <block id="03784a7c5600d29113972955e602a944" category="inline-link-macro">Moteurs DB</block>
  <block id="1d8f1bdc206db1d9edd9fa46f02aa08c" category="paragraph">PostgreSQL est une base de données open-source largement utilisée qui est classée numéro quatre parmi les dix plus populaires moteurs de base de données par <block ref="6e2d0e5987102894082cbdb135303e4d" category="inline-link-macro-rx"></block>. D'une part, PostgreSQL tire sa popularité de son modèle open-source sans licence tout en conservant des fonctionnalités sophistiquées. D'autre part, comme les données proviennent de sources ouvertes, il existe un manque de conseils détaillés sur le déploiement de bases de données de production dans les domaines de la haute disponibilité et de la reprise après incident, en particulier dans le cloud public. En général, il peut être difficile de configurer un système haute disponibilité/reprise PostgreSQL classique avec des systèmes de secours et à chaud, de réplication en continu, etc. Tester l'environnement de haute disponibilité/reprise après incident en mettant en avant le site de secours, puis en retournant au site primaire peut interrompre la production. Des problèmes de performances sont documentés sur le site principal lorsque des charges de travail de lecture sont déployées sur le streaming à chaud.</block>
  <block id="e2543d0568626be8ab6adad9d9a78652" category="paragraph">Cette solution repose sur la technologie de réplication de stockage NetApp SnapMirror éprouvée et mature, disponible dans le stockage cloud FSX ONTAP natif AWS pour PostgreSQL HA/DR. Il est simple à implémenter grâce à un kit d'automatisation fourni par l'équipe NetApp Solutions. Elles offrent des fonctionnalités similaires, tout en éliminant la complexité et les difficultés liées aux performances sur le site principal grâce à la solution de haute disponibilité/reprise après incident basée sur le streaming au niveau des applications. La solution peut être facilement déployée et testée sans affecter le site principal actif.</block>
  <block id="f67bd3c0833b1d6bf90bb26a55f0a9ce" category="list-text">Profitez d'un déploiement haute disponibilité/reprise après incident pour PostgreSQL dans le cloud public AWS</block>
  <block id="420a5f3809172bb0dc9d501758fe94d2" category="list-text">Test et validation d'une charge de travail PostgreSQL dans le cloud public AWS</block>
  <block id="c9d6a5076f52c5abce5f2003446ab211" category="list-text">Test et validation d'une stratégie haute disponibilité/de reprise après incident PostgreSQL basée sur la technologie de réplication NetApp SnapMirror</block>
  <block id="82aa3e78c2089a2941fb745bb8c72f01" category="paragraph">Cette solution est destinée aux personnes suivantes :</block>
  <block id="4a7bde15fa2753ce507cef621fd789b2" category="list-text">L'administrateur de bases de données qui souhaite déployer PostgreSQL avec la haute disponibilité et la reprise d'activité dans le cloud public AWS.</block>
  <block id="c5e04df584e0992a5dbdae10d89ded97" category="list-text">L'architecte de solution de base de données qui souhaite tester les workloads PostgreSQL dans le cloud public AWS.</block>
  <block id="ba083ee91407315383bac538162833ff" category="list-text">L'administrateur du stockage qui souhaite déployer et gérer des instances PostgreSQL déployées sur le stockage AWS FSX.</block>
  <block id="73ad058c671f3e1e105d92585f5ece7a" category="list-text">Le propriétaire de l'application qui souhaite mettre en place un environnement PostgreSQL dans AWS FSX/EC2.</block>
  <block id="d17a638ff086388dc5bfbe98528ccfab" category="section-title">Environnement de test et de validation de la solution</block>
  <block id="863fb5b3a3b3b63b57a387bab70de0a9" category="paragraph">Le test et la validation de cette solution ont été réalisés dans un environnement AWS FSX et EC2 qui ne correspond pas à l'environnement de déploiement final. Pour plus d'informations, reportez-vous à la section <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>.</block>
  <block id="bfa420253f0a67626a51ce1fa045944c" category="image-alt">Cette image fournit une vue détaillée de l'entreprise de la solution de cloud hybride PostgreSQL, y compris les solutions côté local et le site AWS.</block>
  <block id="34d0b9b49aa480630e91a3619ba7ffb2" category="section-title">Composants matériels et logiciels</block>
  <block id="a09dc18a1bff4fa8388afca4627d0911" category="cell">Stockage ONTAP FSX</block>
  <block id="011fedf4050817b8826f95a53d9555b2" category="cell">Version actuelle</block>
  <block id="0b70cdec9293f5625e5aaae9cdd38526" category="cell">Deux paires haute disponibilité FSX dans le même VPC et la même zone de disponibilité que les clusters haute disponibilité de secours et primaires</block>
  <block id="6a79356b19d3b59e92b358357c5b9053" category="cell">Instance EC2 pour le calcul</block>
  <block id="cc4def82629f09f253176dba801a85f0" category="cell">t2.XLarge/4 vCPU/16 Gbit/s</block>
  <block id="e3d6d4b94f9415561957f8c22f5fea2e" category="cell">Deux instances T2 XLarge d'EC2 en tant qu'instances de calcul principales et de secours</block>
  <block id="3008feb4272787858d4d27f7e8acb08b" category="cell">Contrôleur Ansible</block>
  <block id="26b9568eac10de69d574b84626735921" category="cell">CentOS VM/4 vCPU/8 Go sur site</block>
  <block id="7f151fffe66dad0021b1918085977654" category="cell">Une machine virtuelle pour héberger le contrôleur d'automatisation Ansible, soit sur site, soit dans le cloud</block>
  <block id="8b56d55f3caeb71ab2513c28fb1a52fc" category="cell">Red Hat Linux</block>
  <block id="52359c9653f33c68cd1b454f7d05a27b" category="cell">RHEL-8.6.0_HVM-20220503-x86_64-2-Hourly2-GP2</block>
  <block id="fe6120dacb84838d71b1f43da1a3a514" category="cell">Déploiement de l'abonnement Red Hat pour les tests</block>
  <block id="8003cafa06ec27e11cb235ec9544ef74" category="cell">CentOS Linux</block>
  <block id="04cd32c57cf3229ae9374fc80cd50d96" category="cell">CentOS Linux version 8.2.2004 (cœur)</block>
  <block id="63b6df5ba9d257bb0f6fbda5541d9171" category="cell">Hébergement du contrôleur Ansible déployé dans un laboratoire sur site</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="cell">PostgreSQL</block>
  <block id="a3c20b719830dc5fda947c7b6f3e42be" category="cell">Version 14.5</block>
  <block id="f8c3d3a84c62eb07a1009aacdc46a50f" category="cell">L'automatisation extrait la dernière version disponible de PostgreSQL à partir du postgresql.ora yum repo</block>
  <block id="202351f581b52c61061d29151c81d061" category="cell">Version 2.10.3</block>
  <block id="d222003898249e4a560d569acb0b5563" category="cell">Conditions requises pour les collections et bibliothèques requises installées avec le PlayBook des besoins</block>
  <block id="cd1aedf83959dd52fc058b9120f500e3" category="section-title">Facteurs clés à prendre en compte lors du déploiement</block>
  <block id="b062352f67359ac6729601c60a9a57a2" category="list-text">*Sauvegarde, restauration et récupération de base de données PostgreSQL.* Une base de données PostgreSQL prend en charge plusieurs méthodes de sauvegarde, telles qu'une sauvegarde logique à l'aide de pg_dump, une sauvegarde physique en ligne avec pg_basebackup ou une commande de sauvegarde du système d'exploitation de niveau inférieur, et des instantanés cohérents au niveau du stockage. Cette solution utilise des snapshots de groupes de cohérence NetApp pour les données de base de données PostgreSQL et la sauvegarde, la restauration et la récupération de volumes WAL au site de secours. Les copies Snapshot de volume de groupe de cohérence NetApp séquence les E/S au fur et à mesure de leur écriture sur le stockage et protègent l'intégrité des fichiers de données de base de données.</block>
  <block id="a28c157802547f294e145f164007d752" category="list-text">*Instances de calcul EC2.* dans ces tests et validations, nous avons utilisé le type d'instance AWS EC2 t2.XLarge pour l'instance de calcul de la base de données PostgreSQL. NetApp recommande d'utiliser une instance M5 de type EC2 comme instance de calcul pour PostgreSQL lors du déploiement, car elle est optimisée pour les charges de travail de base de données. L'instance de calcul de secours doit toujours être déployée dans la même zone que le système de fichiers passif (de secours) déployé pour le cluster FSX HA.</block>
  <block id="d7aed04148f8b6ba1b91a7ed84d3fd10" category="list-text">*Clusters HA de stockage FSX déploiement sur une ou plusieurs zones.* lors de ces tests et validations, nous avons déployé un cluster HA FSX dans une zone de disponibilité AWS unique. Pour le déploiement de production, NetApp recommande de déployer une paire haute disponibilité FSX dans deux zones de disponibilité différentes. Si une distance spécifique est requise entre le système principal et la veille, une paire haute disponibilité de secours peut être configurée pour assurer la continuité de l'activité dans une autre région. Un cluster FSX HA est provisionné dans une paire haute disponibilité qui est mise en miroir synchrone dans une paire de systèmes de fichiers actifs-passifs afin d'assurer la redondance au niveau du stockage.</block>
  <block id="c6f1f46bc7e80b73e6d77a7f862e0625" category="list-text">*Données PostgreSQL et placement de journaux.* les déploiements PostgreSQL classiques partagent le même répertoire racine ou les mêmes volumes pour les fichiers de données et de journaux. Lors de nos tests et validations, nous avons séparé les données PostgreSQL et les logs en deux volumes distincts pour les performances. Un lien logiciel est utilisé dans le répertoire de données pour pointer vers le répertoire ou le volume du journal qui héberge les journaux PostgreSQL WAL et les journaux WAL archivés.</block>
  <block id="6e6dddb70c24cf218d0163faa3fb6a8f" category="list-text">*Compteur de délai de démarrage du service PostgreSQL.* cette solution utilise des volumes montés sur NFS pour stocker le fichier de base de données PostgreSQL et les fichiers journaux WAL. Lors du redémarrage d'un hôte de base de données, le service PostgreSQL peut essayer de démarrer pendant que le volume n'est pas monté. Cela entraîne un échec de démarrage du service de base de données. Un délai de temporisation de 10 à 15 secondes est nécessaire pour que la base de données PostgreSQL démarre correctement.</block>
  <block id="ee79ca09fee704e63d972baa3c1319a2" category="list-text">*RPO/RTO pour la continuité de l'activité.* la réplication de données FSX du stockage primaire au mode de secours pour la reprise après incident est basée sur ASYNC, ce qui signifie que l'RPO dépend de la fréquence des sauvegardes Snapshot et de la réplication SnapMirror. Par ailleurs, la fréquence plus élevée de la copie Snapshot et de la réplication SnapMirror réduit le RPO. Il existe donc un équilibre entre perte potentielle de données en cas d'incident et coût de stockage incrémentiel. Nous avons déterminé que la copie Snapshot et la réplication SnapMirror peuvent être implémentées dans des intervalles d'à peine 5 minutes pour le RPO et que PostgreSQL peut être restauré sur le site de secours en moins d'une minute pour le RTO.</block>
  <block id="cbeb123cc0c2c950a65a0c39f8412dc4" category="list-text">*Sauvegarde de la base de données.* après l'implémentation ou la migration d'une base de données PostgreSQL vers un système de stockage FSX AWS à partir d'un centre de données On-Prenail, les données sont automatiquement synchronisées en miroir dans la paire HA FSX pour la protection. En outre, les données sont protégées par un site de secours répliqué en cas d'incident. Pour une protection des données ou une conservation des sauvegardes à plus long terme, NetApp recommande d'utiliser l'utilitaire de sauvegarde PostgreSQL pg_basebackup intégré pour exécuter une sauvegarde complète de base de données qui peut être portée vers le stockage d'objets blob S3.</block>
  <block id="d2598d7d09e212cad1231cd233c5f7dc" category="paragraph">Le déploiement de cette solution peut être réalisé automatiquement à l'aide du kit d'automatisation basé sur NetApp Ansible, en suivant les instructions détaillées ci-dessous.</block>
  <block id="7cfbd2a753781ece3080a48b0a56dad2" category="inline-link-macro">na_postgresql_aws_deploy_hadr</block>
  <block id="fce91619a13ef0fd71e3ffe1da6b5724" category="list-text">Lisez les instructions de la boîte à outils d'automatisation Readme.md <block ref="139722adb31b9bbcb8f923b221d78595" category="inline-link-macro-rx"></block>.</block>
  <block id="9a1c6815d4b1e7dc53acf5a926ab662e" category="list-text">Regardez la vidéo suivante.</block>
  <block id="c73ece4b7be6bb88143afe096ded59aa" category="list-text">Configurez les fichiers de paramètres requis <block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix="(" category="inline-code"></block>,<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block>,<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block>) en saisissant des paramètres spécifiques à l'utilisateur dans le modèle dans les sections correspondantes. Utilisez ensuite le bouton Copy pour copier des fichiers vers l'hôte du contrôleur Ansible.</block>
  <block id="00aaa5ff8fbd0841ab311f7d9b1e4e78" category="section-title">Conditions préalables au déploiement automatisé</block>
  <block id="fd10b9eacfe4eed8040bda8cae9ea050" category="paragraph">Le déploiement nécessite les conditions préalables suivantes.</block>
  <block id="e7491272f69c8efda69a595782f44d45" category="list-text">Un compte AWS a été configuré et les segments de réseau et de VPC nécessaires ont été créés dans votre compte AWS.</block>
  <block id="f71558e9ad22e37a70099d8b5d8ac06c" category="inline-link-macro">Guide de l'utilisateur pour les instances Linux</block>
  <block id="eb03aa8f939650517c1c56a6d0b9ad2f" category="list-text">À partir de la console AWS EC2, vous devez déployer deux instances Linux EC2, une comme serveur DB PostgreSQL principal au niveau du site principal et une instance du site de reprise en veille. Pour assurer la redondance des ressources de calcul sur les sites de reprise après incident principaux et de secours, déployez deux instances Linux EC2 supplémentaires en tant que serveurs DB PostgreSQL de secours. Pour plus d'informations sur la configuration de l'environnement, reportez-vous au diagramme de l'architecture de la section précédente. Consultez également le <block ref="32934851360be4fd00506586c2cbc221" category="inline-link-macro-rx"></block> pour en savoir plus.</block>
  <block id="933d3e5f984811b21da2922f3deb56c4" category="list-text">À partir de la console AWS EC2, déployez deux clusters HA du stockage ONTAP FSX pour héberger les volumes de base de données PostgreSQL. Si vous ne connaissez pas le déploiement du stockage FSX, reportez-vous à la documentation <block ref="d73b8b529985c5c89147bd81cb29dbfb" category="inline-link-macro-rx"></block> pour obtenir des instructions détaillées.</block>
  <block id="7053a216e34d0f83be18a65f22ce62ce" category="list-text">Créez une machine virtuelle CentOS Linux pour héberger le contrôleur Ansible. Le contrôleur Ansible peut être situé sur site ou dans le cloud AWS. S'il est situé sur site, vous devez disposer d'une connectivité SSH avec les clusters de stockage VPC, EC2 Linux et FSX.</block>
  <block id="d1186b859105640e1dc347ae7b714afa" category="list-text">Configurez le contrôleur Ansible comme décrit dans la section « configurez le nœud de contrôle Ansible pour les déploiements CLI sur RHEL/CentOS » à partir de la ressource <block ref="a9149ecc8f33f363a4eae3089d5c6cb7" category="inline-link-macro-rx"></block>.</block>
  <block id="007fa0067fff9abdcd3e5b9ce9f20c06" category="list-text">Clonez une copie du kit d'automatisation à partir du site GitHub public de NetApp.</block>
  <block id="0ca21e6da2c89e765706d9a77f412898" category="list-text">À partir du répertoire racine du kit, exécutez les playbooks requis pour installer les collections et les bibliothèques requises pour le contrôleur Ansible.</block>
  <block id="df40cb16c4a24c991c143fbddeedd0bc" category="list-text">Récupérez les paramètres d'instance FSX EC2 requis pour le fichier de variables hôte DB<block ref="ea858a411f1af6150f14b84176148712" prefix=" " category="inline-code"></block> et le fichier de variables globales<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> configuration.</block>
  <block id="57c7844b0a299340cf9b625ce4a0745a" category="section-title">Configurez le fichier hosts</block>
  <block id="ed578fbfbec5634c4fa508cde5bc4e85" category="paragraph">Saisissez les noms d'hôtes des instances EC2 et IP de gestion de cluster FSX ONTAP primaires dans le fichier hosts.</block>
  <block id="6ef214427ca7b42201d0b0508f56df98" category="section-title">Configurez le fichier host_name.yml dans le dossier Host_var</block>
  <block id="6967d323b85203ba993572c1cd814dc1" category="paragraph">Entrez les paramètres appropriés pour votre système dans les champs en bleu souligné, puis copiez et collez les entrées dans le<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> Fichier dans le contrôleur Ansible<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> dossier.</block>
  <block id="77ac1da2cd356e327eb4bfc4c5a21bcc" category="section-title">Configurez le fichier global fsx_var.yml dans le dossier rva</block>
  <block id="7876ddba2c3af67cbee2b37f64072428" category="paragraph">Entrez les paramètres appropriés pour votre système dans les champs en bleu souligné, puis copiez et collez les entrées dans le<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> Fichier sur l'hôte du contrôleur Ansible.</block>
  <block id="d56625a35762821798a2f3dd55ead05d" category="section-title">Déploiement PostgreSQL et configuration haute disponibilité/reprise après incident</block>
  <block id="943a124028d8f011631df765453640dc" category="paragraph">Les tâches suivantes permettent de déployer le service du serveur de base de données PostgreSQL et d'initialiser la base de données sur le site primaire du serveur de base de données EC2 principal. Un hôte de serveur BDD EC2 principal en veille est ensuite configuré sur le site de secours. Enfin, la réplication du volume de la base de données est configurée depuis le cluster FSX du site principal vers le cluster FSX du site de secours pour la reprise après incident.</block>
  <block id="08f6dd070ef1adfcbe3d7f3c70b08905" category="list-text">Créez des volumes de base de données sur le cluster FSX primaire et configurez postgresql sur l'hôte de l'instance EC2 principale.</block>
  <block id="bf22091495c9a041dcbdba3a97795095" category="list-text">Configurez l'hôte de l'instance EC2 de reprise après incident de secours.</block>
  <block id="f2dd18dfc82378171d01bdd3f956bc6f" category="list-text">Configurer le peering de clusters FSX ONTAP et la réplication du volume de la base de données.</block>
  <block id="d681aef28cf1f863d0683a6896f12995" category="list-text">Consolider les étapes précédentes en une seule étape du déploiement PostgreSQL et de la configuration de la haute disponibilité et de la reprise après incident.</block>
  <block id="fe217a2e30a79cebc71db6d5cb676a71" category="list-text">Pour configurer un hôte DB PostgreSQL de secours sur les sites primaire ou de secours, commentez tous les autres serveurs de la section fichier hosts [dr_postgresql], puis exécutez le PlayBook postgresql_standby_setup.yml avec l'hôte cible respectif (tel que psql_01ps ou l'instance de calcul EC2 de secours sur le site primaire). Assurez-vous qu'un fichier de paramètres hôte tel que<block ref="7c0f59fa275836ef9c4f28bec839acca" prefix=" " category="inline-code"></block> est configuré sous<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> répertoire.</block>
  <block id="d3ecdce9695eacdb90ec80fa276865d4" category="section-title">Sauvegarde et réplication de snapshot de la base de données PostgreSQL vers le site de secours</block>
  <block id="3b320790a7f864b473e3baa86de785fe" category="paragraph">La sauvegarde et la réplication de snapshot de la base de données PostgreSQL vers le site de secours peuvent être contrôlées et exécutées sur le contrôleur Ansible à l'aide d'un intervalle défini par l'utilisateur. Nous avons vérifié que l'intervalle peut aller jusqu'à 5 minutes. Par conséquent, en cas de défaillance sur le site primaire, il y a 5 minutes de perte de données potentielle en cas de défaillance immédiatement avant la prochaine sauvegarde Snapshot planifiée.</block>
  <block id="421057a9fa982de2a1c1f79f5f03d750" category="section-title">Le basculement vers un site de secours pour la reprise après incident</block>
  <block id="6ddcc779c247e4adb5b5a56a34edd75d" category="paragraph">Pour tester le système haute disponibilité/reprise PostgreSQL en tant qu'exercice de reprise après incident, exécutez le basculement et la restauration de base de données PostgreSQL sur l'instance de base de données EC2 principale en attente sur le site en exécutant le manuel de vente suivant. Dans un scénario de reprise d'activité effectivement, exécutez la même opération pour un basculement vers le site de reprise sur incident.</block>
  <block id="724a617bc1dcc9b26fedb732f63a569d" category="section-title">Resynchronisation des volumes de bases de données répliqués après le test de basculement</block>
  <block id="6a08e960bd12a4fcddfd08082fbece4b" category="paragraph">Exécutez la resynchronisation après le test de basculement pour rétablir la réplication SnapMirror volume de bases de données.</block>
  <block id="145966bc8e38b26c384abaf4e450f6a7" category="section-title">Le basculement du serveur BDD EC2 principal vers le serveur DB EC2 de secours en raison d'une défaillance de l'instance de calcul EC2</block>
  <block id="73bc97f640d8c1cae3fa624183216b41" category="inline-link-macro"><block ref="73bc97f640d8c1cae3fa624183216b41" category="inline-link-rx"></block></block>
  <block id="40285fa8e3dc4d66bfadb679f67dfde6" category="paragraph"><block ref="40285fa8e3dc4d66bfadb679f67dfde6" category="inline-link-macro-rx"></block></block>
  <block id="68253b5715937494905ba0cb9db91d2e" category="inline-link-macro"><block ref="be48c1546d351a5e48dcf4f28738754b" category="inline-link-rx"></block></block>
  <block id="6dcfba5adaa9302bd59dd5a601b947a2" category="paragraph"><block ref="95bfcff1050e9160bb2bd645993e8c18" category="inline-link-macro-rx"></block></block>
  <block id="031004dd1775e5fd9d35b534e33217ea" category="paragraph">[Souligné]#*vidéos pour bases de données open source*#</block>
  <block id="5b70a7f45ddd32cacfe28af238662d3d" category="video-title">Déploiement automatisé PostgreSQL, configuration de la réplication haute disponibilité/reprise après incident, basculement, resynchronisation</block>
  <block id="61c8e892dd7e1908020eb0a312fd4bbb" category="cell">02/15/2023</block>
  <block id="2ee6a0567aa163f6ace02183cb041cbd" category="cell">Ajout du déploiement haute disponibilité et de la reprise après incident PostgreSQL dans AWS FSX/EC2</block>
  <block id="a54420e6e0f519f841f4280cf2545365" category="sidebar">Bases de données open source</block>
  <block id="67bb2ef7cf3c5ff59f35f28e513bfda3" category="sidebar">Déploiement haute disponibilité et reprise après incident PostgreSQL dans AWS FSX/EC2</block>
  <block id="1ae3eccde141a365ede8f18b188ae588" category="sidebar">Déploiement HA PostgreSQL automatisé et reprise après incident dans AWS FSX/EC2</block>
  <block id="6fabfc29f0b3a196c8407c190bb67293" category="sidebar">SnapCenter pour les bases de données</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">Cette section décrit les résultats détaillés de la procédure de test.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">Procédure de test et résultats détaillés</block>
  <block id="5a05f12c2c7f8b9ff569496691352e05" category="paragraph"><block ref="5a05f12c2c7f8b9ff569496691352e05" category="inline-link-macro-rx"></block></block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">Entraînement de reconnaissance d'images à l'aide de ResNet dans ONTAP</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">Nous avons exécuté le banc d'essai ResNet50 avec un ou deux serveurs SR670 V2. Ce test a utilisé le conteneur MXNet 22.04-py3 NGC pour effectuer l'entraînement.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">Cette validation a été effectuée à l'aide de la procédure de test suivante :</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">Nous avons effacé le cache de l'hôte avant d'exécuter le script pour nous assurer que les données n'étaient pas déjà mises en cache :</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">Nous avons exécuté le script de test avec le dataset ImageNet sur le stockage serveur (stockage SSD local) ainsi que sur le système de stockage NetApp AFF.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">Nous avons validé les performances du réseau et du stockage local à l'aide du<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> commande.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">Pour l'exécution à un seul nœud, nous avons utilisé la commande suivante :</block>
  <block id="014e128029d9142b6957ca4f1b291090" category="list-text">Pour les exécutions distribuées, nous avons utilisé le modèle de parallélisation du serveur de paramètres. Nous avons utilisé deux serveurs de paramètres par nœud et nous avons fixé le nombre de séries de tests à la même chose que pour l'exécution d'un nœud unique. Nous l'avons fait parce que la formation distribuée prend souvent plus de séries de tests en raison de la synchronisation imparfaite entre les processus. Les différentes séries de tests peuvent fausser les comparaisons entre des cas à un seul nœud et distribués.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">Vitesse de lecture des données : locale ou stockage réseau</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">La vitesse de lecture a été testée à l'aide du<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Commande sur l'un des fichiers pour le dataset ImageNet. Nous avons exécuté les commandes suivantes pour les données locales et réseau :</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">Ces deux valeurs sont similaires. Elles démontrent que le stockage réseau peut fournir des données à un débit similaire au stockage local.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">Cas d'utilisation partagé : plusieurs tâches indépendantes et simultanées</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">Ce test a permis d'évaluer l'utilisation prévue de cette solution : la formation sur l'IA multi-tâche et multi-utilisateurs. Chaque nœud a exécuté sa propre formation en utilisant le stockage réseau partagé. Les résultats s'affichent dans la figure suivante, qui montre que la solution offrait d'excellentes performances pour toutes les tâches exécutées à la même vitesse que les tâches individuelles. Le débit total augmente de façon linéaire en fonction du nombre de nœuds.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">Cette figure illustre l'agrégation d'images par seconde.</block>
  <block id="5224aacbc4b8472eb40ead3ee8856b90" category="paragraph"><block ref="5224aacbc4b8472eb40ead3ee8856b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">Ce figurine montre l'exécution en quelques minutes.</block>
  <block id="8255e8c790967568129f1f898048f1c5" category="paragraph"><block ref="8255e8c790967568129f1f898048f1c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">Ces graphiques présentent un temps d'exécution de quelques minutes. Les images agrégées par seconde pour les nœuds de calcul qui ont utilisé huit GPU de chaque serveur de 100 GbE client, associant le modèle d'entraînement simultané et le modèle d'entraînement unique. La durée d'exécution moyenne du modèle d'entraînement était de 35 minutes et 9 secondes. Les cycles individuels étaient de 34 minutes et 32 secondes, 36 minutes et 21 secondes, 34 minutes et 37 secondes, 35 minutes et 25 secondes, et 34 minutes et 31 secondes. Le modèle d'entraînement comptait en moyenne 22,573 images par seconde et 21,764 images par seconde, 23,438, 22,556, 22,564 et 22,547.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">Sur la base de notre validation, un modèle d'entraînement indépendant avec un temps d'exécution des données NetApp s'est établi à 34 minutes et 54 secondes, avec 22,231 images/s. Un modèle d'entraînement indépendant avec un temps d'exécution des données locales (DAS) était de 34 minutes et 21 secondes avec 22,102 images/s. Lors de ces exécutions, l'utilisation moyenne des GPU était de 96 %, comme observé sur nvidia-smi. Notez que cette moyenne inclut la phase de test, au cours de laquelle les GPU n'ont pas été utilisés, tandis que l'utilisation du CPU a été de 40 % mesurée par mpstat. Cela démontre que le taux de livraison des données est suffisant dans chaque cas.</block>
  <block id="f63534f8e2150e0624ee2af349f77999" category="inline-link-macro">Ensuite, les ajustements d'architecture.</block>
  <block id="92a7087794ac4c23f482ff2db8cf1742" category="paragraph"><block ref="92a7087794ac4c23f482ff2db8cf1742" category="inline-link-macro-rx"></block></block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">La configuration utilisée pour la validation peut être ajustée pour s'adapter à d'autres cas d'utilisation.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">Ajustements d'architecture</block>
  <block id="747bf7dbe4329cb636a09e1a7e4b297b" category="inline-link-macro">Précédent : procédure de test et résultats détaillés.</block>
  <block id="61862ef71b0230e76d56381617d456b0" category="paragraph"><block ref="61862ef71b0230e76d56381617d456b0" category="inline-link-macro-rx"></block></block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">La configuration utilisée pour cette validation peut être ajustée en fonction d'autres cas d'utilisation.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">Réglages du processeur</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Nous avons utilisé un processeur Skylake Intel Xeon Platinum 8360Y pour cette validation, comme recommandé par Lenovo. Nous nous attendons à ce que le processeur Cascade Lake équivalent, un processeur Intel Xeon Gold 6330, offre des performances similaires car cette charge de travail n'est pas liée au processeur.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">Augmentation de la capacité de stockage</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">En fonction de vos besoins en capacité de stockage, vous pouvez augmenter le stockage partagé (volume NFS) à la demande, à condition que vous disposiez des tiroirs disques et des modèles de contrôleurs supplémentaires. Vous pouvez le faire depuis l'interface de ligne de commandes ou l'interface Web de NetApp du contrôleur de stockage en tant qu'utilisateur administrateur.</block>
  <block id="326221403d8b3298094c46f2012726ea" category="paragraph"><block ref="326221403d8b3298094c46f2012726ea" category="inline-link-macro-rx"></block></block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">Dans cette validation, nous avons suivi une formation sur la reconnaissance d'images comme spécifié par MLPerf v2.0. Nous avons plus particulièrement entraîné le modèle ResNet v2.0 avec le dataset ImageNet. La mesure principale est le temps d'atteindre la précision souhaitée. Nous avons également établi des rapports sur la bande passante d'entraînement en images par seconde afin de mieux évaluer l'efficacité évolutive.</block>
  <block id="813c7764ec170fb5498e50560d32a97f" category="paragraph"><block ref="813c7764ec170fb5498e50560d32a97f" category="inline-link-macro-rx"></block></block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">Dans cette validation, nous avons suivi une formation sur la reconnaissance d'images comme spécifié par MLPerf v2.0. Nous avons plus particulièrement entraîné le modèle ResNet v2.0 avec le dataset ImageNet jusqu'à ce que nous soyons parvenus à un niveau de précision de 76.1 %. La mesure principale est le temps d'atteindre la précision souhaitée. Nous avons également établi des rapports sur la bande passante d'entraînement en images par seconde afin de mieux évaluer l'efficacité évolutive.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">Le principal cas d'essai a évalué plusieurs processus de formation indépendants (un par nœud) exécutés simultanément. Cela simule l'utilisation principale, un système partagé utilisé par plusieurs data Scientists. Dans le deuxième cas, l'efficacité du stockage scale-out a été évaluée.</block>
  <block id="e34017da9a1a8d672a4859eb7c75947a" category="paragraph"><block ref="e34017da9a1a8d672a4859eb7c75947a" category="inline-link-macro-rx"></block></block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">Cette solution est axée sur une architecture en clusters d'entrée et de milieu de gamme, dotée de systèmes de stockage NetApp et de serveurs Lenovo optimisés pour les workloads d'intelligence artificielle. Elle s'adresse aux équipes de petite et moyenne taille, pour lesquelles la plupart des tâches de calcul sont à un seul nœud (à un ou plusieurs GPU) ou sont distribuées sur plusieurs nœuds de calcul. Cette limitation n'est pas grave, car la plupart des tâches quotidiennes d'entraînement IA sont effectuées sur un seul nœud.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">Tr-4810 : NetApp AFF A400 avec Lenovo ThinkSystem SR670 V2 pour l'IA et l'entraînement des modèles DE ML</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">Cette solution présente une architecture en cluster de milieu de gamme reposant sur un système de stockage NetApp et des serveurs Lenovo optimisés pour les workloads d'intelligence artificielle (IA). Elle s'adresse aux entreprises de toutes tailles, pour lesquelles la plupart des tâches de calcul sont des nœuds uniques (un ou plusieurs processeurs graphiques) ou distribuées sur quelques nœuds de calcul. Cette solution répond à la plupart des tâches quotidiennes d'entraînement IA de nombreuses entreprises.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">Ce document porte sur le test et la validation d'une configuration de calcul et de stockage composée de huit processeurs graphiques Lenovo SR670V2, d'un système de stockage NetApp AFF A400 de milieu de gamme et d'un commutateur d'interconnexion 100 GbE. Pour mesurer les performances, nous avons utilisé ResNet50 avec le dataset ImageNet, une taille de batchs de 408, une demi-précision, CUDA et cuDNN. Cette architecture offre une solution efficace et économique pour les petites et moyennes entreprises. Il s'agit du premier démarrage des initiatives d'IA qui requièrent les fonctionnalités haute performance du stockage de données NetApp ONTAP connecté au cloud.</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">Data Scientists, ingénieurs de données, administrateurs de données et développeurs de systèmes d'IA</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">Les architectes d'entreprise qui conçoivent des solutions pour le développement des modèles d'IA</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">Data Scientists et ingénieurs de données qui recherchent des méthodes efficaces pour atteindre leurs objectifs de développement du deep learning (DL) et du machine learning (ML)</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">Dirigeants d'entreprise et décideurs IT/d'entreprise qui veulent accélérer le délai de mise sur le marché des initiatives d'IA</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Dotée de serveurs Lenovo ThinkSystem et de NetApp ONTAP avec stockage AFF, cette solution est conçue pour gérer l'entraînement d'IA sur de grands datasets, grâce à la puissance de traitement des processeurs graphiques avec des processeurs classiques. Cette validation démontre les performances élevées et une gestion optimale des données grâce à une architecture scale-out qui utilise un, deux ou quatre serveurs Lenovo SR670 V2 avec un seul système de stockage NetApp AFF A400. La figure suivante fournit une vue d'ensemble de l'architecture.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">Cette image représente un commutateur Ethernet entouré par le serveur de gestion, quatre SR670 V2s avec huit GPU chacun et un système de stockage NetApp ONTAP.</block>
  <block id="d0d5bc4c21e600127e347c093cc29e80" category="paragraph"><block ref="d0d5bc4c21e600127e347c093cc29e80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">Performances très efficaces et économiques lors de l'exécution de plusieurs tâches de formation en parallèle</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">Performances évolutives en fonction du nombre de serveurs Lenovo et de différents modèles de contrôleurs de stockage NetApp</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">Protection fiable des données pour respecter les objectifs de point de récupération (RPO) et de délai de restauration (RTO) faibles, sans perte de données</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">Gestion des données optimisée avec les copies Snapshot et les clones pour rationaliser les workflows de développement</block>
  <block id="c8da2691d0a05080662301b92e048a74" category="paragraph"><block ref="c8da2691d0a05080662301b92e048a74" category="inline-link-macro-rx"></block></block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">Cette section récapitule les résultats des tests effectués pour cette solution.</block>
  <block id="6385fabeefcfa0be0a013cdd61625e31" category="paragraph"><block ref="6385fabeefcfa0be0a013cdd61625e31" category="inline-link-macro-rx"></block></block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">Le tableau suivant récapitule les résultats de tous les tests effectués pour cette solution.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">Description du test</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">Résumé des résultats</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">Formation à la reconnaissance d'images : plusieurs tâches simultanées</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">Efficacité et performance exceptionnelles. Toutes les tâches s'exécutaient à pleine vitesse, même lorsque le cluster était entièrement utilisé. Les systèmes de stockage NetApp ont fourni des performances d'entraînement comparables au stockage SSD local tout en facilitant le partage des données entre les serveurs.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">Formation à la reconnaissance d'images : évolutivité horizontale</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">Efficacité élevée pour un maximum de quatre nœuds. À ce stade, l'évolutivité horizontale était moins efficace, mais tout de même faisable. L'utilisation d'un réseau informatique à vitesse élevée améliore l'évolutivité. Les systèmes de stockage NetApp ont offert des performances d'entraînement comparables au stockage SSD local tout en facilitant le partage des données entre les serveurs.</block>
  <block id="09011e7c7cce04b0b96cec58ace75585" category="paragraph"><block ref="09011e7c7cce04b0b96cec58ace75585" category="inline-link-macro-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SR670 V2 et les détails du provisionnement du stockage.</block>
  <block id="86473a82da3bbf22df039db481fe256f" category="paragraph"><block ref="86473a82da3bbf22df039db481fe256f" category="inline-link-macro-rx"></block></block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">Cette section décrit les configurations testées, l'infrastructure réseau, le serveur SR670 V2 et les détails du provisionnement de stockage NetApp.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">Nous avons utilisé les composants de la solution répertoriés dans le tableau suivant pour cette validation.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">Deux serveurs SR670 V2 équipés chacun de huit cartes graphiques NVIDIA A100 de 80 Go</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">Chaque serveur contient 2 processeurs Intel Xeon Platinum 8360Y (28 cœurs physiques) et 1 To de RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux (Ubuntu – 20.04 avec CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">Système de stockage NetApp AFF (paire HA)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">Le logiciel NetApp ONTAP 9.10.1</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">1 groupe d'interface (ifgrp) par contrôleur, avec quatre adresses IP logiques pour les points de montage</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">Pour cette validation, nous avons utilisé ResNet v2.0 avec le niveau de base ImageNet défini par MLPerf v2.0. Le dataset est stocké dans un système de stockage NetApp AFF avec le protocole NFS. Les SR670 ont été connectés au système de stockage NetApp AFF A400 via un switch de 100 GbE.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNET est un jeu de données d'images fréquemment utilisé. Il contient près de 1.3 millions d'images pour une taille totale de 144 Go. La taille moyenne de l'image est de 108Ko.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">La figure suivante représente la topologie réseau de la configuration testée.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">Ce graphique représente la couche de calcul, un Lenovo ThinkSystem SR670 V2, la couche réseau, un switch Ethernet Lenovo et la couche stockage, un contrôleur de stockage NetApp AFF A400. Toutes les connexions réseau sont incluses.</block>
  <block id="1ee331a29f95ebce1684e5e998f3e70c" category="paragraph"><block ref="1ee331a29f95ebce1684e5e998f3e70c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">Le tableau suivant répertorie la configuration du stockage.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">Taille de l'agrégat</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">Taille du volume</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">Point de montage du système d'exploitation</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9 TO</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TO</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">Le dossier /a400-100g contient le dataset utilisé pour la validation ResNet.</block>
  <block id="1ea4953a2e32bbad1a47dd39cbfe929a" category="inline-link-macro">Suivant : procédure de test et résultats détaillés.</block>
  <block id="b20175407b354f0dfc3a4d6a98917f6f" category="paragraph"><block ref="b20175407b354f0dfc3a4d6a98917f6f" category="inline-link-macro-rx"></block></block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">Cette solution NetApp et Lenovo est une architecture scale-out flexible, idéale pour l'entrée dans les applications d'IA des entreprises de taille moyenne. Les performances du stockage NetApp sont identiques ou supérieures à celles du stockage SSD local et offrent les avantages suivants aux data Scientists, aux ingénieurs de données et aux décideurs IT.</block>
  <block id="632d8fd87d5999301cfd5bd0c0f29b5f" category="inline-link-macro">Précédent : ajustements d'architecture.</block>
  <block id="b145bbef70e5528880cc5abbbe8575cd" category="paragraph"><block ref="b145bbef70e5528880cc5abbbe8575cd" category="inline-link-macro-rx"></block></block>
  <block id="aa91666790d55bdaa993592c884df440" category="paragraph">La solution NetApp et Lenovo validée ici est une architecture scale-out flexible, idéale pour commencer dans les environnements d'IA d'entreprise de taille moyenne. Le stockage NetApp offre des performances identiques ou supérieures à celles du stockage SSD local et offre les avantages suivants aux data Scientists, aux ingénieurs de données et aux décideurs IT :</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">Faire évoluer indépendamment les ressources de calcul et de stockage pour réduire les coûts et améliorer l'utilisation des ressources.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">Rationalisation des workflows de développement et de déploiement à l'aide de snapshots et de clones intégrés, pour des espaces de travail utilisateur instantanés et compacts, un contrôle intégré des versions et un déploiement automatisé.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">Protection des données haute performance pour la reprise après incident et la continuité de l'activité.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, Ingénieur marketing et technique, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, administrateur, ai Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">Page produit sur les baies 100 % Flash de NetApp</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">Page NetApp AFF A400</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">Page produit du logiciel de gestion des données NetApp ONTAP</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="cf2dfa7ef96d78d1f3ec76316e1481d0" category="cell">Février 2020</block>
  <block id="54858f2e7ecb57a17b7c0be2dedfcd7b" category="cell">Version initiale. Validation pour SR670 et AFF A220 avec TensorFlow.</block>
  <block id="abb14d21829ba186172f6e1d0b64b55b" category="cell">Janvier 2023</block>
  <block id="c04468d92a14823a475df983d69e5f9f" category="cell">Version mise à jour. Validation pour SR 670 V2 et AFF A400 avec MXNet.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">Cette section présente plus en détail les principaux composants de cette solution.</block>
  <block id="56cdae354d8e4efeaa936d576b919c49" category="paragraph"><block ref="56cdae354d8e4efeaa936d576b919c49" category="inline-link-macro-rx"></block></block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">Les systèmes de stockage NetApp AFF permettent aux entreprises de répondre aux besoins des entreprises grâce aux meilleures performances du secteur, à la flexibilité supérieure, à l'intégration au cloud et à une excellente gestion des données. Conçues spécifiquement pour les systèmes Flash, les baies AFF contribuent à accélérer, gérer et protéger les données stratégiques.</block>
  <block id="bd06e3e9a11cc16a8f389477f9ed6a95" category="paragraph">Le système NetApp AFF A400 est un système de stockage Flash NVMe de milieu de gamme qui repose sur le matériel FAS2650 et les supports Flash SSD.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">Ce graphique représente l'avant du contrôleur de stockage NetApp AFF A400.</block>
  <block id="55f69aa150e5e2d9b4339594dbb70471" category="paragraph"><block ref="55f69aa150e5e2d9b4339594dbb70471" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">Ce graphique représente l'arrière du contrôleur de stockage NetApp AFF A400.</block>
  <block id="e83035ebe127e618e86974c913d42589" category="paragraph"><block ref="e83035ebe127e618e86974c913d42589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5062a65c6ae4cbe0c015396c4011a811" category="paragraph">Les fonctionnalités du système de stockage de milieu de gamme NetApp AFF A400 sont les suivantes :</block>
  <block id="722f61060a76e673835749dd7040109c" category="list-text">La capacité réelle maximale : 702,7 po</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">Évolutivité scale-out maximale : 2-24 nœuds (12 paires HA)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">Prise en charge des hôtes FC 25 GbE et 16 Gb</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">Connectivité 100 GbE RDMA over Converged Ethernet (RoCE) avec les tiroirs de stockage d'extension NVMe</block>
  <block id="2f5979909b8c4a0d58f13de4881feaf1" category="list-text">Les ports RoCE 100 GbE peuvent être utilisés pour la connexion au réseau hôte si les tiroirs NVMe ne sont pas connectés</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">Tiroirs de stockage d'extension de connectivité SAS de 12 Gbit/s complets</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">Deux configurations disponibles :</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">Ethernet : 4 ports Ethernet 25 Gb (SFP28)</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">Fibre Channel : 4 ports FC 16 Gbit/s (SFP+</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100 % 8 Ko en lecture aléatoire @.4 ms 400 000 IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">Voici les fonctionnalités de NetApp AFF A250 pour les déploiements d'entrée de gamme spécialisés dans l'IA et LE ML :</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">Capacité effective maximale : 35 po</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">Évolutivité scale-out maximale : 2-24 nœuds (12 paires HA)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">Basé sur la dernière version de NetApp ONTAP, ONTAP 9.8 ou version ultérieure</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">Deux ports Ethernet 25 Gb pour la haute disponibilité et l'interconnexion de clusters</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp propose également d'autres systèmes de stockage, tels que les systèmes AFF A800 et AFF A700 qui offrent des performances et une évolutivité supérieures pour les déploiements d'IA/ML à plus grande échelle.</block>
  <block id="b2c0ed3ea756cb47f24ee9aef32e0f01" category="paragraph">ONTAP 9, la dernière génération de logiciel de gestion du stockage de NetApp, permet aux entreprises de moderniser l'infrastructure et de passer à un data Center prêt pour le cloud. Avec des capacités de gestion des données à la pointe du secteur, ONTAP permet de gérer et de protéger les données avec un seul ensemble d'outils, quel que soit leur emplacement. Les données peuvent aussi être déplacées librement partout où elles sont nécessaires : la périphérie, le cœur ou le cloud. ONTAP 9 comprend de nombreuses fonctionnalités qui simplifient la gestion des données, accélèrent et protègent les données stratégiques et pérennisent l'infrastructure sur toutes les architectures de cloud hybride.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">*ONTAP FabricPool* cette fonctionnalité transfère automatiquement les données inactives vers des options de stockage de cloud public et privé, notamment le stockage objet Amazon Web Services (AWS), Azure et NetApp StorageGRID.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">* Performances et latence plus faible.* ONTAP offre le débit le plus élevé possible à la latence la plus faible possible.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 aide à répondre aux besoins métier en constante évolution :</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*Évolutivité transparente et continuité de l'activité.* ONTAP prend en charge l'ajout non disruptif de capacité aux contrôleurs existants et l'évolution scale-out des clusters. Les clients peuvent effectuer la mise à niveau vers les technologies les plus récentes, telles que NVMe et FC 32 Gb, sans migration des données ni panne coûteuse.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*Intégration avec les applications émergentes* ONTAP propose des services de données haute performance pour les plateformes et applications nouvelle génération, telles qu'OpenStack, Hadoop et MongoDB, en utilisant la même infrastructure prenant en charge les applications d'entreprise existantes.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">Volumes NetApp FlexGroup</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">Les datasets d'entraînement sont généralement un ensemble de milliards de fichiers. Les fichiers peuvent inclure du texte, de l'audio, de la vidéo et d'autres formes de données non structurées qui doivent être stockées et traitées pour être lues en parallèle. Le système de stockage doit stocker de petits fichiers et doit lire ces fichiers en parallèle pour les E/S séquentielles et aléatoires</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">Un volume FlexGroup (la figure suivante) est un namespace unique composé de plusieurs volumes de membres constitutifs qui est géré et agit comme un volume NetApp FlexVol pour les administrateurs de stockage. Les fichiers du volume FlexGroup sont alloués aux volumes de membres individuels,et non répartis entre les volumes ou les nœuds. Ils présentent de nombreux atouts :</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">Jusqu'à 20 pétaoctets de capacité et faible latence prévisible pour les charges de travail comportant un grand nombre de métadonnées</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">Jusqu'à 400 milliards de fichiers dans le même espace de nom</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">Opérations parallélisées dans les charges de travail NAS sur les processeurs, les nœuds, les agrégats et les volumes FlexVol constitutifs</block>
  <block id="19adba666d12642fc956c8a4c4607a66" category="inline-image-macro">« Cette image représente une paire haute disponibilité de contrôleurs de stockage qui contient de nombreux volumes contenant les fichiers principaux au sein d'une FlexGroup.</block>
  <block id="67243c21916276b166b8cad21f937c57" category="paragraph"><block ref="3998ac0cd0b54d5528002049c9fb6e1f" category="inline-image-macro-rx" type="image"></block>«</block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Gamme Lenovo ThinkSystem</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Les principaux avantages du déploiement des serveurs Lenovo ThinkSystem sont les suivants :</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">Des conceptions modulaires extrêmement évolutives qui s'étendent à votre activité</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">Dans le domaine de l'IA, Lenovo propose une approche pratique pour aider les entreprises à comprendre et à exploiter les avantages DU ML et de l'IA pour leurs workloads. Les clients Lenovo peuvent explorer et évaluer les offres d'IA de Lenovo dans les centres d'innovation d'IA de Lenovo afin de connaître pleinement la valeur de leur utilisation. Pour améliorer le retour sur investissement, cette approche axée sur le client propose des démonstrations de faisabilité pour les plateformes de développement de solutions prêtes à l'emploi et optimisées pour l'IA.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Le serveur rack Lenovo ThinkSystem SR670 V2 offre des performances optimales pour l'IA accélérée et le calcul haute performance (HPC). Prenant en charge jusqu'à huit GPU, la SR670 V2 est parfaitement adaptée aux exigences de charges de travail de calcul intensives du ML, du DL et de l'inférence.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">Cette image représente trois configurations SR670. La première montre quatre GPU SXM avec huit disques HS de 2.5 pouces et 2 emplacements d'E/S PCIe. La seconde montre quatre emplacements GPU double largeur ou huit emplacements GPU simples larges et deux emplacements d'E/S PCIe avec huit disques HS de 2.5 ou quatre disques HS de 3.5 pouces. La troisième montre huit emplacements GPU double largeur avec six disques EDSFF HS et deux emplacements d'E/S PCIe.</block>
  <block id="f3ebf0cd9319acd4d10b09be0d9220c2" category="paragraph"><block ref="f3ebf0cd9319acd4d10b09be0d9220c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">Avec les derniers processeurs Intel Xeon évolutifs prenant en charge les processeurs graphiques haut de gamme (notamment le processeur graphique NVIDIA A100 80 Go PCIe 8x), le ThinkSystem SR670 V2 offre des performances optimisées et accélérées pour les workloads d'IA et d'HPC.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">En effet, la densité des GPU est plus élevée parce qu'un plus grand nombre de charges de travail utilisent des accélérateurs de performances. Les secteurs tels que le Retail, les services financiers, l'énergie et le domaine de la santé utilisent des GPU pour extraire des informations exploitables et stimuler l'innovation avec des techniques DE ML, d'apprentissage profond et d'inférence.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">Le ThinkSystem SR670 V2 est une solution optimisée pour le déploiement de charges de travail HPC et ai accélérées en production. Il optimise ainsi les performances du système tout en maintenant la densité du data Center pour les clusters de supercalculateurs dotés de plateformes nouvelle génération.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">Voici quelques-unes des autres fonctionnalités :</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">Prise en charge des E/S RDMA directes au niveau des GPU, dans lesquelles les adaptateurs réseau ultra-rapides sont directement connectés aux GPU afin d'optimiser les performances d'E/S.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">La prise en charge du stockage direct par processeur graphique dans lequel les disques NVMe sont directement connectés aux processeurs graphiques pour optimiser les performances du stockage.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf est une suite de banc d'essai leader du secteur pour évaluer les performances de l'IA. Lors de cette validation, nous avons utilisé son banc d'essai de classification des images avec MXNet, l'un des frameworks d'IA les plus répandus. Le script d'entraînement MXNet_bancs d'essai a été utilisé pour entraîner l'entraînement à l'IA. Le script contient des implémentations de plusieurs modèles classiques courants et est conçu pour être aussi rapide que possible. Il peut être exécuté sur une seule machine ou en mode distribué sur plusieurs hôtes.</block>
  <block id="a29118c3c40b6309f6b6354a52631e91" category="paragraph"><block ref="a29118c3c40b6309f6b6354a52631e91" category="inline-link-macro-rx"></block></block>
  <block id="f0cbafc85a7a8d2836dd3a3d51266f61" category="sidebar">NetApp AFF A400 avec Lenovo ThinkSystem SR670 V2 pour l'IA et l'entraînement des modèles DE ML</block>
  <block id="3ba3cda3d91af072810327bfd691205c" category="paragraph">Dans cette documentation, nous vous montrerons comment passer à la solution haute disponibilité et de reprise en continu PostgreSQL au niveau de l'application, et créer une solution haute disponibilité/reprise après incident PostgreSQL basée sur le stockage ONTAP AWS FSX et les instances de calcul EC2 en utilisant la réplication au niveau du stockage. La solution crée un système plus simple et comparable et offre des résultats équivalents lorsque l'on compare la réplication de streaming PostgreSQL classique au niveau applicatif pour la haute disponibilité et la reprise après incident.</block>
  <block id="32d16eeba786f125b3c1e4750ad34e08" category="paragraph">NetApp recommande d'exécuter un basculement manuel ou un logiciel de cluster OS bien établi pouvant nécessiter une licence.</block>
  <block id="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-macro"><block ref="0a6f7f4424be62bd8f9208328496eeaf" category="inline-link-rx"></block></block>
  <block id="b898d8d538a4529dfdb2b8bf025323c2" category="paragraph"><block ref="b898d8d538a4529dfdb2b8bf025323c2" category="inline-link-macro-rx"></block></block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Satish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="c12ff13215c1f6de4c6dad4b8a475398" category="paragraph">[Souligné]#*vidéos pour base de données SQL Server*#</block>
  <block id="b4aaa3fbc0d85cfa527c7cb7f59187fd" category="video-title">Déploiement de SQL Server sur AWS EC2 à l'aide d'Amazon FSX pour NetApp ONTAP</block>
  <block id="785e5e204bcb101e73976a8c3ad22887" category="paragraph">Pour en savoir plus sur ce processus, regardez la vidéo suivante :</block>
  <block id="c91dcf7c665570f3603fa32cb3a8c644" category="list-text">Utilisez le Tier Premium ou standard pour les charges de travail dépendantes de la capacité et le Tier Ultra pour les charges de travail exigeant des performances limitées tout en complétant le stockage VSAN par défaut.</block>
  <block id="60ce6ba5fcd445684c9982883f234b8c" category="paragraph">Pour en savoir plus sur les performances de volume Azure NetApp Files par taille ou quota, reportez-vous à la section <block ref="62d66f64400ed6e4ba5e012bbe140a31" category="inline-link-macro-rx"></block>.</block>
  <block id="a01ca5d7b443422e0bc655c4d457707f" category="inline-link-macro">Lien Microsoft</block>
  <block id="37028a2422f1f35ed56a07f1003896d1" category="admonition">Un volume Azure NetApp Files peut être connecté à votre cloud privé à l'aide du portail Azure. Suivez ceci <block ref="c627cf01abf17d7b29d4322a9f16e21d" category="inline-link-macro-rx"></block> Pour monter un datastore Azure NetApp Files étape par étape via l'utilisation du portail Azure.</block>
  <block id="7dfe1e95238cceec93165ab8ff605d28" category="paragraph">Se reporter à ceci <block ref="06f6144b70bdd3c5a376672271533656" category="inline-link-macro-rx"></block> pour obtenir des bancs d'essai de performances détaillés et utilisables lors d'un exercice de dimensionnement.</block>
  <block id="b1404b6b3614fe54358fb1bdb8bd294a" category="list-text">Utilisez le niveau Premium ou Standard pour les volumes de datastores pour des performances et une capacité optimales. Si des performances sont requises, vous pouvez utiliser le niveau Ultra.</block>
  <block id="1048ee221e43763386324d16721681fc" category="list-text">Pour les exigences de montage invité, utilisez le niveau Premium ou Ultra et pour les exigences de partage de fichiers des machines virtuelles invitées, utilisez des volumes de niveau Standard ou Premium.</block>
  <block id="e421004f0e3e2303f272ef4b0fa6c089" category="list-text">Pour les volumes Azure NetApp Files avec des fonctionnalités réseau standard, ExpressRoute est pris en charge. Lorsqu'il est activé, le raccourci envoie directement le trafic réseau aux volumes Azure NetApp Files, en contournant la passerelle pour fournir une bande passante plus élevée et une latence plus faible.</block>
  <block id="80a4a92a47a4b87bb9d0fcf9ded1dda8" category="list-text">VAAI n'est pas activé.</block>
  <block id="94e2529c9624e06356bacdc7dc76dab9" category="admonition">Pour plus d'informations sur l'utilisation des datastores ANF, contactez les architectes de solutions NetApp ou Microsoft de votre région.</block>
  <block id="a8a748d1990bd3dbc648c22396cec9c4" category="admonition">VMware Cloud sur AWS prend en charge les déploiements FSX pour ONTAP à plusieurs zones de disponibilité et même zone d'accès.</block>
</blocks>