---
sidebar: sidebar 
permalink: ai/a400-thinksystem-conclusion.html 
keywords: acknowledgements, additional information, version history 
summary: 'Cette solution NetApp et Lenovo est une architecture scale-out flexible, idéale pour l"entrée dans les applications d"IA des entreprises de taille moyenne. Les performances du stockage NetApp sont identiques ou supérieures à celles du stockage SSD local et offrent les avantages suivants aux data Scientists, aux ingénieurs de données et aux décideurs IT.' 
---
= Conclusion
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:a400-thinksystem-architecture-adjustments.html["Précédent : ajustements d'architecture."]

[role="lead"]
La solution NetApp et Lenovo validée ici est une architecture scale-out flexible, idéale pour commencer dans les environnements d'IA d'entreprise de taille moyenne. Le stockage NetApp offre des performances identiques ou supérieures à celles du stockage SSD local et offre les avantages suivants aux data Scientists, aux ingénieurs de données et aux décideurs IT :

* Partage sans effort des données entre des systèmes d'IA, l'analytique et d'autres systèmes métier stratégiques. Ce partage des données permet de réduire la surcharge de l'infrastructure, d'améliorer les performances et de rationaliser la gestion des données à l'échelle de l'entreprise.
* Faire évoluer indépendamment les ressources de calcul et de stockage pour réduire les coûts et améliorer l'utilisation des ressources.
* Rationalisation des workflows de développement et de déploiement à l'aide de snapshots et de clones intégrés, pour des espaces de travail utilisateur instantanés et compacts, un contrôle intégré des versions et un déploiement automatisé.
* Protection des données haute performance pour la reprise après incident et la continuité de l'activité.




== Remerciements

* Karthikeyan Nagalingam, Ingénieur marketing et technique, NetApp
* Jarrett Upton, administrateur, ai Lab Systems, Lenovo




== Où trouver des informations complémentaires

Pour en savoir plus sur les informations fournies dans ce document, consultez ces documents et/ou sites web :

* Page produit sur les baies 100 % Flash de NetApp
+
https://www.netapp.com/us/products/storage-systems/all-flash-array/aff-a-series.aspx["https://www.netapp.com/us/products/storage-systems/all-flash-array/aff-a-series.aspx"^]

* Page NetApp AFF A400
+
https://docs.netapp.com/us-en/ontap-systems/a400/index.html["https://docs.netapp.com/us-en/ontap-systems/a400/index.html"]

* Page produit du logiciel de gestion des données NetApp ONTAP
+
http://www.netapp.com/us/products/data-management-software/ontap.aspx["http://www.netapp.com/us/products/data-management-software/ontap.aspx"^]

* Diminution des
+
https://mlperf.org/["https://mlperf.org"^]

* Banc d'essai TensorFlow
+
https://github.com/tensorflow/benchmarks["https://github.com/tensorflow/benchmarks"^]

* NVIDIA SMI (nvidia-smi)
+
https://developer.nvidia.com/nvidia-system-management-interface["https://developer.nvidia.com/nvidia-system-management-interface"]





== Historique des versions

|===
| Version | Date | Historique des versions du document 


| Version 1.0 | Février 2020 | Version initiale. Validation pour SR670 et AFF A220 avec TensorFlow. 


| Version 2.0 | Janvier 2023 | Version mise à jour. Validation pour SR 670 V2 et AFF A400 avec MXNet. 
|===