---
sidebar: sidebar 
permalink: ai/ai-edge-test-results.html 
keywords: test, results, aff, offline, single-stream, ef 
summary: 'Une multitude de tests ont été effectués afin d"évaluer les performances de l"architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et flux multiples.' 
---
= Résultats du test
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:ai-edge-test-procedure.html["Précédent : procédure de test."]



== Résultats des tests pour AFF

Une multitude de tests ont été effectués afin d'évaluer les performances de l'architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et le traitement du langage naturel [NLP]), que vous pouvez exécuter dans trois scénarios différents : hors ligne, flux unique et flux multiples.


NOTE: Le dernier scénario est implémenté uniquement pour la classification des images et la détection des objets.

Ainsi, 15 charges de travail ont été testées sous trois configurations différentes :

* Stockage local/serveur unique
* Stockage à serveur unique/réseau
* Stockage multiserveur/réseau


Les résultats sont décrits dans les sections suivantes.



=== Inférence d'IA dans un scénario hors ligne pour AFF

Dans ce scénario, toutes les données étaient disponibles pour le serveur et le temps nécessaire pour traiter tous les échantillons a été mesuré. Nous avons signalé des largeurs de bande dans les échantillons par seconde comme résultats des tests. Lorsque plus d'un serveur de calcul était utilisé, nous faisons état de la bande passante totale additionnée sur tous les serveurs. Les résultats des trois cas d'utilisation sont présentés dans la figure ci-dessous. Pour le cas des deux serveurs, nous avons signalé la bande passante combinée des deux serveurs.

image:ai-edge-image12.png["Erreur : image graphique manquante"]

Les résultats montrent que le stockage en réseau n'affecte pas les performances : le changement est minime et aucune n'a été trouvée pour certaines tâches. Lorsque vous ajoutez le second serveur, la bande passante totale double exactement ou, dans le pire des cas, cette modification est inférieure à 1 %.



=== L'inférence d'IA dans un scénario de flux unique pour le AFF

Ce banc d'essai mesure la latence. Dans le cas d'un serveur de calcul multiple, nous faisons état de la latence moyenne. Les résultats de la suite de tâches sont indiqués dans la figure ci-dessous. Pour le cas des deux serveurs, nous avons signalé la latence moyenne des deux serveurs.

image:ai-edge-image13.png["Erreur : image graphique manquante"]

Les résultats, encore une fois, montrent que le stockage réseau suffit à gérer les tâches. La différence entre le stockage local et le stockage réseau dans un même cas de serveur est minime, voire aucune. De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste inchangée ou les modifications par une très petite quantité.



=== Inférence IA dans le scénario à flux multiples pour le AFF

Dans ce cas, le résultat est le nombre de flux que le système peut traiter tout en satisfaisant la contrainte QoS. Ainsi, le résultat est toujours un entier. Pour plus d'un serveur, nous faisons état du nombre total de flux sur tous les serveurs. Toutes les charges de travail ne prennent pas en charge ce scénario, mais nous en avons fait toutes. Les résultats de nos tests sont résumés dans la figure ci-dessous. Dans le cas des deux serveurs, nous faisons état du nombre combiné de flux provenant des deux serveurs.

image:ai-edge-image14.png["Erreur : image graphique manquante"]

Les résultats montrent des performances parfaites de la configuration : le stockage local et réseau donne les mêmes résultats et l'ajout du second serveur double le nombre de flux que la configuration proposée peut gérer.



== Résultats des tests pour EF

Une multitude de tests ont été effectués afin d'évaluer les performances de l'architecture proposée. Il existe six charges de travail différentes (classification des images, détection des objets [petite taille], détection des objets [grande], imagerie médicale, synthèse vocale, Et traitement du langage naturel [NLP]), qui ont été exécutés dans deux scénarios différents : hors ligne et flux unique. Les résultats sont décrits dans les sections suivantes.



=== Inférence d'IA dans un scénario hors ligne pour la baie EF

Dans ce scénario, toutes les données étaient disponibles pour le serveur et le temps nécessaire pour traiter tous les échantillons a été mesuré. Nous avons signalé des largeurs de bande dans les échantillons par seconde comme résultats des tests. Pour les exécutions d'un nœud, nous faisons état d'une moyenne des deux serveurs, tandis que pour deux exécutions de serveur, nous avons signalé que la bande passante totale a été additionnée sur l'ensemble des serveurs. Les résultats pour des cas d'utilisation sont présentés dans la figure ci-dessous.

image:ai-edge-image15.png["Erreur : image graphique manquante"]

Les résultats montrent que le stockage en réseau n'affecte pas les performances : le changement est minime et aucune n'a été trouvée pour certaines tâches. Lorsque vous ajoutez le second serveur, la bande passante totale double exactement ou, dans le pire des cas, cette modification est inférieure à 1 %.



=== Scénario d'inférence d'IA dans un flux unique pour la gamme EF

Ce banc d'essai mesure la latence. Dans tous les cas, nous faisons état d'une latence moyenne sur tous les serveurs en cours d'exécution. Les résultats de la suite de tâches sont donnés.

image:ai-edge-image16.png["Erreur : image graphique manquante"]

Les résultats indiquent à nouveau que le stockage réseau suffit à gérer les tâches. La différence entre le stockage local et réseau dans un cas de serveur est minime ou aucun. De même, lorsque deux serveurs utilisent le même stockage, la latence sur les deux serveurs reste inchangée ou les modifications par une très petite quantité.

link:ai-edge-architecture-sizing-options.html["Ensuite : options de dimensionnement de l'architecture."]
