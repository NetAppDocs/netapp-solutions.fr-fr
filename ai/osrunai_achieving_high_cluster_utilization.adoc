---
sidebar: sidebar 
permalink: ai/osrunai_achieving_high_cluster_utilization.html 
keywords:  
summary:  
---
= Optimiser l'utilisation des clusters
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Dans cette section, nous émulons un scénario réaliste dans lequel quatre équipes de data science soumettent leurs propres charges de travail pour présenter la solution d'orchestration Run:ai qui optimise l'utilisation des clusters, tout en maintenant les niveaux de priorité et l'équilibrage des ressources GPU. Nous commençons par le banc d'essai ResNet-50 décrit dans la section link:osrunai_resnet-50_with_imagenet_dataset_benchmark_summary.html["RESNET-50 avec résumé du banc d'essai ImageNet sur le dataset"]:

....
$ runai submit netapp1 -i netapp/tensorflow-tf1-py3:20.01.0 --local-image --large-shm  -v /mnt:/mnt -v /tmp:/tmp --command python --args "/netapp/scripts/run.py" --args "--dataset_dir=/mnt/mount_0/dataset/imagenet/imagenet_original/" --args "--num_mounts=2"  --args "--dgx_version=dgx1" --args "--num_devices=1" -g 1
....
Nous avons exécuté le même banc d'essai ResNet-50 que dans https://www.netapp.com/pdf.html?item=/media/7677-nva1121designpdf.pdf["NVA-1121"^]. nous avons utilisé l'indicateur `--local-image` pour les conteneurs qui ne résident pas dans le référentiel docker public. Nous avons monté les répertoires `/mnt` et `/tmp` sur le nœud DGX-1 hôte vers `/mnt` et `/tmp` vers le conteneur, respectivement. L'ensemble de données se trouve à NetApp AFFA800 avec `dataset_dir` l'argument pointant vers le répertoire.  `--num_devices=1`Les deux et `-g 1` signifient que nous allouons un GPU pour cette tâche. Le premier est un argument pour le `run.py` script, tandis que le second est un indicateur pour la `runai submit` commande.

La figure ci-dessous montre un tableau de bord de présentation du système avec un taux d'utilisation des GPU de 97 % et les seize GPU disponibles alloués. Vous pouvez consulter le nombre de GPU alloués à chaque équipe dans le graphique à barres projet/GPU. Le volet travaux en cours affiche les noms des travaux en cours d'exécution, le projet, l'utilisateur, le type, le nœud, GPU utilisés, temps d'exécution, progression et informations d'utilisation. Une liste des charges de travail en file d'attente avec leur temps d'attente est affichée dans tâches en attente. Enfin, la zone nœuds fournit les nombres de GPU et l'utilisation de nœuds DGX-1 individuels dans le cluster.

image:osrunai_image6.png["Figure montrant la boîte de dialogue entrée/sortie ou représentant le contenu écrit"]
