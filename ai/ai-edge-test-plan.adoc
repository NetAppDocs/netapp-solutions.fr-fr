---
sidebar: sidebar 
permalink: ai/ai-edge-test-plan.html 
keywords: test, plan, mlperf, inference, benchmarks 
summary: 'Ce document suit le code MLPerf Inférence v0.7, le code et les règles MLPerf Inférence v1.1. Nous avons exécuté des bancs d"essai conçus pour l"inférence à la périphérie, comme définis dans les tableaux présentés dans cette section.' 
---
= Plan de test
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:ai-edge-technology-overview.html["Précédent : présentation de la technologie."]

[role="lead"]
Ce document suit l'Inférence MLPerf v0.7 https://github.com/mlperf/inference_results_v0.7/tree/master/closed/Lenovo["code"^], MLPerf Inférence v1.1 https://github.com/mlcommons/inference_results_v1.1/tree/main/closed/Lenovo["code"^], et https://github.com/mlcommons/inference_policies/blob/master/inference_rules.adoc["règles"^]. Nous avons exécuté des bancs d'essai MLPerf conçus pour l'inférence à la périphérie, comme défini dans le tableau suivant.

|===
| De service | Tâche | Modèle | Jeu de données | Taille QSL | Qualité | La contrainte de latence multiflux 


| Vision | Classification des images | Reset50v1.5 | ImageNET (224 x 224) | 1024 | 99 % de FP32 | 50 ms. 


| Vision | Détection d'objet (grande taille) | SSD- ResNet34 | COCO (1200 x 1200) | 64 | 99 % de FP32 | 66 ms. 


| Vision | Détection d'objet (petite taille) | SSD : MobileNetsv1 | COCO (300 x 300) | 256 | 99 % de FP32 | 50 ms. 


| Vision | Segmentation des images médicales | NON-ET 3D | Brages 2019 (224 x 224 x 160) | 16 | 99 % et 99.9 % du FP32 | s/o 


| Voix | Parole au texte | RNNT | Lirispeech dev-Clean | 2513 | 99 % de FP32 | s/o 


| Langue | Traitement de la langue | BERT | Squad v1.1 | 10833 | 99 % de FP32 | s/o 
|===
Le tableau suivant présente des scénarios de banc d'essai pour Edge.

|===
| De service | Tâche | Scénarios 


| Vision | Classification des images | Flux unique, hors ligne, flux multiples 


| Vision | Détection d'objet (grande taille) | Flux unique, hors ligne, flux multiples 


| Vision | Détection d'objet (petite taille) | Flux unique, hors ligne, flux multiples 


| Vision | Segmentation des images médicales | Flux unique, hors ligne 


| Voix | Parole-à-texte | Flux unique, hors ligne 


| Langue | Traitement de la langue | Flux unique, hors ligne 
|===
Nous avons réalisé ces bancs d'essai à l'aide de l'architecture de stockage en réseau développée lors de cette validation et avons comparé les résultats à ceux des exécutions locales sur les serveurs de périphérie préalablement soumis à MLPerf. La comparaison consiste à déterminer l'impact du stockage partagé sur les performances d'inférence.

link:ai-edge-test-configuration.html["Suivant : test de la configuration."]
