---
sidebar: sidebar 
permalink: ai/osrunai_run_ai_installation.html 
keywords:  
summary:  
---
= Exécutez : installation ai
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
Pour installer Run:ai, procédez comme suit :

. Installez le cluster Kubernetes à l'aide de DeepOps et configurez la classe de stockage par défaut de NetApp.
. Préparez les nœuds GPU :
+
.. Vérifiez que les pilotes NVIDIA sont installés sur les nœuds GPU.
.. Vérifiez-le `nvidia-docker` est installé et configuré comme exécution docker par défaut.


. Installer Run:ai :
+
.. Connectez-vous au https://app.run.ai["Exécution : interface d'administration d'IA"^] pour créer le cluster.
.. Téléchargez le créé `runai-operator-<clustername>.yaml` fichier.
.. Appliquer la configuration de l'opérateur au cluster Kubernetes.
+
....
kubectl apply -f runai-operator-<clustername>.yaml
....


. Vérifiez l'installation :
+
.. Accédez à https://app.run.ai/["https://app.run.ai/"^].
.. Accédez au tableau de bord Présentation.
.. Vérifiez que le nombre de GPU situé en haut à droite indique le nombre attendu de GPU et de nœuds GPU dans la liste des serveurs.pour plus d'informations sur le déploiement Run:ai, consultez https://docs.run.ai/Administrator/Cluster-Setup/Installing-Run-AI-on-an-on-premise-Kubernetes-Cluster/["Installation de Run:ai sur un cluster Kubernetes sur site"^] et https://docs.run.ai/Administrator/Researcher-Setup/Installing-the-Run-AI-Command-Line-Interface/["Installation de la CLI Run:ai"^].



