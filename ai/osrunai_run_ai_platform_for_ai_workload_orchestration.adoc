---
sidebar: sidebar 
permalink: ai/osrunai_run_ai_platform_for_ai_workload_orchestration.html 
keywords:  
summary:  
---
= Exécutez :plateforme d'IA pour l'orchestration des workloads d'IA
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
* Accélération du time-to-innovation. Par l'utilisationRun:IA : mise en pool de ressources, mise en file d'attente et mécanismes de priorisation associés au système de stockage NetApp, les chercheurs ne sont plus aux casse-tête de la gestion de l'infrastructure et peuvent se concentrer exclusivement sur la science des données. Exécution :les clients qui possèdent des solutions d'IA et NetApp augmentent la productivité en exécutant autant de workloads que nécessaire, sans goulot d'étranglement au niveau du calcul ou du pipeline de données.
* Une productivité accrue de l'équipe. Exécution :les algorithmes d'équité d'IA garantissent que tous les utilisateurs et toutes les équipes bénéficient du partage plus équitable des ressources. Les stratégies relatives aux projets prioritaires peuvent être prédéfinies et la plateforme permet d'allouer des ressources de manière dynamique d'une équipe utilisateur à l'autre, ce qui aide les utilisateurs à accéder rapidement aux ressources GPU convoitées.
* Amélioration du taux d'utilisation des GPU. Le planificateur Run:ai permet aux utilisateurs d'utiliser facilement des GPU fractionnaires, des GPU entiers et plusieurs nœuds de GPU pour l'entraînement distribué sur Kubernetes. De cette façon, les workloads d'IA s'exécutent en fonction des besoins, et non pas de la capacité. Les équipes de data Scientists sont en mesure d'exécuter davantage d'expériences d'IA sur la même infrastructure.


link:osrunai_solution_technology_overview.html["Suivant : technologie de la solution"].
