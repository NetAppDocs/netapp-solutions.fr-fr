---
sidebar: sidebar 
permalink: ehc/aws/aws-guest-dr-networking.html 
keywords: on premises, client networks, Storage networks, Cloud connectivity, VPN, direct connect, Transit gateway, security groups 
summary: 'Cette solution requiert une communication réussie du cluster ONTAP sur site vers AWS FSX pour l"interconnexion de cluster NetApp ONTAP afin d"effectuer les opérations SyncMirror. Par ailleurs, un serveur de sauvegarde Veeam doit avoir accès à un compartiment AWS S3. Au lieu d"utiliser le transport Internet, une liaison VPN ou Direct Connect existante peut être utilisée comme liaison privée vers un compartiment S3.' 
---
= Mise en réseau
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../../media/


link:aws-guest-dr-requirements.html["Précédent : exigences."]

Cette solution requiert une communication réussie du cluster ONTAP sur site vers AWS FSX pour l'interconnexion de cluster NetApp ONTAP afin d'effectuer les opérations SyncMirror. Par ailleurs, un serveur de sauvegarde Veeam doit avoir accès à un compartiment AWS S3. Au lieu d'utiliser le transport Internet, une liaison VPN ou Direct Connect existante peut être utilisée comme liaison privée vers un compartiment S3.



== Sur site

ONTAP prend en charge tous les principaux protocoles de stockage utilisés pour la virtualisation, y compris iSCSI, Fibre Channel (FC), Fibre Channel over Ethernet (FCoE) ou NVMe/FC (non-volatile Memory Express over Fibre Channel) pour les environnements SAN. ONTAP supporte également les protocoles NFS (v3 et v4.1) et SMB ou S3 pour les connexions invité. Vous pouvez choisir ce qui fonctionne le mieux pour votre environnement et combiner des protocoles en fonction de vos besoins sur un seul système. Par exemple, vous pouvez augmenter l'utilisation générale des datastores NFS en utilisant quelques LUN iSCSI ou des partages invités.

Cette solution exploite les datastores NFS pour les datastores sur site pour les disques VMDK invités et iSCSI et NFS pour les données d'applications invité.



=== Réseaux clients

Les ports réseau VMkernel et le réseau Software-defined assurent la connectivité aux hôtes ESXi afin de communiquer avec des éléments externes à l'environnement VMware. La connectivité dépend du type d'interfaces VMkernel utilisées.

Pour cette solution, les interfaces VMkernel suivantes ont été configurées :

* Gestion
* VMotion
* NFS
* ISCSI




=== Réseaux de stockage provisionnés

Une LIF (Logical interface) représente un point d'accès réseau à un nœud du cluster. Cela permet la communication avec les machines virtuelles de stockage qui hébergent les données auxquelles les clients ont accès. Vous pouvez configurer les LIF sur les ports sur lesquels le cluster envoie et reçoit des communications sur le réseau.

Pour cette solution, la LIF est configurée pour les protocoles de stockage suivants :

* NFS
* ISCSI




== Options de connectivité cloud

Les clients disposent de nombreuses options pour connecter leur environnement sur site à des ressources cloud, notamment pour le déploiement de topologies VPN ou Direct Connect.



=== Réseau privé virtuel (VPN)

Les VPN (réseaux privés virtuels) sont souvent utilisés pour créer un tunnel IPSec sécurisé avec des réseaux Internet ou MPLS privés. Un VPN est facile à configurer, mais il manque de fiabilité (si basé sur Internet) et de vitesse. Le point final peut être résilié dans le VPC AWS ou dans le SDDC VMware Cloud. Pour cette solution de reprise après incident, nous avons créé la connectivité à AWS FSX pour NetApp ONTAP à partir du réseau sur site. Il peut donc être résilié sur le VPC AWS (Virtual Private Gateway ou Transit Gateway) où FSX pour NetApp ONTAP est connecté.

La configuration VPN peut être basée sur une route ou sur des règles. Avec une configuration basée sur une route, les points de terminaison échangent automatiquement les routes et la configuration apprend la route vers les sous-réseaux nouvellement créés. Avec une configuration basée sur des règles, vous devez définir les sous-réseaux locaux et distants et, lorsque de nouveaux sous-réseaux sont ajoutés et autorisés à communiquer dans le tunnel IPSec, vous devez mettre à jour les routes.


NOTE: Si le tunnel VPN IPSec n'est pas créé sur la passerelle par défaut, les routes réseau distantes doivent être définies dans les tables de routage via le point d'extrémité du tunnel VPN local.

La figure suivante illustre les options de connexion VPN types.

image:dr-vmc-aws-image3.png["Erreur : image graphique manquante"]



=== Connexion directe

Direct Connect fournit une liaison dédiée au réseau AWS. Les connexions dédiées créent des liaisons vers AWS à l'aide d'un port Ethernet de 1 Gbits/s, 10 Gbits/s ou 100 Gbits/s. Les partenaires AWS Direct Connect offrent des connexions hébergées via des liaisons réseau établies entre eux et AWS, et sont disponibles de 50 Mbit/s à 10 Gbit/s. Par défaut, le trafic est non chiffré. Toutefois, des options sont disponibles pour sécuriser le trafic avec MACsec ou IPsec. MACsec fournit un cryptage de couche 2 tandis que IPSec fournit un cryptage de couche 3. MACsec fournit une meilleure sécurité en masquant les appareils qui communiquent.

Les clients doivent disposer de leur équipement de routeur sur un site AWS Direct Connect. Pour ce faire, vous pouvez travailler avec le réseau de partenaires AWS (APN). Une connexion physique est établie entre ce routeur et le routeur AWS. Pour permettre l'accès à FSX pour NetApp ONTAP sur VPC, vous devez disposer d'une interface virtuelle privée ou d'une interface virtuelle de transit à partir de Direct Connect vers un VPC. Son interface virtuelle privée limite l'évolutivité de la connexion Direct Connect vers VPC.

La figure suivante illustre les options de l'interface Direct Connect.

image:dr-vmc-aws-image4.png["Erreur : image graphique manquante"]



=== Passerelle de transit

La passerelle de transit est une structure au niveau de la région qui permet une évolutivité accrue d'une connexion Direct Connect-to-VPC dans une région. Si une connexion inter-région est nécessaire, les passerelles de transit doivent être pétrées. Pour plus d'informations, consultez la https://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html["Documentation AWS Direct Connect"^].



== Considérations relatives au réseau cloud

Dans le cloud, l'infrastructure réseau sous-jacente est gérée par le fournisseur de services cloud, tandis que les clients doivent gérer les réseaux de VPC, les sous-réseaux, les tables d'acheminement, etc. Ils doivent également gérer les segments de réseau NSX à la périphérie de calcul. Le SDDC regroupe les routes pour le VPC et Transit Connect externe.

Lorsque la solution FSX pour NetApp ONTAP avec disponibilité de plusieurs zones de disponibilité est déployée sur un VPC connecté au cloud VMware, le trafic iSCSI reçoit les mises à jour de la table d'acheminement nécessaires pour permettre la communication. Par défaut, aucune route n'est disponible depuis VMware Cloud vers le sous-réseau NFS/SMB ONTAP FSX sur le VPC connecté pour les déploiements en plusieurs zones de disponibilité. Pour définir ce routage, nous avons utilisé le groupe VMware Cloud SDDC, qui est une passerelle de transit gérée par VMware, afin de permettre la communication entre les SDDC VMware Cloud dans la même région, ainsi qu'avec les VPC externes et d'autres passerelles de transit.


NOTE: Des coûts de transfert de données sont associés à l'utilisation d'une passerelle de transit. Pour plus de détails sur les coûts spécifiques à une région, voir https://aws.amazon.com/transit-gateway/pricing/["ce lien"^].

Le déploiement de VMware Cloud SDDC peut s'effectuer dans une zone de disponibilité unique, à l'instar d'un seul data Center. Une option de cluster étendu est également disponible, ce qui ressemble à une solution NetApp MetroCluster qui offre une plus grande disponibilité et réduit les temps d'indisponibilité en cas de défaillance de zone de disponibilité.

Pour minimiser les coûts de transfert de données, conservez les instances ou services VMware Cloud SDDC et AWS dans la même zone de disponibilité. Il est préférable de la comparer avec un ID de zone de disponibilité plutôt qu'avec un nom, car AWS fournit la liste de commandes AZ propre au compte afin de répartir la charge entre les zones de disponibilité. Par exemple, un compte (US-East-1a) pourrait indiquer l'ID AZ 1 alors qu'un autre compte (US-East-1c) peut désigner l'ID AZ 1. L'ID de zone de disponibilité peut être récupéré de plusieurs façons. Dans l'exemple suivant, nous avons récupéré l'ID AZ du sous-réseau VPC.

image:dr-vmc-aws-image5.png["Erreur : image graphique manquante"]

Dans le SDDC VMware Cloud, la gestion du réseau est gérée avec NSX, et la passerelle de périphérie (routeur Tier 0) qui gère le port de liaison ascendante du trafic Nord-Sud est connectée au VPC AWS. La passerelle de calcul et les passerelles de gestion (routeurs de niveau 1) gèrent le trafic est-ouest. Si les ports de liaison ascendante de la périphérie sont utilisés de manière intensive, vous pouvez créer des groupes de trafic à associer à des adresses IP ou des sous-réseaux spécifiques à l'hôte. La création d'un groupe de trafic crée des nœuds de périphérie supplémentaires pour séparer le trafic. Vérifier le https://docs.vmware.com/en/VMware-Cloud-on-AWS/services/com.vmware.vmc-aws-networking-security/GUID-306D3EDC-F94E-4216-B306-413905A4A784.html["Documentation VMware"^] Nombre minimal d'hôtes vSphere requis pour utiliser une configuration multi-périphérie.



=== Réseaux clients

Lorsque vous provisionnez l'SDDC VMware Cloud, les ports VMKernel sont déjà configurés et sont prêts à être utilisés. VMware gère ces ports, sans qu'aucune mise à jour ne soit nécessaire.

La figure suivante illustre un exemple d'informations sur le VMKernel de l'hôte.

image:dr-vmc-aws-image6.png["Erreur : image graphique manquante"]



=== Réseaux de stockage provisionnés (iSCSI, NFS)

Pour les réseaux de stockage invités d'ordinateurs virtuels, nous créons généralement des groupes de ports. Avec NSX, nous créons des segments qui sont utilisés sur vCenter en tant que groupes de ports. Comme les réseaux de stockage se trouvent dans un sous-réseau routable, vous pouvez accéder aux LUN ou monter les exportations NFS à l'aide de la carte réseau par défaut, même sans créer de segments de réseau distincts. Pour séparer le trafic de stockage, vous pouvez créer des segments supplémentaires, définir des règles et contrôler la taille de MTU sur ces segments. Pour assurer la tolérance aux pannes, il est préférable d'avoir au moins deux segments dédiés au réseau de stockage. Comme nous l'avons mentionné précédemment, si la bande passante de liaison ascendante devient un problème, vous pouvez créer des groupes de trafic et attribuer des préfixes IP et des passerelles pour effectuer un routage basé sur la source.

Nous recommandons de faire correspondre les segments du SDDC de reprise après incident à l'environnement source pour éviter de deviner le mappage de segments de réseau lors du basculement.



=== Groupes de sécurité

De nombreuses options de sécurité offrent une communication sécurisée sur le VPC AWS et le réseau SDDC VMware Cloud. Dans le réseau VMware Cloud SDDC, vous pouvez utiliser le flux de trace de NSX pour identifier le chemin, y compris les règles utilisées. Ensuite, vous pouvez utiliser un analyseur réseau sur le réseau VPC pour identifier le chemin, notamment les tables de routage, les groupes de sécurité et les listes de contrôle d'accès au réseau, qui sont consommées pendant le flux.

link:aws-guest-dr-storage.html["Ensuite, le stockage."]
