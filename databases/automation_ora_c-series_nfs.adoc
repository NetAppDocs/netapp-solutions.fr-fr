---
sidebar: sidebar 
permalink: databases/automation_ora_c-series_nfs.html 
keywords: Database, Oracle, Azure, ANF, Ansible, Automation 
summary: 'Cette solution fournit une vue d"ensemble et des détails pour le déploiement automatisé d"Oracle dans NetApp AFF C-Series en tant que stockage de base de données primaire avec protocole NFS. La base de données Oracle se déploie en tant que base de données de conteneurs avec dNFS activé.' 
---
= Tr-4992 : déploiement Oracle simplifié et automatisé sur NetApp C-Series avec NFS
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Allen Cao, Niyaz Mohamed, NetApp

[role="lead"]
Cette solution fournit une vue d'ensemble et des détails pour le déploiement automatisé d'Oracle dans NetApp AFF C-Series en tant que stockage de base de données primaire avec protocole NFS. La base de données Oracle se déploie en tant que base de données de conteneurs avec dNFS activé.



== Objectif

NetApp AFF C-Series est une solution de stockage Flash haute capacité qui rend la solution 100 % Flash plus accessible et économique pour le stockage unifié. Elle est suffisamment performante pour de nombreuses charges de travail de bases de données Oracle de Tier 1 ou 2. Optimisés par le logiciel de gestion des données NetApp ONTAP®, les systèmes AFF C-Series offrent une efficacité de pointe, une flexibilité supérieure, des services de données de pointe et l'intégration au cloud pour vous aider à faire évoluer votre infrastructure INFORMATIQUE, à simplifier la gestion de vos données et à réduire les coûts de stockage et la consommation d'énergie.

Cette documentation décrit le déploiement simplifié des bases de données Oracle dans NetApp C-Series via des montages NFS utilisant l'automatisation Ansible. La base de données Oracle se déploie dans une configuration de base de données de conteneurs (CDB) et de bases de données enfichables (PDB) avec le protocole Oracle dNFS activé pour optimiser les performances. En outre, elle fournit les meilleures pratiques lors de la configuration du réseau de stockage et de la machine virtuelle de stockage (SVM) avec le protocole NFS sur les contrôleurs de stockage C-Series. La solution fournit également des informations sur la sauvegarde, la restauration et le clonage rapides des bases de données Oracle à l'aide de l'interface utilisateur de NetApp SnapCenter.

Cette solution répond aux cas d'utilisation suivants :

* Déploiement automatisé des bases de données de conteneurs Oracle sur les contrôleurs de stockage NetApp C-Series
* Protection des bases de données Oracle et clonage sur C-Series avec l'outil d'interface utilisateur de SnapCenter.




== Public

Cette solution est destinée aux personnes suivantes :

* Administrateur de bases de données qui souhaite déployer Oracle sur NetApp C-Series.
* Architecte de solutions de bases de données qui souhaite tester les charges de travail Oracle sur NetApp C-Series.
* Administrateur du stockage qui souhaite déployer et gérer une base de données Oracle sur NetApp C-Series.
* Propriétaire d'application qui souhaite mettre en place une base de données Oracle sur NetApp C-Series.




== Environnement de test et de validation de la solution

Les tests et la validation de cette solution ont été réalisés dans un environnement de laboratoire qui ne correspond peut-être pas à l'environnement de déploiement final. Voir la section <<Facteurs clés à prendre en compte lors du déploiement>> pour en savoir plus.



=== Architecture

image:automation_ora_c-series_nfs_archit.png["Cette image fournit une vue détaillée de la configuration du déploiement Oracle dans le cloud public AWS avec iSCSI et ASM."]



=== Composants matériels et logiciels

[cols="33%, 33%, 33%"]
|===


3+| *Matériel* 


| NetApp série C C400 | ONTAP version 9.13.1P3 | Deux tiroirs disques/24 disques d'une capacité de 278 Tio 


| VM pour serveur de base de données | 4 vCPU, 16 Gio de RAM | Deux instances VM Linux pour un déploiement simultané 


| VM pour SnapCenter | 4 vCPU, 16 Gio de RAM | Une instance de machine virtuelle Windows 


3+| *Logiciel* 


| Red Hat Linux | RHEL Linux 8.6 (LVM) - x64 Gen2 | Déploiement de l'abonnement Red Hat pour les tests 


| Serveur Windows | 2022 datacenter x64 Gen2 | Hébergement du serveur SnapCenter 


| Base de données Oracle | Version 19.18 | Patch RU appliqué p34765931_190000_Linux-x86-64.zip 


| OPICH Oracle | Version 12.2.0.1.36 | Dernier correctif p6880880_190000_Linux-x86-64.zip 


| Serveur SnapCenter | Version 5.0 | Déploiement de groupes de travail 


| Ouvrez JDK | Version Java-11-openjdk | Plug-in SnapCenter requis sur les VM de base de données 


| NFS | Version 3.0 | Oracle dNFS activé 


| Ansible | noyau 2.16.2 | Python 3.6.8 
|===


=== Configuration de la base de données Oracle dans l'environnement de laboratoire

[cols="33%, 33%, 33%"]
|===


3+|  


| *Serveur* | *Base de données* | *Stockage DB* 


| ora_01 | NTAP1(NTAP1_PDB1,NTAP1_PDB2,NTAP1_PDB3) | Les montages NFS /u01, /u02, /u03 sont montés sur des volumes C400 


| ora_02 | NTAP2(NTAP2_PDB1,NTAP2_PDB2,NTAP2_PDB3) | Les montages NFS /u01, /u02, /u03 sont montés sur des volumes C400 
|===


=== Facteurs clés à prendre en compte lors du déploiement

* *Organisation du stockage de la base de données Oracle* dans ce déploiement Oracle automatisé, nous provisionnons trois volumes de base de données pour chaque base de données afin d'héberger les fichiers binaires, les données et les journaux Oracle par défaut. Les volumes sont montés sur le serveur BDD Oracle sous la forme /u01 - binary, /u02 - data, /u03 - logs via NFS. Les fichiers de contrôle doubles sont configurés sur les points de montage /u02 et /u03 pour assurer la redondance.
* *Déploiement de plusieurs serveurs de bases de données.* la solution d'automatisation peut déployer une base de données de conteneurs Oracle sur plusieurs serveurs de bases de données dans un seul PlayBook Ansible. Quel que soit le nombre de serveurs de base de données, l'exécution du PlayBook reste la même. Vous pouvez déployer plusieurs bases de données de conteneurs sur une seule instance de machine virtuelle en répétant le déploiement avec différents ID d'instance de base de données (SID Oracle). Mais assurez-vous qu'il y a suffisamment de mémoire sur l'hôte pour prendre en charge les bases de données déployées.
* *Configuration dNFS.* en utilisant dNFS (disponible depuis Oracle 11g), une base de données Oracle s'exécutant sur une VM de base de données peut prendre en charge beaucoup plus d'E/S que le client NFS natif. Le déploiement Oracle automatisé configure par défaut dNFS sur NFSv3.
* *Équilibrage de la charge sur la paire de contrôleurs C400.* placez les volumes de base de données Oracle sur les nœuds de contrôleurs C400 uniformément pour équilibrer la charge de travail. DB1 sur le contrôleur 1, DB2 sur le contrôleur 2, etc. Monter les volumes DB sur son adresse lif locale.
* *Sauvegarde de la base de données.* NetApp fournit une suite logicielle SnapCenter pour la sauvegarde, la restauration et le clonage de la base de données avec une interface utilisateur conviviale. NetApp recommande de mettre en œuvre cet outil de gestion afin de réaliser rapidement (moins d'une minute) des sauvegardes Snapshot, des restaurations rapides (en minutes) des bases de données et des clones de base de données.




== Déploiement de la solution

Les sections suivantes présentent des procédures détaillées pour le déploiement automatisé d'Oracle 19c, ainsi que des informations sur la protection de la base de données Oracle et le clonage après le déploiement.



=== Conditions préalables au déploiement

[%collapsible%open]
====
Le déploiement nécessite les conditions préalables suivantes.

. Une paire de contrôleurs de stockage NetApp C-Series est mise en rack, empilée et la dernière version du système d'exploitation ONTAP est installée et configurée. Reportez-vous à ce guide de configuration si nécessaire : https://docs.netapp.com/us-en/ontap-systems/c400/install-detailed-guide.html#step-1-prepare-for-installation["Guide détaillé - AFF C400"^]
. Provisionnement de deux VM Linux en tant que serveurs BDD Oracle Pour plus d'informations sur la configuration de l'environnement, reportez-vous au schéma d'architecture de la section précédente.
. Provisionnez un serveur Windows pour exécuter l'outil d'interface utilisateur NetApp SnapCenter avec la dernière version. Pour plus de détails, cliquez sur le lien suivant : link:https://docs.netapp.com/us-en/snapcenter/install/task_install_the_snapcenter_server_using_the_install_wizard.html["Installez le serveur SnapCenter"^]
. Provisionnez une VM Linux en tant que nœud de contrôleur Ansible avec la dernière version d'Ansible et de Git installée. Pour plus de détails, cliquez sur le lien suivant : link:../automation/getting-started.html["Commencer à utiliser l'automatisation des solutions NetApp"^] dans la section -
`Setup the Ansible Control Node for CLI deployments on RHEL / CentOS` ou
`Setup the Ansible Control Node for CLI deployments on Ubuntu / Debian`.
+
Activez l'authentification de clés ssh publiques/privées entre le contrôleur Ansible et les VM de base de données.

. Clonez une copie du kit d'automatisation de déploiement Oracle de NetApp pour NFS à partir du répertoire personnel d'administration du contrôleur Ansible.
+
[source, cli]
----
git clone https://bitbucket.ngage.netapp.com/scm/ns-bb/na_oracle_deploy_nfs.git
----
. Etape suivant les fichiers d'installation d'Oracle 19c sur le répertoire DB VM /tmp/archive avec l'autorisation 777.
+
....
installer_archives:
  - "LINUX.X64_193000_db_home.zip"
  - "p34765931_190000_Linux-x86-64.zip"
  - "p6880880_190000_Linux-x86-64.zip"
....


====


=== Configurez le réseau et les SVM sur C-Series pour Oracle

[%collapsible%open]
====
Cette section du guide de déploiement décrit les meilleures pratiques pour la configuration de la machine virtuelle de réseau et de stockage (SVM) sur le contrôleur C-Series pour la charge de travail Oracle avec le protocole NFS à l'aide de l'interface utilisateur de ONTAP System Manager.

. Connectez-vous à ONTAP System Manager pour vérifier qu'après l'installation initiale du cluster ONTAP, les domaines de diffusion ont été configurés avec des ports ethernet correctement attribués à chaque domaine. En règle générale, il doit y avoir un broadcast domain pour le cluster, un broadcast domain pour la gestion et un broadcast domain pour des charges de travail telles que les données.
+
image:automation_ora_c-series_nfs_net_01.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Dans RÉSEAU - ports Ethernet, cliquez sur `Link Aggregate Group` Pour créer un groupe d'agrégats de liens LACP port a0a, qui fournit l'équilibrage de la charge et le basculement entre les ports membres du port group d'agrégats. 4 ports de données, e0e, e0f, e0g, e0h, sont disponibles sur les contrôleurs C400.
+
image:automation_ora_c-series_nfs_net_02.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Sélectionnez les ports ethernet dans le groupe, `LACP` pour le mode, et `Port` pour la distribution de charge.
+
image:automation_ora_c-series_nfs_net_03.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Valider le port LACP a0a créé et broadcast domain `Data` Fonctionne désormais sur le port LACP.
+
image:automation_ora_c-series_nfs_net_04.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"] image:automation_ora_c-series_nfs_net_05.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. De `Ethernet Ports`, cliquez sur `VLAN` Pour ajouter un VLAN sur chaque nœud de contrôleur pour la charge de travail Oracle sur le protocole NFS.
+
image:automation_ora_c-series_nfs_net_06.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"] image:automation_ora_c-series_nfs_net_07.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"] image:automation_ora_c-series_nfs_net_08.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Connectez-vous aux contrôleurs C-Series à partir de l'IP de gestion du cluster via ssh pour vérifier que les groupes de basculement du réseau sont configurés correctement. ONTAP crée et gère automatiquement les groupes de basculement.
+
....

HCG-NetApp-C400-E9U9::> net int failover-groups show
  (network interface failover-groups show)
                                  Failover
Vserver          Group            Targets
---------------- ---------------- --------------------------------------------
Cluster
                 Cluster
                                  HCG-NetApp-C400-E9U9a:e0c,
                                  HCG-NetApp-C400-E9U9a:e0d,
                                  HCG-NetApp-C400-E9U9b:e0c,
                                  HCG-NetApp-C400-E9U9b:e0d
HCG-NetApp-C400-E9U9
                 Data
                                  HCG-NetApp-C400-E9U9a:a0a,
                                  HCG-NetApp-C400-E9U9a:a0a-3277,
                                  HCG-NetApp-C400-E9U9b:a0a,
                                  HCG-NetApp-C400-E9U9b:a0a-3277
                 Mgmt
                                  HCG-NetApp-C400-E9U9a:e0M,
                                  HCG-NetApp-C400-E9U9b:e0M
3 entries were displayed.

....
. De `STORAGE - Storage VMs`, Cliquer sur +Ajouter pour créer un SVM pour Oracle.
+
image:automation_ora_c-series_nfs_svm_01.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Nommez votre SVM Oracle, vérifiez `Enable NFS` et `Allow NFS client access`.
+
image:automation_ora_c-series_nfs_svm_02.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Ajouter une export policy NFS `Default` règles.
+
image:automation_ora_c-series_nfs_svm_03.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Dans `NETWORK INTERFACE`, Renseignez l'adresse IP sur chaque nœud pour les adresses lif NFS.
+
image:automation_ora_c-series_nfs_svm_04.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Vérifier que le SVM pour Oracle est opérationnel et que l'état des lif NFS est actif.
+
image:automation_ora_c-series_nfs_svm_05.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"] image:automation_ora_c-series_nfs_svm_06.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. De `STORAGE-Volumes` Pour ajouter des volumes NFS pour la base de données Oracle.
+
image:automation_ora_c-series_nfs_vol_01.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Nommez votre volume, attribuez la capacité et le niveau de performance.
+
image:automation_ora_c-series_nfs_vol_02.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Dans `Access Permission`, choisissez la stratégie par défaut créée à partir de l'étape précédente. Décochez `Enable Snapshot Copies` Comme nous préférons utiliser SnapCenter pour créer des snapshots cohérents avec les applications.
+
image:automation_ora_c-series_nfs_vol_03.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

. Créez trois volumes DB pour chaque serveur DB : Server_name_u01 - binary, Server_name_u02 - data, Server_name_u03 - logs.
+
image:automation_ora_c-series_nfs_vol_04.png["Cette image fournit une capture d'écran pour la configuration du contrôleur c-series"]

+

NOTE: La convention de nommage des volumes de la base de données doit respecter strictement le format indiqué ci-dessus pour garantir le bon fonctionnement de l'automatisation.



La configuration du contrôleur C-series pour Oracle est terminée.

====


=== Fichiers de paramètres d'automatisation

[%collapsible%open]
====
Le PlayBook Ansible exécute les tâches d'installation et de configuration de la base de données avec des paramètres prédéfinis. Pour cette solution d'automatisation Oracle, trois fichiers de paramètres définis par l'utilisateur doivent être saisis avant l'exécution du PlayBook.

* hôtes : définissez les cibles pour lesquelles le playbook d'automatisation s'exécute.
* rva/rva.yml - fichier de variables globales qui définit les variables qui s'appliquent à toutes les cibles.
* host_rva/host_name.yml - fichier de variables locales qui définit les variables qui s'appliquent uniquement à une cible nommée. Dans notre cas d'utilisation, il s'agit des serveurs BDD Oracle.


Outre ces fichiers de variables définis par l'utilisateur, il existe plusieurs fichiers de variables par défaut qui contiennent des paramètres par défaut qui ne nécessitent aucune modification, sauf si nécessaire. Les sections suivantes expliquent comment configurer les fichiers de variables définis par l'utilisateur.

====


=== Configuration des fichiers de paramètres

[%collapsible%open]
====
. Cible Ansible `hosts` configuration du fichier :
+
[source, shell]
----
# Enter Oracle servers names to be deployed one by one, follow by each Oracle server public IP address, and ssh private key of admin user for the server.
[oracle]
ora_01 ansible_host=10.61.180.21 ansible_ssh_private_key_file=ora_01.pem
ora_02 ansible_host=10.61.180.23 ansible_ssh_private_key_file=ora_02.pem

----
. Mondial `vars/vars.yml` configuration de fichier
+
[source, shell]
----
######################################################################
###### Oracle 19c deployment user configuration variables       ######
###### Consolidate all variables from ONTAP, linux and oracle   ######
######################################################################

###########################################
### ONTAP env specific config variables ###
###########################################

# Prerequisite to create three volumes in NetApp ONTAP storage from System Manager or cloud dashboard with following naming convention:
# db_hostname_u01 - Oracle binary
# db_hostname_u02 - Oracle data
# db_hostname_u03 - Oracle redo
# It is important to strictly follow the name convention or the automation will fail.


###########################################
### Linux env specific config variables ###
###########################################

redhat_sub_username: XXXXXXXX
redhat_sub_password: XXXXXXXX


####################################################
### DB env specific install and config variables ###
####################################################

# Database domain name
db_domain: solutions.netapp.com

# Set initial password for all required Oracle passwords. Change them after installation.
initial_pwd_all: XXXXXXXX

----
. Serveur DB local `host_vars/host_name.yml` configuration telle que ora_01.yml, ora_02.yml ...
+
[source, shell]
----
# User configurable Oracle host specific parameters

# Enter container database SID. By default, a container DB is created with 3 PDBs within the CDB
oracle_sid: NTAP1

# Enter database shared memory size or SGA. CDB is created with SGA at 75% of memory_limit, MB. The grand total of SGA should not exceed 75% available RAM on node.
memory_limit: 8192

# Local NFS lif ip address to access database volumes
nfs_lif: 172.30.136.68

----


====


=== Exécution de PlayBook

[%collapsible%open]
====
Le kit d'outils d'automatisation comprend cinq playbooks. Chacun exécute des blocs de tâches différents et répond à des besoins différents.

....
0-all_playbook.yml - execute playbooks from 1-4 in one playbook run.
1-ansible_requirements.yml - set up Ansible controller with required libs and collections.
2-linux_config.yml - execute Linux kernel configuration on Oracle DB servers.
4-oracle_config.yml - install and configure Oracle on DB servers and create a container database.
5-destroy.yml - optional to undo the environment to dismantle all.
....
Il existe trois options pour exécuter les playbooks avec les commandes suivantes.

. Exécutez tous les playbooks de déploiement en une seule fois.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml
----
. Exécutez les playbooks un par un avec la séquence des nombres compris entre 1 et 4.
+
[source, cli]]
----
ansible-playbook -i hosts 1-ansible_requirements.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 2-linux_config.yml -u admin -e @vars/vars.yml
----
+
[source, cli]
----
ansible-playbook -i hosts 4-oracle_config.yml -u admin -e @vars/vars.yml
----
. Exécutez 0-all_PlayBook.yml avec une balise.
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t ansible_requirements
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t linux_config
----
+
[source, cli]
----
ansible-playbook -i hosts 0-all_playbook.yml -u admin -e @vars/vars.yml -t oracle_config
----
. Annulez l'environnement
+
[source, cli]
----
ansible-playbook -i hosts 5-destroy.yml -u admin -e @vars/vars.yml
----


====


=== Validation post-exécution

[%collapsible%open]
====
Une fois le PlayBook exécuté, connectez-vous à la machine virtuelle du serveur de base de données Oracle pour vérifier qu'Oracle est installé et configuré et qu'une base de données de conteneurs est correctement créée. Voici un exemple de validation de base de données Oracle sur DB VM ora_01 ou ora_02.

. Validez les montages NFS
+
....

[admin@ora_01 ~]$ cat /etc/fstab

#
# /etc/fstab
# Created by anaconda on Wed Oct 18 19:43:31 2023
#
# Accessible filesystems, by reference, are maintained under '/dev/disk/'.
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info.
#
# After editing this file, run 'systemctl daemon-reload' to update systemd
# units generated from this file.
#
/dev/mapper/rhel-root   /                       xfs     defaults        0 0
UUID=aff942c4-b224-4b62-807d-6a5c22f7b623 /boot                   xfs     defaults        0 0
/dev/mapper/rhel-swap   none                    swap    defaults        0 0
/root/swapfile swap swap defaults 0 0
172.21.21.100:/ora_01_u01 /u01 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u02 /u02 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0
172.21.21.100:/ora_01_u03 /u03 nfs rw,bg,hard,vers=3,proto=tcp,timeo=600,rsize=65536,wsize=65536 0 0


[admin@ora_01 tmp]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  62% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.100:/ora_01_u01   50G  8.7G   42G  18% /u01
172.21.21.100:/ora_01_u02  200G  384K  200G   1% /u02
172.21.21.100:/ora_01_u03  100G  320K  100G   1% /u03

[admin@ora_02 ~]$ df -h
Filesystem                 Size  Used Avail Use% Mounted on
devtmpfs                   7.7G     0  7.7G   0% /dev
tmpfs                      7.8G     0  7.8G   0% /dev/shm
tmpfs                      7.8G   18M  7.8G   1% /run
tmpfs                      7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/mapper/rhel-root       44G   28G   17G  63% /
/dev/sda1                 1014M  258M  757M  26% /boot
tmpfs                      1.6G   12K  1.6G   1% /run/user/42
tmpfs                      1.6G  4.0K  1.6G   1% /run/user/1000
172.21.21.101:/ora_02_u01   50G  7.8G   43G  16% /u01
172.21.21.101:/ora_02_u02  200G  320K  200G   1% /u02
172.21.21.101:/ora_02_u03  100G  320K  100G   1% /u03

....
. Validez l'écouteur Oracle
+
....

[admin@ora_02 ~]$ sudo su
[root@ora_02 admin]# su - oracle
[oracle@ora_02 ~]$ lsnrctl status listener.ntap2

LSNRCTL for Linux: Version 19.0.0.0.0 - Production on 29-MAY-2024 12:13:30

Copyright (c) 1991, 2022, Oracle.  All rights reserved.

Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
STATUS of the LISTENER
------------------------
Alias                     LISTENER.NTAP2
Version                   TNSLSNR for Linux: Version 19.0.0.0.0 - Production
Start Date                23-MAY-2024 16:13:03
Uptime                    5 days 20 hr. 0 min. 26 sec
Trace Level               off
Security                  ON: Local OS Authentication
SNMP                      OFF
Listener Parameter File   /u01/app/oracle/product/19.0.0/NTAP2/network/admin/listener.ora
Listener Log File         /u01/app/oracle/diag/tnslsnr/ora_02/listener.ntap2/alert/log.xml
Listening Endpoints Summary...
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=ora_02.cie.netapp.com)(PORT=1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC1521)))
  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcps)(HOST=ora_02.cie.netapp.com)(PORT=5500))(Security=(my_wallet_directory=/u01/app/oracle/product/19.0.0/NTAP2/admin/NTAP2/xdb_wallet))(Presentation=HTTP)(Session=RAW))
Services Summary...
Service "192551f1d7e65fc3e06308b43d0a63ae.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925529a43396002e06308b43d0a2d5a.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "1925530776b76049e06308b43d0a49c3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "NTAP2XDB.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb1.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb2.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
Service "ntap2_pdb3.solutions.netapp.com" has 1 instance(s).
  Instance "NTAP2", status READY, has 1 handler(s) for this service...
The command completed successfully
[oracle@ora_02 ~]$

....
. Validez la base de données Oracle et dNFS
+
....

[oracle@ora-01 ~]$ cat /etc/oratab
#
# This file is used by ORACLE utilities.  It is created by root.sh
# and updated by either Database Configuration Assistant while creating
# a database or ASM Configuration Assistant while creating ASM instance.

# A colon, ':', is used as the field terminator.  A new line terminates
# the entry.  Lines beginning with a pound sign, '#', are comments.
#
# Entries are of the form:
#   $ORACLE_SID:$ORACLE_HOME:<N|Y>:
#
# The first and second fields are the system identifier and home
# directory of the database respectively.  The third field indicates
# to the dbstart utility that the database should , "Y", or should not,
# "N", be brought up at system boot time.
#
# Multiple entries with the same $ORACLE_SID are not allowed.
#
#
NTAP1:/u01/app/oracle/product/19.0.0/NTAP1:Y


[oracle@ora-01 ~]$ sqlplus / as sysdba

SQL*Plus: Release 19.0.0.0.0 - Production on Thu Feb 1 16:37:51 2024
Version 19.18.0.0.0

Copyright (c) 1982, 2022, Oracle.  All rights reserved.


Connected to:
Oracle Database 19c Enterprise Edition Release 19.0.0.0.0 - Production
Version 19.18.0.0.0

SQL> select name, open_mode, log_mode from v$database;

NAME      OPEN_MODE            LOG_MODE
--------- -------------------- ------------
NTAP1     READ WRITE           ARCHIVELOG

SQL> show pdbs

    CON_ID CON_NAME                       OPEN MODE  RESTRICTED
---------- ------------------------------ ---------- ----------
         2 PDB$SEED                       READ ONLY  NO
         3 NTAP1_PDB1                     READ WRITE NO
         4 NTAP1_PDB2                     READ WRITE NO
         5 NTAP1_PDB3                     READ WRITE NO
SQL> select name from v$datafile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/system01.dbf
/u02/oradata/NTAP1/sysaux01.dbf
/u02/oradata/NTAP1/undotbs01.dbf
/u02/oradata/NTAP1/pdbseed/system01.dbf
/u02/oradata/NTAP1/pdbseed/sysaux01.dbf
/u02/oradata/NTAP1/users01.dbf
/u02/oradata/NTAP1/pdbseed/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb1/users01.dbf

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/NTAP1_pdb2/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb2/users01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/system01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/sysaux01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/undotbs01.dbf
/u02/oradata/NTAP1/NTAP1_pdb3/users01.dbf

19 rows selected.

SQL> select name from v$controlfile;

NAME
--------------------------------------------------------------------------------
/u02/oradata/NTAP1/control01.ctl
/u03/orareco/NTAP1/control02.ctl

SQL> select member from v$logfile;

MEMBER
--------------------------------------------------------------------------------
/u03/orareco/NTAP1/onlinelog/redo03.log
/u03/orareco/NTAP1/onlinelog/redo02.log
/u03/orareco/NTAP1/onlinelog/redo01.log

SQL> select svrname, dirname from v$dnfs_servers;

SVRNAME
--------------------------------------------------------------------------------
DIRNAME
--------------------------------------------------------------------------------
172.21.21.100
/ora_01_u02

172.21.21.100
/ora_01_u03

172.21.21.100
/ora_01_u01


....
. Connectez-vous à Oracle Enterprise Manager Express pour valider la base de données.
+
image:automation_ora_c-series_nfs_em_01.png["Cette image fournit un écran de connexion pour Oracle Enterprise Manager Express"] image:automation_ora_c-series_nfs_em_02.png["Cette image fournit une vue de la base de données de conteneurs à partir d'Oracle Enterprise Manager Express"] image:automation_ora_c-series_nfs_em_03.png["Cette image fournit une vue de la base de données de conteneurs à partir d'Oracle Enterprise Manager Express"]



====


=== Sauvegarde, restauration et clonage Oracle avec SnapCenter

[%collapsible%open]
====
NetApp recommande l'outil d'interface utilisateur SnapCenter pour gérer la base de données Oracle déployée dans C-Series. Reportez-vous au document TR-4979 link:aws_ora_fsx_vmc_guestmount.html#oracle-backup-restore-and-clone-with-snapcenter["Oracle simplifié et autogéré dans VMware Cloud sur AWS avec FSX ONTAP monté sur l'invité"^] section `Oracle backup, restore, and clone with SnapCenter` Pour plus d'informations sur la configuration de SnapCenter et l'exécution des flux de travail de sauvegarde, de restauration et de clonage de la base de données.

====


== Où trouver des informations complémentaires

Pour en savoir plus sur les informations fournies dans ce document, consultez ces documents et/ou sites web :

* link:https://www.netapp.com/pdf.html?item=/media/81583-da-4240-aff-c-series.pdf["NetApp AFF série C."^]
* link:index.html["Solutions NetApp pour bases de données d'entreprise"^]
* link:https://docs.oracle.com/en/database/oracle/oracle-database/19/ladbi/deploying-dnfs.html#GUID-D06079DB-8C71-4F68-A1E3-A75D7D96DCE2["Déploiement d'Oracle Direct NFS"^]

