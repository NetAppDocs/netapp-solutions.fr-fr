---
sidebar: sidebar 
permalink: data-analytics/bda-ai-data-mover-solution.html 
keywords: data, mover, hdfs, mapr-fs, s3, spark 
summary: 'Dans un cluster Big Data, les données sont stockées dans les systèmes HDFS ou HCFS, par exemple MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google. Nous avons effectué des tests avec HDFS, MapR-FS et S3 en tant que source pour copier les données vers l"exportation NFS NetApp ONTAP, à l"aide de NIPAM, à l"aide de la commande hadoop distcp provenant de la source.' 
---
= Solution de transfert de données
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
Dans un cluster Big Data, les données sont stockées dans les systèmes HDFS ou HCFS, par exemple MapR-FS, Windows Azure Storage Blob, S3 ou le système de fichiers Google. Nous avons effectué des tests avec HDFS, MapR-FS et S3, afin de copier les données vers l'exportation NFS NetApp ONTAP à l'aide du protocole NIPAM `hadoop distcp` commande à partir de la source.

Le diagramme suivant illustre le déplacement type des données d'un cluster Spark doté d'un système de stockage HDFS vers un volume NFS NetApp ONTAP, afin que NVIDIA puisse traiter les opérations d'IA.

image:bda-ai-image3.png["Erreur : image graphique manquante"]

Le `hadoop distcp` La commande utilise le programme MapReduce pour copier les données. NIPAM fonctionne avec MapReduce pour servir de pilote au cluster Hadoop lors de la copie de données. NIPAM peut distribuer une charge sur plusieurs interfaces réseau pour une exportation unique. Ce processus optimise le débit du réseau en répartissant les données sur plusieurs interfaces réseau lorsque vous copiez les données de HDFS ou HCFS sur NFS.


NOTE: NIPAM n'est pas pris en charge ni certifié avec MapR.
