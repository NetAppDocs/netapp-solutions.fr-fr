---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-hadoop-data-protection-and-netapp.html 
keywords: distcp, copy, backup workflow, hdfs, mapreduce 
summary: 'Hadoop DistCp est un outil natif utilisé pour les copies intercluster et intracluster de grande taille. Le processus de distCp de base d"Hadoop est un workflow de sauvegarde standard qui utilise des outils natifs Hadoop tels que MapReduce pour copier des données Hadoop d"une source HDFS vers une cible correspondante.' 
---
= Protection des données Hadoop et NetApp
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
Hadoop DistCp est un outil natif utilisé pour les copies intercluster et intracluster de grande taille. Le processus de distribution Hadoop présenté dans la figure ci-dessous illustre un workflow de sauvegarde standard utilisant des outils natifs Hadoop tels que MapReduce pour copier les données Hadoop d'une source HDFS vers une cible correspondante.

L'accès direct NetApp NFS permet aux clients de définir NFS en tant que destination cible pour l'outil Hadoop DistCp afin de copier les données à partir d'une source HDFS vers un partage NFS via MapReduce. L'accès direct NFS NetApp joue le rôle de pilote NFS pour l'outil DistCp.

image:hdcs-sh-image4.png[""]
