---
sidebar: sidebar 
permalink: data-analytics/bda-ai-abstract.html 
keywords:  
summary:  
---
= Résumé
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/


[role="lead"]
Ce document explique comment déplacer des données depuis les systèmes d'analytique Big Data et d'informatique haute performance (HPC) pour qu'elles puissent être utilisées dans des workflows d'intelligence artificielle (IA). L'IA traite généralement les données NFS par le biais d'exports NFS. Vous pouvez cependant avoir vos données d'IA dans une plateforme d'analytique Big Data et de calcul haute performance (HPC). Il peut s'agir du système HDFS (Hadoop Distributed File System), d'un grand objet binaire (Blob), d'un stockage S3 ou du système GPFS (General Parallel File System) d'IBM. Dans ce document, nous décrivons comment déplacer les données d'une plateforme d'analytique Big Data et de GPFS vers NFS à l'aide de commandes natives Hadoop, du module d'analytique sur place NetApp (NIPAM) et de NetApp XCP. Ce document présente également les avantages du transfert de données du Big Data et de l'informatique haute performance vers l'IA.
